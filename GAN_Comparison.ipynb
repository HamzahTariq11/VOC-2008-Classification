{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utZx6abZ0B6g"
      },
      "source": [
        "### In this notebook we see how increasing the data for each class improves the overall accuracy of the binary classifier made of VGG16. The GANs were trained on the data of each class and generated samples for them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bka1cjl2iU7"
      },
      "source": [
        "Showing some generated images from our GANS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Model\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Set paths to the data\n",
        "base_dir = os.path.normpath('D:/Generative_AI/VOCtrainval_14-Jul-2008')\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "# Get class names from directory names in train_dir\n",
        "classes = [dir_name for dir_name in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, dir_name))]\n",
        "\n",
        "def build_generator(latent_dim):\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(8 * 8 * 512, activation=\"relu\", input_dim=latent_dim),\n",
        "        layers.Reshape((8, 8, 512)),\n",
        "        layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.ReLU(),\n",
        "        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.ReLU(),\n",
        "        layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.ReLU(),\n",
        "        layers.Conv2D(3, kernel_size=3, padding=\"same\", activation=\"tanh\")\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def build_discriminator(image_shape):\n",
        "    model = keras.Sequential([\n",
        "        layers.InputLayer(input_shape=image_shape),\n",
        "        layers.Conv2D(64, kernel_size=3, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Conv2D(128, kernel_size=3, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Conv2D(256, kernel_size=3, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def schedule(epoch, lr):\n",
        "    return lr * 0.95 if epoch > 10 else lr\n",
        "\n",
        "def train_gan(class_name, epochs=50):\n",
        "    class_train_dir = os.path.join(train_dir, class_name)  # Ensure the path to the specific class directory\n",
        "    model_dir = os.path.join('models', class_name)\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "    print(class_train_dir)\n",
        "    print(train_dir)\n",
        "    train_data_generator = ImageDataGenerator(rescale=1.0/255.0)\n",
        "    train_data_iterator = train_data_generator.flow_from_directory(\n",
        "    train_dir,  # Use train_dir as the directory\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    classes=[class_name],  # Specify the current class being trained\n",
        "    class_mode='categorical')\n",
        "\n",
        "    latent_dim = 100\n",
        "    generator = build_generator(latent_dim)\n",
        "    discriminator = build_discriminator((64, 64, 3))\n",
        "    discriminator.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))\n",
        "    discriminator.trainable = False\n",
        "    \n",
        "    gan_input = layers.Input(shape=(latent_dim,))\n",
        "    gan_output = discriminator(generator(gan_input))\n",
        "    gan = Model(gan_input, gan_output)\n",
        "    gan.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))\n",
        "\n",
        "    # Train the GAN\n",
        "    for epoch in range(epochs):\n",
        "        # Real images\n",
        "        real_images, _ = next(train_data_iterator)\n",
        "        real_labels = np.ones((real_images.shape[0], 1)) \n",
        "\n",
        "        # Noise and fake images\n",
        "        noise = np.random.normal(0, 1, (real_images.shape[0], latent_dim))\n",
        "        fake_images = generator.predict(noise)\n",
        "        fake_labels = np.zeros((fake_images.shape[0], 1))\n",
        "\n",
        "        # Train discriminator on real and fake\n",
        "        discriminator.trainable = True\n",
        "        d_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
        "        d_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
        "        discriminator.trainable = False\n",
        "\n",
        "        # Train generator\n",
        "        misleading_targets = np.ones((real_images.shape[0], 1))\n",
        "        g_loss = gan.train_on_batch(noise, misleading_targets)\n",
        "\n",
        "        print(f'Epoch: {epoch+1}/{epochs}, D Loss Real: {d_loss_real}, D Loss Fake: {d_loss_fake}, G Loss: {g_loss}')\n",
        "\n",
        "    # Save models\n",
        "    generator.save(os.path.join(model_dir, 'generator.h5'))\n",
        "    discriminator.save(os.path.join(model_dir, 'discriminator.h5'))\n",
        "    print(f'Models saved for class {class_name}: Generator at {model_dir}/generator.h5, Discriminator at {model_dir}/discriminator.h5')\n",
        "\n",
        "# Main loop for each class\n",
        "for class_name in classes:\n",
        "    train_gan(class_name, epochs=250)\n",
        "\n",
        "# Set the base directory where the models are saved\n",
        "base_model_dir = 'D:/Generative_AI/VOCtrainval_14-Jul-2008/models'\n",
        "\n",
        "# List all class names - assuming each class has its own directory under base_model_dir\n",
        "class_names = [dir_name for dir_name in os.listdir(base_model_dir) if os.path.isdir(os.path.join(base_model_dir, dir_name))]\n",
        "\n",
        "def generate_images(generator, num_images, latent_dim):\n",
        "    \"\"\" Generate images using the generator model provided \"\"\"\n",
        "    # Generate random noise\n",
        "    random_latent_vectors = np.random.normal(0, 1, size=(num_images, latent_dim))\n",
        "    # Generate images from the noise\n",
        "    generated_images = generator.predict(random_latent_vectors)\n",
        "    return generated_images\n",
        "\n",
        "def save_images(images, class_name, base_output_dir):\n",
        "    \"\"\" Save the generated images to a directory specific to the class \"\"\"\n",
        "    class_output_dir = os.path.join(base_output_dir, class_name)\n",
        "    os.makedirs(class_output_dir, exist_ok=True)  # Create directory if it does not exist\n",
        "    for i, image in enumerate(images):\n",
        "        # Normalize image from [-1, 1] to [0, 1]\n",
        "        normalized_image = (image + 1) * 0.5\n",
        "        # Ensure the image is clipped between 0 and 1 in case of any floating point arithmetic issues\n",
        "        clipped_image = np.clip(normalized_image, 0, 1)\n",
        "        # Save the image\n",
        "        plt.imsave(os.path.join(class_output_dir, f'image_{i+1}.png'), clipped_image)\n",
        "\n",
        "# Main loop to process each class\n",
        "for class_name in class_names:\n",
        "    print(f\"Processing class: {class_name}\")\n",
        "    model_dir = os.path.join(base_model_dir, class_name)\n",
        "    generator_path = os.path.join(model_dir, 'generator.h5')\n",
        "    \n",
        "    # Load the generator model\n",
        "    generator = load_model(generator_path)\n",
        "    \n",
        "    # Generate images\n",
        "    images = generate_images(generator, 500, 100)  # Assuming latent dim is 100 as in previous examples\n",
        "    \n",
        "    # Save generated images\n",
        "    save_images(images, class_name, 'D:/Generative_AI/VOCtrainval_14-Jul-2008/generated_images')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "HByn77332Liy",
        "outputId": "20b65137-366a-430f-835a-4b01ba435617"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-ff5cfdb09b17>:30: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  img = img.resize(resize_dimensions, Image.ANTIALIAS)\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxoAAAA/CAYAAABnyb5KAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAADVIklEQVR4nOz9aZClWXrXCf7Oebe7X9/CY99zz6ysrH1TSUilkpBAAo2QhI1gUA8zQNtoujEDg7Exm575MDYY0x9omramgWlAzYhu0UBLrV1CKm2lKtWalXtkZETG4uEevtz93d+zzIfz3usemVkZHpmpUUn43yoqPTzc77ue5zzL//k/wlprOcIRjnCEIxzhCEc4whGOcIT3EPKP+gSOcIQjHOEIRzjCEY5whCP8ycNRoHGEIxzhCEc4whGOcIQjHOE9x1GgcYQjHOEIRzjCEY5whCMc4T3HUaBxhCMc4QhHOMIRjnCEIxzhPcdRoHGEIxzhCEc4whGOcIQjHOE9x1GgcYQjHOEIRzjCEY5whCMc4T3HUaBxhCMc4QhHOMIRjnCEIxzhPcdRoHGEIxzhCEc4whGOcIQjHOE9h3/4H7WLP27EnwVE/XeLEBIhqL83/694qw/6lsBf/+t//Y/6FB4I/+Sf/JO3/fdr164hpcTzPIQQeJ5Xfw1CCnzpI+t/k1IipUQIgUC45yZYPD/3fA3WWqw1WG2wWLAWT0q8IMQiOfj8gfrn9/8YYxb/NcagtV78/cSJE/e95lRVGObR8PwYIBDufASI+tgS495OaxD1zxoDylqMNQgrscqgsWhtMNqiLVhtMcYifR9fShAWKQVRIJHSc8cV7lqFENiD77gAawUSiAJJ6Hn3uaL5+pmvpfl3LQKxuFJxz7L51l1Hf+UnfoJGFP1Rn8ahcb819Bf+2t/E88D3fMIwAGuQQtCIAsLQJwxCZ+uAMPARAkI/wPd9MAYhBdZKlLGEvsQX0r0vVqCNojIKpQ1Qv3NSIAUoPV9roAEsKKUpywohBFVVorWhrAoEgqqqqJTmX/93/+i+1zwsLTM9t9lA/aZZ4daSqe25xaL1/hoz1oJ16wRAKYOxBqM0CIs2BqXcWtLKIISgEQb4vofveTRbIVHoIevVKucHPYj6r76EpQAiCUK8/bu+vb19wL7N7ZhESoEQEoRACrH4nHs/z91nXZWoMsdYhTXugoWQ+EGIH4QI30cIj4PrzrofxFrxJhtnjMEajTHa/d0atAatDWfOnH7b6/nh/8N/ShgENEIfC/iepBk1wJMEnoeszz8KQjzpEXi+s+sSrLEEnsRYizUGz/NAzm2IQBmDUnphb7RWC5tWKQW1pRT1Vm6MpdKGvCgQQjh7jUBXFQaBVor//r/6+297PUf41sdUGWKlcfuNdVscFoRFCAsYhDVIC54oEJQIo8BU6CrDmhLPSoQtwFYEJsdDYFUBxmJHY9TdHYw20GxiGiFeZxmzeg7VP4Py2lgCrBUYO/cj7l33UkDbh44v8O9jE/b3UlPbLkWeZkSNBlJ6pFkKGJrNFlLsu7z32oY/3H12bi+uXb/Oww899LY/+8fJN83znJ/6qZ+67889QKCxD2MUSZrQaXfIi4I0TVlZXgZk/azEwtn7VnWS/qTiXqffgJAI6xxzFxAKDg6Dt1isEEju3ZBVVWCUwlSKosjd07SWMGrQaFmkHyGkdA7/geO+1Xm8+bwON4w+04pSO8emtofOC3JnDYCwGmENFuWCIqWwxqCVQleCpCzJFFjtkU8SKs9nc2/MzmCKFwRILZhOpwjps7zUouHDubU+68eWkIGP53v4QYDnB86pkd4i8JhHaIEULInwEIHG/N4YsjwlDEKEgCRJaTSbhEHIYvN3V7d4Stzz9yP8YSDwhXPuPB/f85BC4vs+gSdpNRoEfkDg+YDF95xz60sP6Xm1swrzgFQIiedJ995ai9KS0AbOQTcKLM5RFtI5psbgSY9KKYy1VEoTRQHGWopcYLRGYCjLsv69w70L1oCxLiA++Ba5FAGY2vk3FrQQGGPRxmK0oawqlNYYYykrjcBitHZOaWUwyhDPEspZRugHtFd6eKFPGIaELR/h+Vjjjk19vPlaFgjn4M6d9wd8VvPAzNp6GdpFpuSb/YZLdqgSlcZk8ZSyyKgKhbAQNVv4YUij2yNqdxC+qNc5i5yaNW/+fDs/Cbv4Rn1e9yYTvhmiMMD3fIIgxJMC6UnCwKfVbCGlwBMCIQWe8PD9AE96eC5qc47S/EFakL7El3JuGalUhfV97CJoCFwiRXiYOriV0kMbjdEu6Cy1ohGFaK0pqwqspRSWUmlEcDj79pZ3/z42/34B5hHeOyzW/+K9dUGGpE7c6RyhFVKAJcfoCmEqjFHoPEZXBdZY0CUhGkmJtgajC2RpsFvb5Bvb6EpB1IRWiOwl+KKJH3YRkUcZBIszMW84r/qMXFL0UFdk7/m6yAteu3aN4+vrLC0vceXKVaqq5InHH6HVaiOlV/tBB44ouI/PevR+vhu8g4qGIU1Tvvr1l3jfU49yd3fIV599gR/8099Br9tzDqs4+MocxNHD+sOCMW65yjqjNd+IhbV1kMHi+weDDSHEIqM1d+CtVegyp0hSpqMJyWxGlheEjZCo0WTt+HE6S0tIP0DIeUbizfhmlY7DBhrOAdvPVrgz3D+aMdpVbKwFI9DaoKoKLCSzhGxaMDUBSmsmlSDemSC8gFlZMogNw61tovEWr+0lnLt4jmuva1qRh//0eVqhR9BuE7Wa4OHKI0IijMHOb5gQWCSCe7Of970uo9m+e5dm1KDX6/E7n/8yly+d45GHLiM9UQeG8wrhUZBxeBx8rx78fkVhSODJhbMXBi5D3wgDoiAgCgM6rSZWV2hwTp/nuWouIEXtZApZO8CuYqiMwrMuk2yNxWCgdvLAmUttDAZLaAKssWhrqCpNXlYIaynLkmYzQkqBXmSpDwHhzsMtI7Gw4rKu7OWVy2xra1HGorRBGVelKIoCVWkMUFXKBTvOqFCVrtKZ7YxQ2yPKKCQdx4hGk9ZyDz/wqCpLq+ETBZ6zPweK3QcrLPN78F684vfkKO9xXm2dgKgo04Tpzg6T4Yh4GiOkpNNbor3UZ8XzCBsR+O55CVwVU1ixsJHzo1hXXmVRba3TH86BMdz7Pr41At8n9H2iwFXRPOnRiEKaUYPAlzSiCCkl1rgAwfO8unpDXdd17xSey057wsMKV50KAh9jXYBobVC/M+56JBKlNVIId1+MO/dKKbTRVErheRJVVfh+E7LCVbneAebvqjHmTZWmg/vRn5hg41vcZAsBnpRoBVjtgg5jMKZE6AKjpkirXAFSl87eqQxrNLYo0JXGaIVVJcZWaBQeAl/F2DjBDAdUs5w4DTAmJ2rEhMsF0g8xyQz/+Hm8Y4+ivNY8+wDsf/ngt+3e91JrzfUbd/jqN67w6KOX+dKXv87tjU0+fXeHT3z0Q7TabRqNBrKuGAohwMo6uFncpQOf/S36IP//iP0k7z4eZL0+UEVjHvwaY7h24w6TJKMoKr7w1Re5cP4MH3zq0Xoz9Nl/QKL+3xtP6ujhzbFwGsSb79I7hpjTdERdDn3zJiGEOPCHRXbMGENV5CSzKaPtu+xsbpHmBc1uh9Xja7Q6LaJ2i8jz3XM9sGncewBX3r/3+4ffrCTOeZs7SQK7v/ytoSoLR5iy1n1dVRRZgdCG4daIJNUMK0uaFWxNMlRaMhiMUI0Oo3HB689fwezeYTuruHljGyMk7eU+VnrszDIunVplZalNu9MmaoQ0G84xENZihVyEPhZzIC/z9nBVJkcl2dvbJUliptOEb7xwlV6/w7GVFXw/qG/pQSrVPHU5//oIc+y/X2+kcT4YPCEIfJ8oCmlEEVEUIAU0w5BmIyLwJIEv8MIIzxMu0PCls3d1RcMuSHwghURbizFBTR0yLpMshHO6avuojQFrFhXCSikqbdChIQg8qsAnlYI8B+0brLZoqw91TVK4t2ju9gocnTDXhqKsyKsKcDRCrV1wo7TGaIMqFMa4IKOqKjAarHvbi6LCZBnVYIIcx45GNE6g1SJJC5Q2rK12ObbWIvQbzqG13EOfumcLt2/8xtvjrTY5ceDf5kHe3HFxToSjhFilSJOE3e0dBltu3a+dOM4xKeivr6K1dqmDebJzUS05SBt+45Fr6mYdRc0LHfdDFIQ0o5Bms1FXN7xFRcP3HRXWkxJrLYHvvvb8mhJbX+s8MW3qqpgxrkLm1kWA1hqBQBtdB07CBS6+z7z+YbTBGE0UeBityZWHJz1yLEoZfF9izOFt9xzztZkkCc899xzXr1+n1WqxtLREFIWsrKxw8eIloii6J/n1XuC9/ryDn2mMXlQEnE0Xrqokpatw8lY+z7cI6ncZYWs3wSJtSVVOXfBgCgSKwFRQ5aA1mByrNTotsVqD0qAV2lZoW+FZTZQNUVvblDsTysynUB2UrSgqQVtWsDMm8n285g66cxLbbtWh+cEaq9j/f/sABgGYr0vPk7RbTV54+TqbO0NeePFlbt+6w7Xrt9jY3OXRRx7iiccus9TvueDe8xHCLtaSO+bBvffdJbD+uGNBE633OFepf7D78IAVDedWeb7H6soSHoaTqz2Or63xi7/5JTa3xzzxyFkunj5Bsxnheb7LAluwtScr7nmp4D/GBzfHPQ74e2QMzZyrO38RFpnC/c+/N8A4EGggQGjmXMcsThntDrh76w5pltFZWWJpeWlBy5pzzC33fv7iGPUG/WYu5OE2LF/KmttuFx9vtMaoijRLyLMMtMFYyXgwxbeCu8Mxwgo2dyYUmSavSvYGE/ZmOXlekcQZk9wwGiUMN+8Q796lymZMtm9h8fDbKxRZxrULpzh5rMmTl1c4eXyF5f4Kl8+dQkrQNV9DSB9TbzDiUJe0cEXo9ztEvqPWXDh3kqu3d/jCl17goYunuHj2FK12u85eykV4dbR23oz9qpkL4JK8ZGc45fhK31UfHiBT2ghDfN+j227TbkW10+fRbjboNUPa7YC1pTa9ToN2K8T3fediOmKwCyCoq4h23ufg3l2vXgfWgK7toNIa4UmXTdSaeY7aGFtTXepejUqR5RWzJOfa7R1ee30Dqw5bFcT1IeBst7BgtWFW5JTVfk+B0so5TwaqSlMVmip3fzdaO1qitVRlSaU06WiG3R4hs5yo0qAMMqkwWUXh+0yiiG6nRaVchST09yufwu6/wQeYG+8OorY18t5AQ8wDhPnRjKsmKW0wlaLKCrKipNVuO19Ruxs275sSCzqwW391SwcHrd7C1NraQXqAiwkDj26nRb/bqel2Ps1GSBiFRL6k3fBYXW7RiAK6ncidDwZjLMoYd0l19QzrEjuiDhwFrt+oUsrZbFxly5ce1gq0sSijXAXOaIzSNSXP0U/ySjNNcvKiYvPugN3x9IEeibUWpRRf+tKX+Ht/7+/xhS98gaIokFLi+x5RFNHr9fjQhz7MT/7kT/LRj34Uz/Pek+qGtW4Naa0Jw/A9CTYcBVKRJilpMts/V5xVr6qSssixCE6cPEWr1X7Pg5x5VWjOXHhnH7TPgHCVvhyoKKsCpSqQ9VtmFFJpPGtABmjjY4zClBnW1EE7Fk9pRDJA5VOScUY6VWgTgDCUlaSyIcJUNOyAKpR4vSW0dvbSCllvi28OKrx3dO+czV1d6vDh9z/M9jhl485dXr36Otdu3Gb73/wc586e58MffIaPf+RJLl88Q6/boRFGCF/UVWZZr/S6h2WB/WDoPxbMAwxjHGV2PEvY3Nrh4QvnaTYO35/5YD0a9cZZqZLHLp9leanDeDKh1Wpy/fpNNj73eZ595Tjf8dEnefrR86yurDreeU0tuDd9dW8U+x8b9ilEgjhNsdbS73beuxLyPXHGvUEG8w0U3hxoWAPW8YIFYEqF0hpltNuYiwJPSCRyniZcHMM4r2tBG5ln7l3udX/BHpo6pZVrShOgjcYTkqrMmU7HJEmCJzwG2xOU8BjemdCSHhuDCTL02NgboYxHnKTc3dohyyviuGASpwwGY2Z3N9HpBKsKjMkoS9fMa6oZN14xTGYZ2cVVVtuaUFbs7cacXV0iDEAYjWfBeD4iaLlM9KEDDXddvpR02y77O4ljxtMpSRZRljcpspxzZ06wtNwnDEOk59cOzVGwfhBzHvw8o6i04erNbcqyIvJ92s3G/Cc5zD0KwoAw8Oh3Wpxc73Nircdyv8FSr02/1yQMAqT08aREUtMPa6fSGtdc6TJxzhEUHnUlo/b25byXQyDqJkgrat57nTlbBBnGYrBopVFKc3Nrj9969jqR5xGGwaFpLPNCgQEqbbHaUBlNnBWLdWq0dn9shbXWJSoCnzIzVGpeORF1v4egLCtMpbGzAi8uXbBtBFZVWCUwXkLuhUz6LaIW9DshMpALJ32RDLPzrLzrYX5Qu/fGRIk4UDkXzG2Y+7u0YA+IYPhe4HpJQh/P9+m0mq5xvXYchbWLbP+8aGutRRjrWjfM/rHBXdPi7N0HHOoaGo0G3XaTbtu9Z0u9FmtLLVqNkG6nSasR0mqEIL39YLWu7lprXLW6bsRxSQ+LNQqLdOuCedWjtj1W8kaemhXSVdpwAbtxjTUATJOSr7+yQVwoBtP00M9mfrw7d+7wN//m3+RrX/vaPXZ//vXdu9u89to1rlx5hX/83/63fOSjHzv0Me6H8WjIrVs3ed/Tz7ikwHsQvEwnU0ajARjLaDImDENaLddfNxmP2NndZm9vj9XVdT7ykY/RX1p6b/bz+n5NJiN8L6Db673jz7U451FrsKbEVBkSTWFAC0cZlBgMPj5l/TuuEoYfQpGCEHVvp8QzFSYZgMrBaiolKSvnsKeVxQiPvtS01RixdIrg+DF0EGLnvsP8/VxUE2pKIPe+p98c+3uhMZp4OqXVarK6tMw4dj3ERVFQFjl5GjMajLhx4yYvvPQy3/fd38H7nrzA8fV1Ou0WQYhbUwKY2+ZFB+vB9Mhhz+2PL1yQYbDW4ElBmhe8fnuLfqddJ54OfwcesBncbYJFlrGy1OTWxhY//xtf4NlXrpErRZrl7A0GDEcTrt/Y4Ls+8QFOn1yn1WrhScdltvMdgfmOM3dy4d7Tfqvy9B9/3JOBBe7uDXn99iadVpMnHr6If8iG4rf63IOGXCz+f36P55viXJ1lngS0B+7/osV6XovHWqiUQUrfccPnKdIDgcz8A8Q801//mxQCPf9EsW8MDg+DrfnsVZFRWciShMH2LkWhscbn1tYMEwbMxjFeUXFrHGM9yc3NXbSGeBoznkzxPclsEjMcTkhnU6rZHawase+GgTUCUxmqic9AWTptyXM3Au5ONcf6OVmWYny9aNDsNBpIq/Cs4PAJJqcahIW90Yxf+c0v8sXnXqG/tMLqyjKzWUJe5ExmMRfOnuTkyXVarSZSBovgcO6U/sccrL9xHQmgLDWr/TbH15aQtWFshIFznA8B35cEvs+FM2vcvL3JV7/8PEEUsLTc5cx6nyiIsAL6vQ7dTgc/CMAqAl+gNaSlpdSWwHeN4J4n8aWjHglr8T3XlFtVygXm1uL5kjAK8YSs6VjSqRhJt0ZVmvP1l2/y07/6B1y7tcNf/P5PIYXA9w+f0TTaUhnIVEVRN6OruoIiF4mC/bXpCYusRRBUZRY22w8ClBXEsxEUGk1AXml8IehUoDOFnxqwOapfcmY14tR6i1ZDIj2BNmCEKypg97eB+onW/z3ce/zG/ou3tC3WYkVtF+uqk8DRWzzfww992p02eVG4Ci3OFqqqwqsqhK0rJNI594ueDDs/3vwcBE4IxbCoO4o5ZfXt0WpGPHzxlDsfD5pND4SiGYaUZUqRpyRBk6jp6GcSd9+UUpRFhbZQGV03iAsi3wfrst7GqLqHyF2/tQZR78PzXjBPSoTnud4c6xJNRivKsuC1Ozv8f3/py7x0bYsf/I4PvaO96Stf+TIvvfTS2/bmGWN47rnn+Zf/4p/z+OOP0+n23l3CrT5OWVa89OILXLx0maWl5Xf1ma5CohgO9ijyjEpV/Muf+pe8+MJLfPrT38YP/sAP8NKLz7O7t0u71WbzzhaNRotPfPKTCyXI9wJGGXb2tmi1207t7h1ei/PpLRZNZVzFy8jQBZkYwEMHnhOJMCWeUXimRIQSk3tgrAsydEVAgfEkVlsaHYmalpgspywaCFp4UhOGBn9JYM+exPTWKb0IW1cLD6qeiTpIFwezEYewCa7I6BIzk+kMEFy5dpv/5Zd/ixdeeIEkmSG0wlqNkB55ljIa7rG9vcOnP/UxPvGR9/H4Y5fpdjpEQb1neOYNy3w/cXHvkd+4B//x34sXQYYxC38uDAOeevgijTDEWChVdeiE1wO/qUI4XmlZFNzZGbA5iNmbJKgqJy8KijwjiWNeu/46ySzls9/xMS6eO0G72cLzA4TcjwT3JT3f6mX6k1uyMkYDFltn6p985CLtVsMpvRhDFIbvwVHeSFk6GITsb5T7+3wdQFjAOtUma5xMYxS2yPKEKIoIwhALaFVhax6wq9q/VXhbP2dxb6BxWKNrjEFVNVUjdlmJIi/Y3h6QxhWzsWaQGrTvs7uzhwfc3NolCiP29mJKpZiMxuRFjgDi4ZDp7g6YAmtiIAH2S8gua2tQuU/UW2dWCkT3FN3zawy2J2ztVUSxQQhD2BAESyAaAhtUmE7rvtfjkjZus9PWEKc5fhSxurqGRnDn7g6dVhMhLZWGvVHKY2nBhbPrdLs9fD90qlfWslDEucfQvfne/0mGWRhBd62tRkjr5FpNK9FM0wKlDEu91qEqTo0wIPRdQP1TP/VzPP/VZ5k7kUJ6Cypb0AiImg2CwEdgCHzPNY4HIX4YEEbRggbj+T5B0KDZDImiAC/wkb7ECzxHH7CG8xfPoqoKZQAh8YXAkwFLKz1u3dzgVz73JWazhF6vQ7sRgraI4vB6LLZee9pCXim0NU55Bbc2PeEhpKG0jqtP/f0gCqgqswjmAt9DNCVR0MB2GiSnG4yCCSpOWCkrUs8jkJZe5HH5VJ+za22W2g20Jxdm/mBwsfhSsKAHHgbf3H7s7xF2nqSY9ypo7WRalaaqKnxP4vk+0nMyxJ6ALI3J04SwEdU85LqPwfqIuhJCTY/at55ikawxi7h/P4l2P3SiCCMkf+f/+k/Y3bxFGIY0mxHHljs0Ih8/8AmDBq12Cy9oIIUhDDyihuuFFFIShAHS87ECljot57l5Ps1mQBS6IFabCt/zEL6PUQrP92l32/vBkDB4IkBZaLcbvPLabX71d7/KlSsbrK4t4QmB5z2YTbHWMp1OKYrivlVspRTfePYbjIZD2p3ue+KYN5tNrr56hVs3b7C0tPyuP8/1KpUYbdi4fYsvfuELPPvs88xmM9bXjvHVr36ZIAi4fPkym1tbLC0v8+GPfBjPa75776WuVvmBz3Q6pSxyfL/zjj7KWif+oLXrwTJeE4VAS+1kuuvqnRYWISOwObbKUSbHq2KCVgsMCJ1RVprUO4mJTrLixbTSEY3WBt2NbXavb9GqmjSlorvahIfex/ax99FsnAERIfdJES53KeZRxzz9Zw9vF+x+mrTRjNjdicnLiqjZptPto4qCUlWosgQExtcUec6Vl19mNo0Zj2ZYCw9dPEO316HRaBKGwT7bQ4q6BWDutx6sbhw4ibfci/94YU6NNweCDIsTEPCk54QjrKUoK6qyPNRnPniPhtUgYTiZ0estcfz4OncGI/Z271IWBWHgM4tnVGXFr/z2F8hKxff9qY9y6dxJ2u0WgR8gPB8pazMtNNYKHL3KvuFo1Ab7YNb97fCt7VwtokQMc6Wak8dWAMezLSrFNE45sbb8jisbbzzewcW7yPwt/i4WAYYxFqsryrJElxVFkqOUoagUFlCVpigU8SwhjhNkECClR2AabsOe69jDgUzeW0gAOH7DoVBmBXkck8Yl26MJO3sjPB/G44rJOGUwKkhNyPbeXWZxjBSCspKMxjP2BkOqSpHnBVVR1nr+PsKUqGLCWxuFurohJDJoYU3IbC/mbrMJ4ymvvXyXVlPgNRusLkn6osJTFY0whOWlwzwRrNUopZhMY4QQrC4t0e9NmSYZszhBICiqDtM4ZTxNnOqQgIcuhDRbEg8cz6SmC+1XrhZ3+BDncTBb9CC/962B/ezoQSrGvAhn0NoQZyWDccJUWpa6hws0mpGTr7VViZE+MFePslhbYoyTRDRpRpnFzCko7i1y62j/vyx+H0AIs0/nEXNaj0UIw0c+9SlevzXCa3UJQ9c4PhvN+NgTJ5mogp2dPULPw2DrSsl8js0h7hWgsFQ1TTMKApSxGKnrEMoihcEXHgEGVWm00ShlCUOJ32tglanVqDRh5HPq3El83yNThtbSiDs3thilu8RW4FvJqlfy0Ye7LPcaRIFHJaCiHvFg2ZfvP/BMbB1svLO38OD7bOtMrQsurFHoSqGLElspyiKnygvQGg83F8hiMUpjKs1sMsNYQRinNFpNGq02YbOJ8Hy33qSHsO4S9IGjvlPnIvI8VFExHuwy29t2VUth2RT798JVkecBo8EindqfcPfU2d4AcFUzIQXSCwgC9664uUmeC3IlYAouPfQoJ06f4PrNDah7DQLhoa3gu7/7Y/zib36Bq9fvAB4WQaMRURbVoa5pHlRUVcXOzu6BfoC3R6vdBg6fiPqmmFPIsKRpxsbtDZ5+/zO8Uxs37/fY290hTVPSJCWOU5566n0I4fPwQ5f5+te/xle/+jWeeupJrl27xs7ONg8//BBzJbL3yrpKz6dSmizPab7jHhABwnNVCC+sfRGL1NViWzTG9ZhJ2mBLdFCiWwKdTgiVwo+aiCpnlBcIKzCNCCEVHWHwjm/Q6Pw2/RvX0FlE2xdEF1YpH/8Ajc4Snhch8EA4YQkJdcbDvTdzzYFvUqd8C9T7tjVUVUE8Tbj++hZJVrp+SgtRFKKrnMJqsALP+mChzDM279ziK99o4kU+RaV55NJp+n0NxkleSw+kFi7YYF/S/2330ToBdu/T+eMRgFjr5iSJgxb5wDNRWlNUiruDMVapQ33moQMNJ3tqqErF7u6AncGMb1x9nWdfeoF4MiGZjimKjOPH17FxTJFlbG5v8x9+5/fJspzv/faPcPnCKZb6XcIoxPf8Ws9YOiKzNW+IXveX6MGpHIus+II28lYL7VvPabo3SnTnZ+rmrlJpilKzM5qyN5yw3OvgNx8s0HgrKdnFUv2m2TWnl6+1RpclVZERz2ZUecFoZ8Bwe0AyS1Gla7guK8106jiOBsfVDqMG7U6HRiPCcwTHxTAwyz6thcVXb/Aw3gbJLGZrc8Dtm2OUzhmmGXGWgZHs7sWM05JJnrC9tc3a6jobtzfI0hwQzMZT8ix3DkSeUSQDEApTTrA6ds7jW94TDz9o4DV7oGC0OaJdapoq4Vo4YKVpaCy16be7ZDONzgtMp43W919wFoOuSkajKVu7I7b3Jnz5xSts7w4otWE4ntCMXMNnUVYkSUZVFnQabq7D+bMnaDYbByobBz5c7B/ljV/da+7+JFQ/5gEhLPLLFrRx8yfirGQS5+wNp/TaYV3evf81NoIQT0LYbmGiur9DwNnHH+ODzzzKibU+/W6bVq+DH0iiMER6AlkP5lNVhS4VRVFgjEBbTVk4xaY8y0jTnDTLGAwmvP76LTZe30CXiiwpWD19nO/97MdcxTgKuH5zj9Fr10iTBKsUWlonO6oN/XYTbH7oO+VJQRRCFARY4Xo1tK03kZpWI7C0sKhQU+mKqtLowKPtezQ8S1loRklJ4Au6YUjDB4vEnunxyrEOX0pTvvTL/5bxcMaxH/ohGv0enWYEYl/82Tof2vWt4BTxjLZvsO+HfQXmduTgeyABhdXOb9FFTpmlmKLElBWqdBV3lWVk0xhfeDTCiKooKbKUansbVVZMmkP8KKLV7TiFpPV1mp0OXhAifbeezCKDau5ZTvtt5/uVoLdDELghe9qrO0KsxWs06S316LQd9z9sRG5QXxQh/cDNCrJuMJnVbgChMcpRk7WhqEqMUihdUZYFeZVTZCVFmmG1wooSRMAwMXTXVlk+1iMKAsqq4rkvPs/d2xtMhiNUniO8sOZpW9qtxv0uZ7EPXblyhZ/+6Z/mn/7Tf3qonjzf9/mRH/0Rzpw7f9+fPSyqqmJze5ud3V3ejY2bTqf88i//MleuvMLpkyfp9rrs7OzQ7XW5cOEcs+mEV1/dZjyesLl5lyxPWF9f55FHHycIwvfYulqkL1F179Q7oYPZunIq6gqVlOBj0cI1zWtjsdLWnQk+nmiSG43xPfJGH88YrFEY3weriJAEnqAEKuljGl3Ea5/Hdk+R9s6QF1PaS5fZFWvIUcLFfkhi56p+IcLWojKWWsRhLqTxYIkHVSp2tve48tptbm0N+Opzz3PllVeZjoZIqzHWIIVXs2rAWud7mVxw+9ZNqqoknqUk3/5RHr10hpPHoKENfq0G51FXZhGLyuXBjL+zaSwqn/dSqd4qKPnWwzwZLg/urXVCei5/HmcF4yThxsZdVjrNQ33u4SsaVlBVis27O9y6s83XX93gi88+x97OXbqdNsJobFXRaTVpNCK36SpNVhR85bmXEcCn06d45KEzLC/3aTWbBH6E8GU96wE44PpZ9vlxdS5w8YxcQ9w8e1Vn0evfuvfhfivB1vxHd45KKTe5VVvSomQ4Sdi4u4cqy3eUpXirWRUHG873bx6LczBaYY2lyHLiyZjJYI98llBkKbPRjHicYCtDVWrX75BmiJ0BBslkmtDutOh0O/SXl+n2unR6faQvF06wrTO89k3nebhr2rg74srVbTbuDlnu+2zu5ry+uYdEsru9R6E0WWZJkhmjwYwsSUimEySCIk/JZwOsrjDlFKMThAgwNgXUgXOYp1ldqtULl2iuPYznN1yFJ8uJhpq+jZlFEV6/SVkkzLoVe7nANkIa4Wk3Mfk+0EozGIx5/pXrDEYznr9ync2duyz1u1AaR+0wBmPBKKfYkueW6TRme3tIFHgcW1+h3QK/HiA457m+2X7tZ9Lmofm92Jf/fOP3v3VxcBga+1xjoFIuy5LmFaNpxmA0Y2d7m+jk2j3NsG8H1yMhkEGEbHUQWKJOl//kJ/48P/rZZ+h2O4SBh/QkgedmyEhJnRXHZZgXlshln8GpS+l6QJrSmqIouH77Lv/1v/xF/v2/+vdOfcoaksmE1aU+lBlVkmCBPK+n7Wo368AYSysMUIcIbME5957Hgt9vgUDuJwOMKyUgcZu9DCTaugy3rgyRJ/GFxQvgZKuJ5wkajZDQA8/z0FpzvOvTjU/xy//zLcYjzdOPrNPpNBkOJ1QG2u0WYSskBJQAXW9iCxNu7IE5Ffe5nnu4/vMNoi4x1NlLa52Kl8pziiQhH08pkgSjqlq1TmG1m0/iSYknJFmeQ6XQlXbniGXt2Dqdfh/pewjp0ep4GCFcNcHKA8HOvA+E+vjz87j/9UgBIgqRrZ5z66KAz/zg9/EXf/ATnD2xTCvyaLaaBF5NxfMCDAZrbC1D7NaE1hWelCjthuupyvXhJFnBNM4YDKe89NJr/PKv/T43r76CLwVho8VDl05w+dQKnVaTvckMnabklSVP3dwEpNuHpSdo+YdTmTHG8DM/8zP8l//lf0l5SGpFGAacOHHyTc8aHrzCYQ88k/7SEs1Go3YAH+hjFrh16xb/4B/8A65du8bHPvZRPvnJT7C9vc3drbvcvr3B5uYdxuMpWivOqIosKyjLimazyVvVnN8NtNaUeclh5dTfCrZuJ/KohdmFE0sQ0o2PKZUlEAJPgJKSEEGAdL1KWhBYBXgo6dGwAb4WNMoCP9+lkU/Rwzsk+SpfOfET7LZOcvcrP8eL/2zKzk9/g3Y84D/7c2fxzy9x7JHjrF94FN/rAPt9LNKVWjks+WGeBN/e3uZ3f//LPH/lNls7e7z44iuUZc75C5dot1ts3dlgtLdNWRZO0tZYhLUEQYg2mt3BHl977gW0EIzGMU89ep5ja32Wez3CehCpnM9Nkm5PkQi0USjlmAq2rpKGQYBX7xFum5VwyCr0HxXmQca8y9uy769paykqTZKXDCcxd3cH7G7d5cSjlw712YcONIzVbG3v8tM/+2tsbg+5+vo1zpw6wY//8J/n2MoKv//VZ/nt3/k87VaLZruN0k4lKAwCZrOE56/cwCKplObS+eOsr63QareIwsip6giX19LGYKxGVRWVVnUfgJPD830f3z/wsOtS8r4E4VumeP/IMS9FWdwD00qjtKGsFEleMpomDEYzhsMxJ4+tEIXBA2cqtNmvHlgpMEYgD0Tuto5OhTUYw2JQU1mWJLMJyWDI3uY2W7c3yZMMUxqqQpGlBXlRYj2XCZmOYpKkwNvcod1v40c+p06f5OzZs3i+T6PVxPNYUMP2X9bFLryodNwPz764yd7OhL3RmCTzubUx4vbdAdLCaDgGIUnjDGUMeZZhVUk62kKaHFWO0Greg+Eyj9a6193dVh+Lh0Ahg5BWswWyheydZ+3MWbIioKE1vXjCTHU51vERsx2SsoFqNhm2fJb8LmWRodaruu/m7ZEkCb/623/A737pGyRZTrsR8L2f/ggXz55ka3fEb/7+N9DWNeAJXKa80Wi4LJMq2bo7IM8yjh1bYWl5yU0WlxIhXM5YiFqKTmuUqhzvX2uEkPieRxC4ngH3O9LtLFYeoLrNDeG3zto5CFs7kYv8kaV24i1pXjBLMsZxzmiSMBqOyJOEdvP0oQMNa61Tg6pKROnmS7R6XR45dwLfDyiygmbUca1M0g1KC/xgUXc11s1XcS++QYiAsiod3c3ziJPM9XOEIU9dPstf+tHv4dd/4TdQZYE2CV9+6Q5Ba8ipEF65coslX5EXLvFglKM6+Z6HkBB4h9u0pHCz3AQ1owScGhaOHiFhIVMtgQDh5HfnnHAh8KzFJ8QXc6fPorOCanMXv9mht9LifR+8wPqxNmU54dOf+QC/+Gtf5J/+s5+ht7zMX/0bf5nv/rYn8L2FjtN+Ski4A3+zmuubn5GpNz7cszLu950+RW1jjUKXJXkcM9kbEI9GZLMptlKEQYAAVKWcVG9ZgXQZ1DJJGY7GlFpTVSXT8ZiltTUqq/F8H8+X+I0mvu8mbBt7bxplP112+KGknpREfuAEJoB+v8///i98B3/q448jfb+eQO8mwQvpu14Q43KNiIPKUnKRRRV1RKlrWWL3DwqtP8V3f/aj/I2/8f/AmgKdxwwGQzxfsCRHeKHHzesbhJdPkKsCgXC9eNaJgTTCw1XZhRB87GMf49SpU9y6dcvN8Zirc32T+1JWFb/yK7/Ck089xblz5+rZBvf+zpv3w/2k1RvXuLWW2xu32bi1QfCd4TsOMgBOnz7NJz/5Sa68eoVXrrxCnmeMx1Pu3r3LaDRywyzruRpXX7tGURasHz/BYHePwWCPlZXVReP2u6GFGWNI0wTP9wii6E3EnMPCE+4PdYBhhMXWPQiBFEShV8vWWwzzfdwiLYBBGoMpSwKlqMqC7s4tGA4Zd3psLZ3kdvh+ts5+mNcKn9PbL3LluYJXb6R8dOkqQ2v55/844un1bZ7+tlvI79Wsf+BxZNR1lWH2O3flYS+vZou88OKr/M8//5vsDqfkmWPXfPu3fZTHHrpMpTQvvnyFX/m1X2c8HoKVzoZIiR/4tVywJM9zrl67xjSecevOHc6fPsnDF0/T77VpNRs06hlLopbeV2VFluekWcl0EjOdzbAIwjCi2YzodFocX19lqdclipqu9eAPAfvshXf4+3XSxNZ+pKl9Nm0dSyCvFHFWMIpTdvecryjLlNWl3qE+/9CBhkCQphl3twe8/MqrPP7EQ/yVH/lBzp08hq40Uehx89YGjSji2OoKge/TazUQVjCbxcRpztbukBevbVBWJWmScvz4Gr1eF9/3nWqGoFbkcZt4pSriJCNNC7R2nPRmq0m326HVarrpjtJzRulA7uA9Enh419iXFHRldCcpZykrTVFWpEXJeJYxmcVMJhNUWXLmxBpy7qw8yLFMPQjMGleKRC7oWu4dcvxyi5sya4VFqbq0nmbcvnmbjZsb7G0PUEWFZ2sJW5yBc4PENLm25FWJxtLst2i1m0jpEUUNekt9hBQ0mk2ktI5VYOdO/htmCxwCs7Ric2fAaDolnAbc3hwwnUwospQsTsBaylKRpSlYg1UFKt0Fm2JtBliEcCosts7eS69BEPXxG12EH9JvCD78zDM8/fQF/uDKmGsvv84pc5fXk5xjueB7llp8LrFsVQZh+4RlxZJKiUeCcgliKrQ6c6iKqEUwiVM2NnfwPMtf/bG/yNOPXsL3PE6sr3J3b8YLV25htStddtoR/U6DfrdJu9nAk4IiL9nZGZClOd1um0az4UQWcAO5tFKosnDXbCyFcu+aNW7+TbPZpN1qEtTNy0J6tRKNqO/XPDz8FllENQ46cfNSrrWQl4okK4izgtksYzJNmc1isniGJwy9buvQ71vgOTskjcbTFSDod9qEwjBOSjxhQAp8z6fdEkihubI1oNfySfOCy+fOIqRLsCttkMKV6z0p3CyMrMBrN6gqR6/qeAGdThulNMPxCNVaYvzy6wyX2+zd3SM6FpJXFaYskb5AWI3vuTkI4SEVZzwBfv0opawVpeaVl/nXteyLx7zqsf8uyPp7whxIfFiL3bgNv/C7TKZduj/5/Y5C5hvyfJdXXnmdf/APf44Xnn+VZqvHU0/8Lp/5+CN4XrBwJPTi/FyqWRyotB7mPZj/9KJCKuqRedpitUJXJdlsRjweMxwMSEcThNE0Gw3nVBhXMSzLkqpQlHlJmqYM4hlxmtSy7AKEYPXYGvF0QqvbRQZ+PTXcu6eC8eY/HG7AnQBZN6wba2l0eqyv9ilKTSDcIDFr3HR2KS1SSsqixPN9rPQIAok1+/X8qqoQ0ls4vr7n3LaydFW1h86uc/zEMfLJBF0V7A1GfOPWNuXehE99+CE2b21y+uwKyg3nwCjHJwikqGds3Ody6p/59m//dv7+3//7/MN/+A/Z3Nyk3W4xmUy5c+fOW/ZsqErxr//1/8juzg5/6S/9b3n8ySc5ffoMzWb7LQKONy/pg0FGWRS8/vp1fv7nfo5Lly7y0Y99/P7P4W2wtLTET/7kT7K8vMzv/d7vURQ56+vHmEzGbG05CqOshyoOB0M8z2N3b5ff+p3fRvoely9f5uSpU3Q7vW8qs3u/QMxaw2Q6ZnNri36/7xJj79BE7wcadVAqXH3Eq6sY86DfWoERtf9gDFIV6LygijOq3T3C3VuEoxl2WvL6+gX+4JGnsKsdZqXld33L3d/+Oo+vrdH5U/87zrww5uGVkFFD8JWXhvzqjW1umooLo1t8pAh536eeIopcxUwcqLAeznK7/tBWp40xhtlswvmzZ/nxH/tBPvj0I/RaDWZJTL8fce3m61y9eo00ydDGqetFUYQQbg8MowilFKPxhCzPuXH7Dq/duMXZk+usLvUIA49Wo1lTDQvyoqLUCqWdgE6W5mwPx0ziFGuh1YjoddpcOneaixfOMB6PeOThx97Zg/um2J+09Y5+284H8h0YQWzdnJ6i1BSVJs5yRtOU3dGY0fYu2XjI8WPLdLuHEyQ4fKAhBGdPn+QDT15iOtnjez79KZ5+9DJBIFFK8dTD53j/U4+zN5rSazdZ67W5dGKNRhRRVBU37twlTgqnc5zkTGYpYTDGakWjEREEcyqIu2lB4CNkgJml5IUhniUMJzGFMvi+R9jwWV7qcfbkOisrfdrNZi0jB3ZBYPijh7EGXRv9UmnKSpMVpcvAxinTOGM0njGbxiz12pxaX3W1B8sD1XqNqZuDhUAal6UQ0rghUlYsggsrHKdZYxx3PE0Z7Q0Yj6YMB2Nm05jZNMZUhtAPaNRlZwukNfVAGccZT8sMpfog7rC03GM8HOGHYa26I9B1gGGMrudkOTm9wzYHXt/Y4/krN5HCp8gzBjtbjg5R5piyRJU5WlUoVWKqapEFM6ZCIIiaK3jR8iIT6Bu4cP4yH33qIc6f7nFqvc+FM0t0m5Bs7fFr/+tvk964QeLnnJAZOm+QVg+zTkEWdRkCUU9wRlbMipKhFQhjqYoCa+5PZel2mnzXpz7AnTt3OLm+zpOPXKLf7yMFRI2IRy6c4ebGEK0UQRSy0uuy2u+wvtyn33VBuzKQ5xVlOSFPExpRiBcGSOE5o2x1vX5CpzijnXJXkhWUpXYN/IFPs9kgiELa7RbdTocwDPD9sF5/Tkv9WyrYsLhskHWGUGlDXipmacF4ljGNM5IkJYlTstkMlWd0+i163fahs8uh7+FL6WglvsveRo0GqizY3RtSVZbmBY9cF2R5TiOQpPGMttcg8H2SJOaFZ5/lfU8/jgxbpIXizvaEU8d7lEozi1OKUqGqirKsUIXCFxItJPEsY/rSK/hBwMZsSrK3w6nOcZS12LLEehG+cHKoQeCh7eFMtxR1w3BdnfDFgSkscn8GznyzEnWdT1hRO3QGm+Ykv/FlgnFG+D0fgWpM+c//LXIjQfknQRlslmLTkrJQvPrsLifaKV+ZPYcp16mSj7h5OFYsgh5gUZ6/p+nwfq9BnVCZJ08MBkzdzGrdkLGqyqmylCyeUeY5SZxQZjlVXqJqcQWj3DC3Iq8oypJpEpPlOdMkJs0yWk2LlK7hP55N6GcrFHlG2GzWGXpHO5tv0KYO7K21ruJV2737QQiBqkqoFGBZWV6h7QviJKVlQXsSX0AQRfVAPUetRCnSKsfzxGIAYrvZoCwzgiACPKQUFEXBYJTQaASuOV4bGs0WxWhKNkvYTlIwkM8Svvr160wGY1SeglJUaY7wQ3dcaQkeQKCk2WzyQz/0Q3z2s59lPB6jteKLX/wD/tbf+lvs7Oy85ZqcTKf83M//Al/52lc5dmyNj3zow3z605/m0Ucf4dj6cfr9ZZdY8dz088lkyGw6xQ9Cms02ZZExHA75pV/8JX7jN34D6fv8tb/2f+T48WOLe/1OIITg4sWL/N2/+3f5yZ/8SeJ4irHw9/5ff4+bN/95PYDQxxhDFEX4vo/Whps3b/GLv/iLXLx0kfPnL3Dp4iXWj6/TaXdpNBoLn2euZgdOkXIugV1VZU2L0wwGAwaDAWEYcPz4CcLw8MPS3nw9roqJwPVP1bfFsziJesCiwVTYMofpBLO5QTDcQ+9NEHgor4UcDrgrW/yH9Q/wlRPnuHKt5OTODsXVEb/93/wy5uYdrnRboEooQjbPLTPLd9l99VlMts1zox7e7Wd4utnjv35/ybkoorLunOa1jUOLAAl46slH+eEf+Ay//puf50MfeIZPffT9rK10QUDUikB6PP30kwzGE8rqLihNFDVp1cnuVqPp1kxVoI0iThR5npFlGXd39uh22rSbTTqtJr7n5gJpbfCkpNWM6LZbVNoSJxmTOGZnd0gcJ4S+x5e7XVaWl0hnUz7znd/5jp/dGzHvCUmLikobeq0Q7IMn2+cD+SwuwCgrXQ/szFwiL8kYjmaMhwOK0QCs4tTpUzSiwymkPoDqlKDdbvFDf+Z7+fTHP8zKcp9mM6r5mz7HVpd48uHzfOX515ACTh5b4tGLZ2m3GiitOL2+wixOyarKUQB8p1o0b8wxRtclfNe/oLVCaUuRO/rAYDLl7t6YOCuZZRmz1P15/KELPPPYBZ554hH6vY7LRGHYH7byzmEPEDsf1ETZuqyujXOsq1rBKS1KkjQnzXMms4TpLGU6naKU4vKFs7Qa0QPTpsDJ5CIERoi64dwijY+d06fqcr6rLxiUrijKgiSOmYwnTGZTdgYDJoMJyTTGGkGz0aSjFVpDpQ1Kut/NqsI1DHnOWYlaUd1PkFOWZc1VnN+0+T00iyDjsI7fcDRjZ2+ML32m4wH5cAurVT2XwGCqAqNLrFVYW6GNBFshRETkLfH06Ue5tNIn8qHlSU51Grzvow/xif/NB+kfX0IEfXZfuUr68h+wiuC/+HMfZuvzfT4scoJmwReem/FKnHLWFOylMS1dsGvPs2cljVJyPLcsS0dH8737OxWelDx6+Rx/5//0V1wGphnh1QpskRCcPbnKSr9Dlhd4HqwsdTixssTKSpdmGKC0pcpKqkpjMXi4Sb6REFhpHA9fSrTWJFVGVfO04yRjPM2YzDKoKYcWENKj32+zvrbEseUllpf7tXzx/syV9wJz0QNvLhH6gFhU5uqvlbHkpWKS5IxnKZNZShxnZElKNptSpjHWFJw5+zDdTttd6yGO60uJHziaiqxFDYKwQVUqVFFR5hV3RiUnlzt0Oi2k53O+1UNXuSu/C8HTH/4Iwmq0qrhxc4vdcUa/5eEHHv1ugzguSNKSyljiOHPOqlJgNcVkRq4zbO3IonIwB3qIrMCXFt/3CQ5J0Z5TpjwEQd3LuKhZ2QUJDWshy3JENiXd3WH77oRkZrh8qstqUSB++2XKlzbxP/gw7G6y8Wsvs3RiBXHBzZIxeCi1zHjyHP/ip/4pt7e/gRAZZ88fp79ynL1JzvFjTmrVwlxMsB7aVWfkDtGnYYwbrClsbec8l0nGWIwUWKtRZeHm7lQlszhxsuFliVYVs2lJEARgDHmeo7QhywuSLCdJE7IsAwTG1DREa5nFMcZo8jynoRTW8/Ac58zd3wOVDGNMnVg5HH3K9z0iz8OvI7BGo+kcGGNRyqJVQSUEszQnDEM3LFI6iflGEGCFQFclSlVkQhJ4HlJYXr25zdnjSxRlSaMRYm098b00hGGAsgZPCIabQzyhCaOIjVdfxSiNNx4gKuXeS+kTeB6h5x96VtB8rXmeR7/fp9/vY61le2eHTqfN9vY3vy9VVXHjxi1u3LjFc8+9wL//2Z/l0sWLPPboIzzx+BOu0nH2NIHn89P/+l/xhc9/kQsXLrC0vEyWJrz40su8+OLLBEHAj/3Yj/L440/i++9OLn5+PW7AY8jy8jJlWXL23BmOHz9OVZW02x2qShEEPp1OhyiKKIqSyWTKc994jtFgxGhvQK/fY2VllU6nQ7fXww98lpeWaTYbCCEpShcYJ0lKksbM9QSKoiCKIk6fOU2/v/SuKFhu/RkCBGEd7M+H6kpVIMoMOZtgh9vIOEZdu4m+fZeyyglbkihMkXaEGA35lei7+X92TpJ/Y0b5P/0s9kc/wNKlM5jWMna1AcsraF2g0gD/UgexY6mmT0J6DisscjXg1OmYlnTDMst6Ls+DzAlyRXiPpaUl/sIPfR+f+c5vw/d8Vlb6+N7cH5L0OopHLp3nG8+9zO7uAIRPv99nZXWVfq9PGPpkWUqSZ2RFTpEXGFHPrKkq0qxA1vKu/nw2inT0xVmaME1SZnHM3mDINE64c+cO8SxBCutGA/g+VXE4EY8HxQu390gLzbc/ceqBKHVzm7XYW7UmKxV5pUiy0u2tScZ0mjDeG1DORlitabUbPPTQpUO/hw9U0QDJysoSK8v9miNaGxQBjajBoxfPsLk9RqmKk6trrB9fphEFlEXlOMFaYYXTaldKucy2qY1z3Szp+wFFUZLlBXmhqJQlK0pe29zj7mBAmhXEccxoPOHWxm1eu36D1288jBQe73/8IivLKy478F74SBbiNKfddFz4Q//anDJl5g2gxlUxipIkL4jjnDjNGE9mJHGKKivWVnpcOnvikKXCN8NY5/BaM19YHsZYpLEYaRBGYKnpVfUQK6UUWZ5R5AVF4TKtxhpKrVGlplIKpSqE8FDWoq1BYaiUQluNH3h0uhqsZTQcsbq2TD/vU7WazAcEWuEoBE521A3804dQYwHY2rjDeG+X0A/JJwPKqZvIqo0B4TL3kRfSbKwhpaQZdek2W3SaESfWVnnykbNcON7lQqfkZDvm2KXjeJ0G6TQjtz22hhv8o//7f8f09g0i32PcPsE0afGaGtOk4DfGMdfjHUoMFS262XFOmWNkgURME7LBDpfWmzVV4TBPTuL7Ect9n0XFYOHPe6wf63PuxDIvX9/A8yLWlvucPL5MFAVg3QT5NC/JisophWk3VC2McGozShOFEdrAZJa6fiftntfuYMrdvQme79dDmJxcqVKac6dPcOHsOg97sNLv15WNfbnid4u8KJmlOSu9DoH/4Gpqc565tdZRkErXlDaZJkzjnPF4RjqbUSQpKk8xuqDTbXP61HEC3zssc8oNqfMEnrff80TgMy0VX372Jn/qw5eZpQV3dqec7HjkRIDl/HqDlaUOg2nMf/jdr/H0kw9x5vQ6p8+c4MRpj0gatgdjskIzneW0As1rt8dEaLQ1lFWJrkrOXTzJseM9Altx9doWVVGhtJNttNZllPvtgFbD5zCKRnMIwH9DG5uxUBpNWVbs7gwYXL/D3gvPcevabb727G2+8cpV/KrN3/nOZ/ie/jH0F+4i2wKkxmJpHT+G7Qe0PrXEZOsKX3hxyJ2holI5L7z2GxRKYRDcuvE8/+Jf/izPX5vyN3/yx3jm8dP4vqxVm+Zmep/6cz+zvej3MrYmmFuQteiEFZjK0QfLvGQ2jVGqImpG5KnbV6SFJElJ0wzpexRFTp4V5GVBVuRUVUmr3SaIfLwwwIsCJrMZcZKx4vsUVYkfRXWgNm8Ct04xfBFoUP/3/s8oCgMCbz6jwhKGHlleIHyfvHC9ImvLbbBugntZKfqdNrMkQeAzywrWV1sUFWxujzh3YhmlNZ1IUlaKOFdEAQxHKY3AI88LPOuGsKq8BCuwZYytZvhWY6zGZCm6Usxnt0khCX1B+IBzNA5CCOFmzdRV58MEYUVRcvfuDtvbu3zlK1+j2WqyurLC+XPnOHHiBJ/77d9iZ2eX3/v8F5Gek5JWqqLRaPAd3/Ht/PiP/2UuXry82IveDd5IbfI8yTPvfz8f+ciH2N3dwfcDhJC1kiaEYUQYhkwmE6zRlLlL6i0tLTmZ/yCg1W0TRRFrq6t02m1XpRCSsiwpK9ew7HsBWitOnDjB8eMnWF1dO/QA0m96LVgCBH5dBbTW4FdTmNyF8W3YuYP92h1kXGGLEjHaIexPabZi5HQP1Agx3UPswaz7CeJpC7+Zw2jK9lDzse9e4sr/+c9x90pBFVgCT6Mnirs9g6cfQ4wbMKtgPMU/qZic6/NCAo83U8aZYS30aXhOsc4exii4B4T0PLrdLu1OpxbTc/vGXFK/2Wxw+vgaJ46tcvXqDbyGx9kzZ7h49ixrK31macrW3h6lKpnFTi3QWOe3SOnRbrcx1pIXpWPfGIOQElVVjKcjsizHaEUYhmhlGO3ukU4ni55IZyveeRP/W8O9j8NZyWiakuSKbjM8VLJ6oYRaq6FWtZ+alYokL5jMEiZTJ+U8G42oZlOs0Xie5On3v4/lfq9OzNwfDzawTwgkHm4C6vwyXbbN8yRrS10unD7OcDRlfXWJdquB9ARFUbE3nHF3MHXOrxQEvk9eVMziDM9zEwY9KQkjnzQtGAyn7I2ndNptcqXZ3B2wOxyRJDPyrGQyHjHc2yWezdCq5PjaKitLHbrdLkEQ8u7rGVBUmo3tERdOrdKss0KHtVf7lQxNVlakZeV45ElGkmbEcUoSZ5RFQbMR8tRjD9FqRG7TegdGUVuLMAYjJMIYZD1h2BiBNLKekKtBeDXtwFLkBapSZHnKeDigLEqKvCArMmazmMhvUJYldlF5sqRlQVlVNFoNRBCSZBmj0Zj+UtfN2shLt0kFwT6HunbCrbGOQqUP5/mNBxOq6cQ5Y+nUyToCnhfRjgKWO8t8+NQqT156mEYroNFp0e9H9BqGZj/i2PoyncjSK4ZoclKRceWrG/yjf/M5vvu7v51Ln/jT/Pr2o5Rqmcr45LEG2ceL1nk6KPiKn5A3lrGmQgifRzyfS6bJVdPgXJrA7gT/WAdPBGSlYPk+1+OytxLhUz+Dg0ZH0Gw0OL7W5cadgF67yXKvTbfVwAKjScLOYMwszVD1hGOlnUBCWRk8T1IUJUGQI6THcDwjKUqms5SV5R6jaczm9g7NdhvfD4mz1FHn6iATYZFWEzxywWXavHc2dfat4CRnCxpRSM9vPki+hboW5ygExpIWFbO0YJoUTGYpk2lCMosp4hmqyLG6wPM8nnrqSY4fWz10kAHge4Iw8Ah9gZQeCMEkKXj5zoQnHzmLJzyev3KTtabHSHc4cyLixIljCKEYznJOr6/w3d/9KXxb4UmfX/+9F/jYBx7h+Vs7aFUSSkunGTCLM25uj3ji7DIS17cVeJJLl0/zvqcvU412yCpNtreHKnPAgNEuMxa67Lc4ZKekJyCw+5UMD4utMsrhmJ3RmI2r18h+9w/4rc99gY29O3xjMGajMHi6xUfDSxxLDIxG+F2DfLQLjQxxVrDynz8NZc62KvjCL77Kz37xRcbj206C11TMN8A8n3D96ufZ3HqVIDD87f/sL/HEw6cAjbIGH29RPTqMcX1THwS2pnsIqGeoGK0XvGlj3dpo1c5HmWaks4yiKtG541VP4xlxlqLqzGe328VvRDTbbZbXVtC27ktTFVWeU0UNgkDWuvqg6zlEZm7f5lnCQ7x8URggMKjK3TMhIclKhB/SakrazZAi1wSRTzOSTDPN1Y0hx5caTKYjnr9ynW/78BPIsMHqco/RNKURBDQCSZwVDEYzzh9r40tLXBjyQmNxE+ptmbPcjXjk8iOcXG1yazvmxZfvUiiN1dpVP62rpDUbHs0HnER9cB8zxrCyssJHP/IRNjY2SNL00J/jEgwV5aRiMpny+o2b+L6PUlXdC6NA7R/z0qVL/PAP/wXe/4FnHAX7PWzanPewSSl59JFH+Ox3fYar114jTRIqpWg0m3i+h5QeVVlx4/XXSfOCMIh4/eYtoq0t+r0unufT6XWpqgrP9zh5wgmqtFpNR3ttNOqmY8Fqd4Uzp8/S7XXfdZABrmdLWI3QFUJryAbIvVdg46uI8U3Y3WHyYsnXxw+TNad82/qLdIoNxCBGjnOINVaB0AFNbSAH+VAHufYEmVwmkhUfOuNxNWwyLgye0ehTku4sxldNbKNN1VGo5S7+kuJW2WCsPYxS+FVKy/PwtcSK4JDJrv0ZbFbIhQItVgJmoWoahAG9bpvLF87y6tUbVMCFs6e4fP40UehhUcRxzMadO8RJCkIQhEH93CX9fo9Ua8rKzRsx2lHii6JgOpswnU7IZglLy0u0u0uUaYquCpf0rW3CH4bulBAuaJxlFdvjmH5rhW/mYr1RMEFr1ztcakfrn6V1v2OcMo0TZtOEbDqljMeLYY5nzp3mkYcvP1Cy64GoU/PlahdCibgHakBKj0YUsdJr0Qx9Wg0XVVWl4u72gOubu2RlhRBujkQripgmOZWqVURqw+x5kjQv2R2M2R4MycqCZqvDaDYljmPiOCbPMsbDPao0wZQlw8GA5199jUcfOs+lc6fxpce7jTSsdUo2mzsD2k2fcyePHfr3FhGicTy3JC+J05xpnBGnjkeeJClV6QZHPXzpHBfOnHC38x0axUUPxoESvpRgrVyckzACWQeJRmus0qhSMR5NmSV1iSxOUJXGKouiIhEWT/rImg+dl7lriA0Cmu0WQRgS+IGL6scTltdWqaqKQAXIesiYNXbBXzZGOZrXISD9NsZ46LIgCpqstZv00FzuRPzpk0tcOHuctc6U1skBjVNreC1Bo1MRRiU6sMTqDnfvDLg7yZABNLcrdp/b4vmXXuLTH3iEzmNdHv+//ec8/3wLr4Ao11hd0spucOLul4mOPYxKSmyZIfKUD/qbnC4Lvqh8wjJkPS+5OanoVVAdQm50YTQttdLTvtmp4zjarYBjKz167RbNhlO3yPOKW1sDRpOYvCid3LMQFJWPQdKojWFRlq7pOwjZG05IsoLheMrOcMZ4OmM0SzAywA9AVYbpLGEymVKVik4nJBCW48dXaTabSOEy++8G86yKtU7a1w0BOvRvLwJirCtfO/nakvEsZZrkTCYzkllMHs/QRYbVzllbO7bKxQtn8OR8gOThjhpGgRtS53luQBuWMPB44ctfokxTvPdd5OFzxxkNhhxf6yCAK7d2uHJjg9dvjvirP/xJXrx6k4dP9Wg2mrz0yhWeenidMo25dP4Er90ZM9lL2B7HnD3RZTSrgwghaHUaxFXI118dcrJp2RkkdIREui5gQFJVzpkNfOkmVx8C/oFAzRjL7myP4c5Ntnd2uD7YQz13hYe+9qt86corfD0tKS20vIAfOvMoP3z6SZ767GM0mx6i7eE/cwYRzdDD22yPPF74g5jffOEq39iMuTl+md295+vA7uAuZzEmJp2lfPn3PsetH/szPP7wSawuQZUIP0BIH0RwqOsxxiC0cAmVuh/CSc46G6eUJsschVMGPu1eH6xxDmAYMiru4gc+WZ6RZLVwQJGTZDlSCFZWVmg12/RPrNHu1/xuz3d0xDgGz6M1TwbV1Kr5e+p68cyimqH1/e1c4Ev3PKVbbJ4XkJeKcpqwO0o5d3qN0LPsbI/ZGYYYIZjGCegGp08e57tWmiACJnFGp90E6XFzd0av5d7jlZZg++42lQ3YmRb4xqk5mnrYSGttjcefeR8XVyWDz3+D/lKLzAqscDqFWKcC6XkC7wHoLG+EEIJ+v8/xk8fvaeh/J7DWOtGYt4DneXzmuz7D93zv9xK8S8rU20EIyerqGo8/8TjdXpft7W2yIncBRLeLlJLd3V12du5S5iVFUVHpkvGkYHd31/Xm1HtGp9NBK0Oz2eTs2bOEkeuvm9vAXq9Hr99b9KC+W3jlDJntoHdfQYy3EDtXELtXkLO7gMYOhtzaPMP/+5UZk+wV/vmfus2j1S4is6Asop7rZ7UmSMbITGO7DbyPv4/uyS7v74d8NhpjxB1GeQ6ioMo1HWKKqWHSOItow14hGU9SiqFPZ+cSzaUu0lboQpFLgSfaGBEdQoRA3PPV/O1yv+YoA1LgKIBBQLvV4tLFcyR5wVK/R6sRUaqKneGIK69dY3tnG186fd2gcoplgfSZTmdgnUiRE5EoAfcuZlnKbDqlSFNmkzGNRgtVFGBdUG/uUYB7byGAXtu963fHKQ+dXDnQ/+ZgF/+tpxZZW9snV9UIpIcXSiZkjKcJ48mMNEnIRkOqPGM+IHh9fY2PfPiDh+7NmOMdpi3fcPpyHoYYVnoNTDvEk4Ysy5nFKa/d3GRnNEFIj6oqMdbQabUolaERuGivrPnk1kJRVeyNxly7eZudvV1a3S5e0EQZg9aKPEvJsxijSgROZWI0nrC1M2QyTWhE0Tu9sHuuUXqCvMjZHU44fXzVqUG9DeZOvtaOEqFrrfO8cNJgcZqRxJlrTizdzIQwCHjs8nkCz6sHi70zWGMct5f9zU1IkNY4yTIhsNKi64xbURQUecFsOiVOM+I0o1AVFkOep1SqJElTwjBCSukyQ54kikKsrDcd4Qz7LI5pzhokacJsOmFtdcX1ghiz4Dlrsx+A2UPRjGCtexa9POakvsPTUvH965LzXsKJVsrSGYvNNvn91wz/+IswajV44umH+PDDy5ztFuyMFa+NLaa3zqxskWclp70SVWp6YYDa3uJkOOQvfmeX3kpOOgwwhSK0iu/fjVnWMR9f97hVdZFjhbyt2Jg1aJczRGYZNRQag1cpbKbQ6f314hctt2Ku7VNn7J02J0prAs/j9IlVp6gmJNNZytZgyu2tAVml9513nOKS1pZWFJIUOWlWYYFSVSRpyXg6ZWNz03GLg4Co0QAESZyQ5jmD4ZCiKOj1euzujVjpd0jinLKsCPzgXQfrc0gJQgqqSi8qmveDtSwoQ3OhA2MFcV4SZyXjyYwsTsinE1SRYk0FQtDt9Xjy6adoNd21PsjGHIU+oSfwAn8R4GRxwsc/foJG3+PuIGFzkHLqzDp/cHXIBx4/T6dZ8NILr/Glr1zlz3/Xkzz28EWOr/Sw1vKTf+XPcmNjh06vw+3dMb/7xa+z0g54+MJJ4irkN5+9RV5pfKEp0oyrmyOIr/OiNCTDIe0eeEqDDEAbjHbBgvQkjehwFi6vCkZZzGt7W4zSKdfGe1wb7hCnM1SccmbnNhe2XyMyFbkxhELymZXj/F/+k09w7pMPEZy/DN02QlVYUaE/9/sMvrDLb95M2NiTzAzE5R7TZPubZrjcvdRkyWBBz7S6RGUxWoIfhERhD8+P7lvV0EbXgg8uYSWsExCxurYzWrlAHoEfBnTabaTn9G8tkmljTDEeEWc5syRlmrjKnsAFxL4n8UOP5bU+/ZUVjIG4yBG+T6XcbCitKrTn1Nq0sVhNPb17vzH8sBWN0HfNwG4SvaNQ5aUizzTGaFrDkHYUUKYVnZUGaak5udJHepKdaYFRinZD8vrmmNAf0WxENAOJEC12xylWFWztVSz3fHRVYFz7PG7uryXo9Pi9KyM+v/M6a+s9htOcY0tOSUZ6rupqtMKT4oFpj2+61iDk7OnTrCwvk6aHo1w8KJqNBh//5MdZXV2rRcPeu2rGPpwlD8KIEydO0mw2WVldZTAcEscxYeSSrM1Gg7XVY5S5S67NRi5ZmucFZVlitAv2Op0OQRDRbDVZWV6m3WySm4w4jul2u/X8FP89CTIAzPXfhI3fw9t8DjHeRRQlWIWoUmzDw6oZWZ4xVg1yFbleHWMRgeseX+hQFBrMFE8bjBDIx44znGq++PkN/nry/+Gx9S/h+TlkGaacYlMJeYi9EyJGClDYmU9WhujJk+j1v43tnEZrDx3njvnQCzj8/ImaiFnfJ7f6XFVjrmxXVorSGPr9Po1WRVpkjOOEOE148eVX2d666ySdPTdM1ConbZ2KhN2dbZTSddLU0RqNcX8v84I8SSjTjKpU5F66/6bUCTajFVl5+EGrh2OMOV9gqd1ASMnOtCQtKlrRvYkbgeuzvbmXMNy6w6XzJ+m2m4DFk242lDaWIAjIs4LpYI9iNkWX5eKGNhshn/70J1hZ7j9wH/GD++NC3Bs1guN5WkNZVvh1tlsrxc7eiK3tEdc2tpnmBRY3TVprzSzNGARu4jFYilKRl2WdCVJMpjNu3b7F7mCPTrfPmXMX8OoNpspTdFHg+17dOyGwBrK8Ik3zQ6l93B/WSe4al/ktSkUzCnirx39wgJg2enFvPCFoN0LiNKcsCpIkIU0yitxFws1mA10WDCZT+p3WuzpbYywCg5YCWVcxFpUEz23CElE7+oaqKqlUQVWW5GlOVVaLzSQInIKOxSKEpayKOrMXkBcZYaOJH/h0Wy3CRoiqy+x1AoyqrNC6cplKu98MbMx+teUw+IF8TLOZ8Il2xgV/Qr9b4vkKYQw2CTC7Mde2evzyVkEsSzh7Fr0LX71jyZXl1d2C7fQOZzttjukJftMQ5hU/+MQjXDpxjOVqyo+uvsL3fmwHm+XYMscUlv54hn/iKs/YTXb8AH9vhLB7qFuC3XGHr+Tn2QtCUi9iS0W07g7orC9z6b6qdbWSD6LOEIC1+6vJOSmCdqNBGIXMUqekdHtzj7u7Qwrtmrb8wKcZRaRGk+VuHcRpRl5VTGczRxkxltFwyMadDYLQZ3X1GBeXHblLGU2aJmRpSlGWxElCFIUYIRlNZxwvVmg23rmqyeJqDzSFGmNQWqO0JpRvNjuLNQRUlXIZ+7mjJtxMkcB3/U6TaUwax+Tx1AUZWjkObrvDBz/8Qc6dPl7bxsOaawffl/iewJeOfgiWJC/42h3Dpy6scePODn/2U4+wmyT8/C/+Fs+9dIFHTzb48R/4BH/2Mx9lpdfid/7gJe7ujXjo7DqPXzrJ9jhDVzO+8LVrfPpDj9FtNbkzhP/h3/4y1197lTQrCK1HliSwcQ1jKihiECFexzqqnXX9cQa3lrx6tsJh8DtXX+Tm3hbXx9tMypxcKwqlIEsIK0GYZYS1oyCAsyLgs/46a6MMcfUW+naOMAFq53VEr416fpvdLcG//sYXeHEU48s203KP0szuey6qzMlns5oO5lS+KqUoZjP8lsDvhPfnFRuLEWY/0ICFH7Lo55ESpCRqNYnCkEajgS4rBrsDN1VHCJAeXhCiLWSFU0P0fA9lDH4zRAYBrU7Xce7T1A3oMmYeAbvjIxdN47amT+1Xbw/XoxEGfn3uMM9gZ1lJqgQNz/Dy1Zs8fvkMrUaLWztTZOARBZIXXt0j8DVPXDrO7335Cqos+dDTjxNFHt945TaPXzztBm7oCi8MuLYdUxQlnq1Qej5jI2N3axstJpjZmJsbu+SzGD/1EMY5IKoCpMDzDl9F+2ZoNps8/PDDXL50gd29PYricMP8HgS+79Ntt98zp/ztIKWg3W4TBD5R1CBqNBgMB25QcZ7Rbrc5duwYxhjiLCaIfHpZl8loymgyJkszqsplx5MkIZ7NGI/HrK2uumRgWWInkwOVsffmosytL+K/8uvIqsDmJcII8DzciAcBypBmKcaOEULi+QrrOXqjUNZFoAEQG2RVEZUF2XaAfDii3JjRHP8ONv93/NxvTfjIU3DjBcGnHisQicXugkwFg5cs9pTkhU3BJx7SyKxFknqIwEcbDzWZEXULmt3+Ia9qvo/u76dikcpzMr5CeORlRV6UaGtRFjZ3RgynOaPxmBs3bpPPplhjCBshxhhKpRwzo6oWw5SVrrDGoCqN0copcZYVZZZRZBlKGyopabaaSCERuIqGVk5i+r6oLyMrleu9rel6c+d+LmXv1QlL19ssOb7cRkifcVotqFNSijrpa7mynXD1+h3SG88zmcY88vgj7t/rBHmpFJNpymhnl2w0rBOg7i4ur65gcXNcVpYP+0z28UDUqYN3Yv4Q5zxqAOkmtRGEEVmWszeYcH1jh+3BCKRHnOeMxxPA0RSqqqTZaLmGG6WZJTFVWVKWBdO6B0OpiiAMMdoNh6myjDSeAJbe0ip5WeF5TtpTKUNVOzMPgoNB08EsVOD7NJsRymiKsqQZBfv/Xr/P7iFqRtMZm9t7rKys4PsuexsGPpHvY2rln2SWUhQFWDh/7hTNyOfll6+wMxhx4dSJd2VG5vMzhHHa107X271gWhtXwqsdXWMcxUBXmjLNyeMYYTS+sHTbDfI8Jaob06w2rqHWKPJc40UBfiBoNUParQaNZgPhSRqN0E07VxXaKKqywg+cwoyxdXVD60M3SQL8p9GXiU5uETADq/YflFEIBSYXZFkPZUeUWjOJK7buTAlNTrsT8Hgblj2PJzoCMZmRmpBKaZ5c7dLYS/iZ//632Y2vcNrf5VRXMxwptAJtPWRR0FSG2TRn507CU5OK67OQ35/1max28Jcu4jUbdDpNtocTLlaHeedcGdflEutMC3MKlcb3faT0CQJJFIbMkoTN7QnXb+8SF6VrRMudmlQQBpRlSaPZQgo3q6ZQBcPhuH4fNMPdXQZ7u3R6PdaOHUcbSzybUZQFcZKg68xOnufkeemC4EqhlTpU1WnBlb/3m3MZEBzx3g2H9L39mSxzlYu5YzWHMYasqLh26w6nThxbDK6c2xttHBUzjWOy0dA5rDUFJGh2iFpdlvo9dyz74NlM35NID4QnKYoKYSHd3ebrX8opFFy+eIp/89M/z7f/mc/yE3/xe/jy116h02pwa1AxTXOQAc++eJXB7i7PPLTOYJJybKXH7l7Ob/3u11nphtzaM9y4M+bVl56l17LMBFT19GRfp5R55gZeSoEtMmQZuEuUDTd8z/fwpMDzD3dtv/L8V9iLx6gAKmvwhOfodbrOxJcKY2DV8/GFoSsDzpRNeq9kpL9wBXn+HHJSkOdDNpTg+bLiD2TGq8MNhmWFtTtok8IhhnCqKmOyuUUx3CFot5HWUI4SqmRK8xiIzup9P8M58Pubo7amTlgK5p2jBvAipxAU1tLpZTV1qlShxyhJ2NjZZjqbUeQlRiuaUUQjiuh0Oy74F5Ko2cQPQsJmE6MNUjr7OZ9VIa1Tp7I46q+e94gYVVc07n9PhJSEYYAXuIqGMpaXb+7SbDS4cKrDWi/i1VsDPD/h2s3bFMZysuMRNRucX48IvJN85H2PsDPNGKWandfvstJrkhUlN3amTMYjWq0m7TDAq5x0sdYWVWqsrEg3b7v1qhIXsOMjjKpFWiwWD6MtSIl8lxUN6XmsrKxy+sxpui9foSgG7+rz3goC8L23Tgi+p8epbYvWGmMtvaU+QRQSBCFpliDGgiiMXIO6VgTTgNXlVWZxTL+/zPJ0hc2tTTd41lryLCOZzhZ9kmEjQqmK6XhMGse1kzm/wneJPIG9HQgj93nWOa9WOMqczmAwm9H3JhQtnzAEUdVHDiRWWawnED7EVYeYAD8GlVsYFlz0X0BXGV9/zfL0ObizqWHFrU+5YyCFpa7gpYnl5+4a3vc4lMVxbifLlMMYP55iqhxzIqJz/OQDUOAOBhuwCDjqbwspaYShW8dS4nsht4e7pNkWg8Eee7s7qMJRKIu4qmWAXb+NLkuKNEV6HlordOX+WKUcg8UYjFJUqnTPCqfWZhEoKrRWtbLqIYJ1AePxlN/50gsoC54f4AUhQRgQhCGe5xEGPh6WIHSyypUV9Fs+ygpevr1Xr1XhmADakmrBKKmoJlNMpbh94za5aIAwlGmKqgrCVp9sPCQZ7tS2yw0BPnXqBB/80DN87jc/x82btzl39syhaKEH8Q4DDXDF14NJR0EQBBTKkk5mxHHG3iRhazgkjCKMhd29PXZ39+7JyAVBSFmVWOOoVmkSk6cTksmAfDpxvPVmiySOSZOEeDomjxNW1tZZXj/Bzt4Q6QXOuZDOJTGHMPBZUQAs6FBzNc8533aefb90/iTgOPhZHdG663bOkpMUFdze3OH5F15h7eQppBTESUazEfLQ+dMkeUGeFZRFgdWGkyeO8cEnHyHJc/bGU1aWXIT4YPnXNzwN4wYrSSGx0i4cOmNkrYjkmgDdgC43hCtLXOATeJJmGNAM2iRJRrMZEc9cw7onBJWukJ5PGEVUSuGXFVEQsLLUQ1uLFwYu+s9zVF0SdgGG2ZeJnFcz7OHlbb3d2/j9CUjlGpFsnXkxbp5ClmoGqsXl7hJLSykfOdbjMlMIMsJ2HyF7xAScaElSv8lt43FnOiVLPfpa8j9941VevvssgR4SSijqWMYa5+j5UroBi0rT9wSpTqn8Ds2+5KzfJtUhN3cLtLA8OTtMSfSNhpB7bKJrAowYp1OGuzFVqdgdjUnynCAI2Nq+S1YUTpZTKawxtDsdkIJZHJMmKXmeo1VJliZMdneJpxOqIic9e47RaMRgMHSTbLWi1+2wfvw4SeIk+BpRiFHKGc1DPKNpkhLnFaXW7r07QHWSc+nPemFZKykqxShO8aR0Qae1i4m5gefRbIYMJlNefv5F0uwhlleWEEI4lTOliRoNhuMJ2WyCLrM6qJGsra8RtnrsbW8zGM8cdelQb9i98AMPT7hrr5QzpEu9CM+m7F5/hd1br7F9d8zQ6/PJjz/Nt3/sMWaF5md/5Qs0fMHjTz7Ohz76DGeWIm69fotf+De/w3f9qQ+QpBVPfeAZGlLwja99jTjJ+K5v+yD9k8f5H3/q3+AJsM0mvV6PZDCmt9xDhk3U+FU3OG2RBRNugrSQjkN8CHjCUJQ5gddwSiz1AGmDc5JH0wIdG04bSRPJtil4LhvwkZca3BltsWwMJrWEMuKXZzf5J/kdtJSMdII21YH7/PZ3XAjBudOn+MTHniAdjzGjCfE0oZxl+Kag32rUG/Tbw6mBycVG51mJWVSvapl0gRtIKSVhGGEFVFpTVBWTOGESJygEyrrB4llRgpVEjQZxXhCkKcdKhdWWRrfhspE1zQXh7ptWGuFLN5SU/T3DzU0yi7/fD74nXSWlcD0H40nG0vIS1668SjzrsrbSp9ls0vA03/eph1FFjNUKG3RoNxv8D//L77G2sswLr9zguz75GJ1AcuvaLVRrlQ8+eZ6sZ6lEmy89+yrDcYyHZjTJXDLOevihh04ndaXMc3LhRezeFe2BrCtp5t27uEIItFE0IjdD4g8DFsudjdtkWUaz2fxDOcYcqlIMh0OmycxNgm606Pf7hJFT14rjhPF47KjHYUAjcpXqbqeg1WwwHA0IAg+Me6+n8YzRcEh28iRRI8L3fIqiYDQe18pH741AhzA56BzrhU5UwlgsJZgMUUr0TLGzM6MvN4iaPg1dOltrBAQgQgFagILCk2jPR5QCEhCJorFS8tjFir99wdB5SHAhArtlkJ5FdAQisHip4ckl+C86gqWO4YqOyFNLvnWbzTspzW5Ecfc6x86eptF8ELbHG4IMWCT1pIBup4UvJLM4JSlKtFLMplPGe3tYrWi22hRZ4oIInECRNU6RcJ5S15UTS7CLXiyDrgUwdL1vSMRij3PJV2e3lvqHm6QdBD5r/Sabm3eZTJ3aE9JDei4hIevoKWx1nSiCDFwyxPfrfGYAWIQUGCux3XV0qTFJDIAqMnZevwpYTFWCNfiNMSpPODi9vN1q8qEPPcPK8hKXLl/izOmTcEj/7SDexZs7bwifZ2adIdneG3H15ia3Nu7iRxFB4PP45bN89YWX2d7eJo6dEQOLX5eN3YTWgrLISdMJZTKlmo0RdRY3Hu+xtdGgzDNm4yFlWXD2wiXW1k8gwybxLKkjVUe3OIxSQZoXKO3oHJ6c90dYpJCuv0IbpOchPI+8qKCoKCqX6VF12T7wPfqdJtJKdgcTijRj+85Wzb4XmKUu41nCZJaQ1Hrunid532OXWOm3Weq1Wfr4B2m3mhwQtX9HcD0aEiPdRjfnMTsDVVefhAQrqJRrZDK1moexpjaOIUhBkiWuAdAXBPWwO4UBYWlGDawVaK2QEtqtNsL30UrXSleWPC+JyrIOKAR6UVnRGH34ioaUPigDrYNb3Hxnh9uZZBfFd50/z6c+0OT8qZBItnhtT6GiNUwjwvM0aRWzZyTLjSbfmO6xF0TcSEs2xhPSvMAqN7fAGvuWeVkhQBmBwhJ4lmZ3GXLJ9XSPAEs3bHF3Mz7kk5qnVwArEW6eMaKW5zNYXru5yY3bd6gKV/E7ffIESZoxmcaMJmOKPENIgSc9sqJAW0OR5UgBqizJ4imz0ZDJYI8iTwHB7s4O08nUyXoKOL6+zvueeJR2s0WaOc3wpX6XbruFUa5J7H64vrHL3LAb63ovpHTSpU5R0FW0PCnxfUeRnCaZ6+eqaYYIie9LzhxbQQrJcDgmm025cf0Gu6MVAt8jzXIajSaNRoO97V3KJF4Eqyurq3zbJz/Cna1d7t6+RZFn7uDvwBgqYwn8elaFqN+zqMPyqXXS7Q1WVlf5/h/4Tl555TU+92t7FB97P7/0q7+P8EOCKOL1G7cYTWN+/C98LxcvnuEn/tI59qYFcTpgpdtmN6545LGHuXThJGUy43e/9hqqrPACgVUVeeYojMZop/8uJMpzMx+QTjRDel49j+Rw1xSGAVrOaaASXZfdAwNpWTHNLC9kll2tUBiGVvKlcpvLM82r1YinZ4aWijgVLnGtGrJhplgDPd8n8jwmSh8qKF3vLPF9Tz2Dt32btBUyMT5ff3FGXkDf30MR8MS5x11V/G1gtEWg0fU07JpUAKIedmZcn59AIDwPK6AsSrIsJ05yhpMZ42lCYTQKi7IWPI8SwTQv6WrFqvCIwgZCuGnpCInwhKsMu/Ksa0a21vUdKtePZ0xtQ3St5nIIO+dLgTUKWylAsDeY8Kuf+zIfffoik6zisZUug60NGifO8itfvkGRjPm2py9wezdBlRPOn1hmpR3w6Hc/6WThwxOce+g4ePDvfuELPHZuiVz2uLMTY4opnlXMYqeoI32f/voK5dSnzCseeeQhtu9ukyQb6CrC6AACV030rFg0rL9zWPK8YPP2HaaTybv8rLdGnCS89MrLFEX+hx5oRI0Gylg272yxu71Np9fj4sWLLC0ts7TsJPGrmxVJkmCtRQpBs9lCSslk4mZn+V5ApUtu3bzJYLBLq9nikUcfodVqo41hd2eXq1ev8uhjj3Ps2LH3hhImgap0wQYCMW9UzjKwHhqLySvWzCbtMCRQtapXaaG0WL/2/awgFz7GCPqiINrRTKqYpKzwOhXt0iJ9N6TXXgWtJJQWf9kiTwOJpd+yoAXTwZT02jVGo5xh/hAP3blJ2R9i9bu54IMkf0BKgtAnTmNevnKV0XhCOoudaE5WsLp8jKoqyGaThYKd8OaT0XXdA2ZcIrKu5DvapMaoqqY+1xV4A1mWOv/KOEZJEIQ8+dQThzrzTrvFpz72AcpKMRqP2dnZY28wZDweuybttMBYKN6o3mbnfSqONwEgghZCt7BVji1qiqs16CKpv3Y/V2VT9/ti/74ZC0Wl8AOfx556mht3dvG3dzl+7P7V54N4F83gBzOz7uRarRbLS31ufeEbvPTa6yDgM5/6OO1GRJKmTCdTiixF4MrQZS7wPJ8gjOi02vj9HqpcZufOTeIsRkinKZ3OpkTtmZu/UZV4fsDFixdZP34SKwIGwxH9XpfQD9DG3LdpG6DXblEpNyui0q6/xGJISu10rLXBDwLyomQyjesI0tBrtwg8j0mS0WmG9NpNsqIir/WEjdFgBVZKfE8yjROGe2OKhd6w4O7ekBNrzonqtppuk8JllN7JsD53XNdPYYzBCIOt5W2ldI6FtG6CLAKqosAYRVkULshTFV7gEUYhGkMQ+rSaEQIXhCEtUdgAaWm0fTdnwWqiRsSxtTVKVTGdTms1EEVZVq5KJQRS+m4WANSzHw7JUwREVgAKN67A1A4XkBtsZditPHZVTN+bEqw22G0JZnmLaS9ABj5eo0AXJVmWMExzznXbFHmBbTa4JRWTfIIwik/0Iz75/jP8u6/c4lpyL29YAJcij5/4+Hn+3bNbvFooZKKJmpZbWxuEVhJHXV586fUHeFpi30Ga921Ypzxz/NgKnoS7uwM2Nze5ePY8p0+fwiQJSeICVukJ2lGEEBKjLc0oYqnTpdVoEIYBeZZw7dp1KqWRQQiex2wyoYyK+nlCv9fh4pkTRGFAXhQkaY7E1JNqD6jKvQ2yNHUN6UqhjEUpUzd61+QwIZB1E2MY+BjlMuBGu+GCRmusEBw/fozolE9RVgyGI4y1ZHFMWThnzhiDXlkhns1IJ6Oa4uHs4fmL51lbWybJSs6cO8up42sP8BzuRRB4BJ5zZD3PqY5MRhPWz5/nQ5/8OJ1ej1sbO3zyOz7KjauvsTFM+ZEf/Dh5BS/cHDEZTfjkJz+AymZcvT3g5Zde5vrNXZKtG/zI93yYKmyxN0zotIb8/m/9FjeuXkeVGq+3QjWbUUxngOTuRoaQm5xb8VDSwwXXxs118JwM7/2VWBwELqDLi5IC1wOktaZRarIkR2rNRmUZGTfUz6J5Qc/4b9KCIArIdcqasKQqYcMUBFLyzPEl/vLDJ8hzxT979iY3q5I16aEs7JrKKY0eeH084LLxeN/uNpOf/il46sPsXHqcV8YhZjShz4AoUjyiqoWc5DeDqSUWpdZO/EIIxKK67hozhRD4vueqbMZSlRVpljGZzBgNJyhjUMq4Xqa6siGkBd/NniiKyvWO5CWmYwh8pzplse5dV4ogkLWamlrIds/nBc2nOx8m0JCek6akznhOBwNuXi24cGGF4902z750i7NnT3J1c0JgNbrK+Zn/9Xf4zs9+F3/wxWf5ke//BNu7u0Rr62RVwr/66V/iOz9wkmtjxS/9/G/y7d/5cW5cvcWnPv4EuzsD7uyMsCp3eS0D8WSGLhQYTVoZJ+UbNTGp67sU1uIZSxQcfmDfN4Nrtg/YHexRlA/enzGfv/F2cziU0nz9a1/n7tYWS0vL73g/vR/mn6uVpshyrl+/RrvTptvtsrK6ShREpEnKdDJjNBrRjCKiIKDbahKFAWmaEvo+xipGkxHT6YzReMSJk7eYzmZ4vke312P9+Dqz2Yzbt2+yurrqKsXv8nqsLSHXUE1dNcNaUBYbg+hpTCroG8kJq1iRPrLehi24fg4FaAuVQHoFopthTsSUjQqzMiP1A+xEoHcsYmQRDQmXBfL/195/B9mZpel94O+cz15/86Y3QCYS3hQK5V2X6ao2093T09PTQyeJXHJExmqD4pCSdoPcpUKxSzIoGlEMBU2sJEqihmOoIYcSp3tmuqfdtC3vUQWgYBNI76//7Dn7x/nuRaJsVgG9lEL5RMAkcPPm/dw5r3ne5wkEwtYIH1QAndTm+qpkfxixuraNk5NMHThD+cWIE81rvFMzs56fDL0YNSvmCUMRKxQL3HP3MZ5/5S2uX71KfWMTKQSjI6OMToyzsrxEqkEnJvlKEMie+bMWOLaDQOC6Hp7vobUiCAMa9TpRHCEy5TmtdDY4bgpu0pLk8zlmZ2d3eY3M/e06NmMjQ4yNDJGmiiCMaLU7vPbaWeauzvVZOD1a9s3cSt/8q1Lo1gY6bpsT3/uPXgjfv580WRegf/46nS7PPf8qrQfu552VLpuXzjGQS/nMZ56kXCzu+mrcRkfj1mzRnHyHqfFRhgdrpEnM6soKV2/M0+wELK+s4tk2J87cbfhlQuB6Pr7vUygUyOfz+H6ONI147tnnePm5HxJ3GwigUhtmcGTMaFXHkXEeHx1idnqcNDVmgb4j8V0bKdiVxrxjGw4dmRO3ytSiNpsdOmGE0gLXsWk2W6xtbJGkmlzOxbEtUstiu9HAcwZoBjGNdocoUYhsRkVrhWVZhGFE2O3SaXXMjSONssmNhVWGa1WmJ0ZJleL8leuEYcw9Jw9/4vb0zuBdipRkRyVAo0yAmWXhWmmS2CQa3aBLsVgkiSNczwVL4Bfy5EsdY96UKhxhYTkW0jEt4HzODFkKrUlVQrFYwLYtYm1uVJXEqCRF2WZjNi1zs/kmqTGR29UxhRpHgY40QhplGS0laVMibYUKBFtRlyDqgkrpRhEpKXk/NOpB2hgNWkox5nlM+pKc0LhpRJrYJFrjasVfenCWL//jv0r7T/91/snz87d+CCH40sEB/tJ/8Z8w8Hf+O/7a95eJWgsU7zrI6QN3oy9fwYo0vvdJqn3Z4oBR0hFCUi0XOHP8IJevL3NjfoGl1VWGlpZpNFtYAk4ePsChA/uZGB81lW/bJu/75HIudjarVG+0eO2tS/zoJ8+xvLqKLWFm3z4Qmm7HqEqVi0VGh6qUC3karRZBEFAuFZFoHNtmN+6i9548RKsT0O4aT4vN7SYa6GTiB0G3g+V4ZoCuY/xueqZWCAutFDqNKReMolyzE9ANYnNONKShoUdpDUGjYe6rvmqHqTQrJHGcsG9ihPGRmnnu4rg/ZPtxYLoZYFsWrmt8YOJOi7XL77B51ZiJuuUqaadJrVbkW//b7xI//Qjt1KXRaKLSgFoO/qff+EOUtFlZmOfwsWN8+SufJbI8fu23vkFjY4XyF59iY30Nx7VNgUMrhO1TGBhEY6PTxMxceRGqkw0ga5BC4TkSx2JXyl0ASbtJEgSEUUCkU2JsVCqIGhHtMGbClgzFRmb1DDZHS0UmK1Xy0mbfoQnSOMQeLLI8lzB7uchCGvP006fwwi6lrS5H8j6lpuavTY6yrVL+34ur3EgTdlIXqsLiL0wc5Od/4d9n9fXv8c7Ll2jVzsCJU4x+78dMrK5Qu3t8V/xlI419k2KltaFEGPaUUYKxrV7Hx1AZmq0mjUaL7XoTlZqOQ7PVItWKVtAliVM8IXCzgcggjmk02gwMdI1Mbma4ZdmghRE0sSzXdOWytUynJnExfO20T6n4KFhSYFua3vhDLu8SNTf5/rd+wKkTB7GkEYVYXdvAy+eZ2j9FM15haXWVzz3zGFeWN/m1X/899u/fz9jYEH/yFx+hHUbcO7TBI//pl1nq+qxdPk9YX+W1l19k+si9VEo+q41NdBQRNbbNs6gVF15/Da00YzM1Umnc6klTXN/FymR4bwdCwF2nT3PX6dO8cfbtj3y96ZBaWJa168RNAEEQsra2ytFjx3bpw/DJYNs2lWqF7UYjW/e6bG1vsr29RblUzgbuYWN9nUq5wvDwEJPj4xnNKkfU6XLhwgVWllcAk6guLiyztrpG0O2Sz5vuRyGf58b1Gxw6eITyLqk3HwopQNioRoxqaaQF+IJ0XUEEuiMZK0iqUlIb1IjUJvY0sgCiq5GJQIeaJJaM+RuMjmyQChCdPLnVApVBn/hti84VQeoLvJrE9jVbXUW3DWVlk8QgkSxtWCQNmyjpsn/I5fB9o8xffZXGhXlsJrCc2xEluVkQF9mfnutx1/EjfPbx+1m4cp3W5hZht0MUdqlvbVLf3iaOE/K5HKVygYHKAI5nOmOFfIHqwEBmslijUinhOi7Xr8/z/e9+n9XVFTrdJqkC1/UZGBik0+kSx6HZpwsFCvnd0cB2GkTeHE+Q5HyPfM5naNAYP1arFbY2t9nY2GJra5soShBZccq2bZI4RqchpJugs3X5I7eOW19Q39jguVcuofMDqLDNRqvLwuIK1WO7vxdvk/R3K9dcCEmx4DMxMojveSilWFpaodkJWVxa5vjhWX7l3/savmsGEm3HxpJG3k9aEoEkTRUj1SKry/NcvXQBncD0wcNMzRzk/PlzFKIyaRpTLRcZH6rSChOTsaYJBd8xtIJdf3zR/1MKgSUllUKORjfA1VDO+7RaDlEcYVkO+bxPPu+TxsYNO9WwWW+z1WiSKI3l+agdfgpht0sax1m3wWS2AO1ul6vzy4wODqC04uKlq3Q7XQ5OT1ItFT5RFaantCWEafELUpKeCgsWWhqKgBZms47jmCiMyLkesqhw3QqpSozzrWPjeja+79Lpds3wqG0qvDnXw3dtHFuiM3112zbzG44QWFKgVUoSmXOmegNJmcZ9j0K1GwR1gZMoLJWQCkiFoeK0upJyARxhUbRdSiIlWVzHKzpUi3ls11Ro7FQiLLB9UEMOORny4IhDAYXcihAqIdAJv/3GVTp/5b/kufPr7/MpNN+9us3+//zv861La0TapzZY4a//p19hc3uFN//bC2xcjBC7lOy9CdEPhjKGmQlmLIdapchAuUChYLp0rVaX+nYd33d5/JF7ePieE8YtHInnWNi2zHigRsIuCEKqlSKNZpP41ZRSscChgwfwfZd3Ls6xtV3Hccww/0AlT8636HQcHMfFz2TxdnM0vudSKZfQShHFPdU4zdpmnbcvXCMKwswI1XRKjKhJRkUREq0TQxvRikYnYG2rQaoFwnIQmlsCiyToGp7qjuuileL61auMDFXZNz6E49pcur6MThVHZiayc7r758iSRtJaWkb9xPwbeNUqw9USw4Nlrs8t8MbLLzI1O8vE5BAr6w2KnqS9XWdkcIB26uPaEl80mD49yXqzw9xSg4uX58i7mvzIAFfn1ygMTVEud7l68TJam7WjNjqMdEynSgrINZaotxv0klGdRNjC+CPY9u7uN085SC1pdNrUWwFxKnEcD3+lQyyMRHLOtVkgxZawqRJ0GuImEa+8eYHCYJG5jWXOL4e81t5iKery937jh3jAAemwIjRPWy5Pfe1+gmab/+7Xf8CNILnlBtKYDtXqq6+wce06jaDMUw8c5L6JIs99P4WFgHrbYjcuK0mcoi3oBRGWtlA913NlNldLGmPMnt9C2I0IMqU/ISFMjCpLqkFIG9u1sVwbjSTOqE9GkS0gjEJc18G2HdC2UYFBGHptHPeLJkoJlDIS7SpTddpNQUVaxhPHdc0AcxQ2OXj8CIvXLnF9boG008LZnOXhR+4mbbc4f+4yn3/6ETbrbf7r/+bX+NSnHsRB8c65d1iZv879Ryc4P1fHDjfxhaZlF3js8fuod0KmjpxmbmGTrc16f82RXp5cpWL2tGz2JJEuWmcJcKaOZ1nitjoaPT+dSqXCV37xq/z+N7/F2tr6B3YmLEsyPDTE0aNHGazVyOVztNpt3jz7FlevXO0PRr/n+wUkcUi72TBU5dtMjj7seKSUTE9P43ke8/MLxGlMuxsQdiOOHT9OHMWgVSZjC5OTU5y66y5GRsbwfY80jXn91Vf5+//VP+C1189SqVY5deokYRiysLDA1NQUrWaTtbU1XM/jrtOnKVfKt92lefmNLvNveXgtQauhKHmKk/skoqVIu5qtBtRjWIvavHNJs7AkGSpbDI5b5ISi0RV0E8HlULBgneUrrb9D56wg70lG4xYPNt7i/JLi8pbm7aZAScmgK3l+I2QjglNFgZVqRjyNTBUrgWLfaMxMZBzUN3OSiwubxLky99zhRNGSknKxyPFDM+yfGmPx+nWUbVEul+i0jTy/EILjx4/y5BOPMjY6QqoVtmWZWalcjnzOM2uCZeP6LvXtw7Qamzz37MvEaxHEEblcnmPHTrC6tsbC4jxgTB4/7tG8+zr3bvepfZOUCgXy+RxKmU7HD3/yMjfW22DnKHuawaLLjbnrRGEEvKsz9L63z3taHb2fimrUzRBrEqHRRGH4QW/yvrhz9r/ZB/VzPvvGhxgZHqLeaHJ49gDvXJ2j3Wpz5OAMdx2ZNhr3OlNK6i0YWaAFZmDn/Pl3WF9bJ0m3qA0McM/pUywvGy6kY5l+Ua1a5oDSOColCgJKeccECx/7U9+E59iU8z451yXnuTRyRubMtqFSLDBcrdINQuI0RSnY2m6wXW8SxUbyTPfmIzLX0l41EiERUpiESgjqzRaNToDWik6nS9Bs0my2GCgXdz0svRNJqrD0zdvDnFaNUJo0AW2ZKqBRnDJUL0sKbFtiFXykJYljQznoL2TCKGYgLaIkIZfLZZUBRc73cB0Hx3Fws19CSsOLzgZN4zRBiEwRrKfMkO4+0Xgx9dGdCi4aT3SZEhpPWFxBkY88FqUil0vpdrc5e7VFtVoEHRIGEXFiko1KwSWWASpNyEuJjCKWIxenE3F33uNKPMzXV9f55h9coPs+511reLuT8J8/e4MY0FaJQrHC9GCOicIAP+g2OdcI+Mxw7WNfs96DLbINU2BUhYrFAoOVEhMjw+TzOSqlMlub61SKRQ7un6RWLeLnPGOkKM2MkxB+//MmSYptWzxw5jjzi6soDcNDg0xNjrKx1SJODb0jiWJyvodtC3zHNvx/S36szVkASIHnufiZfny1VEQpzcXLNxgYqJAoxcriogmoLRuQ+L5H0EkJY02j2eLawjL1ept2u2OSkHdJVPfoUu9e21qNJitrG4yP1khjxcWL1yCNmZ4c6RsZ7haWZWNbGolESBcQpHHC4sWL1CtV5gsVCgMDOH4Rj5hqdZC11TWSgbKhgVmCP/qjH3P3qaMM5xW5cpnf++6LfO8b/5bZY8c5c/8ZVhcXWVleIw4iGo0WaaqRcYLlFfDzPtLL4bselhQEnSZaNW8WoZRGaEMN3W1HgytLFBfnWWt3KHRD8gWPYqlA2AjoRIqNlW2eV4rnw5jtNEJ2Q8TWdpbagLdkEWbc4xjjs1G1LA4i+H8M1fh2GHCuFfLiTy4g4pQkvjW41kADxa+tXeP7/+IfMyxSZg4+xH3xMuOeA4T8eDvmjPKze+PDkSojXyu1Ik0l6BSpZVbI0aarp1RW2EgIwqgvm54kimazSaNRN4PaWiARSNtCaIm55Szi1EhXBt3QUFxcD9t1TSGAbI1TKSrjQ2uliVOVrW8pabbG7aYCbwmjxtszY2vVN9lsdqlO7kd7PkFqU5SaF376MjP7x7h64RJv7RulWirxzGceIOqm/F9/5U+w1Y5wVMDblxb55rd+hNAJX3j6Xl67sMbKtYukqWJmeozluSu065tmGFtovEqVwsggvuURhQlplGCJBoKe47omjiK0SrHk7RngCWGUje699z7O3H033/7Odz/wtfl8ni996Yv8uT/75xgdG6NcKbOxscF//8/+Gf/kH/8T4jihXC7z5JNP8Mabb3B97kZf8rhQLGDZVp+j/rNEPp/n0KFDfPOb3+TG3DxBO2SgXGGgOoDjOYam6Pvkc3kefPBBjh4/Ts7PZ3LJJrF7+OGHyeUKzM7O8tRTT9Hpdrlx4zoAjUaTlZUVqtUqURhwK2X9k+F3Xqvzz364TSHzbhFpwpELFmVLsN8TNKIUFSkWUsW60vgtQW5d4M0rCo6gqwWLQcpakoI6y4z3NoEyzIeK1Bw77vK9q4pvBvupDHyRG4u/hdCbNFWCJSRvRma2wU9TXAGetDjlt5GvXuZyp4zdXuW5liCvy3zxNo/V4CatSGCEiMZGhzl29BBn33wbz3c4ffokFy9e5vrcNYqlEo89+hBf+fIz5PIeZKIltmUZkRjbuM0LadS6oniQ9I99iShM+NFPWnQ6bQqFIkePHWZqeh/1P2rSbjZNcnqbtLde4jEyZGYkemuM57mUBkcR3W2E5TBzYJDZkTxJHDJ/fZ5UfdwZ4B0UKiEg6aCjFlnlkI3N+q7jOLjtRGMHD8yM32FJmdEYhpm7scj0vnGuzi/i+z6HZvdTKuaz6k1G5cnUm/QOetnY2CBf+OynuT6/wI9/9GMUglq1wr6pKeauz9FttlhdXcN3bcaHq5CExFHOKI1Y4pPMgfYhpGS4UuqrSZV8zygJOJqi71Et5nBty5gqBZHhjXfaqCQxw4G9Kks/wchuSIHJaKXVlwFudINMAShFC9OW/5h3Qx9JrMDqUe5Mq7CnkCUEkCoSpdHKKCYgBa5rUyzmCeMI13XpdDrYlpNV2HwaacvQU7SC1Iy4K2VoWEHQpdVuMZgmOLaNZdsIC6LeYDUm4BWZHYJRoDKb8G6Hwf+ajmmLFAtBqGIO4nLA9tm0bWSaECVdFlXMS40Vtt6JiKVFvjCAbXvkfA8VxiA1qxvL5KVNzpJEKiLFpuLkOFMaY11qtlPovFumdQc0EOheV0rRam0zd/0GBddlIcrxVnOdB4P2J7hqO39ithAKi2Ihx9EDk6ysrlPI5xkeqtHY2sBzHYZrFVzHIefnMrqVUdjp3WtKaWxHUS4l7J8cZt++CZbXt3E8j8FqhZNHD9EJIsIoIYpjLEtiWz52wcqqtdlsxcdYEHfSrHqfaWSoSi7nMTk6SKvT5Zxj0W6HFAo+URizf2qU8+cvMn+9Q6PRRtvb1De3SLtd8yy9+2q87+cRJGlKq9VGKU2j3WF7fZ0kCqg3WuSGazfVdncBKSW2hBTTbUEYmQspHOJOkzRWdFpbuG6eze0Oy42UYtFnaWWd0fExrq/W2diuUxse4uKlOoWaojA4hF5eJlcs8cIPf8zI2Ajb6+tEsSJom0F9oRWOJcjnfKSfw5YCkgRfh4g4pPdApUloVN6sm3LBH4WXv/ED3nz7dQqeQycKKUrBRLlEPVI4yuJamvBmGNNWYGpU6pYzHyiT4Gk0NvCV2X187fQRrnzvRR7OF7iiUn49qfPXX7zAgJCsvM+GlgCvqy5Xg5hJKZFBk+Vmi3Zdcb25xGvBeWab9xj6pvPhA7xKK4RKTfFEKpSW2Nk1lsKIVgiRdR1STRhERv2n0WRrexstJMWi6cJZtoOUFkkcm5kBKQiShHYQ0m51aDWalCvFbIbODE9rhDE9TTLHdXomrarvX2OSDN2fTfswWJmAic6CeK0F3Xab9aUGuUoF23FwfI/mRoMgSelsr/D6G5ewvRwHhopMTE3w3CvneePta4yNDNBoB0xPT7I2f4U3zi9T36pTKpdAw9tvnEdKgSWymT5L4BfLVKs1HKGJtESHKXGzjdDGjZ5MwldaEvu2h8HNWjEyOsKTTz7BD3/0I4IgZHBwkDRN2d7e7r9ucHCQJ598kjP33EMun0cIwdDQCL/01a/yja9/g0uXLjMwUOWhhx/k2PFj/Mvf+pfcuDGPEEZpLJfP7dpr5raORwgOHpzlwIEZbly/jlKa4eFhioUc2/VtcjmPUqkMaIZHRvBz+X5BVUgYGR3j1F2n2Nqqc+jQITN7OjbGs8/+hCuXLpuBcds2sYOQPaG924ItFYmWrMeJEUMAlrJ71W5ncUj2DCsBZEU7Hfa3mez/zUzXaqAyAQZNTgj2XYmpR5KNKKTTKdLUPnGSIAT4WtNQMd0epUmDVCk31tdZ//ofMHrVZmQgT0tohv0mvrO7WOGDsTNCzaY2LJvaYI2Txw7w7WqJMPKZObCfJE05f+4CQ7UaRw4fYmxkBNd3sk6eyARbJAITGyJMoSJJE+46fZzP/1ydpZUVLly4iJcpqx0cH2N+YZEL77xDohWbO+7xO4H+3BJQKOSBBkPVHEf21SjnXB555H4ujw6zubHJxsYmje2syPJ+m2JWWEBIbMcywj2pkbnVadCf/UAIrl6+xmCtyuFDM7v6nHfAQLsXXGOCagTlcpHxsRFynstgrcLk+BiLS8sM1QbMMI0wJnsIgdCiNyhvjhWN57jsmxrj0Uce4qUXXqZZb6K14uTRg1y9NsfbZ89y6co1wjg0EqvJAFEUmnkCxzKDfZ/0cDCLf88Z2LjPmpmGJImJ4wTbkhRzHmlszAfTJM28AfStVZReIi2MbrO0bBzPxc/5+L5HvdGm0w3Q0qJQqRqjw1R9ogXSzEJYiLSXYEiESPvdES0lGmUqcXGC1PQ3Mb+QBykJwhjLcbAdF00T23Uo2WUsW/ZpbmQD316qkJgBZmNY5IEFrjK+GypVIFKEMjxq4w5OX2t+N7gQ1wniLQQpaMV14AepQAobiTJqD1EWGmlQaLaSTr9q0ZtJSdOE7X6fxzw4q3ELnYYsx9vEu0x8tAad1lm98gL/zT85xszEKM2giLIdKqXSx75mBkahDKH7z5DjOIyPDDIyVKOYzzE1Ocr6+haW0OQLOTzPM1SOrEtmaETayPBJhVSKUrHAxMggxw9O0epGdLoBEjh5eD/bzRbXF1dY39pGyBkKhbxZhLMuguu6mRHmJ4MGBkpFBkpFhDB/3z85RhSnFPMeliUp5k2Avra+TRxG1NfXiTodTAS5Gx5ptuFqRRxFtIKArUabOIrRStPthjs+ze4yDce2jAdOIgkbLQSZ+3Mc0wkC3LJH2tkmzlXQyicRik6zQxhHbKxuErSbOIUyr567Sqol4bV5KsNDaLvEhXeuYFsu164uEIYxhUKB5vYWxvRNkSYxcRyS92yEAgttpEaze7OnWuNYNgIjHLEbBGHIZhCwGXRRwDpwvdVFCGMoGmfzf8bRRSOtIodsnyipM6cUQrgoFYAQlKTkP7rnBA/+4qdYvLbIyo1tNrsJkYazpDgo4n7rfQc0BCgiHVPXsLp8jdY//ylTh0LmliNsP2U8D7uxBjG8dw3SqAJaWiCE6u8jGkOBU0qTam1EvXtS6q6LbdtUqxUK+WKmiZ8NkAMb9W2SNMXxXKI0JYhi0sz5SunsNyH7+1XPo8h4BKm+Kk1f8nIX65xjW6RaI4TVL061N7cQSZtiXrOxlbLmgE41y9cXKRRy6DRi49Ic11+PcPIl3GiDFJeFi5p9B/fT2tpgfb0N1hpRlJDGxrQwjlJsRxp3dSwsrSn7kqpvaEBFP8/GSgOVBiypGLQxwo2DxHTednnPfSgEuK7Ho488Rm1ggMWlFc6cuZvPfe5z/N2/83fZ3NpCSkm5VGZ29iD5QoHe8yuEZvbAQU6cOMnVq9dIUiOV+8U/+UUq5Qr/6B/9Y9bW1mg0G6ytrBAnMZ6bndefwUB4D4ODQ0xNTlEulRgervHAA/ezf2aGs2ffZHVtDdd1GB4ewfN9euQZIwAi8Pw8J0+cYnVlHdd16HY7lItFHn3kMXSqOH/+HJZl9teoN0B/m02NZ06Pcv2FAiIOeXEj4VqUyTELSHbQZXpx5btxs5CrkdKmXByj1V4jVREdDd+sazSCdjpPe/sfoVSbHkW4+a431Bjh/TDVNJsdPFnirpEqd0/bePuLuNYdNnUUxtLAc11mpqcYGx1hfWOLiYlRcrkcr77yBhNjw4yPDeP5Pq7n3DSqFPQLcKIX1wmBpWyq1Sr33Xeac29f5sYN072v1+scmN3PQw/cRxCEXLt2mQsXL9/Z4+kdlhAUci4Ogn3DJfKeTZKmeJ7N0aMHSdUBGs02V67e4NL5d4ijd1OfNLlCjlwux+jYMLOz07z11jvoNGVra4tGo72TSUWaprzy8us0mrtT27wD1KkdP10IkBa+5zFQLSOlmdKfHB3mzcxoREqZJSSy/z07K6I6GyiulAoM1gaQlmB5cYlOq8nM1IRxzVRw6fIVFpdWmRofJa0kxLHpPHiee8cGwDSQ8z0sIbGkUapSWpOkKSJLKqSUNx8dfTNz7pUdpGVlVQhJsVSkUDCD1LZj0+50qLfaWL7P6MgwSarYarapFHJZK333q0miEkh73Ys06y8ptJV9JimwhTFg0QKkbVMolTIzKjOo7XkeCoW0jbZ7oZAjn8tRLBVJ0pQoM6kBYyIjhMgqgSAsaboa0gTOaZpk9KtMHk5DqnSfPrUb1CbvR8g69dUFWlumlZyiSHW8g172rvdSRk7v3e7wxh3UQ6sQMO7zV7pbZoD940AnNBvrnH31GpcXIp6YyBFtDZLjkwytZTUWYZIgoW8q5jiORS6fo1jMMzI0YKoVqosQCtf1zcBXttABCAu01GhlvBYc22GoNsC+iVFefesKKI1nW4yP1JieHGV+aZWV1W063YBqpYxh4tgIzL2xa2rOB6D3/b3r5LkWjm1RyHs4loVtSWZnJikUC5w/d5lmfQvSeHcNvX5ZzxQrOt2QlbUttlttQ6uxXLbbXRrtDsV8btd7smfbuK5tvBgwz65fHaSzvYpObeJ2C3REohq0oi4qMUP8SiXkasMmQUtCGos3QNpEjS3C+hZJ0MWRUCgVaTcaYDl0trdAgO24xncBSZykhN0Oec9Fp4puXyIahLQywyazfjq77Gg8vf8wpc0mjop5aXWeNZ2QZqcwRu9cvQFQqstaEmFpDUiEXYV4FTDSrhsvnEPpEJEofjNo89OgCwJCrQk/5FnSWSEg0LAVNVmZWyDWBxmrHedwsshxnWDtmG/7IKRZQK+1xtJkjfG0302XUpJKc1yp1pnUssB2DN3BdRwsIcn7HoNDg0hpJKWbjSZREhPFCVIIXN/F9X3T0cUsYGmqUFnAlKY9s8psTVO9bkb2daKywfUPh+3YRKGg29o2YiFIuo1tBAmbuSLVgQGizS3cYpEbF68xMjHK+vV5Bodr+LmQ+tYWiU5I4hivVGP1xlVcz6ZSLdLtRtS3NkljjW0Lwm6HJLFQShhZXZ0SxylBN6DoO2hStNBY3SYiVSAyjxuh8Kw7G6iPjY2SL+SxLMGRw4f45a99jX/zO/+GF158EYDBwRpDQ0PcTDJMYF6pVvnCF36O5194njRJWVleplQs8st/7Jd5/vkX+Na3vsXly1f46U9+ymOfepKRsYk7QDZ6f/SqybmcT6VaNYwBNKVKmfHxcZYWF0BrcrkcY2NjuI6744PcrLSPT0wxO3uAxcVF5ubmGBkZZWb2IM989nNYts3LL71Mtxswv7DA4SNH8Xz/tj732PZb/NUHUsp5j3/9LPzrG5q1OCZQEEhBMzNN2c027Vo5xgYe5FrwR6QqQgPrShlJezSoBjsX9fchJwOCgq357EwLPbTJbCmmWGmSKzYQfPSasDvc2nW3HZvBwSq1WoUwSqmUShTyBUaGh6nValQHytiOxHHsLMbTpngrb3Z7egUHKcH3XcYnhtk/M4Xv+yRJzPyNRe6//wz3njnBwtIy77xzgavXr9+h43nv0eU8m6Gqz8xoGaVMVzVKEqOkFyW0OgFuoYSwbEz/+qY/U7GU5+GHH+DGjQXGR4eZGh9jY32Lmel9LCwu8dyzz1MoFCmXS3SDkDAIGahVsoTlo3EHhsGzsy5Ext/SSAHNRoP19U1arRZSaFqdNhub22gtDKdW9icJ+tAZX12g8X2XocEaA0OjdDodhgbKjA5VGRysIaRRdEqy7kIhnyOJHZJU4XvubQdJO+E6Dq5tUS7kKOTcfsDd6Ya0u8aLoyc5p7XO/A1sbNelWCgwOT7CytoG2/UGp44ewPM8thsthICltQ1UmjA0UGVibBitNZ3AXLiBcuGWBOyjoFKFEqmRexSClAQhbFP1zip+CZqeD4UQ0uhKe8bRW0fmwVFpiu95+LkcEkE+71MbqCItydrGFh26mdeIab1b0gR8UkqENL4jfcPEzNujr+qlNCqFZBcbMMCDDz/A/kOjfO8Pf8iNyyVajW100kakAUpnrtC8z0Dg+0AIH0uOkOh50AoFHxoYffAbgePkmRmusjlQIJgoMRsF7Jv4pLKqPUUMILuHTOvSppWZVB45OE0cGz32MIwz1ZBekiF2JKRGnUtpkyj6vs9grUK1UqSc8xgarFAu5sn7DipJjLGZ6yKEUVTSSpk5m+yaflLs/M7eR/MchyCM+/K5GsVgNU+p6BPHMdfnbLbWVlBpvLNk1jssENoEhUrh53Pk8kU6QZcoDAmjiPXNOs1OF23buH6O7UaLa4urzE6NUcztbmO2LGmGXi2BVhGlapHc6BBO3s0GZSPSJCIJO6g4RaNAGXWeZn0bo+ohSZX5U2tN2twCrYlQpEmEVjGWiNHC5eDhI3Q6HZaXV1FoWu0uYdcm9SNsFGEUms1aSLAlo+ODVPMFkDbOLte4+1rrPDGzn2KrxW9tb/AHScCaVoRakYKhTpiGWnauU7bStH8V03g9e86ggeafLizRrTd5I0n4zU6LTa1IdvkY9V5WlIJ7cpogjLin2sIuWIxO1szAwkcgiVOkJY3xoDSCAIaS2pNjFVg92kdqxsvDKKTdaiIzfnXBzzEwUGVkZBhpm8DBsSy63S6tIDTbrwVIc260NiILGSEVpdiRdOh+ktGjTaW9OY1ddEodx0XEaSYtbeHl83TbTVApzY0NonYXx3GQ3YgwCLh++RpuLk+0tIYMAwrlPL5tsb3RJeqGdLY38fJ5coVBWturkIagFEEksB2PKGwipWtEQlKd0X0lqZZ0E23CuiSh7+wobRzLxpGSO7WtmjmKIkODw8zfmOfg7Cwjo6M8+dRTvPjSS0ZpqVjAdXcWb0yskcvl+PzPmUTjG1//Bq+88gqXL13igQcf4i/+xb9Iu93m9dde4/z5i7z5xms8OTycOYX/7GDbDiMjI5RKBYQQ+J6H67jUBodNcS1N8X0P613O6r2YYWh4mEc/9TgvvfgCc9fmWFhYpFobNB5Bn3ocS1q88srLXLt6hZWTJ9m/f/q2BsIn7p5GVdqIMOWzYZO7782zupgSCsHV9ZD51Qaxgh80QtYSzbtdlXb+PU5DNtbfMr4S2bp969jxhy0OpiBQdm0+O1HmgcEOXf86leIBak+cojYq8bzbS6rejV5MZcmMBpkpxcVRhN+Thw9D4jjJXMGNcIk51Vmcx809rncJbMsln4dCoYDv52k06rRabXK+z/jECNP7p9AaOn2bg48H013aUcjmvdck5znM7h/A9yyCOCGOE8I4phvGtDtGGbLe6JImxlxwZHSEXM6nOlDlwMw+hgYHuDG/iGVbpKni4KyZp56cGGPmwAx3332KUrHA0soa3U6HwwcP0A12Y1R8B4fBeymHwFQCG80Gy0srrK6u0+p0WVyY5+LlaySpwpW99uGtVU+R8dTRRj+4Ui4wODTCuC04eeQgxbzHY/ffzU9/8gLTE2PsmxrHsi1ydo7UMUpKjvPJaB/vfRx6N6Qgn/MYGa6hVLZpdQO2G2026w1arQ5JHKFUipACz3E5cvQQo8M1hmsD5DyHc1euc+7iVWYmRtFa47sOed+j0w2YHBni0P4JlFJ0giirVOqP3R5NVYpIew+SRmcKUxork4CUKGkWJwtDpZLCRqOxpUBpjeu6FHJ5mnaDIApNsJrPk6+UKZaKCNdldXmFKA6xHYFE4jrGKFHaDkiJFhKdPYxaGWlOhelm6CzZ2O0Q0Z9+4l6CvIVSD9L+9CMsLdXZbnZpriywvXDemB7FAWFzxXAI39duL7u+OkSpxm36Igpsq8bI8HEOHCpwdLbAXUeqdKotKkOdj/72j3jv3kUX0vxqNlp4votWCUHQ4frCMt0gzmZ+ZD/R6FHCRKboJDOupeva1ColTh87yIF940xNjqHiiANTo9QqBWrVEjnXxbEd4+EiRZZoWHesK9hLBB3HJkqMa7PGeKlEsaIdRFQHyjiuy2Ixz8bysjFMYmcKpsnl8hw5foTz569w6PA0J08c5qVXztJutwlSzXajSTeIcHN5coUcKZpGq83CyjqH90/sio4opMzU5wSChOZWnWajg7RSpOtiOeZ5cAZKSMfDtsG3ACRKWxQ8gVTGV8TzXQYqRaQl8bwcOd+n6DsM1SpMTY4wNFzjwIEp/ou/+f9leXmVNIrobNdxHRsdCKRQJFGY3RGSfLnA1z57LyODZSIldk0/PHlglLi1hhvn+BLjPJhqNrsxjTTm5ajD1c02yra5GoS0U7WD+tkr290MG3whWdWa3+wGRCm0tfpYyboUggEp+bztcJfTIh1e5sH9Aa2RAm7ZZjeyRkmaILWFZWm0Nmp2trZAS7QWhqopMetOkhAnkQmCVEa18lwczydXLiJcm1zOp9vtoG2oDlZRm9sEYYTEBm2GtI1pVYRMTXDSO+RUm+Si7wqeUajSVJOo3fkFuY6D1jFp2CVfqVKaGMfabpJ0Oug0JI1D4k4HlSYmcRKaqGuGMoXQtNoOQrokUYhxQlG0mw1a9QaSGNuCJNUkRiiRfKlAaWCE9aUbCCFJE0XUCYiDALvTptvoYGW8bLAQtsfQ8AC5nH0HDPt2HLfrMjExxtmzNhMTk+TzBR599BEKhTxRFFEuld/Tle7FC9P7p/mbf+NvUS6X+MNv/SHf+c53OXT4CM88/Qzj4+P83/+z/4x3Ll3mf/ntf8XQ6Bh33XXmjvhPfBCklIxPjOL7rtlDC4aW5/s+GmNSWCqXcZz3DtMLIbAsydDQME99+mneevMt5ufnuXHjBqVSidGxcZ5+5jP4vs9LL7/EC88/R6lUolod6AvpfFwU7/kK6eGTWPkixxtznNzeRm1A1K6TdD3SV99mbW6dr2xa/Gg95p1A0IlTtjSsJopQaQKtiTUoFbPRufge005HGM7KR60PVddh2vN4uOZRre3j6AFJ6UTEwPRhLLuC7X1SSvL74SaDQGZFpXqjycb6NvPz8xyYnTZzXFpx8fJVTp8+avbBTCWxd6p7CXe/OCNBYuE5DsVyiYHBGtKGo8cOcPTYfmrVIlP7himWi6it3QXmO9FLKrtRTLMVkGqVFQjoD6QrIYjTlFo5R6sb0goiukFIN4joBBGtVmBMS7c2SZMIy3F4+JH7GR8ZBsxwfpwkdDsdXnntdaYmJyjkc2iMeeCnHnsIx7bRWjMxOmzOoZRZofmjccdVp8A8OBPjo/iuQ6VcNIZR9XomHfZe/vXOBaB3UqWUlHI5RoZHOHlkP2PDgzi25PSxWU4eP87BqTEGB8uGjpX1QaToGTV93IdP9wP0/ofLHmIhBBPjo9QGKrQDw9VuNDts1Ru02x0zG9IbgE5TyqUSJw/PkPOMfwAaukFE2G6xsrbB5NgwtVIB17aZHh+hVMjjZ1Kavuvc/Owf8xjStDfEKW4NpDVgCbQ0ajpSmEomGO87kU1rG6UWMyilMRKaOc+jXCpSyOcplAp0ux0c18F2HSxpIWybOE76FAIhjeyj0jeL0gr6/GWtNXGqd0UpADhz/zjddp3ZE/fQTaHRUnSVTXO9QbPd4Lnz67z+2ttszb1Dd22BqLtBGnVAJyiVZJ9B02OCKrX1sc7prZBYVo5c6Qj7Zw5QGbN56JEqDx0aQh4bwh/enRHPh0FjukpCC3K5HJPjQ7iOQ7lUoJj3sSSUikWTSPdvE9G/7uZNsg5WNhfk+y4TIzWGahVs28L1C0xPjfPQmRPMTk/huCbJMB1G08kwi+qdCyp63RfHtpDSKGWEcUq7G9Nod9ludQiCEG1JuEV5yFSRbc/lyLHD3HXiCFvbbSYnRqkU8wzWBrjn9HEWV9Z448JlKqUSk2MjeL5Risv7HjnP3fWzZEsTDEudYFnS8PeTFFDQiQBFm62MISqRtqmQ247Esh2anovj5igWc+TdHF6+SLVcolqtUqoUqJRLFEslyoU8XsFnq51y6OQpfvDDl0h1NqtDloxr0zlVSiNsyROPn+SXnrkPx3VIowShd3dMhU8/TNRcI1/SnG6tEWxsIxsNLBnwS3Gb628ss3itySvrklfCiOU0JdaCLa0IlOr1QAFTqZxTCYtRQhlJ9DEz9gEhecTL8+RwhRG3w8SRkJl7a8TSxj521JhLfgSSRJkkAwupMvUtaQorQhsJVpWagXmtFVEYESfGGFJbAstzwJIooSmWi4bG6jrEaUoaJ9jSBIhxHBPHKe0gJJ/EeLZFmkQgrX5nLcmSi5uJhs4SDeMXtJuOBkJjZb+ibof60hJIge072G7OzA05EiltbBSSFB2nqDhGpylpGhOGCco1z7YtzX1rWRLfd8jlPSqlIiMjgwwMVDh2/BBvvH2Z3/rNhb7ioZBGxjnvu4RBG8IEpW0QkCvmeOK+GWMs+7H1HD8YuXyeJE3I53NMTk0iBIyNjTEyMsLy8jLVSoVypWpO0Y7nt9cFGBsb4y//6l+h1Wzy/PPP8+ijjzI9PcPx48f5G3/zb/K3//bf5qfPPk+tNsDAf1xj//6Z25aF/TA4ma9KsVAglzNeCbZtZdQSTblUxrLsD/j55rn3/Rz7Z6Y5d/5tbly/xqFDB/F9n3KlzAMPPcTVa1d59ZVXyOXyfO5zn8+60R//s176zlkGyyGu30WWJyjM3o92rmKLADuMEIdmKQRNJuau8uDZBeo6T5IkrG5uc/byGje2El4JFC91DTMg7e+xN2EJgYXIqM7vL7RiCcG4Z/Hlk4M8/OgsQ/dO0y3lgZSwXqeyfxYhfxbdKDPMnc/lcV2XbhSRKIXv2QRBQKPZZGlppV+46ylw9gvh/Xcx0NkXUkrGhmtMTIwzMTnM0888yuT4CLZlcWB6kunpfdwQu1dq2gmt4aWX3+TGjQWUzhR2yESGHAfb87C9HIcPTiBsSbMdEUURQRDS7YYEYUrc7ZKGXRzbZubwLJVyyQyGZ3HvhQsXWV5eYnhkxNDFsudFyJ4cfUbt/gSzWnc+0RDGSfH08SMcOTzLzL5xJveNMTIyzNTEOLa9uw8phMD1LKamJrn/3rsoFHxQiqmxQe4/fZShgTLFfKE/y2ALgbItLLF72kdvg1jd3CbIjJmy64fWmiQb9svlc3SjhHanQ6sT0Gx36HYDwtAMoBdLBYJWizhSVCpFPNfJhoVgq9FieXGZoFGn3W5hydEsmdCM1KpIeZP6Yt3GImi6BNrQGHSfvJz9kiBTLGE4zAKzsZj5mGxzTBRCQaoStE7J5XOUigVKWTfDLxSoDWk63ZB6vY5KEqLIdBF0v0shsiRGgBamM4/uD1wqxa4rfQDnz69ycKrCaBpQGCyyOeCQSh97ZoBGt87s0Wk+8+g9rG+usXj1GnbYIWy3WV1d5a2356hvd2g352k2VjJai6H2fTIIpDXAvsEZHt9XpZJzqDklwg1FpTpMdXj4E77vzffv1/CFpFgscM9dh9FKUykXOHp4P7mcw2CtmqXVVj8Zvvn90LN/N2ukcQ0fqlUpl4t4npHoq1RKzB6YZP+ESXRv7ZDIzPDn9jbknXQ2jXkWHFsaydEopRVE1FsBjXaXRqtFtxvSajQIOjfVuw4fPYKUgtHREQ7O7usvikmq0AqOHZ4xsrq+SycIOHZwhnKxQBTHRHFMMTNHeu82+EFXQPSlYy2rdz7M86P718c8UmmiSRNN0ucQR2jawEa2KWUqZUL1RnDMNSOrjpHNM1lGQldYoJIQpQVhmqDTxLjTCnj4wRP8zb/yJxgZHyFKwbIUSu2Ou3xxuUVtQNLFY2RykHRkAB11kCKksN7mnukp7m3XeWZ+laWrLZaDmLqwuX69zrX1LjdixVuxYjlJiLUyEs/A5od0D98PthDscy0+P17l6N2jDB4eoOBrok6MNTGGVZ7ZVXKbJsYEzVbGvFNJAVIYaVMp+j5KaaKI44hUg7QdlJDEiRnQdjyLgUrVUIJsE8gYuotjTEujNHutxpIWaZwSi6Qva2tmvAwFVWFmxLVSpDoz7UsSklQb/4RdQmtJ2OkSdjIJUwE9aonIvIrMjI5NoWgKP4VCgXypRKHgU845jI8NMT5coVIqUS4VKJcLFIo5KqUifj6P63vYjo9XfoGvf+N7tOpddBoTBwLpuUbGNk0JIhNAWq7Dpx8/yp/9hfvxXYfgk8VI7wvLssnlcnieS6FQQCMYHByiVCoTBYEJsr0PnnszHhYzfOELX+IPfv8v8dJLL/OlL/8Ctm1z//3386u/+qv86q/+Kv/m3/yvHD58hP/wL/xHd+7Dvw96yn+WZfWXTuMvZQQIBmoD2FlF+MOSnWKhQLVcwXZtbLsXnglqtUE+//mf4x/8/b/H2bNv8MQTT+K4n0xu+IffPk+9GfLQmVFGqtuMN1pYrkCJPIldwapVyI0O4991htGH1xlLQG83ODq3zMk3LrM1v8Ej623qCl7aavGj5Q4bSmNJQUdpOqnpergCKpbFVprwfo0NS0DJttBRQmW0iDucpyE8lla2GekGlEa2kHZIb1bozqB37iXlcpmjR47Q7ETMzkwzMz3B7Ox+XnnlLIWCMUsU2qwv76axv+cKCtBCMDhUZnikytjoIKdPnaRcKoGAfVPjHD4yQ72+8fE/cZZc75scAZ2wsbFJ0A0IgpgkNa1KrTW2X2ClmifVEIaJca0PAqIgQCUJKuyyb2oU27a45+6T+K6bpbgCpVIWFpepVCo8/OD9txTre9euz0D6oHPwIbhjV/CWG0nAQLXEgQMzVCsVSpU8x08cZWb/1Id+uJsHYILvnOczOFhlfHTYbPxS4Hs5xkeHjWmK55qNRYis0Wsq9PJjVGOjJOHspeusbWyZ9jrmxjKBhkQpzdDQAPmcT7PVpt3p0ukGxFGEShXlcom7jx/klZdeZXTfJKdPHDFa7toMil+6ep2l+QUGqhWqZeOk2Ltg9h0csEv7tIcdj4Sm/7VQAmSaCXBkiQCJOV6t+nzEKIwBiet4ONmcSa6QRwnTnhOWTacb4do2WtNPmtI0xbLtrHthzpvSCoQw3ZLUJEFJot7TEv8g/MP//o949N4DPPnQQcYDQT5v4couLRlQdhIqkxOcmR2kHXSIHrsbl4Cktc3y2havvrXEG69fZXN9gfnrN1haXmB7cwGtQrROTUCu3/3IfHA4KqQk51bYPzjAkQELfyDPxhJsBg1OnByiOG6R+8TFl1437ebXUkgq5SK2ZeM4FgcPTJLPefi+dytPVNxyxbNDMtQHI8Nn4bk2xYKPkymHSSEoFnI4ro1lWzsSC9GnTH2cO1MDURwThBGp0iRJipbmuvdUgrTS5HMeaZrS7Ma0gph6q0Or06XVbBEFIXEQGtUpIF8scfLkkSyxMi3i5dVNlhYXSNOYmamxzLcDPNfl9LFD+J5naFq2jWNZH3tF7CUkOd/nq19+jIP7R1jfqLO01WXuxgqNrQYqMLNBvW6ZpkczuXnt0OJmcqN7BqKC3qyJmZOKsufVUHpUGhF1uoRhgOXYqDjCUxFefoAvfOFTlKsVtlsBUpqg1hgmfTR+51vPM1XWDExPc880TB4cBytP3N1C1VzC0gSFcoFCUGd6cZVDNIm6W0Q36my9tMWFrTY/6VhcbIasb4W8E0Z0spmrj5Oye1IwJgUDls3o6Aj+5AhJGNGaa5PT29jT22in+JEVZ0OdkiB1Nhcm0ZZEKoWUAiVkRn0z92Ecx6jUFFk8y0JYNuVCAdcx6l22ZeHYNoHbxfN8Mz+kI2zLMuuZUkRRDMLCojejsXP+QhhaqDKd2l4nw8xp7ELe1gIpNDKjtZoJU7nj/gKdKDPUGcQINPX1Ov1kRAuQEtu1cR0bz3PwfQ/PMyaq0naxHR/HNnKbtusSaUEcpWg0Ok0R0ghoCCCJu3339SNHp/jLf/ppJqcmSKX17l75bcEk4YaWkssKAgIjv14pV5ieOYCfe3+p4/48pBAcO3aMfKFAuVrt0yOllNx77708/vjj/MZv/HqmjPMxucgfE0HQRSnFQK1GIV8ATLElzgwfjcTtR8NQvKCQz+9INMwxj46NUR2oIYWF7Xzy0G1iZpzv//4L/OTaFieG8zw5t87BQzWGjk3RarVwhIWKNE65hFM7AI6NGO0iayMM7ZtkeHWJ8cUN7KTBXZcWOP2iTcuSWF7CDzYTvr8RkqiUSCs2E/WBd40C0hQ6WtCImpS2bjA2YUHRIpe2CJbP4k+fwvEKn/hY3wuzMgsBjutwcHY/a5sNRoeHGR0Z4aknHmZ1eY3pmalMuCj7tj7R5X1aGmCoTEKQz+col4tM759kaHgQxzNGnKVSkdpghdrgJ3N2F0JwYGYf+/dP0e0GBEFIvdFmu96g0+mysbHJVr3F9naTJNXGLDdJzFxhGFAo5pg9eZhjh2bwXON71jsAkXVjDsxOo1JFbaCaFaHp//+7P8vHxR3uaNAPfFzbZmpynEI+R6mQY2J8lGKxgBZGD9rgXdnJTmjDbVRJTKVcMAuTljg2DAxU8F0na0WahEBmow0IgRa7dwf3XYeH7z7GZqPJysY2rVaHdrtLtxsQxyFhHFF3LIJul1a7QxhFJLHhLVcqFR66+xgTwzUccY8ZnK722lHmGOIwoFjwefDBexkfHf6ZtW+TNMXKDKiSLAgwvzRaGy6dUsLIn0qJEgKJIkUg0aRJQqxSbNfFcRyiKMS2HKRt4zoekTCuu77v4/s+QpsBYksaQz6lNWkUZ4OhCqVF3y/DKHXRH7zarY/GcMXht3/3O/zeD77NidnDPHz6OKf2j1MasXFKEle0aLQS7GKFwdoQthXhj+SZPjDAqePjpL9wP9vNgM3NLj/64Yv80XNv0m02sAt5Ll6eY23uLEqFaOI+de7dlZdeUG/bFWRhCDkouF4Z4PDwGHmvgNJdrl2v41brHDr84R4AH41e6dsETbmcjyWNhHC5VEJnevY3lzvRD0huvacEZFLGaZpAZhRpSWk6flJTyPm4rpvRmqwdP7ufmu7+Y2vN6voWixvbRHGCkNJ4z2hzHFFsvFbGhgdJlaDZ6dLqBrS7oaEfhiEqivAdm64A6XqMT05QrZT6n6LeaPH6G2+hkphiIW9mSrL2o8wMA83j39sRPsFiKIxPg+VY/Nk/9UXkn1SQhnRjxdzyNu/MrXDx2iJnryzz6uuXaaxv0tneImk30b2gshcE9WtFPQKYzmYQBD1yr+gHlabTFjcaaA1JaByFtUhxhcMP3ryOnS9ycLJKpehiWxauLTm0i2MSA2N8843X8S7UeXO8yqcOrXByZpDygIfMW1gyR7ORkBamcI9PYcs2hXgN/8A6hZkug5uSk52EpB1y9dk5vn9hnuWcoOgL3mjGvL7ZNZ1hev24Wx+gm5uVIJA2a1RYaFc4HCTUxj3CTotk+TLx/Jt4R4dBfvgzlMRJNgwusaQyUuRKmsRWCpRQpGi0NrLjaZLS7XQQChykoRlklWXbNlTVVKmsOKTwXI80UbiOg8QMn8dJjLDsLBQXpi/aS7Z6s2epoYz2EoyeEtVHIVWKvKc5fnQfni1pdQKCKKbdDkmj2CS1/Vf35NOze0tn51sJkiAlDlI6rQho37z9tegXVHrXRqMzyU5NFMQgUjoqpS0laRxia6gODfD//I+/xsP3HCYRklTf2WBBa00YhoyPjzM0NNIvtbiuw8jkJKdOnbol0P4gdLtdJqcmeeihB2+Zw6pWq3z553+eH//wBzz04EP8LJMMACsr1O0c+k6SmCROKBSKVKvVD/3+3vEnaUKSJlQHBnAcJ1PbMq/x/RxjE+OYpeSTU1sf/tIvUAhTrq+tcn5F85s/WuKeS2scXIg5fO8Y46OCuLNE8/o1Yqokto2f07iuwi5U8A5X8Q9HpGGbY3e3OfZUC7sEbKxz4IUOhZc2SNnirfUW60FEIwpJtaJgWcy6rhEbEJptrQmihHYz4rmfLhO+sMpTn9ec/MKXcIsFos72roRePi5659SybEZGhhiolMkXcriuw4mjhzl86BBTExPmHIsPunN6V+zWIqHtOFQrFYaGB8nlXCzbGNQ6jkM+5zM7M/WJP7fKZLjzOZ98zmdwoApiEqU1nU7Ad77/U+pbDVKt0GlqDKRjU1i1rAL7JscpFbJY+l37oxCCI7MHMkZPdoLuYJx6hxMN3f/dcOQTEpUiERSK5ZvuhNnnN8ei6Yks9i5ZTzJwZXWDer1JHCdmb5YSnVWppNDZUE4vKOq71e36/PROdinvU8r77B8dIk4VURzT6QZs1Zu8ce4SQRDQ7Zgkw2weGsd12TcxyshgFSEkM/smAFDqZsVFac3Rw7Pk/Bzjo6M/U45omiqElqQ7vTM0/Wqylsps0JkBU4/aJYVApQlxHJMkCXESEycJnuNiCRuETZoFuELaJImRq7WlRRQmdIKQcpqikpRME9RQS5RxTkdrEqWM4lTfzGp3icYXn7mLZx7cx+WFZV58/Rr/9Pw8Jw5M8PSDJ7j3+EGGKz7h+gpabTC/LBCtmIHhEsNjVUp5G68oGR8ZIjkYcuxQjl/6xdNIyyKSef7wu2/wO7/5B8RRwNyNq0RRl057lTSNs7Z+AcexGRkZpb5dJ+ikWMkKUTrNC29do5Wm/NyJEY7PjNMuVkn1HeAV9O5nDVor0iQlSmPy+TyCzJG0Nw9jrOR63/SeBVlrRRyFRskoio3PCh5Ka8I4pRNE+N2IQsFUi0xC1VtVPz4X28vUy5rNNkEYZYejjfwxRjvf9QvEUUyz1SaIAsIwIo6MF40lYHxshHWh8P0c95w+1ueCCiGYn19k4foNhkZGOHXicH/33c1A5K6fONPMNDQ/KRGWi+O61IoWQ4ND3HV4P9eW1vj2a9fYiGwWry8TdUOSVgPjoy0R2ZpmxrO0mR/LjLYs20HYwlB5sJCYQWWJxhKKJEqNApw28tlSQRJ0uHjxOvlcjpWNAQ5OVCm4knxud3LKf+5XvsLFH/pcOHuds+9c519ciTg+OcXjpw9x6MgEY4MVGhtv0a5vs40mEh7Kq+LIEsWJBHs0wW5HWNsBx4ZH2L9yAMvW5OyY3311nuS1FZI0ZrsV0kwVraxbWZIWRWnhWSYJ6UYJ9TBmHcXFKGX5QpNPjUww/Ng0AkWi013x25I0RWqNshRKCSNqYVloLY2ULfTXNqUUcRybgpXShi+apFmnIyGKon7Cmqo0U64SSMshSY0sZBAEuL6HtFPjlC3MawxD1dBBe74ZSrND6nZ3iUYUJ/h5j3/4N/4vdLohq+tbLNU1b51f4LW3rrC2tsHqxhZbm9sk3Y6RLtdmH9U7NtPeqdu59vdv6ncFQ8bMMGPXhy2SCFCp8YxJQoo2FKtDrLZi3ri4TLFcNLMilsXtEkR3olqtsr21lQ3EG9pRtVI1qod+jt10IRzHZmJ8nLGxMXNs4qYKYblcZnrfFAMfEeTfLoQQhtKWyzFYGzQ0KjLVM2GoqsVi6dZCyHvfBJSi02qT83NUKpX3vFZrDUpn83SfHOe+c56cXeTnfmGcIy/P89xbFv/2Ypv2hcvs++EiT332OKfHu8wO53FEQnPd5vrqJltxG6ecR6LJVxyGR/P4Ik9l/wQDowVsDU/PhNz/+A1ie5VnX1jmuXdS3nhzjbqI2OiuM+04nHFcjg66lCYEG5HFYlezfm6d5xaaLK40+czVOY7cc4ix48ewRuOPPqBdo/esaMwepzBuCwLLspFCUqsNMDY2ZoyLM3XHW9sa7z33/aIfiihK8DwvUzC0kMLqx6NCCDzvkxcj3/d+yNY833eZGB8lWVgilyuSy/nkfJdWs0W73abVavPGG28x8KmH8L0Pptzt/Kx3ErftDG5w60KWJinvXLrGuUvXmJ4apVw4RpymXLuxQKruoWd0crPG0nuvm5es0+ry+tkLLK+sEoSB2awRbNcbXLk6TyGXo3tvQKngQP/9PuFR9IMWgWNZOJak4HvUKiVWNurcWFwCNPl8DoRAJaZFfmVuniiOOX3kAOW8f8tC0lvwatUK1XIJab2X53cnkaoU47Iu+5unlAq0hbYslMJ0PIQZyO09YBoQGb85jmMgUz3KpNyMzrypvkaBcSmW0iKMQlzfpR0a510Pie152VAkGX1EZ12Mm1rzu630AaxcvsQXHz3C/ceqzA7k+PFrS7xw7h3eeucis/umeODUKc4cHuK+RycYLBr/iKWL55i/5LDZTLETiScV5X0VSlMF9o2V8Ss5pJ3jwNRT/IlfeBQU/Kt//UdcvLLFj3/4PbrBOkJIKuUh9k1N8qXP/xw53WXurfPUt5u0YsE785f4+lsX2Hy7wfDAAEceOsZd9x++zSu4w9NAQ7vd4fK1BXK+T6VcYnOrzo3FVRzbYaA2gJa9++y99C+tjZlhNwhZXtnA911DM8roJMvL69y4sUwYRgwOVsnCeW6qWH3cREMwPFChXCzQ7gasb28TBBGNZpt6q00QhIRBwNZ2gzAMieOIJElJ4hiVJlgIZmf2cd+pwzQa0wBUy4Us7zLrhG1bFMtljh45RK1a/vBN+zbQCyAFGnRKkkK73WZts86bV1f4o5eu8Pwbc1w9f5VgbZGkXc86Elb/+9GiT4NJUPRssOI0RkTcTCj7Zy/re4iegGqv3CJIE0V9e4uLV68jSXClYKDkkmvtzsjqe+fnmDh0iq/df5LTP36Wn76wyrevLvO7V5qcHJnngakCjx7xmLh/kqbsgCW5vNJgdUsRdhSWBYWCJJ93qY7lGDtQw3MsIkvy2MQJHno8ZnNtg/MvzPPT+UWuNOvU45BqHPGYZXGgYHH3kRob3YQbawGldI25l7/PG5sRc3P38akr04zuG2Pg5GN4fHSVNkmSzFA1k7jVFjI1RRSzXplnQmbrWRwZrnKn3SIIAuh1IrTpXsaxMYhM06xDm71PFCc02y1yeZ8oihHSxs7oBhojC6yUNvYiSt/0CNI9A7/0PUo87w9BoiTDE1PYUnD8hKH+Jl+CZidge3Obn7x+lX/77EXevjBHY3WVxuJ1VLcL/Xslu4cyYQ+yAU6tFMIySllCSCN9nSrzPSo1ne3M/Vdr0KlZ/5XSbG1s89vffpUbK5scmBpipFLEdR0O372r2+4jkaYpvucwe2DGdFbRJElCq93m9Om7qFQrfFCS0ZMUXltd4eu/+285eGC2n2jshOu5FCuVXXVGbgdaa9LEsAFKxTJSmrnRKIppt7sMDY/i5T7Yz6cXf2xsbvL222+TLxYYG5/g3ccfRSGNRoOhoaHbWvv8qMvyjYR9D/lM3Ffl5wdjhvIJP5qzuLy+xT/77ZcpTe3nzLTg6Zkm+ycqDIyV2dzK88NzG0RuAT/ncahVwLEsjk7VOFarkJOQ2y8pHT5EN1nhkVMBR67FRC9dYWMr5cc//B75pMNBC9ZjTRiXKVgRzxx02X96lF9qdTj7xhrv/OQ68+fW+OyfkngH6li58U98rO8PE5solTI/v8jy8gpLyyvMHpgwsRPQardvFvVv6fLf3GffneQnccLZty5w+co1ikWXu+86gfBN4bvZbNNqdmi1Ppm87fsexY57wLIs7jtznNN3Gep+b5xAZ58rCEMsy/qIJONOkiNvxR14ArMT3gt4tKnwLK+sc/HyHJ9/8iEazRaXr1xje6vOH//SZygVC+aARBZcmS/6G7AGojRhs9ni5PFZJsZG6BngbWxuc+niNfZNZQ9iPwXr0RU+vgfAraoW9L/ftixOHZlhsFqimPfxPBcpJEmqWNnYohuEGTUpW9w/4H136+J7O9BKoYWxt9EatKWQ2iQcljIbMVoa7XktTTKQBbc6iYmDgCiMSKOYIIiMAlZ2LeIkRQhDjkjTNAvyLJQWJKkiThRWkqJlgsIEWEqBzoYmtTL0hESlu670AWysrHL9VYGe2MfJYyeYGh3mibuGeGt1i4VGyvdf/DE/eUHx4Gsz/Pyn72Li0DTTd80SxR303CqttSZXL64i5nP4wzaHZkepThcpD1bwHJfxsQIIj//wVz5DlOZ4+dkjtJtdFha3WFluoOKYreVFmnGTpNtmdnaSmcOHOXrmKFevb/H6y+e5cHWd4NwFRqZrsCsyy/tevZu/a5MoCGHmWYrFItIStDsB1xfWODy7PwtsTUXm5rMjbnk/pTTCMgHi1OQ4tmMjpVGwKRaKpEnK0FBtR3Lxbuz+Geo9M77r4LsOgxVDH0yShCCOWd+q89wrb9Oo11FaZVX7m8FerVZhanwI17EZHa699+xomD0wTalcppxp1f8sWupJkkkZSEGiFUEQsrq+zbWFNd64vMxz5xc5f2GR9fllkvoqaXv7A9vqt1aUb6aRWvd+u9l6Ny/trRG9/zPrne05pElKu9uh0WyzvL5FFOUYGqjs6pi2U5uNdo7RySpTZ07yywMVDr8g+PG1lDcXbrB+I+XyjVFmzm1y+swIx86Msu+ePOdWu1y83mVjM+J6C6xuDmtTM1X0OThUYLDs441oBkcFudFxDkwf5f5XXqc1v8Fqs87V+UVGhAAVsbHapJXPMTg5yJnTNaaemmH+8jYXXrzOc39whbHBMmeUT/HUg1nQ+cFIkwQlJZbO/Fg0SARSm+RCKTPzkKCIwsCIVAhjHqaEwHO9bCM2c0U6S7ATZVyOjTCCkYZ2bAdSUFFC6mQKYNJCCyMHrpQmU5rsr23pjiSjT6H9EGhtZtrsbP6tN/OWJCnNdsilhS1evrTG9cUt6uvbBBsbpJ1unzYIAi0UoBBKmX0wUzDTWiO1cUaX0jIUyqzbZgmBjTDd7lSiksh0SbJ9POo2WVtd4dxVl04QEUwNU9hlF2130GysrXHixMmMXgJBECCFoST7H2FKF8cx3/72tzn39gV+9S//ZQrF98qg5nyfKIwJ4ztZFX8vtNYEYYBlWUztm+qLyoRRRJoqJiYm+12OD1tVfd9n9uBBBocGcV1vRyxirkkYhoRhQKFQuC2vMK/ocGFzmI2XS4SnajyTT/jsac1DhzXrFwQXnSF+6/mX+NFKmTde63Bstsjn7jvMfffNcv+nT9Ho2LxxtsFmfYOz55a5fmGErbsOInMFKrHFVFniDbgUxsuUj0Tkxusk9QZ3z5xEtTssnlsgutHi7HLCZlMzcWmbJzqCY/dN8MtfG4SxIeJ8GZ0fQOxSPGh30Dv+0ARBlytXrnF1bp6r127w6EN3s7m5zfUbi7z55jnuuefEjvXog57l7PoITRSFXLo8x9W5OQ4fnMTzMuqb0szNXWdldZ0rV67dweO59VNIKfHeJTcrMHRE70MSjHe//meBO+QMfutFiNOYbhBw5uQRHrznLlrNJlEYMTE2hO87JpDKgiOtd+SI2e6s0pTNjS2GKiXuveekGa7KAjDHcahWitx99xEzK9DrINyScd45Gb6BUoFqqfCeBvTYUJWeapVtyV00eX+2UKkyrshC9z0rLAlYmp4qgbBMkmEqtpBxdNCZYQ2YtmwhnyNJUkMzihO8jPFmBotdHMsiiGNUqkiSlCiOkXGCLSx66jy9TVaplFRBolR/OHh3lT5YSQTffGeTfL3G8EyVY8Nlnv6FGk+rDXKDFS4tufytv/U/8Xs/+TGvnrtKqVjjySfv5plP382Rxw5gS8HW0jo3rixz4aW3eXn5ItXzeYaHS0yNe1T25bCKg+TzExRsm6c++xBhq8XmRgMtPTY3ExZX1plf2uK5BcUbVxKmOvO8sNpl9tAMX/pjn+HLjkeiFaVy/hNeOX3zz4wypVRCFMcMVIsMDZkWeqWU58C+EQoFU/0z11Dt6IOo/vuoxFzPZqNNqVjoK2ggzH2SpDEzByYZGhzo//vNvsjt3cW9SyulwHEcXNfJFjubJE3xHRsr56EzhR4T3GsWltZwLMnk6NBNwYLeZxJGGnd8ZIheZeJn0c0IogQZxzgSoiBidbPO1fkNrs6vcnVhi83VLew0oFp26CifWOZJ4hSU6nP1TTtb9AsPpsvIu5bI3hr17oT7ZvAIhspi53xyBY+872HbFlGckqSabri74MkWKWevzKOE5tTIfoanijyY6/LY/S0a1xw2uxX+2Us3ePXVBb535SL7XpjgoTOTfO6rD/DgAz4qTVhcbPLW2x1ePL/CuY1N2s2AaqGMG8XsKwhyrmCsluPQA+PIB0s0t1psXS2RCo+1rQad+VXqnYDnNjosNZocWG5z6r5xPvdn7ibxSqigSGEojxQffUxpelNkVSmNZSksLLRUpssnAG1eE8fZMLgy3SLXdohj45gbhil+zqzbaWrm09pRaAowwiKJYlI3RWnMWhfa2I4JGswVlDvWOG140Tu6tloL9C7qKVoDqUJbEpUmNNoha9ttri5u8/LFFV48d4033ppja2GJcH0Z1W3cQoLqddBu/j271VLz/6nSQMJOGzUB9MiNN2NZp99JA42VKra3G1xfXDNUQAmlDxjO/rjQWnNj7jpxGFIo3hQA6HY6DFQqPPPpp24qKn3Ac+55Hl/80s/zmc9+juHh4b6ef980Lo65fOkyvudRKt1JL4ZbjyOOY86fP8fzzz2H7/lMTk31Oy4bG2s0m9umWPQhfgO94y8WCn0qa/Y//b91Oh2e/emzrK6u8eRTn76tGY3coQL2pSZvbzv4iyNcWLpIzXI4/tAQMw+UuC8u8szQJN95q86vX2nw3RfW+cn5ZR56dY6vfeUhzjx4nF/84gGuXnWYcBLCIObq+XNcXXU5PDBNODyB7RYZP1PAHxO4Ew7WwTYjpw7hpA5jF+a4+8rbNN+ao77cIqznOHtpixff3GR4okJxcJXFBI7vm+Tp/1cD7+gnPtT3gd7xCxzbwXccTp06huc51OtNFpfWuDG/mK3fPdHxd8e5O/YgbdaAtfVt2u0OM9NTPPnkY3i+2fuQgkazS7PeYuS21Sk/GB+2J/b25Z8Rc/8jcYd6ijczxSiKuHr1Om+fu8jE2DClQo6NrU2GhoZ47OF7EUKjdIIUEqElYCpEvTdIk5jl5WVee/MCKxublIt5ehljt9thc3OTqfFRTp84iGPb3Lo5f1B19jbQ61S8S2XFKGMZPf1/pxlG//MYaKURUpmuAhrjYNVP4jN1k96ZUtmQfc9ITxF1Q6QybqdCOmjoz3SoNAWlsW0by3Gw7ExTvhcwWjeDLaUVQsjMETwzsso24t1Wo0fGJrh2dZPi4gIF3+H7K5IXNkZ5+swBTpYqnBmx+Kf/9a/y+vPv8D/+i2/z0us/4g9/8hz//H85yVd/6TN86eceYPrgLHdNDjI1UWBrdZ2t+Xmal89z9UqRckWTrw1QObaNVxvAK1cpVQaoDI+h0y4zB32OtsZotpo8dP8B1tdWWd/Y5lt/+ArPffs7/GFtmKVOl6i7xi9+7gv8J3/140oo6vf8qZVJEoJOB0uYJDZNUzrtNoW8mz03ACpL0rPZpCyq0drw2OPIGEjm815fUlolima9RaPR6ssq9zsaokftu71n6NaFzJiqFXI+j9xzgiCKKRXy/dZukiQEYUQYRURRjOvYwPvPWL07+fhZoN2JEShjchZFpAoKhRzjIzWqlRJH9g2yXm/R6gasbzZoNVs0213i0GiVp6k2iiBdo0gnbQk6JU41SZSgotjMMmVqdlKb4XNzgNlslU4RCKTlYXkehaEa1aFByqUCnufh53JYjpMFkB+NfSPDXL2xyfJ6CxBY7jBj9lEeOeZz4NgcRx2fI/t9fnS2xr969S1+tPAW37+wxtdfafPU55/kc08d4/DhYQ4eanHy8AusrGzw9sVVXrjaRCrBdKXCcAHWEo99pTFGZn2skmI6DBGBw/7NOuk7F7lv7gZPLazSCbs8+/oc/9X3L3P40BDRYIFIlHjiiZjP3aM+ckNSWpO1YzN6mkSLFKFMqC1NCRGEoZqkmT+Gik3HwRLSzCcISao0cRxl/kIWSWxoVkkcozVEYUw3DLF9F5WmRjIim0HTpFmAbz6TQvcTjX4Xaxe3axxFYEuiJKTZ6rK8VufitU3Ozm/z3DtzrCyt0lhbJ2pskIZds++8h3L8frh1t9r5TOv+v93sorLjXYWwkLZjJJyVIohSVrc6aH171eVeAP7W2Tf5nd/5ba5fm+PP/fljfYn6ODJzM6urK/1P+7691mwdqNVq7/n33t4yN3eNf/lbv87I8AjFYvG2PveHYWtri+9/9zu8dfYsTz71afZPzyCEYG11leefe47NzS0GB2sf29vr/YZ1h0dG+JU//xc4ffr0rgxIPxDRPLpxkUqrgbN+g6XtFc5GTa690+Khh/KMP51n/Ffv4T+41uXzb97gR69e5NdeXudbP3yF771ygbtPzPCVz93PI4/ex/1PnKAyYLF5ZY5r356nWhjm6rNXuOLmeKvhoacq7K8prFyJ0ckSnxpL2ffAvRSe+BpjwQKTwTJ0mpx4a56F585xtd5Ft1LO/XSBVxciPlXfnbreB+NmUmH2I/NnEsdcuzbPysoG99xzgpPHZrAsC893GRmtcd99p7OZVoXGyijKtyYbOguslFZsbm3z4mvn2Kw3eOiBu5iZnugXmoIgpt5sMzBQ44H77rrN4/lk+HeVYPRwm4nGzfY/2vBT6/U6C0vLJFrj2pLNrW1eee0tlpbX6LY7qFQbiUZhboCbHPObC2C+UODUySOcOHmUyQnDvVRKsbK8yo0bSygtzLBO7zOInZ/nzuLmW38wveRnxWv7uOgPm+94JrQCJXubs0YrSc800cgBYyqy2iz0Ckk3iLEcmzCJyWtNqkBknRKFIFIay3FJM2feJFVYqULH0c3qmgaE0ZbvbTC94aVd7cDAcjNBN2MGqLN23uKnQcrK2RbPv5TwH3zxGGcemGb/wUmeKElOHhrl0tuX+e1/9Sw/Pfc2f+/vvsRv/PoRvvRzT/PlX7iHkZFB9t93nH0n6jQXrtHqhLTPnid+fZ6zC3WiwRKDwyX8XBFt2RQKRYbGa3g5m5GBMqODg6TJKHEU8PSjh6nPXaNxY5WfvrXIf/s7r7ByY/WTXrUdfzcKULbjMlCrUa4MYFu28WtBkERRny0llDYJutCIHR08IYx+e75odPMty+pv5ImOUQLiJMm6gRIzT3Dz59/8TLf/LN2cV5JMjgyhd9ALdwoj9AQLPmzI8WedZAB0wgShFY4lQAt812W0ajNYzAHCOKdGEYnStLohjVaLdjcgSTRBENGMUjqdLlEUoRS0uoEZvO8mWLbFdqNJEpuh4zTTP49TTRglJHFCFKdoleJYEse2sT2bykCVUiFPtZSnVi5SyBldfrHLQKPsOXiqQ2c7YS2NWGx0WZ1f4p2jM3ztrgPcNa2ZPDLIL680+fSPXV768TV+e26Ln770HZ597Xn+5W9M84VnPsszn72fmX1neOiYzelT53ji2jzt7Rbffznk4nrKdzciqjgMzwv2VxSnyoKx0TylA+P4h/eT26pTvXEFrVaZnZvnwbcaNIHLq23+1zeWGK5O8Zl4N5RKkd0vRjpbiYy2qrN7S2p6Kl4qzWRnU0OLipMITUqqDa0vyQQstDQFMpUqhGWZc6s1xjHD0JiEVMg0BaEyw8yezKHuM+Fu0pnAyGd/9NEEYUSaSDphxHazy+pGm1Y3wNIJ45U8TlKm7UnaFY/O5hZJFBoJco1JWnuU1CTNzo1Rm7upNqWzgsT7yRG/+1+08ZHxPbxykVypiOO4CCGxpcS1b988TSnFG2+8zk9+/GM+9eRTPPTwowA0Gg1+7/e+zuLSImMTk3yc9ef91oax0TH+zJ/5sxw5epSB2uAHvu52Ua1W+cWv/hJf+OKXmJicxLZtms0Gv/Y//3N+7xvfYHhohPHxXc4YvA/92vyzIJ/P88ADD9zyb58cDsVcwEytztLSFme31tDdJsGaQG073HdthdEHx6l8cZSx+x7jy49XOPOtV/n9F7f45683+O5PXuOF185x+vD3OTQzxR//+U9x5q5p9v/KBHIlZV+3zcF2m2vdkMU0YmklphukXLm4xmKpy9F9NkcP5Jke96kUZnGKMe7QUWbuPcZ0qwmLq0y3f0xcqFAYq97Gcer3fGXo3AkLi2u88MLbzF1fYnb2AGjN1uY28zeW2De5nyNHDqFUapINZBaz6JsdQPPAo3VKFEXMzc2zvLJCmiZUS8Ve4504jpm7vsji0irDo6PMzOy7jeP5Py7uUEfDUAGEgFptkIcfvJ/7z9yN7djEUczgwAB3HT1AtVw0bpb9b5P0Brl7S7TluNRqQ9RqvRZTL/3QDNaGOHniGKdtl0q53P/+n1k3Y5f430FDg76kZk91BDBRqUBryyQcKMPnzarDPb0vY74XkypIJVg9rwZLorSglx8kmYmVtAwNJtWaKFV0uiFKOrjKXIP+IihvqrP0/9Q323gfhThycGObA+UCb3VX2VjbpqPneX7Rxl/e5nt/OM99/94pHj86wtQDBxmfPcDJoSqvvX6Jf/mjN/n9V17mH/yjn/A///oQpcooX/ri5/jcZx/m3vtOM1PxSQ8dpLMwRzg3z9xKzMJcyHBNEoYJa2qZqF7DzdtURgbIVSoIociVRvHKeYanRhDbl5mZdVhqPMnnvvT0bVy97LyhQVrYMoft+NlClmDZNmPjo1hyHD/nI6QNopde7Oyomb9Y0sJC49wSF2hcVzJQNUmU6zrYluT/H89OX2zhXV/vTDbEDuPKf1dotSMsqXFsYwAqpYXlO3i4WFKQohmxLZQ2HgRRGBkevDAUQ0MjTLKKOYSpohvEdLsxUWwU2uIkQUiIQ9Mx6UYJ3TghjFPCSBnna9vCsSykAMc1yaLn2OR9xxQJVEaL3AXCzU1ySZMDQ1W2tha4utKl1e7yg9cvcD3ax+NRlfumQ+4/MsPY8cN8/vFXuefHr/OTnwp+f26L37v8Cv/g4pv8D79eZXJ4gF/+ymd58slZjp14CM9uMTB6hUvzTS6sxmysNfCshLCV8MJKl6llh+GCzXA1ZeLQOGr/IK5bpHokz31PdSBf4KF3Npn6h2c5eM9+/PJH6+X7nuHuS3lTq1AIkXUlJFIab5PeLFgqpHEAtj28JEZaRrErl8/jeT5KKTO/BKSlMp6b0Gq2ENLQ9UqFIp6fw7JsM0sghInhsy7gTiitjfKVNgo0u2k6NdsJnmeBFniOzWC1iO95TI7WODkzTKPTpd3p0mgGtDrGxynohDTbXYJYEQYxnW5Ip91BWBaxTkFLoiiEJKHTDgBjjhZHIQjjak6aopGoRIFKEJiZLstx8ItFikM1SrUq5WKeUqlAsZjDugO+T7Zt88f/xJ/ic5//AtVqBdt2iKOYb/zu1/nJj37Eww89zKEju+PKvN960achlUp84ee/nNUhfzZrixACz3XZPz1zy7/ncnkefuRRDswe5O6772Zy6pNLmv4sMHrvYaavXKCx1WB4xKGazzO3qAmimLSWY2VTs/G/zXF4qU3lFzycE3czXWzy5+9e4+EfrvCbP93i24sxr7+zwGsXlnj2hbd5/K59fP7Ln+Oee+5j6P82Qm19hf/Pa4tsB/O4nqJeK7KgoR1G2OsJ6x1B57wgV99m9kCOkcOjyMIweBVSXPYdP4C0y8hddm4/GLd+f09xrdsNGKgN8OknH+PM6SOEQcTFS9e4eGWR5aV1mvUGYLoSYkf9oMcM6RfIhcR1PY4eOchU5nBfLuWM8afWNBptFhZW2dzcpljM47k/+3nd/z3ijs1omCl3ibQkA+VK//IqnfK5px/nU488QLGQz+zMbzZGBSZZFP2velXO7BXZa6WUVKs1KpWBm7kFOysAsv+e/2dEuVTOgrWdC6upEksh+y33HqQ0nhsC021wPR/H8xC2YyRJtaZYLFLIF/B8z3RApIVtu0jHIYwjLNumUipSyOVxPM8MU4peEiNuaVworUl79DO1u2u0//RhzoUhZ6cs8Ec4uNkkirsUi2WmBme59OwK9X+1wPrRJvc/Psijd01RvfcYD46OMXj8IPJ3xnjp7UtoHaO0xb/+N9/hu997lqcev48/9rVneODRe6jUpjh2YJHJjRYC8HyHpNul3QppRx0CW0EHgnCDYtHBK44gLd9Q0qozlGddvvpphzBufIKrtvM86B30JfO1RiOEgy1tKhWP3kCT7t3rO5t5/WdHZ/9/c3oj6+FmVD8H29kR+L8nUf/ZbMgf5+t/VwjjBMMyk6RZdVHaYFkSW5g1KBUSy5FYApP0CYEtjeM5ygwYq1QRK20oiamZqYjj2HT2UoUAOmFEFKXE2WvTVBGnmig03jaWEEaNNauSS8tCaZU5VieoZHczGvsP1FhccHH0Nvv8kI1cQjFfxbE0OdfhpbdXaJ3dJj3W4NBDZxg7+jTVjZQvTuV5YOEylW+s8vUrgq1AcmFpm3/869/k639U5qufvYuvfuV+pu99homjHU5tLLA0d4myl+LokCiq0m0miCSlHW+zvbZJq95lYqaAOzmDKI4i7BQ/Ocvjj8yjckDy0RLRn37q8f693IsA+mtebyPJZpi0MutNmphOUZKYbpJt20Z6Ukp0JiKSqpQ0TjMZbmXmEoSRvbSkZSiy8qY/k97Zide9n9nrBYr+1x+FbqxItcSzQCKplvJU8jcpk0EYkqTmfmw0GgTdAImmG8W0woRWNyRKUqIgASFotAMSLdnuBDgSljfrWFLgCkW320ULSaoV3TAhCFLiJCWMYjzLxrXMaIdfKFAul/FyHpVijpLnUMh5uM7tzT72qE2O49yinOS4Ds989jMcO36MyclJarWh/utv9+eZP2/rbT7qh/SDlb4Rr23z+BNP9Aspt0VzuuVH3ZkDsSsTHH78MYq1Ko7nE221UKmH9nP4OUk4f4NgeRsBtOcUpX3TuLNjuPtC7j21wpEvr/Dvb1XZ1kXCMGZ7u0mj3uKdhS2UfZ5Hnhxi6OHHGJlao9JYQbkJ+yslZrY2UZZNGEQo2yUNIuxGm/L+EazhKsJ2Sbub2GOT8NX9kPrIgdHbPNqM2rHjb67rcOjgPmamx+GzD2NbFlEUMjg4wF2nDjI+OsLY2CBSyn7s9L43kQCRFdiLxWJG0dvx0AvNwMAA99xznMmpYQYGKtS3t2/zeP6PCaF/FvIte9jDHvawhz3sYQ972MMe/k+NOyfPtIc97GEPe9jDHvawhz3sYQ8Z9hKNPexhD3vYwx72sIc97GEPdxx7icYe9rCHPexhD3vYwx72sIc7jr1EYw972MMe9rCHPexhD3vYwx3HXqKxhz3sYQ972MMe9rCHPezhjmMv0djDHvawhz3sYQ972MMe9nDHsZdo7GEPe9jDHvawhz3sYQ97uOPYSzT2sIc97GEPe9jDHvawhz3ccewlGnvYwx72sIc97GEPe9jDHu44/n+az2YyopxvVgAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 1000x1000 with 15 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set the path to the directory containing images\n",
        "image_dir = '/content/generated'\n",
        "\n",
        "# List all files in the directory\n",
        "image_files = [os.path.join(image_dir, file) for file in os.listdir(image_dir) if file.endswith('.PNG')]\n",
        "\n",
        "# Define the number of images to display and the size to which images should be resized\n",
        "resize_dimensions = (64, 64)\n",
        "\n",
        "# Ensure you do not try to display more images than are available\n",
        "num_images_to_display = min(15, len(image_files))  # Change 5 to however many you'd ideally like to display\n",
        "\n",
        "if num_images_to_display == 0:\n",
        "    print(\"No images found in the directory.\")\n",
        "else:\n",
        "    # Randomly select images\n",
        "    selected_images = random.sample(image_files, num_images_to_display)\n",
        "\n",
        "    # Create a figure to display the images\n",
        "    plt.figure(figsize=(10, 10))  # Adjust the size as per your preference\n",
        "\n",
        "    # Loop through the selected images, resize them, and display them\n",
        "    for i, image_path in enumerate(selected_images):\n",
        "        img = Image.open(image_path)\n",
        "        img = img.resize(resize_dimensions, Image.ANTIALIAS)\n",
        "        plt.subplot(1, num_images_to_display, i + 1)  # Adjust the grid parameters based on your number of images\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')  # Turn off axis numbering and ticks\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIeXq9XO0eqC"
      },
      "source": [
        "Datasets have been generated for 100 , 200 and 500 seperately"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysClqpyy0B6m"
      },
      "source": [
        "# Training VGG for 100 images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-27T20:17:31.487717Z",
          "iopub.status.busy": "2024-03-27T20:17:31.487327Z",
          "iopub.status.idle": "2024-03-27T20:17:31.524670Z",
          "shell.execute_reply": "2024-03-27T20:17:31.523660Z",
          "shell.execute_reply.started": "2024-03-27T20:17:31.487686Z"
        },
        "id": "5yvGc6dD0B6m"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Set the paths to the train and test directories\n",
        "train_folder_path = \"/content/train100\"\n",
        "\n",
        "# Each class has its own directory within the train directory\n",
        "class_names = [d for d in os.listdir(train_folder_path) if os.path.isdir(os.path.join(train_folder_path, d))]\n",
        "\n",
        "# Create a dictionary to hold our training image paths\n",
        "train_data_lists = {class_name: [os.path.join(train_folder_path, class_name, img)\n",
        "                                 for img in os.listdir(os.path.join(train_folder_path, class_name))]\n",
        "                    for class_name in class_names}\n",
        "\n",
        "def build_binary_classification_model():\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
        "    x = Flatten()(base_model.output)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dense(1, activation='sigmoid')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=x)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Configure the ImageDataGenerator for training data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-27T20:21:47.273429Z",
          "iopub.status.busy": "2024-03-27T20:21:47.273071Z",
          "iopub.status.idle": "2024-03-27T20:53:42.064272Z",
          "shell.execute_reply": "2024-03-27T20:53:42.063265Z",
          "shell.execute_reply.started": "2024-03-27T20:21:47.273402Z"
        },
        "id": "BTm84egH0B6m",
        "outputId": "074d209e-0b92-4b96-bdaa-36c02c81de6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training for class: Cat\n",
            "Number of positive samples for Cat: 362\n",
            "Number of negative samples before balancing: 6545\n",
            "Number of negative samples after balancing: 362\n",
            "Found 579 validated image filenames belonging to 2 classes.\n",
            "Found 145 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711570916.501287      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 8/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 3s/step - accuracy: 0.4938 - loss: 0.9617  "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711570936.761835      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5191 - loss: 0.8871"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711570941.792594      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5217 - loss: 0.8812 - val_accuracy: 0.6484 - val_loss: 0.5867\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 383ms/step - accuracy: 0.7188 - loss: 0.5770"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.7188 - loss: 0.5770 - val_accuracy: 0.7059 - val_loss: 0.5906\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711570961.017522      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 428ms/step - accuracy: 0.6867 - loss: 0.5625 - val_accuracy: 0.6562 - val_loss: 0.5932\n",
            "Epoch 4/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6875 - loss: 0.5134 - val_accuracy: 0.6471 - val_loss: 0.5891\n",
            "Epoch 5/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 407ms/step - accuracy: 0.7436 - loss: 0.5249 - val_accuracy: 0.7344 - val_loss: 0.5545\n",
            "Epoch 6/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6250 - loss: 0.6533 - val_accuracy: 0.5294 - val_loss: 0.8044\n",
            "Epoch 7/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 423ms/step - accuracy: 0.6746 - loss: 0.5584 - val_accuracy: 0.7109 - val_loss: 0.5042\n",
            "Epoch 8/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7500 - loss: 0.4272 - val_accuracy: 0.8235 - val_loss: 0.3720\n",
            "Epoch 9/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 424ms/step - accuracy: 0.7845 - loss: 0.4247 - val_accuracy: 0.7109 - val_loss: 0.5479\n",
            "Epoch 10/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8125 - loss: 0.4178 - val_accuracy: 0.6471 - val_loss: 0.5339\n",
            "Finished training for class: Cat\n",
            "Training for class: Sofa\n",
            "Number of positive samples for Sofa: 207\n",
            "Number of negative samples before balancing: 6700\n",
            "Number of negative samples after balancing: 207\n",
            "Found 331 validated image filenames belonging to 2 classes.\n",
            "Found 83 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711571014.100407      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 3/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 386ms/step - accuracy: 0.5295 - loss: 0.7479"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711571050.326675      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5549 - loss: 0.7680"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711571053.809749      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 4s/step - accuracy: 0.5553 - loss: 0.7666 - val_accuracy: 0.4531 - val_loss: 0.7341\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 386ms/step - accuracy: 0.5312 - loss: 0.6805"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.5312 - loss: 0.6805 - val_accuracy: 0.4737 - val_loss: 0.7439\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711571074.503574      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 397ms/step - accuracy: 0.6421 - loss: 0.6428 - val_accuracy: 0.6875 - val_loss: 0.6200\n",
            "Epoch 4/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6562 - loss: 0.5688 - val_accuracy: 0.5789 - val_loss: 0.8273\n",
            "Epoch 5/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 402ms/step - accuracy: 0.6065 - loss: 0.5823 - val_accuracy: 0.6406 - val_loss: 0.6074\n",
            "Epoch 6/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5625 - loss: 0.6379 - val_accuracy: 0.6316 - val_loss: 0.7440\n",
            "Epoch 7/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 400ms/step - accuracy: 0.6550 - loss: 0.6012 - val_accuracy: 0.6094 - val_loss: 0.6891\n",
            "Epoch 8/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6250 - loss: 0.5143 - val_accuracy: 0.4211 - val_loss: 0.8428\n",
            "Epoch 9/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 424ms/step - accuracy: 0.7167 - loss: 0.5636 - val_accuracy: 0.5469 - val_loss: 0.8696\n",
            "Epoch 10/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7188 - loss: 0.6686 - val_accuracy: 0.5789 - val_loss: 0.6471\n",
            "Finished training for class: Sofa\n",
            "Training for class: Sheep\n",
            "Number of positive samples for Sheep: 151\n",
            "Number of negative samples before balancing: 6756\n",
            "Number of negative samples after balancing: 151\n",
            "Found 241 validated image filenames belonging to 2 classes.\n",
            "Found 61 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711571113.188959      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m6/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - accuracy: 0.4996 - loss: 0.8278"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711571145.198617      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 5s/step - accuracy: 0.5194 - loss: 0.8053 - val_accuracy: 0.7188 - val_loss: 0.5355\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711571146.384614      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 384ms/step - accuracy: 0.6562 - loss: 0.6293"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5s/step - accuracy: 0.6562 - loss: 0.6293 - val_accuracy: 0.7586 - val_loss: 0.4675\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711571175.031345      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 388ms/step - accuracy: 0.6562 - loss: 0.6878 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
            "Epoch 4/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.7500 - loss: 0.5950 - val_accuracy: 0.7500 - val_loss: 0.5275\n",
            "Epoch 5/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 384ms/step - accuracy: 0.7189 - loss: 0.5963 - val_accuracy: 0.7241 - val_loss: 0.5799\n",
            "Epoch 6/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8750 - loss: 0.3106 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
            "Epoch 7/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 400ms/step - accuracy: 0.7621 - loss: 0.5076 - val_accuracy: 0.8125 - val_loss: 0.4280\n",
            "Epoch 8/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8125 - loss: 0.4568 - val_accuracy: 0.7586 - val_loss: 0.4376\n",
            "Epoch 9/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 367ms/step - accuracy: 0.7752 - loss: 0.5181 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
            "Epoch 10/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9375 - loss: 0.3766 - val_accuracy: 0.8438 - val_loss: 0.4327\n",
            "Finished training for class: Sheep\n",
            "Training for class: Diningtable\n",
            "Number of positive samples for Diningtable: 184\n",
            "Number of negative samples before balancing: 6723\n",
            "Number of negative samples after balancing: 184\n",
            "Found 294 validated image filenames belonging to 2 classes.\n",
            "Found 74 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711571209.674637      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2:49\u001b[0m 24s/step - accuracy: 0.5888 - loss: 0.8137"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711571234.224046      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5383 - loss: 0.8424"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711571238.046211      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4s/step - accuracy: 0.5356 - loss: 0.8387 - val_accuracy: 0.5312 - val_loss: 0.7117\n",
            "Epoch 2/10\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 390ms/step - accuracy: 0.5000 - loss: 0.7512"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.5000 - loss: 0.7512 - val_accuracy: 0.6000 - val_loss: 0.6834\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711571250.798737      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 397ms/step - accuracy: 0.6117 - loss: 0.6532 - val_accuracy: 0.6094 - val_loss: 0.6394\n",
            "Epoch 4/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6562 - loss: 0.6257 - val_accuracy: 0.7000 - val_loss: 0.5908\n",
            "Epoch 5/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 452ms/step - accuracy: 0.6699 - loss: 0.5983 - val_accuracy: 0.5938 - val_loss: 0.6632\n",
            "Epoch 6/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5625 - loss: 0.6633 - val_accuracy: 0.5000 - val_loss: 0.6944\n",
            "Epoch 7/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 391ms/step - accuracy: 0.6076 - loss: 0.6695 - val_accuracy: 0.5312 - val_loss: 0.6755\n",
            "Epoch 8/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5625 - loss: 0.6767 - val_accuracy: 0.5000 - val_loss: 0.6867\n",
            "Epoch 9/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 395ms/step - accuracy: 0.6502 - loss: 0.6478 - val_accuracy: 0.5625 - val_loss: 0.6631\n",
            "Epoch 10/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7188 - loss: 0.5501 - val_accuracy: 0.8000 - val_loss: 0.5401\n",
            "Finished training for class: Diningtable\n",
            "Training for class: Horse\n",
            "Number of positive samples for Horse: 258\n",
            "Number of negative samples before balancing: 6649\n",
            "Number of negative samples after balancing: 258\n",
            "Found 412 validated image filenames belonging to 2 classes.\n",
            "Found 104 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711571354.679989      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14:02\u001b[0m 77s/step - accuracy: 0.4643 - loss: 0.7181"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711571357.291683      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591ms/step - accuracy: 0.5419 - loss: 0.8757"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711571362.484510      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 703ms/step - accuracy: 0.5421 - loss: 0.8685 - val_accuracy: 0.5625 - val_loss: 0.6925\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 381ms/step - accuracy: 0.5000 - loss: 0.7061"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 883ms/step - accuracy: 0.5000 - loss: 0.7061 - val_accuracy: 0.7500 - val_loss: 0.5664\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711571372.894466      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 430ms/step - accuracy: 0.4850 - loss: 0.7178 - val_accuracy: 0.4479 - val_loss: 0.7046\n",
            "Epoch 4/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4286 - loss: 0.7080 - val_accuracy: 0.2500 - val_loss: 0.7212\n",
            "Epoch 5/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 431ms/step - accuracy: 0.5426 - loss: 0.6882 - val_accuracy: 0.5833 - val_loss: 0.6767\n",
            "Epoch 6/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6071 - loss: 0.6630 - val_accuracy: 0.2500 - val_loss: 0.8170\n",
            "Epoch 7/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 430ms/step - accuracy: 0.5006 - loss: 0.7044 - val_accuracy: 0.5729 - val_loss: 0.6901\n",
            "Epoch 8/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5000 - loss: 0.6938 - val_accuracy: 0.5000 - val_loss: 0.6985\n",
            "Epoch 9/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 440ms/step - accuracy: 0.5551 - loss: 0.6859 - val_accuracy: 0.6875 - val_loss: 0.6824\n",
            "Epoch 10/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7812 - loss: 0.6750 - val_accuracy: 0.3750 - val_loss: 0.7336\n",
            "Finished training for class: Horse\n",
            "Training for class: Person\n",
            "Number of positive samples for Person: 1701\n",
            "Number of negative samples before balancing: 5206\n",
            "Number of negative samples after balancing: 1701\n",
            "Found 2721 validated image filenames belonging to 2 classes.\n",
            "Found 681 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711571417.140117      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521ms/step - accuracy: 0.6186 - loss: 0.6734"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711571462.277415      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 563ms/step - accuracy: 0.6187 - loss: 0.6730 - val_accuracy: 0.6369 - val_loss: 0.6182\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/85\u001b[0m \u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 386ms/step - accuracy: 0.7500 - loss: 0.5503"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 133ms/step - accuracy: 0.7500 - loss: 0.5503 - val_accuracy: 0.6667 - val_loss: 0.6861\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711571476.328152      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 424ms/step - accuracy: 0.6623 - loss: 0.6200 - val_accuracy: 0.6354 - val_loss: 0.6155\n",
            "Epoch 4/10\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - accuracy: 0.7812 - loss: 0.5221 - val_accuracy: 0.8889 - val_loss: 0.4870\n",
            "Epoch 5/10\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 428ms/step - accuracy: 0.6856 - loss: 0.5949 - val_accuracy: 0.6473 - val_loss: 0.6047\n",
            "Epoch 6/10\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.6250 - loss: 0.6696 - val_accuracy: 0.6667 - val_loss: 0.7906\n",
            "Epoch 7/10\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 423ms/step - accuracy: 0.6648 - loss: 0.6126 - val_accuracy: 0.6503 - val_loss: 0.6055\n",
            "Epoch 8/10\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.5625 - loss: 0.6710 - val_accuracy: 0.6667 - val_loss: 0.4902\n",
            "Epoch 9/10\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 424ms/step - accuracy: 0.6807 - loss: 0.6015 - val_accuracy: 0.6562 - val_loss: 0.6038\n",
            "Epoch 10/10\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.7812 - loss: 0.5761 - val_accuracy: 0.7778 - val_loss: 0.4347\n",
            "Finished training for class: Person\n",
            "Training for class: Motorbike\n",
            "Number of positive samples for Motorbike: 263\n",
            "Number of negative samples before balancing: 6644\n",
            "Number of negative samples after balancing: 263\n",
            "Found 420 validated image filenames belonging to 2 classes.\n",
            "Found 106 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711571644.799887      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 4/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1:02\u001b[0m 7s/step - accuracy: 0.5460 - loss: 0.8535 "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711571666.021081      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5414 - loss: 0.8163"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711571670.660013      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2s/step - accuracy: 0.5432 - loss: 0.8122 - val_accuracy: 0.6146 - val_loss: 0.6784\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 387ms/step - accuracy: 0.5938 - loss: 0.6796"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5938 - loss: 0.6796 - val_accuracy: 0.9000 - val_loss: 0.4975\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711571671.847429      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 428ms/step - accuracy: 0.5519 - loss: 0.6925 - val_accuracy: 0.6979 - val_loss: 0.6604\n",
            "Epoch 4/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6250 - loss: 0.6568 - val_accuracy: 0.8000 - val_loss: 0.5918\n",
            "Epoch 5/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 435ms/step - accuracy: 0.6503 - loss: 0.6456 - val_accuracy: 0.7188 - val_loss: 0.6136\n",
            "Epoch 6/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.4086 - val_accuracy: 0.9000 - val_loss: 0.4654\n",
            "Epoch 7/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 433ms/step - accuracy: 0.5889 - loss: 0.6314 - val_accuracy: 0.6771 - val_loss: 0.6082\n",
            "Epoch 8/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7500 - loss: 0.5709 - val_accuracy: 0.7000 - val_loss: 0.7489\n",
            "Epoch 9/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 434ms/step - accuracy: 0.6856 - loss: 0.5801 - val_accuracy: 0.7188 - val_loss: 0.5924\n",
            "Epoch 10/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7500 - loss: 0.5267 - val_accuracy: 0.6000 - val_loss: 0.8626\n",
            "Finished training for class: Motorbike\n",
            "Training for class: Bus\n",
            "Number of positive samples for Bus: 180\n",
            "Number of negative samples before balancing: 6727\n",
            "Number of negative samples after balancing: 180\n",
            "Found 288 validated image filenames belonging to 2 classes.\n",
            "Found 72 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711571717.178711      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - accuracy: 0.5624 - loss: 0.8048"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711571721.619044      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 532ms/step - accuracy: 0.5593 - loss: 0.8010 - val_accuracy: 0.4688 - val_loss: 0.7091\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.7500 - val_loss: 0.6392\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711571722.257669      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 440ms/step - accuracy: 0.5491 - loss: 0.6739 - val_accuracy: 0.5781 - val_loss: 0.7113\n",
            "Epoch 4/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.7500 - val_loss: 0.6450\n",
            "Epoch 5/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 441ms/step - accuracy: 0.6273 - loss: 0.6410 - val_accuracy: 0.7031 - val_loss: 0.6150\n",
            "Epoch 6/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.7500 - val_loss: 0.5073\n",
            "Epoch 7/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 445ms/step - accuracy: 0.7042 - loss: 0.5655 - val_accuracy: 0.7969 - val_loss: 0.4391\n",
            "Epoch 8/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.8750 - val_loss: 0.3703\n",
            "Epoch 9/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 448ms/step - accuracy: 0.7146 - loss: 0.5398 - val_accuracy: 0.7812 - val_loss: 0.5399\n",
            "Epoch 10/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.2500 - val_loss: 0.9993\n",
            "Finished training for class: Bus\n",
            "Training for class: Bicycle\n",
            "Number of positive samples for Bicycle: 253\n",
            "Number of negative samples before balancing: 6654\n",
            "Number of negative samples after balancing: 253\n",
            "Found 404 validated image filenames belonging to 2 classes.\n",
            "Found 102 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711571759.352243      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 6/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 398ms/step - accuracy: 0.5259 - loss: 0.9273"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711571814.755423      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.5330 - loss: 0.8436"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711571817.850344      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 5s/step - accuracy: 0.5327 - loss: 0.8361 - val_accuracy: 0.5833 - val_loss: 0.6850\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 383ms/step - accuracy: 0.3750 - loss: 0.7898"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.3750 - loss: 0.7898 - val_accuracy: 0.5000 - val_loss: 0.7044\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711571819.102821      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 426ms/step - accuracy: 0.4764 - loss: 0.7034 - val_accuracy: 0.4167 - val_loss: 0.7551\n",
            "Epoch 4/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4688 - loss: 0.7270 - val_accuracy: 0.5000 - val_loss: 0.7058\n",
            "Epoch 5/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 426ms/step - accuracy: 0.5224 - loss: 0.6956 - val_accuracy: 0.4583 - val_loss: 0.6964\n",
            "Epoch 6/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5000 - loss: 0.6889 - val_accuracy: 0.6667 - val_loss: 0.6882\n",
            "Epoch 7/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 425ms/step - accuracy: 0.5511 - loss: 0.6885 - val_accuracy: 0.4479 - val_loss: 0.6986\n",
            "Epoch 8/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6562 - loss: 0.6391 - val_accuracy: 0.6667 - val_loss: 0.6800\n",
            "Epoch 9/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 426ms/step - accuracy: 0.6059 - loss: 0.6591 - val_accuracy: 0.7292 - val_loss: 0.6183\n",
            "Epoch 10/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4688 - loss: 0.7020 - val_accuracy: 0.3333 - val_loss: 0.8034\n",
            "Finished training for class: Bicycle\n",
            "Training for class: Aeroplane\n",
            "Number of positive samples for Aeroplane: 288\n",
            "Number of negative samples before balancing: 6619\n",
            "Number of negative samples after balancing: 288\n",
            "Found 460 validated image filenames belonging to 2 classes.\n",
            "Found 116 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711571861.581381      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 398ms/step - accuracy: 0.5793 - loss: 0.6737"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711571903.313635      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5913 - loss: 0.6603 "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711571905.354552      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 3s/step - accuracy: 0.5945 - loss: 0.6564 - val_accuracy: 0.7500 - val_loss: 0.5326\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 385ms/step - accuracy: 0.7188 - loss: 0.5538"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7188 - loss: 0.5538 - val_accuracy: 0.7000 - val_loss: 0.4758\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711571906.622061      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 440ms/step - accuracy: 0.7383 - loss: 0.4880 - val_accuracy: 0.7292 - val_loss: 0.5302\n",
            "Epoch 4/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5938 - loss: 0.6280 - val_accuracy: 0.8000 - val_loss: 0.4710\n",
            "Epoch 5/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 407ms/step - accuracy: 0.7383 - loss: 0.4566 - val_accuracy: 0.7708 - val_loss: 0.6459\n",
            "Epoch 6/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7812 - loss: 0.4679 - val_accuracy: 0.7000 - val_loss: 0.6551\n",
            "Epoch 7/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 428ms/step - accuracy: 0.7398 - loss: 0.4839 - val_accuracy: 0.7188 - val_loss: 0.5852\n",
            "Epoch 8/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9167 - loss: 0.2034 - val_accuracy: 0.8500 - val_loss: 0.2832\n",
            "Epoch 9/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 420ms/step - accuracy: 0.8493 - loss: 0.3243 - val_accuracy: 0.7083 - val_loss: 0.4849\n",
            "Epoch 10/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.4380 - val_accuracy: 1.0000 - val_loss: 0.1366\n",
            "Finished training for class: Aeroplane\n",
            "Training for class: Train\n",
            "Number of positive samples for Train: 220\n",
            "Number of negative samples before balancing: 6687\n",
            "Number of negative samples after balancing: 220\n",
            "Found 352 validated image filenames belonging to 2 classes.\n",
            "Found 88 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711571953.088263      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - accuracy: 0.4937 - loss: 0.7840"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711571958.380502      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 508ms/step - accuracy: 0.4921 - loss: 0.7816 - val_accuracy: 0.5312 - val_loss: 0.6846\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2s/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.3750 - val_loss: 0.6991\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711571982.721479      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 429ms/step - accuracy: 0.5429 - loss: 0.6924 - val_accuracy: 0.5312 - val_loss: 0.6845\n",
            "Epoch 4/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.4583 - val_loss: 0.7069\n",
            "Epoch 5/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 425ms/step - accuracy: 0.5249 - loss: 0.6875 - val_accuracy: 0.5469 - val_loss: 0.6452\n",
            "Epoch 6/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.3750 - val_loss: 0.7084\n",
            "Epoch 7/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 424ms/step - accuracy: 0.5586 - loss: 0.6599 - val_accuracy: 0.5625 - val_loss: 0.6411\n",
            "Epoch 8/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.5417 - val_loss: 0.6586\n",
            "Epoch 9/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 423ms/step - accuracy: 0.6959 - loss: 0.6217 - val_accuracy: 0.6719 - val_loss: 0.5787\n",
            "Epoch 10/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.5417 - val_loss: 0.6585\n",
            "Finished training for class: Train\n",
            "Training for class: Bottle\n",
            "Number of positive samples for Bottle: 294\n",
            "Number of negative samples before balancing: 6613\n",
            "Number of negative samples after balancing: 294\n",
            "Found 470 validated image filenames belonging to 2 classes.\n",
            "Found 118 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711572023.586427      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 2/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 385ms/step - accuracy: 0.4219 - loss: 0.9128"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711572082.153071      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.4845 - loss: 0.8627"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711572087.729426      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 5s/step - accuracy: 0.4881 - loss: 0.8565 - val_accuracy: 0.4167 - val_loss: 0.7417\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 380ms/step - accuracy: 0.5312 - loss: 0.6619"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.5312 - loss: 0.6619 - val_accuracy: 0.5455 - val_loss: 0.6836\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711572088.982528      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 426ms/step - accuracy: 0.5475 - loss: 0.7045 - val_accuracy: 0.5729 - val_loss: 0.6811\n",
            "Epoch 4/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - loss: 0.6830 - val_accuracy: 0.5455 - val_loss: 0.6831\n",
            "Epoch 5/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 420ms/step - accuracy: 0.5927 - loss: 0.6808 - val_accuracy: 0.5104 - val_loss: 0.7057\n",
            "Epoch 6/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - loss: 0.6925 - val_accuracy: 0.5455 - val_loss: 0.6553\n",
            "Epoch 7/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 420ms/step - accuracy: 0.5952 - loss: 0.6641 - val_accuracy: 0.5104 - val_loss: 0.6866\n",
            "Epoch 8/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5938 - loss: 0.6255 - val_accuracy: 0.5455 - val_loss: 0.6681\n",
            "Epoch 9/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 427ms/step - accuracy: 0.6464 - loss: 0.6427 - val_accuracy: 0.6667 - val_loss: 0.6096\n",
            "Epoch 10/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7188 - loss: 0.5866 - val_accuracy: 0.6364 - val_loss: 0.6718\n",
            "Finished training for class: Bottle\n",
            "Training for class: Boat\n",
            "Number of positive samples for Boat: 265\n",
            "Number of negative samples before balancing: 6642\n",
            "Number of negative samples after balancing: 265\n",
            "Found 424 validated image filenames belonging to 2 classes.\n",
            "Found 106 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711572136.108766      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5623 - loss: 0.7461   "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711572159.344049      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n",
            "W0000 00:00:1711572160.500477      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.5626 - loss: 0.7441 - val_accuracy: 0.7083 - val_loss: 0.6221\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 390ms/step - accuracy: 0.7500 - loss: 0.5905"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7500 - loss: 0.5905 - val_accuracy: 0.5000 - val_loss: 0.6290\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711572161.654392      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 449ms/step - accuracy: 0.6431 - loss: 0.6678 - val_accuracy: 0.7083 - val_loss: 0.5174\n",
            "Epoch 4/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8125 - loss: 0.4297 - val_accuracy: 0.6000 - val_loss: 1.0867\n",
            "Epoch 5/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 412ms/step - accuracy: 0.6638 - loss: 0.6294 - val_accuracy: 0.7396 - val_loss: 0.6389\n",
            "Epoch 6/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7500 - loss: 0.6295 - val_accuracy: 0.9000 - val_loss: 0.4935\n",
            "Epoch 7/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 428ms/step - accuracy: 0.6377 - loss: 0.5948 - val_accuracy: 0.7396 - val_loss: 0.5202\n",
            "Epoch 8/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7500 - loss: 0.4879 - val_accuracy: 0.7000 - val_loss: 0.6937\n",
            "Epoch 9/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 425ms/step - accuracy: 0.7162 - loss: 0.5238 - val_accuracy: 0.7188 - val_loss: 0.5661\n",
            "Epoch 10/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7188 - loss: 0.6184 - val_accuracy: 0.7000 - val_loss: 0.5540\n",
            "Finished training for class: Boat\n",
            "Training for class: Car\n",
            "Number of positive samples for Car: 472\n",
            "Number of negative samples before balancing: 6435\n",
            "Number of negative samples after balancing: 472\n",
            "Found 755 validated image filenames belonging to 2 classes.\n",
            "Found 189 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711572206.299000      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m20/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 391ms/step - accuracy: 0.5103 - loss: 0.8133"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711572246.461983      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5145 - loss: 0.8027 "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711572248.436425      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step - accuracy: 0.5157 - loss: 0.7997 - val_accuracy: 0.5000 - val_loss: 0.7348\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/23\u001b[0m \u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 407ms/step - accuracy: 0.4062 - loss: 0.8562"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4062 - loss: 0.8562 - val_accuracy: 0.6207 - val_loss: 0.6484\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711572249.910416      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 416ms/step - accuracy: 0.5411 - loss: 0.6856 - val_accuracy: 0.7063 - val_loss: 0.6072\n",
            "Epoch 4/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5938 - loss: 0.6892 - val_accuracy: 0.6207 - val_loss: 0.6560\n",
            "Epoch 5/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 423ms/step - accuracy: 0.6326 - loss: 0.6430 - val_accuracy: 0.6500 - val_loss: 0.6247\n",
            "Epoch 6/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6250 - loss: 0.6460 - val_accuracy: 0.6207 - val_loss: 0.6153\n",
            "Epoch 7/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 432ms/step - accuracy: 0.6974 - loss: 0.6070 - val_accuracy: 0.7000 - val_loss: 0.6527\n",
            "Epoch 8/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8125 - loss: 0.6252 - val_accuracy: 0.5517 - val_loss: 0.6650\n",
            "Epoch 9/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 426ms/step - accuracy: 0.5832 - loss: 0.6709 - val_accuracy: 0.6750 - val_loss: 0.5888\n",
            "Epoch 10/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6875 - loss: 0.5699 - val_accuracy: 0.7241 - val_loss: 0.5573\n",
            "Finished training for class: Car\n",
            "Training for class: Cow\n",
            "Number of positive samples for Cow: 159\n",
            "Number of negative samples before balancing: 6748\n",
            "Number of negative samples after balancing: 159\n",
            "Found 254 validated image filenames belonging to 2 classes.\n",
            "Found 64 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711572346.335240      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 382ms/step - accuracy: 0.4531 - loss: 0.8992"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711572419.933160      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - accuracy: 0.4669 - loss: 0.8801 "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711572422.802455      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 13s/step - accuracy: 0.4682 - loss: 0.8708 - val_accuracy: 0.5781 - val_loss: 0.8528\n",
            "Epoch 2/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6250 - loss: 0.7638 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 439ms/step - accuracy: 0.6923 - loss: 0.6264 - val_accuracy: 0.5469 - val_loss: 0.8443\n",
            "Epoch 4/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7812 - loss: 0.6363 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
            "Epoch 5/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 440ms/step - accuracy: 0.7362 - loss: 0.5886 - val_accuracy: 0.5625 - val_loss: 0.6771\n",
            "Epoch 6/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6875 - loss: 0.5744 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
            "Epoch 7/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 436ms/step - accuracy: 0.7163 - loss: 0.5697 - val_accuracy: 0.6875 - val_loss: 0.5927\n",
            "Epoch 8/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7500 - loss: 0.4794 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
            "Epoch 9/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 442ms/step - accuracy: 0.7485 - loss: 0.5261 - val_accuracy: 0.7500 - val_loss: 0.5752\n",
            "Epoch 10/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7188 - loss: 0.5969 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
            "Finished training for class: Cow\n",
            "Training for class: Bird\n",
            "Number of positive samples for Bird: 344\n",
            "Number of negative samples before balancing: 6563\n",
            "Number of negative samples after balancing: 344\n",
            "Found 550 validated image filenames belonging to 2 classes.\n",
            "Found 138 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711572458.933041      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552ms/step - accuracy: 0.4971 - loss: 0.7963"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711572466.395120      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523ms/step - accuracy: 0.4991 - loss: 0.7859"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711572468.703270      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 613ms/step - accuracy: 0.4996 - loss: 0.7830 - val_accuracy: 0.4609 - val_loss: 0.6838\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 401ms/step - accuracy: 0.3438 - loss: 0.7488"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.3438 - loss: 0.7488 - val_accuracy: 0.5000 - val_loss: 0.6855\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711572470.035750      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 415ms/step - accuracy: 0.5559 - loss: 0.6856 - val_accuracy: 0.5469 - val_loss: 0.7028\n",
            "Epoch 4/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6250 - loss: 0.5998 - val_accuracy: 0.7000 - val_loss: 0.5800\n",
            "Epoch 5/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 422ms/step - accuracy: 0.6593 - loss: 0.5892 - val_accuracy: 0.6250 - val_loss: 0.6579\n",
            "Epoch 6/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5938 - loss: 0.5560 - val_accuracy: 0.4000 - val_loss: 0.6322\n",
            "Epoch 7/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 434ms/step - accuracy: 0.6162 - loss: 0.6177 - val_accuracy: 0.4922 - val_loss: 0.7070\n",
            "Epoch 8/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4375 - loss: 0.7144 - val_accuracy: 0.3000 - val_loss: 0.6875\n",
            "Epoch 9/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 428ms/step - accuracy: 0.5996 - loss: 0.6635 - val_accuracy: 0.3906 - val_loss: 0.8267\n",
            "Epoch 10/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6250 - loss: 0.6743 - val_accuracy: 0.6000 - val_loss: 0.5558\n",
            "Finished training for class: Bird\n",
            "Training for class: Pottedplant\n",
            "Number of positive samples for Pottedplant: 244\n",
            "Number of negative samples before balancing: 6663\n",
            "Number of negative samples after balancing: 244\n",
            "Found 390 validated image filenames belonging to 2 classes.\n",
            "Found 98 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711572522.264415      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588ms/step - accuracy: 0.4942 - loss: 0.8066"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711572528.404535      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572ms/step - accuracy: 0.4947 - loss: 0.8019"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711572529.868858      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 685ms/step - accuracy: 0.4951 - loss: 0.7979 - val_accuracy: 0.4688 - val_loss: 0.7129\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 380ms/step - accuracy: 0.5938 - loss: 0.6756"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 422ms/step - accuracy: 0.5938 - loss: 0.6756 - val_accuracy: 0.5000 - val_loss: 0.6867\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711572535.223115      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 437ms/step - accuracy: 0.5191 - loss: 0.6958 - val_accuracy: 0.5104 - val_loss: 0.6921\n",
            "Epoch 4/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8333 - loss: 0.6647 - val_accuracy: 1.0000 - val_loss: 0.6227\n",
            "Epoch 5/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 436ms/step - accuracy: 0.4794 - loss: 0.6959 - val_accuracy: 0.5417 - val_loss: 0.6854\n",
            "Epoch 6/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6667 - loss: 0.6817 - val_accuracy: 0.5000 - val_loss: 0.7250\n",
            "Epoch 7/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 413ms/step - accuracy: 0.5585 - loss: 0.6882 - val_accuracy: 0.4896 - val_loss: 0.7102\n",
            "Epoch 8/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6250 - loss: 0.6595 - val_accuracy: 0.0000e+00 - val_loss: 0.9641\n",
            "Epoch 9/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 448ms/step - accuracy: 0.4975 - loss: 0.7028 - val_accuracy: 0.5625 - val_loss: 0.6835\n",
            "Epoch 10/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5625 - loss: 0.6723 - val_accuracy: 1.0000 - val_loss: 0.5530\n",
            "Finished training for class: Pottedplant\n",
            "Training for class: Tvmonitor\n",
            "Number of positive samples for Tvmonitor: 272\n",
            "Number of negative samples before balancing: 6635\n",
            "Number of negative samples after balancing: 272\n",
            "Found 435 validated image filenames belonging to 2 classes.\n",
            "Found 109 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711572577.617179      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 4/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 399ms/step - accuracy: 0.5371 - loss: 0.9297"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711572581.408187      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568ms/step - accuracy: 0.5546 - loss: 0.8453"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711572585.768620      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 671ms/step - accuracy: 0.5543 - loss: 0.8398 - val_accuracy: 0.5625 - val_loss: 0.6721\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 383ms/step - accuracy: 0.6250 - loss: 0.6559"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.6250 - loss: 0.6559 - val_accuracy: 0.7692 - val_loss: 0.5718\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711572601.187788      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 430ms/step - accuracy: 0.6280 - loss: 0.6724 - val_accuracy: 0.5000 - val_loss: 0.6854\n",
            "Epoch 4/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4688 - loss: 0.7277 - val_accuracy: 0.6154 - val_loss: 0.6074\n",
            "Epoch 5/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 431ms/step - accuracy: 0.6130 - loss: 0.6178 - val_accuracy: 0.6042 - val_loss: 0.6601\n",
            "Epoch 6/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5000 - loss: 0.7205 - val_accuracy: 0.6154 - val_loss: 0.6381\n",
            "Epoch 7/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 431ms/step - accuracy: 0.5477 - loss: 0.6822 - val_accuracy: 0.6979 - val_loss: 0.6172\n",
            "Epoch 8/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5000 - loss: 0.6805 - val_accuracy: 0.6154 - val_loss: 0.6700\n",
            "Epoch 9/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 424ms/step - accuracy: 0.6295 - loss: 0.6252 - val_accuracy: 0.6458 - val_loss: 0.6078\n",
            "Epoch 10/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7188 - loss: 0.5335 - val_accuracy: 0.4615 - val_loss: 0.8468\n",
            "Finished training for class: Tvmonitor\n",
            "Training for class: Dog\n",
            "Number of positive samples for Dog: 410\n",
            "Number of negative samples before balancing: 6497\n",
            "Number of negative samples after balancing: 410\n",
            "Found 656 validated image filenames belonging to 2 classes.\n",
            "Found 164 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711572646.460872      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 8/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 391ms/step - accuracy: 0.5361 - loss: 0.7658"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711572694.112199      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5232 - loss: 0.7370"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711572699.521955      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 3s/step - accuracy: 0.5224 - loss: 0.7358 - val_accuracy: 0.4938 - val_loss: 0.6950\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 403ms/step - accuracy: 0.5625 - loss: 0.6915"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5625 - loss: 0.6915 - val_accuracy: 0.5000 - val_loss: 0.7055\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711572701.025577      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 415ms/step - accuracy: 0.5049 - loss: 0.6936 - val_accuracy: 0.5063 - val_loss: 0.6917\n",
            "Epoch 4/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4375 - loss: 0.7054 - val_accuracy: 0.5000 - val_loss: 0.6877\n",
            "Epoch 5/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 434ms/step - accuracy: 0.5103 - loss: 0.6916 - val_accuracy: 0.5938 - val_loss: 0.6667\n",
            "Epoch 6/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6250 - loss: 0.6601 - val_accuracy: 0.5000 - val_loss: 0.6917\n",
            "Epoch 7/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 427ms/step - accuracy: 0.5396 - loss: 0.6947 - val_accuracy: 0.5188 - val_loss: 0.6932\n",
            "Epoch 8/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4688 - loss: 0.6949 - val_accuracy: 0.5000 - val_loss: 0.6947\n",
            "Epoch 9/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 439ms/step - accuracy: 0.4829 - loss: 0.6935 - val_accuracy: 0.5250 - val_loss: 0.6930\n",
            "Epoch 10/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4062 - loss: 0.6934 - val_accuracy: 0.7500 - val_loss: 0.6927\n",
            "Finished training for class: Dog\n",
            "Training for class: Chair\n",
            "Number of positive samples for Chair: 380\n",
            "Number of negative samples before balancing: 6527\n",
            "Number of negative samples after balancing: 380\n",
            "Found 608 validated image filenames belonging to 2 classes.\n",
            "Found 152 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711572766.768344      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - accuracy: 0.5681 - loss: 0.6950"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711572775.406732      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 484ms/step - accuracy: 0.5661 - loss: 0.6953 - val_accuracy: 0.5625 - val_loss: 0.6887\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.6667 - val_loss: 0.6896\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711572776.301141      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 449ms/step - accuracy: 0.5216 - loss: 0.6947 - val_accuracy: 0.5234 - val_loss: 0.6818\n",
            "Epoch 4/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.4583 - val_loss: 0.6790\n",
            "Epoch 5/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 430ms/step - accuracy: 0.5617 - loss: 0.6791 - val_accuracy: 0.5391 - val_loss: 0.6776\n",
            "Epoch 6/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.6250 - val_loss: 0.6626\n",
            "Epoch 7/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 427ms/step - accuracy: 0.6542 - loss: 0.6205 - val_accuracy: 0.7266 - val_loss: 0.5977\n",
            "Epoch 8/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.8750 - val_loss: 0.5503\n",
            "Epoch 9/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 440ms/step - accuracy: 0.7197 - loss: 0.5359 - val_accuracy: 0.6875 - val_loss: 0.6185\n",
            "Epoch 10/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.8333 - val_loss: 0.4722\n",
            "Finished training for class: Chair\n"
          ]
        }
      ],
      "source": [
        "# Loop through each class and train a binary classification model\n",
        "for class_name in class_names:\n",
        "    print(f\"Training for class: {class_name}\")\n",
        "\n",
        "    # Retrieve the list of image paths for the positive class\n",
        "    positive_images = train_data_lists[class_name]\n",
        "    if not positive_images:\n",
        "        print(f\"No images found for class {class_name}. Skipping this class.\")\n",
        "        continue\n",
        "    positive_labels = [1] * len(positive_images)\n",
        "\n",
        "    # Build a list of image paths for the negative class (all other classes)\n",
        "    negative_images = []\n",
        "    for other_class_name, image_paths in train_data_lists.items():\n",
        "        if other_class_name != class_name:\n",
        "            negative_images.extend(image_paths)\n",
        "\n",
        "    print(f\"Number of positive samples for {class_name}: {len(positive_images)}\")\n",
        "    print(f\"Number of negative samples before balancing: {len(negative_images)}\")\n",
        "\n",
        "\n",
        "    random.shuffle(negative_images)  # Shuffle the negative images\n",
        "    negative_images = negative_images[:len(positive_images)]  # Balance the positive and negative datasets\n",
        "    negative_labels = [0] * len(negative_images)\n",
        "    print(f\"Number of negative samples after balancing: {len(negative_images)}\")\n",
        "\n",
        "    # Combine and shuffle the positive and negative samples\n",
        "    combined_images = positive_images + negative_images\n",
        "    combined_labels = positive_labels + negative_labels\n",
        "    combined_list = list(zip(combined_images, combined_labels))\n",
        "    random.shuffle(combined_list)\n",
        "    combined_images, combined_labels = zip(*combined_list)\n",
        "\n",
        "    # Split the data into training and validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(combined_images, combined_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Create DataFrames for the training and validation sets\n",
        "    train_df = pd.DataFrame({\n",
        "    'filename': X_train,\n",
        "    'label': [str(label) for label in y_train]  # Convert labels to strings\n",
        "})\n",
        "    val_df = pd.DataFrame({\n",
        "    'filename': X_val,\n",
        "    'label': [str(label) for label in y_val]  # Convert labels to strings\n",
        "})\n",
        "\n",
        "    # Create data generators for training and validation\n",
        "    train_generator = train_datagen.flow_from_dataframe(\n",
        "        train_df,\n",
        "        x_col='filename',\n",
        "        y_col='label',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='binary'\n",
        "    )\n",
        "\n",
        "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    val_generator = val_datagen.flow_from_dataframe(\n",
        "        val_df,\n",
        "        x_col='filename',\n",
        "        y_col='label',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='binary'\n",
        "    )\n",
        "\n",
        "    #Build the binary classification model\n",
        "    model = build_binary_classification_model()\n",
        "\n",
        "    # Train the model on the data\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=len(X_train) // 32,\n",
        "        validation_data=val_generator,\n",
        "        validation_steps=len(X_val) // 32,\n",
        "        epochs=10\n",
        "    )\n",
        "\n",
        "    # Save the trained model\n",
        "    model_save_path = os.path.join('models', f\"{class_name}_binary_model.h5\")\n",
        "    os.makedirs('models', exist_ok=True)\n",
        "    model.save(model_save_path)\n",
        "\n",
        "    print(f\"Finished training for class: {class_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-27T21:06:11.405655Z",
          "iopub.status.busy": "2024-03-27T21:06:11.405248Z",
          "iopub.status.idle": "2024-03-27T21:06:11.476224Z",
          "shell.execute_reply": "2024-03-27T21:06:11.475260Z",
          "shell.execute_reply.started": "2024-03-27T21:06:11.405622Z"
        },
        "id": "53VHmpB70B6m"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the path to the train directory\n",
        "train_dir = \"/content/test100\"\n",
        "\n",
        "# Iterate over each subfolder in the train directory\n",
        "for class_name in os.listdir(train_dir):\n",
        "    class_dir = os.path.join(train_dir, class_name)\n",
        "\n",
        "    # Check if the item in the directory is a subfolder\n",
        "    if os.path.isdir(class_dir):\n",
        "        # Define the path to the subsubfolder\n",
        "        subsubfolder_dir = os.path.join(class_dir, class_name)\n",
        "\n",
        "        # Check if the subsubfolder exists\n",
        "        if os.path.exists(subsubfolder_dir):\n",
        "            # Iterate over each file in the subsubfolder\n",
        "            for file_name in os.listdir(subsubfolder_dir):\n",
        "                file_path = os.path.join(subsubfolder_dir, file_name)\n",
        "\n",
        "                # Move the file to the parent subfolder\n",
        "                if os.path.isfile(file_path):\n",
        "                    shutil.move(file_path, class_dir)\n",
        "\n",
        "            # Remove the empty subsubfolder\n",
        "            os.rmdir(subsubfolder_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbJmSJqU0B6m"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import classification_report, confusion_matrix, average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "model_dir = '/content/models100'\n",
        "test_data_dir = '/content/test100'\n",
        "\n",
        "# Initialize ImageDataGenerator for preprocessing\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Store average precision scores for mAP calculation\n",
        "ap_scores = []\n",
        "\n",
        "# Loop through each model file in the models directory\n",
        "for model_file in sorted(os.listdir(model_dir)):\n",
        "    if model_file.endswith(\".h5\"):\n",
        "        print(f\"\\nLoading model {model_file}...\")\n",
        "        model_path = os.path.join(model_dir, model_file)\n",
        "        model = load_model(model_path)\n",
        "        class_name = model_file.replace(\"_binary_model.h5\", \"\")\n",
        "        print(f\"Model for class '{class_name}' loaded successfully.\")\n",
        "\n",
        "        # Create DataFrame for test data with labels as strings\n",
        "        images = []\n",
        "        labels = []\n",
        "        for folder in os.listdir(test_data_dir):\n",
        "            folder_path = os.path.join(test_data_dir, folder)\n",
        "            for image_file in os.listdir(folder_path):\n",
        "                images.append(os.path.join(folder, image_file))\n",
        "                labels.append(str(int(folder == class_name)))  # Convert boolean to int to string\n",
        "\n",
        "        test_df = pd.DataFrame({\n",
        "            'filename': images,\n",
        "            'label': labels  # Labels are now strings\n",
        "        })\n",
        "\n",
        "        # Prepare test generator\n",
        "        test_generator = test_datagen.flow_from_dataframe(\n",
        "            dataframe=test_df,\n",
        "            directory=test_data_dir,\n",
        "            x_col='filename',\n",
        "            y_col='label',\n",
        "            target_size=(224, 224),\n",
        "            batch_size=32,\n",
        "            class_mode='binary',\n",
        "            shuffle=False)\n",
        "\n",
        "        # Predict and evaluate\n",
        "        predictions = model.predict(test_generator, steps=int(np.ceil(len(test_df)/32)))\n",
        "\n",
        "        predicted_labels = (predictions > 0.5).astype(int)\n",
        "        ap_score = average_precision_score(test_generator.classes, predictions)\n",
        "        ap_scores.append(ap_score)\n",
        "        #print(f\"AP score for class '{class_name}': {ap_score:.3f}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-27T21:08:41.987215Z",
          "iopub.status.busy": "2024-03-27T21:08:41.986753Z",
          "iopub.status.idle": "2024-03-27T21:08:41.993626Z",
          "shell.execute_reply": "2024-03-27T21:08:41.992480Z",
          "shell.execute_reply.started": "2024-03-27T21:08:41.987178Z"
        },
        "id": "XX9tsH-o0B6m",
        "outputId": "aa3c5f0c-887e-4106-c301-e7f8e16f5c98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.145\n"
          ]
        }
      ],
      "source": [
        "# Calculate mean Average Precision (mAP)\n",
        "mAP = np.mean(ap_scores)\n",
        "print(f\"\\nMean Average Precision (mAP) across all classes: {mAP:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQZsTv_m0B6m"
      },
      "source": [
        "# Now for 200 samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpvWJiCP0B6n"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the train folder path\n",
        "train_folder = '/content/train200'\n",
        "\n",
        "# Iterate through each class subfolder in the train folder\n",
        "for class_folder in os.listdir(train_folder):\n",
        "    class_subfolder = os.path.join(train_folder, class_folder)\n",
        "\n",
        "    # Ensure it's a directory\n",
        "    if os.path.isdir(class_subfolder):\n",
        "        # Get the path of the second subfolder\n",
        "        second_subfolder = os.path.join(class_subfolder, class_folder)\n",
        "\n",
        "        # Ensure the second subfolder exists\n",
        "        if os.path.exists(second_subfolder):\n",
        "            # Move images from the second subfolder to the first subfolder\n",
        "            for image_file in os.listdir(second_subfolder):\n",
        "                src_path = os.path.join(second_subfolder, image_file)\n",
        "                dest_path = os.path.join(class_subfolder, image_file)\n",
        "                shutil.move(src_path, dest_path)\n",
        "                print(f\"Moved {image_file} from {second_subfolder} to {class_subfolder}\")\n",
        "\n",
        "            # Remove the second subfolder\n",
        "            os.rmdir(second_subfolder)\n",
        "            print(f\"Removed {second_subfolder}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-27T21:15:18.542242Z",
          "iopub.status.busy": "2024-03-27T21:15:18.541531Z",
          "iopub.status.idle": "2024-03-27T21:35:51.808480Z",
          "shell.execute_reply": "2024-03-27T21:35:51.807400Z",
          "shell.execute_reply.started": "2024-03-27T21:15:18.542202Z"
        },
        "id": "FZN9rZUl0B6n",
        "outputId": "05b1627e-a61f-4f0b-9be7-018e4f2a7265"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training for class: Cat\n",
            "Number of positive samples for Cat: 362\n",
            "Number of negative samples before balancing: 6545\n",
            "Number of negative samples after balancing: 362\n",
            "Found 579 validated image filenames belonging to 2 classes.\n",
            "Found 145 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711574127.402241      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 5/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 884ms/step - accuracy: 0.5273 - loss: 0.7811"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574131.296019      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512ms/step - accuracy: 0.5222 - loss: 0.7661"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574137.395853      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 590ms/step - accuracy: 0.5223 - loss: 0.7644 - val_accuracy: 0.5312 - val_loss: 0.6899\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 393ms/step - accuracy: 0.3438 - loss: 0.7563"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.3438 - loss: 0.7563 - val_accuracy: 0.5294 - val_loss: 0.6874\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574138.662644      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 416ms/step - accuracy: 0.5359 - loss: 0.6836 - val_accuracy: 0.4844 - val_loss: 0.7002\n",
            "Epoch 4/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3750 - loss: 0.7556 - val_accuracy: 0.3529 - val_loss: 0.7069\n",
            "Epoch 5/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 417ms/step - accuracy: 0.6469 - loss: 0.6623 - val_accuracy: 0.5156 - val_loss: 0.8700\n",
            "Epoch 6/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4688 - loss: 0.9322 - val_accuracy: 0.6471 - val_loss: 0.6387\n",
            "Epoch 7/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 410ms/step - accuracy: 0.5538 - loss: 0.7076 - val_accuracy: 0.8047 - val_loss: 0.6521\n",
            "Epoch 8/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6562 - loss: 0.6698 - val_accuracy: 0.5882 - val_loss: 0.6753\n",
            "Epoch 9/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 422ms/step - accuracy: 0.6570 - loss: 0.6303 - val_accuracy: 0.5156 - val_loss: 0.7166\n",
            "Epoch 10/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4688 - loss: 0.7945 - val_accuracy: 0.5294 - val_loss: 0.7385\n",
            "Finished training for class: Cat\n",
            "Training for class: Sofa\n",
            "Number of positive samples for Sofa: 207\n",
            "Number of negative samples before balancing: 6700\n",
            "Number of negative samples after balancing: 207\n",
            "Found 331 validated image filenames belonging to 2 classes.\n",
            "Found 83 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711574192.403895      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 3/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 383ms/step - accuracy: 0.5156 - loss: 0.7867"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574195.657187      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593ms/step - accuracy: 0.5453 - loss: 0.7546"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574199.034521      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 712ms/step - accuracy: 0.5478 - loss: 0.7511 - val_accuracy: 0.5156 - val_loss: 0.7254\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 380ms/step - accuracy: 0.5312 - loss: 0.6835"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.5312 - loss: 0.6835 - val_accuracy: 0.5263 - val_loss: 0.7311\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574200.053993      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 401ms/step - accuracy: 0.6701 - loss: 0.6593 - val_accuracy: 0.5000 - val_loss: 0.6983\n",
            "Epoch 4/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5312 - loss: 0.6950 - val_accuracy: 0.6842 - val_loss: 0.6585\n",
            "Epoch 5/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 426ms/step - accuracy: 0.5471 - loss: 0.6963 - val_accuracy: 0.5312 - val_loss: 0.7081\n",
            "Epoch 6/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7273 - loss: 0.6293 - val_accuracy: 0.5263 - val_loss: 0.7712\n",
            "Epoch 7/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 425ms/step - accuracy: 0.6656 - loss: 0.6357 - val_accuracy: 0.5469 - val_loss: 0.7262\n",
            "Epoch 8/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6562 - loss: 0.5929 - val_accuracy: 0.4737 - val_loss: 0.7639\n",
            "Epoch 9/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 407ms/step - accuracy: 0.7086 - loss: 0.5863 - val_accuracy: 0.5781 - val_loss: 0.7250\n",
            "Epoch 10/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7500 - loss: 0.4971 - val_accuracy: 0.6842 - val_loss: 0.5549\n",
            "Finished training for class: Sofa\n",
            "Training for class: Sheep\n",
            "Number of positive samples for Sheep: 151\n",
            "Number of negative samples before balancing: 6756\n",
            "Number of negative samples after balancing: 151\n",
            "Found 241 validated image filenames belonging to 2 classes.\n",
            "Found 61 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711574238.418736      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m3/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 395ms/step - accuracy: 0.4635 - loss: 0.8472"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574241.748669      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 884ms/step - accuracy: 0.5366 - loss: 0.7779 - val_accuracy: 0.6875 - val_loss: 0.6893\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574244.055770      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 385ms/step - accuracy: 0.6875 - loss: 0.7131"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.6875 - loss: 0.7131 - val_accuracy: 0.6207 - val_loss: 0.6349\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574244.939538      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 373ms/step - accuracy: 0.6870 - loss: 0.6138 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
            "Epoch 4/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.7188 - loss: 0.5545 - val_accuracy: 0.6250 - val_loss: 0.6670\n",
            "Epoch 5/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 394ms/step - accuracy: 0.7564 - loss: 0.5587 - val_accuracy: 0.8276 - val_loss: 0.5386\n",
            "Epoch 6/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7188 - loss: 0.5703 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
            "Epoch 7/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 407ms/step - accuracy: 0.7888 - loss: 0.4375 - val_accuracy: 0.7812 - val_loss: 0.5118\n",
            "Epoch 8/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8125 - loss: 0.4915 - val_accuracy: 0.6897 - val_loss: 0.6070\n",
            "Epoch 9/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 395ms/step - accuracy: 0.7879 - loss: 0.4753 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
            "Epoch 10/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8125 - loss: 0.3940 - val_accuracy: 0.8125 - val_loss: 0.4209\n",
            "Finished training for class: Sheep\n",
            "Training for class: Diningtable\n",
            "Number of positive samples for Diningtable: 184\n",
            "Number of negative samples before balancing: 6723\n",
            "Number of negative samples after balancing: 184\n",
            "Found 294 validated image filenames belonging to 2 classes.\n",
            "Found 74 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711574278.080256      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m8/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665ms/step - accuracy: 0.4918 - loss: 0.8128"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574283.027690      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630ms/step - accuracy: 0.4927 - loss: 0.8090"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574284.471493      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 772ms/step - accuracy: 0.4935 - loss: 0.8059 - val_accuracy: 0.4531 - val_loss: 0.7187\n",
            "Epoch 2/10\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 380ms/step - accuracy: 0.6250 - loss: 0.6648"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.6250 - loss: 0.6648 - val_accuracy: 0.3000 - val_loss: 0.8512\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574285.469477      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 394ms/step - accuracy: 0.5330 - loss: 0.7018 - val_accuracy: 0.5781 - val_loss: 0.6796\n",
            "Epoch 4/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5938 - loss: 0.6768 - val_accuracy: 0.5000 - val_loss: 0.6646\n",
            "Epoch 5/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 395ms/step - accuracy: 0.5107 - loss: 0.6924 - val_accuracy: 0.5625 - val_loss: 0.6985\n",
            "Epoch 6/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4062 - loss: 0.7557 - val_accuracy: 0.5000 - val_loss: 0.6910\n",
            "Epoch 7/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 401ms/step - accuracy: 0.5591 - loss: 0.6832 - val_accuracy: 0.6094 - val_loss: 0.6610\n",
            "Epoch 8/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5938 - loss: 0.6779 - val_accuracy: 0.6000 - val_loss: 0.6720\n",
            "Epoch 9/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 438ms/step - accuracy: 0.6428 - loss: 0.6562 - val_accuracy: 0.5312 - val_loss: 0.6495\n",
            "Epoch 10/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6667 - loss: 0.6207 - val_accuracy: 0.8000 - val_loss: 0.5747\n",
            "Finished training for class: Diningtable\n",
            "Training for class: Horse\n",
            "Number of positive samples for Horse: 258\n",
            "Number of negative samples before balancing: 6649\n",
            "Number of negative samples after balancing: 258\n",
            "Found 412 validated image filenames belonging to 2 classes.\n",
            "Found 104 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711574321.262377      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 9/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 394ms/step - accuracy: 0.5114 - loss: 0.7751"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574326.913705      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581ms/step - accuracy: 0.5165 - loss: 0.7633"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574328.939382      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 690ms/step - accuracy: 0.5185 - loss: 0.7600 - val_accuracy: 0.5729 - val_loss: 0.6682\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 385ms/step - accuracy: 0.4062 - loss: 0.7530"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.4062 - loss: 0.7530 - val_accuracy: 0.3750 - val_loss: 0.7272\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574330.106219      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 432ms/step - accuracy: 0.5383 - loss: 0.6921 - val_accuracy: 0.7292 - val_loss: 0.6287\n",
            "Epoch 4/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5938 - loss: 0.6737 - val_accuracy: 0.2500 - val_loss: 0.8180\n",
            "Epoch 5/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 438ms/step - accuracy: 0.6147 - loss: 0.6549 - val_accuracy: 0.6354 - val_loss: 0.6362\n",
            "Epoch 6/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6562 - loss: 0.6217 - val_accuracy: 0.5000 - val_loss: 0.6945\n",
            "Epoch 7/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 434ms/step - accuracy: 0.5777 - loss: 0.6693 - val_accuracy: 0.6771 - val_loss: 0.5717\n",
            "Epoch 8/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6562 - loss: 0.6001 - val_accuracy: 1.0000 - val_loss: 0.4383\n",
            "Epoch 9/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 436ms/step - accuracy: 0.6681 - loss: 0.5771 - val_accuracy: 0.6667 - val_loss: 0.5682\n",
            "Epoch 10/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.6875 - loss: 0.6412 - val_accuracy: 0.5000 - val_loss: 0.4938\n",
            "Finished training for class: Horse\n",
            "Training for class: Person\n",
            "Number of positive samples for Person: 1701\n",
            "Number of negative samples before balancing: 5206\n",
            "Number of negative samples after balancing: 1701\n",
            "Found 2721 validated image filenames belonging to 2 classes.\n",
            "Found 681 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711574374.836734      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.5875 - loss: 0.6682"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574411.445425      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 461ms/step - accuracy: 0.5880 - loss: 0.6679 - val_accuracy: 0.6399 - val_loss: 0.6219\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/85\u001b[0m \u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 388ms/step - accuracy: 0.8438 - loss: 0.4823"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8438 - loss: 0.4823 - val_accuracy: 0.4444 - val_loss: 0.6308\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574414.816383      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 423ms/step - accuracy: 0.6621 - loss: 0.6172 - val_accuracy: 0.6592 - val_loss: 0.6084\n",
            "Epoch 4/10\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.7812 - loss: 0.5619 - val_accuracy: 0.6667 - val_loss: 0.5460\n",
            "Epoch 5/10\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 427ms/step - accuracy: 0.6661 - loss: 0.5950 - val_accuracy: 0.6682 - val_loss: 0.5979\n",
            "Epoch 6/10\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.5938 - loss: 0.6406 - val_accuracy: 0.8889 - val_loss: 0.5604\n",
            "Epoch 7/10\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 424ms/step - accuracy: 0.6815 - loss: 0.5813 - val_accuracy: 0.6637 - val_loss: 0.6120\n",
            "Epoch 8/10\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - accuracy: 0.7188 - loss: 0.5788 - val_accuracy: 0.5556 - val_loss: 0.7340\n",
            "Epoch 9/10\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 422ms/step - accuracy: 0.6944 - loss: 0.5835 - val_accuracy: 0.7024 - val_loss: 0.5891\n",
            "Epoch 10/10\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - accuracy: 0.6562 - loss: 0.5485 - val_accuracy: 0.5556 - val_loss: 0.6724\n",
            "Finished training for class: Person\n",
            "Training for class: Motorbike\n",
            "Number of positive samples for Motorbike: 263\n",
            "Number of negative samples before balancing: 6644\n",
            "Number of negative samples after balancing: 263\n",
            "Found 420 validated image filenames belonging to 2 classes.\n",
            "Found 106 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 1/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1:44\u001b[0m 9s/step - accuracy: 0.5000 - loss: 0.7324"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574581.523537      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n",
            "W0000 00:00:1711574583.795007      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569ms/step - accuracy: 0.5105 - loss: 0.8031"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574589.353379      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 672ms/step - accuracy: 0.5112 - loss: 0.8002 - val_accuracy: 0.5104 - val_loss: 0.7017\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 382ms/step - accuracy: 0.4688 - loss: 0.7115"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.4688 - loss: 0.7115 - val_accuracy: 0.4000 - val_loss: 0.7684\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574590.494241      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 398ms/step - accuracy: 0.4518 - loss: 0.7040 - val_accuracy: 0.5104 - val_loss: 0.6954\n",
            "Epoch 4/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5000 - loss: 0.6949 - val_accuracy: 0.4000 - val_loss: 0.7077\n",
            "Epoch 5/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 454ms/step - accuracy: 0.4602 - loss: 0.7031 - val_accuracy: 0.4896 - val_loss: 0.6946\n",
            "Epoch 6/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5938 - loss: 0.6928 - val_accuracy: 0.6000 - val_loss: 0.6733\n",
            "Epoch 7/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 458ms/step - accuracy: 0.5148 - loss: 0.6980 - val_accuracy: 0.4896 - val_loss: 0.6970\n",
            "Epoch 8/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4062 - loss: 0.6950 - val_accuracy: 0.7000 - val_loss: 0.6739\n",
            "Epoch 9/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 412ms/step - accuracy: 0.4890 - loss: 0.6897 - val_accuracy: 0.5417 - val_loss: 0.6980\n",
            "Epoch 10/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5312 - loss: 0.7080 - val_accuracy: 0.7000 - val_loss: 0.7281\n",
            "Finished training for class: Motorbike\n",
            "Training for class: Bus\n",
            "Number of positive samples for Bus: 180\n",
            "Number of negative samples before balancing: 6727\n",
            "Number of negative samples after balancing: 180\n",
            "Found 288 validated image filenames belonging to 2 classes.\n",
            "Found 72 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711574634.552725      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - accuracy: 0.5300 - loss: 0.7354"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574638.981746      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 528ms/step - accuracy: 0.5291 - loss: 0.7351 - val_accuracy: 0.4531 - val_loss: 0.6553\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.6250 - val_loss: 0.6044\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574639.604206      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 433ms/step - accuracy: 0.6709 - loss: 0.6232 - val_accuracy: 0.7344 - val_loss: 0.6164\n",
            "Epoch 4/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.5000 - val_loss: 0.9117\n",
            "Epoch 5/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 433ms/step - accuracy: 0.7324 - loss: 0.5692 - val_accuracy: 0.8281 - val_loss: 0.4715\n",
            "Epoch 6/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.7500 - val_loss: 0.3992\n",
            "Epoch 7/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 434ms/step - accuracy: 0.7492 - loss: 0.4812 - val_accuracy: 0.7969 - val_loss: 0.5285\n",
            "Epoch 8/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.8750 - val_loss: 0.4015\n",
            "Epoch 9/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 437ms/step - accuracy: 0.7313 - loss: 0.5799 - val_accuracy: 0.7969 - val_loss: 0.5634\n",
            "Epoch 10/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.8750 - val_loss: 0.4643\n",
            "Finished training for class: Bus\n",
            "Training for class: Bicycle\n",
            "Number of positive samples for Bicycle: 253\n",
            "Number of negative samples before balancing: 6654\n",
            "Number of negative samples after balancing: 253\n",
            "Found 404 validated image filenames belonging to 2 classes.\n",
            "Found 102 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711574676.564544      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 5/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 393ms/step - accuracy: 0.6001 - loss: 0.8125"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574680.666613      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580ms/step - accuracy: 0.5713 - loss: 0.7799"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574684.263776      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 693ms/step - accuracy: 0.5687 - loss: 0.7775 - val_accuracy: 0.4792 - val_loss: 0.7238\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 389ms/step - accuracy: 0.4688 - loss: 0.7313"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.4688 - loss: 0.7313 - val_accuracy: 0.1667 - val_loss: 0.7842\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574685.399101      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 430ms/step - accuracy: 0.5400 - loss: 0.6926 - val_accuracy: 0.5417 - val_loss: 0.6921\n",
            "Epoch 4/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3750 - loss: 0.7135 - val_accuracy: 0.5000 - val_loss: 0.7009\n",
            "Epoch 5/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 436ms/step - accuracy: 0.4913 - loss: 0.6955 - val_accuracy: 0.4583 - val_loss: 0.6993\n",
            "Epoch 6/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4375 - loss: 0.7017 - val_accuracy: 0.5000 - val_loss: 0.6961\n",
            "Epoch 7/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 446ms/step - accuracy: 0.5021 - loss: 0.6943 - val_accuracy: 0.5625 - val_loss: 0.6905\n",
            "Epoch 8/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4000 - loss: 0.6967 - val_accuracy: 0.8333 - val_loss: 0.6839\n",
            "Epoch 9/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 429ms/step - accuracy: 0.5254 - loss: 0.6904 - val_accuracy: 0.5000 - val_loss: 0.6927\n",
            "Epoch 10/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5312 - loss: 0.6903 - val_accuracy: 0.6667 - val_loss: 0.6707\n",
            "Finished training for class: Bicycle\n",
            "Training for class: Aeroplane\n",
            "Number of positive samples for Aeroplane: 288\n",
            "Number of negative samples before balancing: 6619\n",
            "Number of negative samples after balancing: 288\n",
            "Found 460 validated image filenames belonging to 2 classes.\n",
            "Found 116 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711574731.645535      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 7/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 391ms/step - accuracy: 0.6055 - loss: 0.7459"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574736.519536      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538ms/step - accuracy: 0.6307 - loss: 0.7235"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574739.979107      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 634ms/step - accuracy: 0.6332 - loss: 0.7205 - val_accuracy: 0.6458 - val_loss: 0.6445\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 383ms/step - accuracy: 0.6250 - loss: 0.5768"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.6250 - loss: 0.5768 - val_accuracy: 0.7500 - val_loss: 0.5122\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574741.115478      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 411ms/step - accuracy: 0.7074 - loss: 0.5456 - val_accuracy: 0.7083 - val_loss: 0.5642\n",
            "Epoch 4/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.5962 - val_accuracy: 0.5000 - val_loss: 0.6486\n",
            "Epoch 5/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 431ms/step - accuracy: 0.8009 - loss: 0.4528 - val_accuracy: 0.6875 - val_loss: 0.7358\n",
            "Epoch 6/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7812 - loss: 0.5137 - val_accuracy: 0.6500 - val_loss: 0.7626\n",
            "Epoch 7/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 430ms/step - accuracy: 0.7854 - loss: 0.4338 - val_accuracy: 0.6875 - val_loss: 0.5019\n",
            "Epoch 8/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8125 - loss: 0.3801 - val_accuracy: 0.6500 - val_loss: 0.8850\n",
            "Epoch 9/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 414ms/step - accuracy: 0.8330 - loss: 0.3605 - val_accuracy: 0.6771 - val_loss: 0.7085\n",
            "Epoch 10/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.5863 - val_accuracy: 0.8000 - val_loss: 0.5086\n",
            "Finished training for class: Aeroplane\n",
            "Training for class: Train\n",
            "Number of positive samples for Train: 220\n",
            "Number of negative samples before balancing: 6687\n",
            "Number of negative samples after balancing: 220\n",
            "Found 352 validated image filenames belonging to 2 classes.\n",
            "Found 88 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711574787.387718      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.5077 - loss: 0.7621"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574792.610956      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 501ms/step - accuracy: 0.5104 - loss: 0.7580 - val_accuracy: 0.5469 - val_loss: 0.6897\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.4583 - val_loss: 0.7194\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574793.223356      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 423ms/step - accuracy: 0.5820 - loss: 0.6804 - val_accuracy: 0.4531 - val_loss: 0.7581\n",
            "Epoch 4/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.6667 - val_loss: 0.5879\n",
            "Epoch 5/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 428ms/step - accuracy: 0.6189 - loss: 0.6368 - val_accuracy: 0.6875 - val_loss: 0.5971\n",
            "Epoch 6/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.6667 - val_loss: 0.6157\n",
            "Epoch 7/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 430ms/step - accuracy: 0.7051 - loss: 0.5535 - val_accuracy: 0.6719 - val_loss: 0.5550\n",
            "Epoch 8/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.7917 - val_loss: 0.4595\n",
            "Epoch 9/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 429ms/step - accuracy: 0.7380 - loss: 0.5083 - val_accuracy: 0.8125 - val_loss: 0.3920\n",
            "Epoch 10/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.7500 - val_loss: 0.6728\n",
            "Finished training for class: Train\n",
            "Training for class: Bottle\n",
            "Number of positive samples for Bottle: 294\n",
            "Number of negative samples before balancing: 6613\n",
            "Number of negative samples after balancing: 294\n",
            "Found 470 validated image filenames belonging to 2 classes.\n",
            "Found 118 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711574833.799260      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m10/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 392ms/step - accuracy: 0.5573 - loss: 0.8388"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574839.915761      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553ms/step - accuracy: 0.5519 - loss: 0.8187"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574842.278507      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 645ms/step - accuracy: 0.5507 - loss: 0.8149 - val_accuracy: 0.5521 - val_loss: 0.6819\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 384ms/step - accuracy: 0.5625 - loss: 0.6852"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5625 - loss: 0.6852 - val_accuracy: 0.4545 - val_loss: 0.7069\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574843.408071      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 430ms/step - accuracy: 0.5136 - loss: 0.7062 - val_accuracy: 0.5208 - val_loss: 0.6879\n",
            "Epoch 4/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 0.6827 - val_accuracy: 0.5455 - val_loss: 0.6879\n",
            "Epoch 5/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 427ms/step - accuracy: 0.5436 - loss: 0.6934 - val_accuracy: 0.4896 - val_loss: 0.6896\n",
            "Epoch 6/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7812 - loss: 0.6575 - val_accuracy: 0.6818 - val_loss: 0.6498\n",
            "Epoch 7/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 425ms/step - accuracy: 0.5779 - loss: 0.6739 - val_accuracy: 0.5104 - val_loss: 0.6861\n",
            "Epoch 8/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5000 - loss: 0.6609 - val_accuracy: 0.6818 - val_loss: 0.6284\n",
            "Epoch 9/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 424ms/step - accuracy: 0.5294 - loss: 0.6794 - val_accuracy: 0.5000 - val_loss: 0.6797\n",
            "Epoch 10/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 0.6433 - val_accuracy: 0.5455 - val_loss: 0.6723\n",
            "Finished training for class: Bottle\n",
            "Training for class: Boat\n",
            "Number of positive samples for Boat: 265\n",
            "Number of negative samples before balancing: 6642\n",
            "Number of negative samples after balancing: 265\n",
            "Found 424 validated image filenames belonging to 2 classes.\n",
            "Found 106 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711574890.814882      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m10/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608ms/step - accuracy: 0.5860 - loss: 0.7079"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574896.534746      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554ms/step - accuracy: 0.5892 - loss: 0.7013"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574898.797968      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 658ms/step - accuracy: 0.5903 - loss: 0.6992 - val_accuracy: 0.6667 - val_loss: 0.6198\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 385ms/step - accuracy: 0.5312 - loss: 0.8833"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5312 - loss: 0.8833 - val_accuracy: 0.5000 - val_loss: 0.6210\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574899.961291      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 427ms/step - accuracy: 0.7235 - loss: 0.5173 - val_accuracy: 0.6979 - val_loss: 0.5952\n",
            "Epoch 4/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7188 - loss: 0.4977 - val_accuracy: 0.9000 - val_loss: 0.3036\n",
            "Epoch 5/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 432ms/step - accuracy: 0.7841 - loss: 0.4278 - val_accuracy: 0.8438 - val_loss: 0.4374\n",
            "Epoch 6/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8750 - loss: 0.3316 - val_accuracy: 0.7000 - val_loss: 0.5113\n",
            "Epoch 7/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 419ms/step - accuracy: 0.8585 - loss: 0.3169 - val_accuracy: 0.8646 - val_loss: 0.6251\n",
            "Epoch 8/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7812 - loss: 0.6328 - val_accuracy: 0.6000 - val_loss: 0.8683\n",
            "Epoch 9/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 417ms/step - accuracy: 0.8144 - loss: 0.4149 - val_accuracy: 0.8438 - val_loss: 0.3784\n",
            "Epoch 10/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9062 - loss: 0.2088 - val_accuracy: 0.7000 - val_loss: 0.4819\n",
            "Finished training for class: Boat\n",
            "Training for class: Car\n",
            "Number of positive samples for Car: 472\n",
            "Number of negative samples before balancing: 6435\n",
            "Number of negative samples after balancing: 472\n",
            "Found 755 validated image filenames belonging to 2 classes.\n",
            "Found 189 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711574944.658757      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 1/23\u001b[0m \u001b[37m\u001b[0m \u001b[1m3:24\u001b[0m 9s/step - accuracy: 0.4062 - loss: 0.8347"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574947.191735      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - accuracy: 0.5308 - loss: 0.8276"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574956.715473      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 556ms/step - accuracy: 0.5321 - loss: 0.8240 - val_accuracy: 0.5437 - val_loss: 0.6636\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/23\u001b[0m \u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 399ms/step - accuracy: 0.4062 - loss: 0.7166"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.4062 - loss: 0.7166 - val_accuracy: 0.5172 - val_loss: 0.6882\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711574958.110709      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 426ms/step - accuracy: 0.6101 - loss: 0.6490 - val_accuracy: 0.6500 - val_loss: 0.6144\n",
            "Epoch 4/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5938 - loss: 0.6026 - val_accuracy: 0.7931 - val_loss: 0.5522\n",
            "Epoch 5/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 433ms/step - accuracy: 0.6998 - loss: 0.5950 - val_accuracy: 0.6750 - val_loss: 0.6084\n",
            "Epoch 6/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7188 - loss: 0.5294 - val_accuracy: 0.7586 - val_loss: 0.5149\n",
            "Epoch 7/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 427ms/step - accuracy: 0.6977 - loss: 0.6060 - val_accuracy: 0.6438 - val_loss: 0.5878\n",
            "Epoch 8/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6875 - loss: 0.5796 - val_accuracy: 0.7241 - val_loss: 0.6449\n",
            "Epoch 9/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 434ms/step - accuracy: 0.6429 - loss: 0.6353 - val_accuracy: 0.6062 - val_loss: 0.6391\n",
            "Epoch 10/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7188 - loss: 0.6148 - val_accuracy: 0.7931 - val_loss: 0.5608\n",
            "Finished training for class: Car\n",
            "Training for class: Cow\n",
            "Number of positive samples for Cow: 159\n",
            "Number of negative samples before balancing: 6748\n",
            "Number of negative samples after balancing: 159\n",
            "Found 254 validated image filenames belonging to 2 classes.\n",
            "Found 64 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711575020.860581      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m6/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - accuracy: 0.5342 - loss: 0.7957"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711575025.309710      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741ms/step - accuracy: 0.5293 - loss: 0.7962"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711575026.628403      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 926ms/step - accuracy: 0.5257 - loss: 0.7966 - val_accuracy: 0.5469 - val_loss: 0.6570\n",
            "Epoch 2/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5625 - loss: 0.6821 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 441ms/step - accuracy: 0.6209 - loss: 0.6652 - val_accuracy: 0.5938 - val_loss: 0.6290\n",
            "Epoch 4/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6562 - loss: 0.6553 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
            "Epoch 5/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 439ms/step - accuracy: 0.6577 - loss: 0.6502 - val_accuracy: 0.7500 - val_loss: 0.5865\n",
            "Epoch 6/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6250 - loss: 0.6399 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
            "Epoch 7/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 448ms/step - accuracy: 0.6466 - loss: 0.6121 - val_accuracy: 0.7656 - val_loss: 0.6052\n",
            "Epoch 8/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7188 - loss: 0.5694 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
            "Epoch 9/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 449ms/step - accuracy: 0.7053 - loss: 0.5868 - val_accuracy: 0.7344 - val_loss: 0.5709\n",
            "Epoch 10/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4688 - loss: 0.7184 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
            "Finished training for class: Cow\n",
            "Training for class: Bird\n",
            "Number of positive samples for Bird: 344\n",
            "Number of negative samples before balancing: 6563\n",
            "Number of negative samples after balancing: 344\n",
            "Found 550 validated image filenames belonging to 2 classes.\n",
            "Found 138 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711575061.817307      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m10/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 613ms/step - accuracy: 0.5844 - loss: 0.8183"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711575067.625712      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521ms/step - accuracy: 0.5734 - loss: 0.7863"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711575071.486536      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 606ms/step - accuracy: 0.5726 - loss: 0.7830 - val_accuracy: 0.5391 - val_loss: 0.6832\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 395ms/step - accuracy: 0.7812 - loss: 0.6048"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7812 - loss: 0.6048 - val_accuracy: 0.7000 - val_loss: 0.5930\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711575072.749532      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 423ms/step - accuracy: 0.5069 - loss: 0.7232 - val_accuracy: 0.6016 - val_loss: 0.6815\n",
            "Epoch 4/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6875 - loss: 0.6653 - val_accuracy: 0.7000 - val_loss: 0.6627\n",
            "Epoch 5/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 435ms/step - accuracy: 0.6165 - loss: 0.6718 - val_accuracy: 0.6328 - val_loss: 0.5974\n",
            "Epoch 6/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3333 - loss: 0.7724 - val_accuracy: 0.5000 - val_loss: 0.7073\n",
            "Epoch 7/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 430ms/step - accuracy: 0.6355 - loss: 0.6392 - val_accuracy: 0.7266 - val_loss: 0.6054\n",
            "Epoch 8/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5938 - loss: 0.8084 - val_accuracy: 0.5000 - val_loss: 0.9992\n",
            "Epoch 9/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 412ms/step - accuracy: 0.6714 - loss: 0.6022 - val_accuracy: 0.5625 - val_loss: 0.6700\n",
            "Epoch 10/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4375 - loss: 0.7483 - val_accuracy: 0.8000 - val_loss: 0.5570\n",
            "Finished training for class: Bird\n",
            "Training for class: Pottedplant\n",
            "Number of positive samples for Pottedplant: 244\n",
            "Number of negative samples before balancing: 6663\n",
            "Number of negative samples after balancing: 244\n",
            "Found 390 validated image filenames belonging to 2 classes.\n",
            "Found 98 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711575124.556848      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 6/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 772ms/step - accuracy: 0.4921 - loss: 0.9007"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711575128.691281      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561ms/step - accuracy: 0.4906 - loss: 0.8467"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711575132.086433      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 677ms/step - accuracy: 0.4914 - loss: 0.8408 - val_accuracy: 0.5729 - val_loss: 0.6906\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 382ms/step - accuracy: 0.4062 - loss: 0.6953"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.4062 - loss: 0.6953 - val_accuracy: 1.0000 - val_loss: 0.6638\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711575133.217279      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 403ms/step - accuracy: 0.5141 - loss: 0.6930 - val_accuracy: 0.5521 - val_loss: 0.6892\n",
            "Epoch 4/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4688 - loss: 0.6949 - val_accuracy: 0.0000e+00 - val_loss: 0.7224\n",
            "Epoch 5/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 426ms/step - accuracy: 0.5120 - loss: 0.6884 - val_accuracy: 0.5521 - val_loss: 0.6829\n",
            "Epoch 6/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6562 - loss: 0.6367 - val_accuracy: 0.0000e+00 - val_loss: 0.7056\n",
            "Epoch 7/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 434ms/step - accuracy: 0.4900 - loss: 0.6975 - val_accuracy: 0.6042 - val_loss: 0.6692\n",
            "Epoch 8/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6250 - loss: 0.6635 - val_accuracy: 0.5000 - val_loss: 0.7266\n",
            "Epoch 9/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 415ms/step - accuracy: 0.5889 - loss: 0.6825 - val_accuracy: 0.5625 - val_loss: 0.6814\n",
            "Epoch 10/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5938 - loss: 0.6456 - val_accuracy: 1.0000 - val_loss: 0.6620\n",
            "Finished training for class: Pottedplant\n",
            "Training for class: Tvmonitor\n",
            "Number of positive samples for Tvmonitor: 272\n",
            "Number of negative samples before balancing: 6635\n",
            "Number of negative samples after balancing: 272\n",
            "Found 435 validated image filenames belonging to 2 classes.\n",
            "Found 109 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711575175.365452      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 3/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 394ms/step - accuracy: 0.5278 - loss: 0.8411"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711575178.629940      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561ms/step - accuracy: 0.5402 - loss: 0.7739"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711575183.425936      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 666ms/step - accuracy: 0.5413 - loss: 0.7701 - val_accuracy: 0.5000 - val_loss: 0.8469\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 386ms/step - accuracy: 0.5625 - loss: 0.8268"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5625 - loss: 0.8268 - val_accuracy: 0.7692 - val_loss: 0.5608\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711575184.576172      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 422ms/step - accuracy: 0.5918 - loss: 0.6470 - val_accuracy: 0.6458 - val_loss: 0.6116\n",
            "Epoch 4/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6875 - loss: 0.6376 - val_accuracy: 0.6154 - val_loss: 0.5401\n",
            "Epoch 5/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 430ms/step - accuracy: 0.7386 - loss: 0.5632 - val_accuracy: 0.7083 - val_loss: 0.5082\n",
            "Epoch 6/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6875 - loss: 0.6036 - val_accuracy: 0.6154 - val_loss: 0.7806\n",
            "Epoch 7/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 426ms/step - accuracy: 0.6963 - loss: 0.5447 - val_accuracy: 0.7083 - val_loss: 0.5048\n",
            "Epoch 8/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7188 - loss: 0.5029 - val_accuracy: 0.7692 - val_loss: 0.3709\n",
            "Epoch 9/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 433ms/step - accuracy: 0.7872 - loss: 0.4532 - val_accuracy: 0.6875 - val_loss: 0.7090\n",
            "Epoch 10/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7188 - loss: 0.8198 - val_accuracy: 0.8462 - val_loss: 0.4634\n",
            "Finished training for class: Tvmonitor\n",
            "Training for class: Dog\n",
            "Number of positive samples for Dog: 410\n",
            "Number of negative samples before balancing: 6497\n",
            "Number of negative samples after balancing: 410\n",
            "Found 656 validated image filenames belonging to 2 classes.\n",
            "Found 164 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711575229.009741      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 1/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2:48\u001b[0m 9s/step - accuracy: 0.4062 - loss: 0.9716"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711575231.528096      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - accuracy: 0.4856 - loss: 0.8074"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711575239.665948      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 570ms/step - accuracy: 0.4865 - loss: 0.8042 - val_accuracy: 0.5250 - val_loss: 0.6921\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 393ms/step - accuracy: 0.4375 - loss: 0.7249"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4375 - loss: 0.7249 - val_accuracy: 0.5000 - val_loss: 0.6974\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711575241.050834      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 426ms/step - accuracy: 0.5250 - loss: 0.6985 - val_accuracy: 0.4812 - val_loss: 0.6982\n",
            "Epoch 4/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5312 - loss: 0.6889 - val_accuracy: 0.2500 - val_loss: 0.7280\n",
            "Epoch 5/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 428ms/step - accuracy: 0.4977 - loss: 0.6941 - val_accuracy: 0.4688 - val_loss: 0.6942\n",
            "Epoch 6/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3750 - loss: 0.7028 - val_accuracy: 0.5000 - val_loss: 0.6865\n",
            "Epoch 7/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 429ms/step - accuracy: 0.5359 - loss: 0.6880 - val_accuracy: 0.5188 - val_loss: 0.6922\n",
            "Epoch 8/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5312 - loss: 0.6900 - val_accuracy: 0.7500 - val_loss: 0.6674\n",
            "Epoch 9/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 412ms/step - accuracy: 0.5119 - loss: 0.6919 - val_accuracy: 0.4875 - val_loss: 0.6929\n",
            "Epoch 10/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5000 - loss: 0.6958 - val_accuracy: 1.0000 - val_loss: 0.6625\n",
            "Finished training for class: Dog\n",
            "Training for class: Chair\n",
            "Number of positive samples for Chair: 380\n",
            "Number of negative samples before balancing: 6527\n",
            "Number of negative samples after balancing: 380\n",
            "Found 608 validated image filenames belonging to 2 classes.\n",
            "Found 152 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711575297.600196      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - accuracy: 0.5100 - loss: 0.9386"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711575305.876939      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 461ms/step - accuracy: 0.5110 - loss: 0.9314 - val_accuracy: 0.4922 - val_loss: 0.6911\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.5417 - val_loss: 0.6850\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711575306.740065      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 424ms/step - accuracy: 0.5146 - loss: 0.6945 - val_accuracy: 0.4922 - val_loss: 0.7018\n",
            "Epoch 4/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.5000 - val_loss: 0.7040\n",
            "Epoch 5/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 428ms/step - accuracy: 0.5918 - loss: 0.6825 - val_accuracy: 0.5000 - val_loss: 0.7006\n",
            "Epoch 6/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.5833 - val_loss: 0.6798\n",
            "Epoch 7/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 430ms/step - accuracy: 0.5734 - loss: 0.6822 - val_accuracy: 0.5391 - val_loss: 0.6812\n",
            "Epoch 8/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.7083 - val_loss: 0.6423\n",
            "Epoch 9/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 428ms/step - accuracy: 0.5688 - loss: 0.6857 - val_accuracy: 0.5703 - val_loss: 0.6809\n",
            "Epoch 10/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.2500 - val_loss: 0.8988\n",
            "Finished training for class: Chair\n"
          ]
        }
      ],
      "source": [
        "# Loop through each class and train a binary classification model\n",
        "for class_name in class_names:\n",
        "    print(f\"Training for class: {class_name}\")\n",
        "\n",
        "    # Retrieve the list of image paths for the positive class\n",
        "    positive_images = train_data_lists[class_name]\n",
        "    if not positive_images:\n",
        "        print(f\"No images found for class {class_name}. Skipping this class.\")\n",
        "        continue\n",
        "    positive_labels = [1] * len(positive_images)\n",
        "\n",
        "    # Build a list of image paths for the negative class (all other classes)\n",
        "    negative_images = []\n",
        "    for other_class_name, image_paths in train_data_lists.items():\n",
        "        if other_class_name != class_name:\n",
        "            negative_images.extend(image_paths)\n",
        "\n",
        "    print(f\"Number of positive samples for {class_name}: {len(positive_images)}\")\n",
        "    print(f\"Number of negative samples before balancing: {len(negative_images)}\")\n",
        "\n",
        "\n",
        "    random.shuffle(negative_images)  # Shuffle the negative images\n",
        "    negative_images = negative_images[:len(positive_images)]  # Balance the positive and negative datasets\n",
        "    negative_labels = [0] * len(negative_images)\n",
        "    print(f\"Number of negative samples after balancing: {len(negative_images)}\")\n",
        "\n",
        "    # Combine and shuffle the positive and negative samples\n",
        "    combined_images = positive_images + negative_images\n",
        "    combined_labels = positive_labels + negative_labels\n",
        "    combined_list = list(zip(combined_images, combined_labels))\n",
        "    random.shuffle(combined_list)\n",
        "    combined_images, combined_labels = zip(*combined_list)\n",
        "\n",
        "    # Split the data into training and validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(combined_images, combined_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Create DataFrames for the training and validation sets\n",
        "    train_df = pd.DataFrame({\n",
        "    'filename': X_train,\n",
        "    'label': [str(label) for label in y_train]  # Convert labels to strings\n",
        "})\n",
        "    val_df = pd.DataFrame({\n",
        "    'filename': X_val,\n",
        "    'label': [str(label) for label in y_val]  # Convert labels to strings\n",
        "})\n",
        "\n",
        "    # Create data generators for training and validation\n",
        "    train_generator = train_datagen.flow_from_dataframe(\n",
        "        train_df,\n",
        "        x_col='filename',\n",
        "        y_col='label',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='binary'\n",
        "    )\n",
        "\n",
        "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    val_generator = val_datagen.flow_from_dataframe(\n",
        "        val_df,\n",
        "        x_col='filename',\n",
        "        y_col='label',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='binary'\n",
        "    )\n",
        "\n",
        "    #Build the binary classification model\n",
        "    model = build_binary_classification_model()\n",
        "\n",
        "    # Train the model on the data\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=len(X_train) // 32,\n",
        "        validation_data=val_generator,\n",
        "        validation_steps=len(X_val) // 32,\n",
        "        epochs=10\n",
        "    )\n",
        "\n",
        "    # Save the trained model\n",
        "    model_save_path = os.path.join('models', f\"{class_name}_binary_model.h5\")\n",
        "    os.makedirs('models2', exist_ok=True)\n",
        "    model.save(model_save_path)\n",
        "\n",
        "    print(f\"Finished training for class: {class_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-27T21:49:51.737736Z",
          "iopub.status.busy": "2024-03-27T21:49:51.737359Z",
          "iopub.status.idle": "2024-03-27T21:49:51.746418Z",
          "shell.execute_reply": "2024-03-27T21:49:51.745495Z",
          "shell.execute_reply.started": "2024-03-27T21:49:51.737705Z"
        },
        "id": "w3EkMJoG0B6n"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the path to the train directory\n",
        "train_dir = \"/content/test200\"\n",
        "\n",
        "# Iterate over each subfolder in the train directory\n",
        "for class_name in os.listdir(train_dir):\n",
        "    class_dir = os.path.join(train_dir, class_name)\n",
        "\n",
        "    # Check if the item in the directory is a subfolder\n",
        "    if os.path.isdir(class_dir):\n",
        "        # Define the path to the subsubfolder\n",
        "        subsubfolder_dir = os.path.join(class_dir, class_name)\n",
        "\n",
        "        # Check if the subsubfolder exists\n",
        "        if os.path.exists(subsubfolder_dir):\n",
        "            # Iterate over each file in the subsubfolder\n",
        "            for file_name in os.listdir(subsubfolder_dir):\n",
        "                file_path = os.path.join(subsubfolder_dir, file_name)\n",
        "\n",
        "                # Move the file to the parent subfolder\n",
        "                if os.path.isfile(file_path):\n",
        "                    shutil.move(file_path, class_dir)\n",
        "\n",
        "            # Remove the empty subsubfolder\n",
        "            os.rmdir(subsubfolder_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BincvhyL0B6n"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import classification_report, confusion_matrix, average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "model_dir = '/content/models200'\n",
        "test_data_dir = '/content/test200'\n",
        "\n",
        "# Initialize ImageDataGenerator for preprocessing\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Store average precision scores for mAP calculation\n",
        "ap_scores = []\n",
        "\n",
        "# Loop through each model file in the models directory\n",
        "for model_file in sorted(os.listdir(model_dir)):\n",
        "    if model_file.endswith(\".h5\"):\n",
        "        print(f\"\\nLoading model {model_file}...\")\n",
        "        model_path = os.path.join(model_dir, model_file)\n",
        "        model = load_model(model_path)\n",
        "        class_name = model_file.replace(\"_binary_model.h5\", \"\")\n",
        "        print(f\"Model for class '{class_name}' loaded successfully.\")\n",
        "\n",
        "        # Create DataFrame for test data with labels as strings\n",
        "        images = []\n",
        "        labels = []\n",
        "        for folder in os.listdir(test_data_dir):\n",
        "            folder_path = os.path.join(test_data_dir, folder)\n",
        "            for image_file in os.listdir(folder_path):\n",
        "                images.append(os.path.join(folder, image_file))\n",
        "                labels.append(str(int(folder == class_name)))  # Convert boolean to int to string\n",
        "\n",
        "        test_df = pd.DataFrame({\n",
        "            'filename': images,\n",
        "            'label': labels  # Labels are now strings\n",
        "        })\n",
        "\n",
        "        # Prepare test generator\n",
        "        test_generator = test_datagen.flow_from_dataframe(\n",
        "            dataframe=test_df,\n",
        "            directory=test_data_dir,\n",
        "            x_col='filename',\n",
        "            y_col='label',\n",
        "            target_size=(224, 224),\n",
        "            batch_size=32,\n",
        "            class_mode='binary',\n",
        "            shuffle=False)\n",
        "\n",
        "        # Predict and evaluate\n",
        "        predictions = model.predict(test_generator, steps=int(np.ceil(len(test_df)/32)))\n",
        "\n",
        "        predicted_labels = (predictions > 0.5).astype(int)\n",
        "        ap_score = average_precision_score(test_generator.classes, predictions)\n",
        "        ap_scores.append(ap_score)\n",
        "        #print(f\"AP score for class '{class_name}': {ap_score:.3f}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-27T21:53:28.075873Z",
          "iopub.status.busy": "2024-03-27T21:53:28.074936Z",
          "iopub.status.idle": "2024-03-27T21:53:28.080789Z",
          "shell.execute_reply": "2024-03-27T21:53:28.079887Z",
          "shell.execute_reply.started": "2024-03-27T21:53:28.075838Z"
        },
        "id": "3nbZpZ0I0B6n",
        "outputId": "96d93f9d-b6e5-48e8-8de4-463dc4f0507f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.148\n"
          ]
        }
      ],
      "source": [
        "# Calculate mean Average Precision (mAP)\n",
        "mAP = np.mean(ap_scores)\n",
        "print(f\"\\nMean Average Precision (mAP) across all classes: {mAP:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qha4ozka0B6n"
      },
      "source": [
        "# 500 samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtuUswHh0B6t"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the train folder path\n",
        "train_folder = '/content/train500'\n",
        "\n",
        "# Iterate through each class subfolder in the train folder\n",
        "for class_folder in os.listdir(train_folder):\n",
        "    class_subfolder = os.path.join(train_folder, class_folder)\n",
        "\n",
        "    # Ensure it's a directory\n",
        "    if os.path.isdir(class_subfolder):\n",
        "        # Get the path of the second subfolder\n",
        "        second_subfolder = os.path.join(class_subfolder, class_folder)\n",
        "\n",
        "        # Ensure the second subfolder exists\n",
        "        if os.path.exists(second_subfolder):\n",
        "            # Move images from the second subfolder to the first subfolder\n",
        "            for image_file in os.listdir(second_subfolder):\n",
        "                src_path = os.path.join(second_subfolder, image_file)\n",
        "                dest_path = os.path.join(class_subfolder, image_file)\n",
        "                shutil.move(src_path, dest_path)\n",
        "                print(f\"Moved {image_file} from {second_subfolder} to {class_subfolder}\")\n",
        "\n",
        "            # Remove the second subfolder\n",
        "            os.rmdir(second_subfolder)\n",
        "            print(f\"Removed {second_subfolder}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-27T21:56:53.640850Z",
          "iopub.status.busy": "2024-03-27T21:56:53.640158Z",
          "iopub.status.idle": "2024-03-27T22:17:20.673738Z",
          "shell.execute_reply": "2024-03-27T22:17:20.672311Z",
          "shell.execute_reply.started": "2024-03-27T21:56:53.640814Z"
        },
        "id": "5OS2r7CD0B6t",
        "outputId": "59d9127e-cc40-45b3-bde8-a3c6f04899ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training for class: Cat\n",
            "Number of positive samples for Cat: 362\n",
            "Number of negative samples before balancing: 6545\n",
            "Number of negative samples after balancing: 362\n",
            "Found 579 validated image filenames belonging to 2 classes.\n",
            "Found 145 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711576622.490901      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 6/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 764ms/step - accuracy: 0.5324 - loss: 0.7583"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711576626.658146      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506ms/step - accuracy: 0.5265 - loss: 0.7366"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711576632.398010      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 585ms/step - accuracy: 0.5269 - loss: 0.7353 - val_accuracy: 0.4453 - val_loss: 0.7308\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 389ms/step - accuracy: 0.5000 - loss: 0.7112"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5000 - loss: 0.7112 - val_accuracy: 0.7059 - val_loss: 0.6428\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711576633.663911      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 429ms/step - accuracy: 0.4949 - loss: 0.6986 - val_accuracy: 0.5078 - val_loss: 0.6921\n",
            "Epoch 4/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4375 - loss: 0.6932 - val_accuracy: 0.5882 - val_loss: 0.6889\n",
            "Epoch 5/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 428ms/step - accuracy: 0.4967 - loss: 0.6922 - val_accuracy: 0.5312 - val_loss: 0.6885\n",
            "Epoch 6/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6250 - loss: 0.6852 - val_accuracy: 0.5294 - val_loss: 0.6885\n",
            "Epoch 7/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 424ms/step - accuracy: 0.5377 - loss: 0.6831 - val_accuracy: 0.5078 - val_loss: 0.6902\n",
            "Epoch 8/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5625 - loss: 0.6641 - val_accuracy: 0.5882 - val_loss: 0.6816\n",
            "Epoch 9/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 405ms/step - accuracy: 0.6166 - loss: 0.6451 - val_accuracy: 0.6641 - val_loss: 0.5856\n",
            "Epoch 10/10\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6562 - loss: 0.6419 - val_accuracy: 0.6471 - val_loss: 0.5831\n",
            "Finished training for class: Cat\n",
            "Training for class: Sofa\n",
            "Number of positive samples for Sofa: 207\n",
            "Number of negative samples before balancing: 6700\n",
            "Number of negative samples after balancing: 207\n",
            "Found 331 validated image filenames belonging to 2 classes.\n",
            "Found 83 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711576686.574617      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 6/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 767ms/step - accuracy: 0.4160 - loss: 0.9969"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711576690.629105      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599ms/step - accuracy: 0.4329 - loss: 0.9223"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711576693.282307      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 724ms/step - accuracy: 0.4364 - loss: 0.9106 - val_accuracy: 0.5781 - val_loss: 0.6870\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 381ms/step - accuracy: 0.5000 - loss: 0.7025"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.5000 - loss: 0.7025 - val_accuracy: 0.4211 - val_loss: 0.7169\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711576694.304403      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 400ms/step - accuracy: 0.5183 - loss: 0.6986 - val_accuracy: 0.5781 - val_loss: 0.6704\n",
            "Epoch 4/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4688 - loss: 0.6974 - val_accuracy: 0.4211 - val_loss: 0.6902\n",
            "Epoch 5/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 430ms/step - accuracy: 0.5403 - loss: 0.6885 - val_accuracy: 0.5781 - val_loss: 0.6719\n",
            "Epoch 6/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4545 - loss: 0.7070 - val_accuracy: 0.5263 - val_loss: 0.6914\n",
            "Epoch 7/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 430ms/step - accuracy: 0.5958 - loss: 0.6633 - val_accuracy: 0.6719 - val_loss: 0.6464\n",
            "Epoch 8/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6250 - loss: 0.6238 - val_accuracy: 0.7368 - val_loss: 0.5883\n",
            "Epoch 9/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 441ms/step - accuracy: 0.6105 - loss: 0.6671 - val_accuracy: 0.6719 - val_loss: 0.6438\n",
            "Epoch 10/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6364 - loss: 0.5860 - val_accuracy: 0.7895 - val_loss: 0.5242\n",
            "Finished training for class: Sofa\n",
            "Training for class: Sheep\n",
            "Number of positive samples for Sheep: 151\n",
            "Number of negative samples before balancing: 6756\n",
            "Number of negative samples after balancing: 151\n",
            "Found 241 validated image filenames belonging to 2 classes.\n",
            "Found 61 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711576732.949735      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m4/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 400ms/step - accuracy: 0.4603 - loss: 0.8154"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711576736.634594      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 890ms/step - accuracy: 0.5218 - loss: 0.7748 - val_accuracy: 0.6875 - val_loss: 0.5234\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711576738.605317      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 391ms/step - accuracy: 0.6562 - loss: 0.6238"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.6562 - loss: 0.6238 - val_accuracy: 0.8621 - val_loss: 0.4696\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711576739.494381      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 378ms/step - accuracy: 0.6702 - loss: 0.5961 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
            "Epoch 4/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.6562 - loss: 0.6696 - val_accuracy: 0.7812 - val_loss: 0.5443\n",
            "Epoch 5/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 397ms/step - accuracy: 0.7304 - loss: 0.5591 - val_accuracy: 0.7586 - val_loss: 0.5129\n",
            "Epoch 6/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6875 - loss: 0.6132 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
            "Epoch 7/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 431ms/step - accuracy: 0.7573 - loss: 0.5226 - val_accuracy: 0.8438 - val_loss: 0.4365\n",
            "Epoch 8/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7812 - loss: 0.3717 - val_accuracy: 0.8276 - val_loss: 0.4595\n",
            "Epoch 9/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 377ms/step - accuracy: 0.8046 - loss: 0.4489 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
            "Epoch 10/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8125 - loss: 0.3346 - val_accuracy: 0.8750 - val_loss: 0.2647\n",
            "Finished training for class: Sheep\n",
            "Training for class: Diningtable\n",
            "Number of positive samples for Diningtable: 184\n",
            "Number of negative samples before balancing: 6723\n",
            "Number of negative samples after balancing: 184\n",
            "Found 294 validated image filenames belonging to 2 classes.\n",
            "Found 74 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711576772.603175      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m4/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.5671 - loss: 0.7204   "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711576775.944273      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632ms/step - accuracy: 0.5561 - loss: 0.7176"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711576778.934285      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 766ms/step - accuracy: 0.5566 - loss: 0.7157 - val_accuracy: 0.6406 - val_loss: 0.5923\n",
            "Epoch 2/10\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 383ms/step - accuracy: 0.7500 - loss: 0.5748"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.5748 - val_accuracy: 0.7000 - val_loss: 0.6120\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711576779.968999      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 404ms/step - accuracy: 0.6762 - loss: 0.6204 - val_accuracy: 0.7656 - val_loss: 0.5174\n",
            "Epoch 4/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5625 - loss: 0.6016 - val_accuracy: 0.9000 - val_loss: 0.2240\n",
            "Epoch 5/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 402ms/step - accuracy: 0.7201 - loss: 0.5348 - val_accuracy: 0.6562 - val_loss: 0.5712\n",
            "Epoch 6/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6875 - loss: 0.6598 - val_accuracy: 0.9000 - val_loss: 0.5158\n",
            "Epoch 7/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 409ms/step - accuracy: 0.7071 - loss: 0.6056 - val_accuracy: 0.7500 - val_loss: 0.5556\n",
            "Epoch 8/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7188 - loss: 0.5706 - val_accuracy: 0.9000 - val_loss: 0.4271\n",
            "Epoch 9/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 409ms/step - accuracy: 0.7025 - loss: 0.5589 - val_accuracy: 0.7188 - val_loss: 0.5387\n",
            "Epoch 10/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5938 - loss: 0.6604 - val_accuracy: 0.9000 - val_loss: 0.4919\n",
            "Finished training for class: Diningtable\n",
            "Training for class: Horse\n",
            "Number of positive samples for Horse: 258\n",
            "Number of negative samples before balancing: 6649\n",
            "Number of negative samples after balancing: 258\n",
            "Found 412 validated image filenames belonging to 2 classes.\n",
            "Found 104 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711576816.434020      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 5/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 397ms/step - accuracy: 0.4994 - loss: 0.9413"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711576820.656954      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595ms/step - accuracy: 0.5030 - loss: 0.8645"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711576824.256043      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 704ms/step - accuracy: 0.5036 - loss: 0.8575 - val_accuracy: 0.5000 - val_loss: 0.6968\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 391ms/step - accuracy: 0.4688 - loss: 0.7081"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.4688 - loss: 0.7081 - val_accuracy: 0.3750 - val_loss: 0.7455\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711576825.391088      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 436ms/step - accuracy: 0.6421 - loss: 0.6609 - val_accuracy: 0.5521 - val_loss: 0.6766\n",
            "Epoch 4/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6562 - loss: 0.6260 - val_accuracy: 0.5000 - val_loss: 0.5753\n",
            "Epoch 5/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 440ms/step - accuracy: 0.6646 - loss: 0.6276 - val_accuracy: 0.6146 - val_loss: 0.6239\n",
            "Epoch 6/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5312 - loss: 0.6103 - val_accuracy: 0.6250 - val_loss: 0.7476\n",
            "Epoch 7/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 440ms/step - accuracy: 0.7836 - loss: 0.4846 - val_accuracy: 0.8229 - val_loss: 0.5440\n",
            "Epoch 8/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9062 - loss: 0.4825 - val_accuracy: 0.7500 - val_loss: 0.4788\n",
            "Epoch 9/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 439ms/step - accuracy: 0.8369 - loss: 0.4201 - val_accuracy: 0.7708 - val_loss: 0.5419\n",
            "Epoch 10/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8438 - loss: 0.5036 - val_accuracy: 0.7500 - val_loss: 0.3298\n",
            "Finished training for class: Horse\n",
            "Training for class: Person\n",
            "Number of positive samples for Person: 1701\n",
            "Number of negative samples before balancing: 5206\n",
            "Number of negative samples after balancing: 1701\n",
            "Found 2721 validated image filenames belonging to 2 classes.\n",
            "Found 681 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711576870.160006      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step - accuracy: 0.6077 - loss: 0.7087"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711576905.039973      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 441ms/step - accuracy: 0.6081 - loss: 0.7080 - val_accuracy: 0.6845 - val_loss: 0.5879\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/85\u001b[0m \u001b[37m\u001b[0m \u001b[1m2:50\u001b[0m 2s/step - accuracy: 0.0000e+00 - loss: 1.3178"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 1.3178 - val_accuracy: 1.0000 - val_loss: 0.3490\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711576910.121157      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 424ms/step - accuracy: 0.6224 - loss: 0.6337 - val_accuracy: 0.6920 - val_loss: 0.5923\n",
            "Epoch 4/10\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - accuracy: 0.7500 - loss: 0.5015 - val_accuracy: 0.7778 - val_loss: 0.4613\n",
            "Epoch 5/10\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 422ms/step - accuracy: 0.6760 - loss: 0.6062 - val_accuracy: 0.6920 - val_loss: 0.6198\n",
            "Epoch 6/10\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - accuracy: 0.5938 - loss: 0.6139 - val_accuracy: 0.7778 - val_loss: 0.6453\n",
            "Epoch 7/10\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 420ms/step - accuracy: 0.6677 - loss: 0.6120 - val_accuracy: 0.6905 - val_loss: 0.5632\n",
            "Epoch 8/10\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - accuracy: 0.5625 - loss: 0.6418 - val_accuracy: 0.4444 - val_loss: 0.6250\n",
            "Epoch 9/10\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 422ms/step - accuracy: 0.6903 - loss: 0.5855 - val_accuracy: 0.6949 - val_loss: 0.5725\n",
            "Epoch 10/10\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - accuracy: 0.6562 - loss: 0.6149 - val_accuracy: 0.5556 - val_loss: 0.6255\n",
            "Finished training for class: Person\n",
            "Training for class: Motorbike\n",
            "Number of positive samples for Motorbike: 263\n",
            "Number of negative samples before balancing: 6644\n",
            "Number of negative samples after balancing: 263\n",
            "Found 420 validated image filenames belonging to 2 classes.\n",
            "Found 106 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711577076.433646      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 2/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - accuracy: 0.5295 - loss: 0.7412 "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577079.101978      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556ms/step - accuracy: 0.5816 - loss: 0.7128"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577084.396810      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 658ms/step - accuracy: 0.5828 - loss: 0.7109 - val_accuracy: 0.5833 - val_loss: 0.6502\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 381ms/step - accuracy: 0.5000 - loss: 0.7009"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.7009 - val_accuracy: 0.6000 - val_loss: 0.6285\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577085.518831      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 426ms/step - accuracy: 0.6182 - loss: 0.6264 - val_accuracy: 0.5833 - val_loss: 0.6635\n",
            "Epoch 4/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5938 - loss: 0.6696 - val_accuracy: 1.0000 - val_loss: 0.5606\n",
            "Epoch 5/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 436ms/step - accuracy: 0.6257 - loss: 0.6195 - val_accuracy: 0.7500 - val_loss: 0.6989\n",
            "Epoch 6/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.6429 - val_accuracy: 0.5000 - val_loss: 0.7955\n",
            "Epoch 7/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 434ms/step - accuracy: 0.7001 - loss: 0.5274 - val_accuracy: 0.6354 - val_loss: 0.6119\n",
            "Epoch 8/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6875 - loss: 0.5518 - val_accuracy: 0.4000 - val_loss: 1.0077\n",
            "Epoch 9/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 458ms/step - accuracy: 0.7669 - loss: 0.4617 - val_accuracy: 0.8542 - val_loss: 0.6161\n",
            "Epoch 10/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7188 - loss: 0.5588 - val_accuracy: 0.9000 - val_loss: 0.5867\n",
            "Finished training for class: Motorbike\n",
            "Training for class: Bus\n",
            "Number of positive samples for Bus: 180\n",
            "Number of negative samples before balancing: 6727\n",
            "Number of negative samples after balancing: 180\n",
            "Found 288 validated image filenames belonging to 2 classes.\n",
            "Found 72 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711577129.266599      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.5646 - loss: 0.8224"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577133.692867      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 528ms/step - accuracy: 0.5668 - loss: 0.8153 - val_accuracy: 0.4844 - val_loss: 0.7224\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.5000 - val_loss: 0.7656\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577134.328411      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 431ms/step - accuracy: 0.5784 - loss: 0.6602 - val_accuracy: 0.6250 - val_loss: 0.6176\n",
            "Epoch 4/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.8750 - val_loss: 0.4929\n",
            "Epoch 5/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 432ms/step - accuracy: 0.6625 - loss: 0.5903 - val_accuracy: 0.5938 - val_loss: 0.6194\n",
            "Epoch 6/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.7500 - val_loss: 0.5846\n",
            "Epoch 7/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 437ms/step - accuracy: 0.6862 - loss: 0.5848 - val_accuracy: 0.7031 - val_loss: 0.4921\n",
            "Epoch 8/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.6250 - val_loss: 0.4706\n",
            "Epoch 9/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 437ms/step - accuracy: 0.7433 - loss: 0.4746 - val_accuracy: 0.7344 - val_loss: 0.4602\n",
            "Epoch 10/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.6250 - val_loss: 0.5246\n",
            "Finished training for class: Bus\n",
            "Training for class: Bicycle\n",
            "Number of positive samples for Bicycle: 253\n",
            "Number of negative samples before balancing: 6654\n",
            "Number of negative samples after balancing: 253\n",
            "Found 404 validated image filenames belonging to 2 classes.\n",
            "Found 102 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711577170.775194      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 4/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 392ms/step - accuracy: 0.4349 - loss: 0.7499"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577174.452517      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573ms/step - accuracy: 0.4755 - loss: 0.7344"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577178.347209      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 681ms/step - accuracy: 0.4774 - loss: 0.7331 - val_accuracy: 0.5312 - val_loss: 0.7042\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 386ms/step - accuracy: 0.6250 - loss: 0.6403"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.6250 - loss: 0.6403 - val_accuracy: 0.3333 - val_loss: 0.7328\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577179.480811      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 427ms/step - accuracy: 0.5786 - loss: 0.6580 - val_accuracy: 0.4688 - val_loss: 0.7551\n",
            "Epoch 4/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6250 - loss: 0.6403 - val_accuracy: 0.5000 - val_loss: 0.7273\n",
            "Epoch 5/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 441ms/step - accuracy: 0.5699 - loss: 0.6828 - val_accuracy: 0.6250 - val_loss: 0.6386\n",
            "Epoch 6/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5312 - loss: 0.6996 - val_accuracy: 0.3333 - val_loss: 0.7233\n",
            "Epoch 7/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 431ms/step - accuracy: 0.6275 - loss: 0.6327 - val_accuracy: 0.4688 - val_loss: 0.7789\n",
            "Epoch 8/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5625 - loss: 0.6637 - val_accuracy: 0.5000 - val_loss: 0.7899\n",
            "Epoch 9/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 432ms/step - accuracy: 0.6101 - loss: 0.6685 - val_accuracy: 0.4375 - val_loss: 0.7490\n",
            "Epoch 10/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3750 - loss: 0.7591 - val_accuracy: 0.6667 - val_loss: 0.6755\n",
            "Finished training for class: Bicycle\n",
            "Training for class: Aeroplane\n",
            "Number of positive samples for Aeroplane: 288\n",
            "Number of negative samples before balancing: 6619\n",
            "Number of negative samples after balancing: 288\n",
            "Found 460 validated image filenames belonging to 2 classes.\n",
            "Found 116 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711577223.141706      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 4/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 390ms/step - accuracy: 0.5410 - loss: 1.0036"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577226.863572      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538ms/step - accuracy: 0.5921 - loss: 0.8618"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577231.472120      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 633ms/step - accuracy: 0.5959 - loss: 0.8533 - val_accuracy: 0.7708 - val_loss: 0.5621\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 381ms/step - accuracy: 0.7812 - loss: 0.5264"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7812 - loss: 0.5264 - val_accuracy: 0.6500 - val_loss: 0.5806\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577232.594757      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 427ms/step - accuracy: 0.7076 - loss: 0.5512 - val_accuracy: 0.5833 - val_loss: 0.6347\n",
            "Epoch 4/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8333 - loss: 0.4275 - val_accuracy: 0.8000 - val_loss: 0.4637\n",
            "Epoch 5/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 426ms/step - accuracy: 0.7044 - loss: 0.5021 - val_accuracy: 0.7812 - val_loss: 0.4580\n",
            "Epoch 6/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8125 - loss: 0.3795 - val_accuracy: 0.8000 - val_loss: 0.4537\n",
            "Epoch 7/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 430ms/step - accuracy: 0.7627 - loss: 0.4617 - val_accuracy: 0.7604 - val_loss: 0.6804\n",
            "Epoch 8/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8438 - loss: 0.4152 - val_accuracy: 0.8000 - val_loss: 0.4942\n",
            "Epoch 9/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 416ms/step - accuracy: 0.8195 - loss: 0.4139 - val_accuracy: 0.7812 - val_loss: 0.4379\n",
            "Epoch 10/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8438 - loss: 0.3903 - val_accuracy: 0.9000 - val_loss: 0.1863\n",
            "Finished training for class: Aeroplane\n",
            "Training for class: Train\n",
            "Number of positive samples for Train: 220\n",
            "Number of negative samples before balancing: 6687\n",
            "Number of negative samples after balancing: 220\n",
            "Found 352 validated image filenames belonging to 2 classes.\n",
            "Found 88 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711577278.572017      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - accuracy: 0.5049 - loss: 0.8501"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577283.731624      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 497ms/step - accuracy: 0.5080 - loss: 0.8443 - val_accuracy: 0.6562 - val_loss: 0.6728\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.5417 - val_loss: 0.6864\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577284.355421      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 423ms/step - accuracy: 0.6593 - loss: 0.6514 - val_accuracy: 0.5312 - val_loss: 0.7065\n",
            "Epoch 4/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.7083 - val_loss: 0.6278\n",
            "Epoch 5/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 428ms/step - accuracy: 0.7097 - loss: 0.6030 - val_accuracy: 0.8750 - val_loss: 0.5702\n",
            "Epoch 6/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.8333 - val_loss: 0.5598\n",
            "Epoch 7/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 428ms/step - accuracy: 0.7882 - loss: 0.5310 - val_accuracy: 0.4844 - val_loss: 0.8699\n",
            "Epoch 8/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.7083 - val_loss: 0.7756\n",
            "Epoch 9/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 429ms/step - accuracy: 0.7851 - loss: 0.4356 - val_accuracy: 0.8281 - val_loss: 0.3997\n",
            "Epoch 10/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.7917 - val_loss: 0.4262\n",
            "Finished training for class: Train\n",
            "Training for class: Bottle\n",
            "Number of positive samples for Bottle: 294\n",
            "Number of negative samples before balancing: 6613\n",
            "Number of negative samples after balancing: 294\n",
            "Found 470 validated image filenames belonging to 2 classes.\n",
            "Found 118 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711577324.708192      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 3/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 390ms/step - accuracy: 0.4774 - loss: 0.9114"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577327.992069      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545ms/step - accuracy: 0.4504 - loss: 0.8381"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577333.058026      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 636ms/step - accuracy: 0.4513 - loss: 0.8347 - val_accuracy: 0.6042 - val_loss: 0.6779\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 384ms/step - accuracy: 0.6250 - loss: 0.6790"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.6250 - loss: 0.6790 - val_accuracy: 0.6818 - val_loss: 0.6491\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577334.181500      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 426ms/step - accuracy: 0.5059 - loss: 0.6966 - val_accuracy: 0.6458 - val_loss: 0.6674\n",
            "Epoch 4/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4688 - loss: 0.6965 - val_accuracy: 0.6364 - val_loss: 0.6541\n",
            "Epoch 5/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 425ms/step - accuracy: 0.5368 - loss: 0.6855 - val_accuracy: 0.5521 - val_loss: 0.6632\n",
            "Epoch 6/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5625 - loss: 0.6836 - val_accuracy: 0.6364 - val_loss: 0.6469\n",
            "Epoch 7/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 427ms/step - accuracy: 0.6217 - loss: 0.6642 - val_accuracy: 0.5625 - val_loss: 0.6597\n",
            "Epoch 8/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6562 - loss: 0.6415 - val_accuracy: 0.4545 - val_loss: 0.7363\n",
            "Epoch 9/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 425ms/step - accuracy: 0.5268 - loss: 0.6892 - val_accuracy: 0.7396 - val_loss: 0.5906\n",
            "Epoch 10/10\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7188 - loss: 0.6069 - val_accuracy: 0.9091 - val_loss: 0.4895\n",
            "Finished training for class: Bottle\n",
            "Training for class: Boat\n",
            "Number of positive samples for Boat: 265\n",
            "Number of negative samples before balancing: 6642\n",
            "Number of negative samples after balancing: 265\n",
            "Found 424 validated image filenames belonging to 2 classes.\n",
            "Found 106 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711577381.375232      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 9/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 654ms/step - accuracy: 0.5774 - loss: 0.7404"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577386.851908      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566ms/step - accuracy: 0.5894 - loss: 0.7191"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577389.504167      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 669ms/step - accuracy: 0.5925 - loss: 0.7146 - val_accuracy: 0.6771 - val_loss: 0.5608\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 386ms/step - accuracy: 0.5000 - loss: 0.7840"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5000 - loss: 0.7840 - val_accuracy: 0.7000 - val_loss: 0.6139\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577390.640177      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 411ms/step - accuracy: 0.7305 - loss: 0.5619 - val_accuracy: 0.7396 - val_loss: 0.6375\n",
            "Epoch 4/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7500 - loss: 0.5607 - val_accuracy: 0.7000 - val_loss: 0.7236\n",
            "Epoch 5/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 449ms/step - accuracy: 0.7114 - loss: 0.5595 - val_accuracy: 0.7188 - val_loss: 0.5365\n",
            "Epoch 6/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8125 - loss: 0.4943 - val_accuracy: 0.7000 - val_loss: 0.5336\n",
            "Epoch 7/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 417ms/step - accuracy: 0.7475 - loss: 0.5117 - val_accuracy: 0.7396 - val_loss: 0.5355\n",
            "Epoch 8/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6875 - loss: 0.4777 - val_accuracy: 0.8000 - val_loss: 0.4617\n",
            "Epoch 9/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 416ms/step - accuracy: 0.7506 - loss: 0.4841 - val_accuracy: 0.7292 - val_loss: 0.5308\n",
            "Epoch 10/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6562 - loss: 0.6723 - val_accuracy: 0.8000 - val_loss: 0.5351\n",
            "Finished training for class: Boat\n",
            "Training for class: Car\n",
            "Number of positive samples for Car: 472\n",
            "Number of negative samples before balancing: 6435\n",
            "Number of negative samples after balancing: 472\n",
            "Found 755 validated image filenames belonging to 2 classes.\n",
            "Found 189 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711577434.666767      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m16/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 395ms/step - accuracy: 0.5903 - loss: 0.6883"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577443.059711      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step - accuracy: 0.5945 - loss: 0.6837"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577446.704728      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 555ms/step - accuracy: 0.5950 - loss: 0.6831 - val_accuracy: 0.7063 - val_loss: 0.6016\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/23\u001b[0m \u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 414ms/step - accuracy: 0.7500 - loss: 0.5048"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7500 - loss: 0.5048 - val_accuracy: 0.7586 - val_loss: 0.5047\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577448.106968      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 426ms/step - accuracy: 0.6538 - loss: 0.6208 - val_accuracy: 0.5562 - val_loss: 0.6791\n",
            "Epoch 4/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5312 - loss: 0.6866 - val_accuracy: 0.4828 - val_loss: 0.6959\n",
            "Epoch 5/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 423ms/step - accuracy: 0.5545 - loss: 0.6845 - val_accuracy: 0.5063 - val_loss: 0.7164\n",
            "Epoch 6/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6250 - loss: 0.6429 - val_accuracy: 0.5172 - val_loss: 0.7430\n",
            "Epoch 7/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 429ms/step - accuracy: 0.5964 - loss: 0.6547 - val_accuracy: 0.6812 - val_loss: 0.5844\n",
            "Epoch 8/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5000 - loss: 0.7652 - val_accuracy: 0.7241 - val_loss: 0.4947\n",
            "Epoch 9/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 428ms/step - accuracy: 0.6962 - loss: 0.5724 - val_accuracy: 0.7500 - val_loss: 0.5526\n",
            "Epoch 10/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6250 - loss: 0.5873 - val_accuracy: 0.7241 - val_loss: 0.5466\n",
            "Finished training for class: Car\n",
            "Training for class: Cow\n",
            "Number of positive samples for Cow: 159\n",
            "Number of negative samples before balancing: 6748\n",
            "Number of negative samples after balancing: 159\n",
            "Found 254 validated image filenames belonging to 2 classes.\n",
            "Found 64 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711577510.172630      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 385ms/step - accuracy: 0.4844 - loss: 0.7474"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577513.097575      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739ms/step - accuracy: 0.4984 - loss: 0.7773"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577515.875255      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 913ms/step - accuracy: 0.4969 - loss: 0.7783 - val_accuracy: 0.6094 - val_loss: 0.6555\n",
            "Epoch 2/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7188 - loss: 0.6185 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 443ms/step - accuracy: 0.6684 - loss: 0.6269 - val_accuracy: 0.6094 - val_loss: 0.6634\n",
            "Epoch 4/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5625 - loss: 0.6417 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
            "Epoch 5/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 444ms/step - accuracy: 0.7042 - loss: 0.5801 - val_accuracy: 0.5312 - val_loss: 0.7303\n",
            "Epoch 6/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6562 - loss: 0.6352 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
            "Epoch 7/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 453ms/step - accuracy: 0.7803 - loss: 0.4889 - val_accuracy: 0.6875 - val_loss: 0.5972\n",
            "Epoch 8/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7188 - loss: 0.5303 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
            "Epoch 9/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 454ms/step - accuracy: 0.7196 - loss: 0.5318 - val_accuracy: 0.6562 - val_loss: 0.7661\n",
            "Epoch 10/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6875 - loss: 0.6085 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
            "Finished training for class: Cow\n",
            "Training for class: Bird\n",
            "Number of positive samples for Bird: 344\n",
            "Number of negative samples before balancing: 6563\n",
            "Number of negative samples after balancing: 344\n",
            "Found 550 validated image filenames belonging to 2 classes.\n",
            "Found 138 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711577550.657943      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 556ms/step - accuracy: 0.5135 - loss: 0.7414"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577557.630531      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515ms/step - accuracy: 0.5119 - loss: 0.7386"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577560.259722      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 602ms/step - accuracy: 0.5113 - loss: 0.7379 - val_accuracy: 0.5391 - val_loss: 0.6820\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 388ms/step - accuracy: 0.3438 - loss: 0.6991"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.3438 - loss: 0.6991 - val_accuracy: 0.9000 - val_loss: 0.6338\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577561.515278      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 431ms/step - accuracy: 0.5040 - loss: 0.7096 - val_accuracy: 0.5625 - val_loss: 0.6876\n",
            "Epoch 4/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5312 - loss: 0.6969 - val_accuracy: 0.5000 - val_loss: 0.6813\n",
            "Epoch 5/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 415ms/step - accuracy: 0.5099 - loss: 0.6919 - val_accuracy: 0.4219 - val_loss: 0.7234\n",
            "Epoch 6/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4688 - loss: 0.7063 - val_accuracy: 0.8000 - val_loss: 0.5750\n",
            "Epoch 7/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 429ms/step - accuracy: 0.5601 - loss: 0.6787 - val_accuracy: 0.6094 - val_loss: 0.6484\n",
            "Epoch 8/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5000 - loss: 0.7269 - val_accuracy: 0.4000 - val_loss: 0.7912\n",
            "Epoch 9/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 409ms/step - accuracy: 0.5342 - loss: 0.7036 - val_accuracy: 0.4375 - val_loss: 0.6856\n",
            "Epoch 10/10\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4375 - loss: 0.6834 - val_accuracy: 0.6000 - val_loss: 0.6441\n",
            "Finished training for class: Bird\n",
            "Training for class: Pottedplant\n",
            "Number of positive samples for Pottedplant: 244\n",
            "Number of negative samples before balancing: 6663\n",
            "Number of negative samples after balancing: 244\n",
            "Found 390 validated image filenames belonging to 2 classes.\n",
            "Found 98 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1:45\u001b[0m 10s/step - accuracy: 0.8333 - loss: 0.3367"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577613.377587      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n",
            "W0000 00:00:1711577615.609624      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578ms/step - accuracy: 0.5682 - loss: 0.8881"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577620.763554      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 689ms/step - accuracy: 0.5625 - loss: 0.8825 - val_accuracy: 0.5000 - val_loss: 0.6920\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 381ms/step - accuracy: 0.5000 - loss: 0.6956"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5000 - loss: 0.6956 - val_accuracy: 0.5000 - val_loss: 0.6957\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577621.887505      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 403ms/step - accuracy: 0.4945 - loss: 0.6944 - val_accuracy: 0.5938 - val_loss: 0.6911\n",
            "Epoch 4/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3438 - loss: 0.6967 - val_accuracy: 0.5000 - val_loss: 0.6909\n",
            "Epoch 5/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 427ms/step - accuracy: 0.4988 - loss: 0.6939 - val_accuracy: 0.6042 - val_loss: 0.6784\n",
            "Epoch 6/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4062 - loss: 0.7127 - val_accuracy: 0.0000e+00 - val_loss: 0.7633\n",
            "Epoch 7/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 408ms/step - accuracy: 0.5173 - loss: 0.6948 - val_accuracy: 0.4271 - val_loss: 0.6931\n",
            "Epoch 8/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5000 - loss: 0.6929 - val_accuracy: 0.5000 - val_loss: 0.6943\n",
            "Epoch 9/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 415ms/step - accuracy: 0.5165 - loss: 0.6927 - val_accuracy: 0.4167 - val_loss: 0.6970\n",
            "Epoch 10/10\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4688 - loss: 0.6952 - val_accuracy: 0.0000e+00 - val_loss: 0.7202\n",
            "Finished training for class: Pottedplant\n",
            "Training for class: Tvmonitor\n",
            "Number of positive samples for Tvmonitor: 272\n",
            "Number of negative samples before balancing: 6635\n",
            "Number of negative samples after balancing: 272\n",
            "Found 435 validated image filenames belonging to 2 classes.\n",
            "Found 109 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711577663.858320      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 1/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1:45\u001b[0m 9s/step - accuracy: 0.4211 - loss: 0.8814"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577666.343377      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574ms/step - accuracy: 0.4882 - loss: 0.9203"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577671.987297      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 677ms/step - accuracy: 0.4911 - loss: 0.9112 - val_accuracy: 0.4792 - val_loss: 0.6926\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 387ms/step - accuracy: 0.5625 - loss: 0.6835"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5625 - loss: 0.6835 - val_accuracy: 0.3077 - val_loss: 0.7250\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577673.122950      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 423ms/step - accuracy: 0.5578 - loss: 0.6878 - val_accuracy: 0.5208 - val_loss: 0.6744\n",
            "Epoch 4/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4688 - loss: 0.6846 - val_accuracy: 0.5385 - val_loss: 0.6848\n",
            "Epoch 5/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 423ms/step - accuracy: 0.5619 - loss: 0.6766 - val_accuracy: 0.6979 - val_loss: 0.5646\n",
            "Epoch 6/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6250 - loss: 0.6193 - val_accuracy: 0.6923 - val_loss: 0.4993\n",
            "Epoch 7/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 423ms/step - accuracy: 0.6066 - loss: 0.6634 - val_accuracy: 0.7708 - val_loss: 0.6023\n",
            "Epoch 8/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6875 - loss: 0.6462 - val_accuracy: 0.6923 - val_loss: 0.6405\n",
            "Epoch 9/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 422ms/step - accuracy: 0.5990 - loss: 0.6598 - val_accuracy: 0.7188 - val_loss: 0.5609\n",
            "Epoch 10/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7188 - loss: 0.5386 - val_accuracy: 0.3846 - val_loss: 0.8109\n",
            "Finished training for class: Tvmonitor\n",
            "Training for class: Dog\n",
            "Number of positive samples for Dog: 410\n",
            "Number of negative samples before balancing: 6497\n",
            "Number of negative samples after balancing: 410\n",
            "Found 656 validated image filenames belonging to 2 classes.\n",
            "Found 164 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711577717.297795      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 392ms/step - accuracy: 0.5363 - loss: 0.7981"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577723.740516      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step - accuracy: 0.5314 - loss: 0.7771"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577728.053799      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 575ms/step - accuracy: 0.5316 - loss: 0.7751 - val_accuracy: 0.5562 - val_loss: 0.6905\n",
            "Epoch 2/10\n",
            "\u001b[1m 1/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 418ms/step - accuracy: 0.6250 - loss: 0.6691"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6250 - loss: 0.6691 - val_accuracy: 0.7500 - val_loss: 0.6205\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577729.467110      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 439ms/step - accuracy: 0.5998 - loss: 0.6719 - val_accuracy: 0.6000 - val_loss: 0.6522\n",
            "Epoch 4/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6875 - loss: 0.5908 - val_accuracy: 0.0000e+00 - val_loss: 0.9574\n",
            "Epoch 5/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 435ms/step - accuracy: 0.6444 - loss: 0.6347 - val_accuracy: 0.5063 - val_loss: 0.7308\n",
            "Epoch 6/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6562 - loss: 0.6017 - val_accuracy: 0.5000 - val_loss: 0.8136\n",
            "Epoch 7/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 444ms/step - accuracy: 0.6170 - loss: 0.6410 - val_accuracy: 0.5625 - val_loss: 0.6744\n",
            "Epoch 8/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6250 - loss: 0.6445 - val_accuracy: 0.5000 - val_loss: 0.6575\n",
            "Epoch 9/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 422ms/step - accuracy: 0.6550 - loss: 0.6124 - val_accuracy: 0.6187 - val_loss: 0.8008\n",
            "Epoch 10/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5938 - loss: 0.8790 - val_accuracy: 0.5000 - val_loss: 0.9334\n",
            "Finished training for class: Dog\n",
            "Training for class: Chair\n",
            "Number of positive samples for Chair: 380\n",
            "Number of negative samples before balancing: 6527\n",
            "Number of negative samples after balancing: 380\n",
            "Found 608 validated image filenames belonging to 2 classes.\n",
            "Found 152 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "W0000 00:00:1711577786.321569      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - accuracy: 0.4942 - loss: 0.7824"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577794.721327      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 469ms/step - accuracy: 0.4929 - loss: 0.7804 - val_accuracy: 0.5625 - val_loss: 0.6872\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.3333 - val_loss: 0.7176\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1711577795.576387      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 424ms/step - accuracy: 0.4903 - loss: 0.6950 - val_accuracy: 0.4922 - val_loss: 0.6951\n",
            "Epoch 4/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.4167 - val_loss: 0.7041\n",
            "Epoch 5/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 430ms/step - accuracy: 0.4951 - loss: 0.6964 - val_accuracy: 0.4922 - val_loss: 0.6912\n",
            "Epoch 6/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.4583 - val_loss: 0.6957\n",
            "Epoch 7/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 442ms/step - accuracy: 0.5761 - loss: 0.6842 - val_accuracy: 0.5000 - val_loss: 0.7119\n",
            "Epoch 8/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.3750 - val_loss: 0.8830\n",
            "Epoch 9/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 430ms/step - accuracy: 0.6247 - loss: 0.6403 - val_accuracy: 0.5938 - val_loss: 0.6521\n",
            "Epoch 10/10\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.4167 - val_loss: 0.6973\n",
            "Finished training for class: Chair\n"
          ]
        }
      ],
      "source": [
        "# Loop through each class and train a binary classification model\n",
        "for class_name in class_names:\n",
        "    print(f\"Training for class: {class_name}\")\n",
        "\n",
        "    # Retrieve the list of image paths for the positive class\n",
        "    positive_images = train_data_lists[class_name]\n",
        "    if not positive_images:\n",
        "        print(f\"No images found for class {class_name}. Skipping this class.\")\n",
        "        continue\n",
        "    positive_labels = [1] * len(positive_images)\n",
        "\n",
        "    # Build a list of image paths for the negative class (all other classes)\n",
        "    negative_images = []\n",
        "    for other_class_name, image_paths in train_data_lists.items():\n",
        "        if other_class_name != class_name:\n",
        "            negative_images.extend(image_paths)\n",
        "\n",
        "    print(f\"Number of positive samples for {class_name}: {len(positive_images)}\")\n",
        "    print(f\"Number of negative samples before balancing: {len(negative_images)}\")\n",
        "\n",
        "\n",
        "    random.shuffle(negative_images)  # Shuffle the negative images\n",
        "    negative_images = negative_images[:len(positive_images)]  # Balance the positive and negative datasets\n",
        "    negative_labels = [0] * len(negative_images)\n",
        "    print(f\"Number of negative samples after balancing: {len(negative_images)}\")\n",
        "\n",
        "    # Combine and shuffle the positive and negative samples\n",
        "    combined_images = positive_images + negative_images\n",
        "    combined_labels = positive_labels + negative_labels\n",
        "    combined_list = list(zip(combined_images, combined_labels))\n",
        "    random.shuffle(combined_list)\n",
        "    combined_images, combined_labels = zip(*combined_list)\n",
        "\n",
        "    # Split the data into training and validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(combined_images, combined_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Create DataFrames for the training and validation sets\n",
        "    train_df = pd.DataFrame({\n",
        "    'filename': X_train,\n",
        "    'label': [str(label) for label in y_train]  # Convert labels to strings\n",
        "})\n",
        "    val_df = pd.DataFrame({\n",
        "    'filename': X_val,\n",
        "    'label': [str(label) for label in y_val]  # Convert labels to strings\n",
        "})\n",
        "\n",
        "    # Create data generators for training and validation\n",
        "    train_generator = train_datagen.flow_from_dataframe(\n",
        "        train_df,\n",
        "        x_col='filename',\n",
        "        y_col='label',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='binary'\n",
        "    )\n",
        "\n",
        "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    val_generator = val_datagen.flow_from_dataframe(\n",
        "        val_df,\n",
        "        x_col='filename',\n",
        "        y_col='label',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='binary'\n",
        "    )\n",
        "\n",
        "    #Build the binary classification model\n",
        "    model = build_binary_classification_model()\n",
        "\n",
        "    # Train the model on the data\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=len(X_train) // 32,\n",
        "        validation_data=val_generator,\n",
        "        validation_steps=len(X_val) // 32,\n",
        "        epochs=10\n",
        "    )\n",
        "\n",
        "    # Save the trained model\n",
        "    model_save_path = os.path.join('models', f\"{class_name}_binary_model.h5\")\n",
        "    os.makedirs('models3', exist_ok=True)\n",
        "    model.save(model_save_path)\n",
        "\n",
        "    print(f\"Finished training for class: {class_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-27T22:19:10.967069Z",
          "iopub.status.busy": "2024-03-27T22:19:10.966699Z",
          "iopub.status.idle": "2024-03-27T22:19:10.975238Z",
          "shell.execute_reply": "2024-03-27T22:19:10.974294Z",
          "shell.execute_reply.started": "2024-03-27T22:19:10.967038Z"
        },
        "id": "p_JG3zr80B6t"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the path to the train directory\n",
        "train_dir = \"/content/test500\"\n",
        "\n",
        "# Iterate over each subfolder in the train directory\n",
        "for class_name in os.listdir(train_dir):\n",
        "    class_dir = os.path.join(train_dir, class_name)\n",
        "\n",
        "    # Check if the item in the directory is a subfolder\n",
        "    if os.path.isdir(class_dir):\n",
        "        # Define the path to the subsubfolder\n",
        "        subsubfolder_dir = os.path.join(class_dir, class_name)\n",
        "\n",
        "        # Check if the subsubfolder exists\n",
        "        if os.path.exists(subsubfolder_dir):\n",
        "            # Iterate over each file in the subsubfolder\n",
        "            for file_name in os.listdir(subsubfolder_dir):\n",
        "                file_path = os.path.join(subsubfolder_dir, file_name)\n",
        "\n",
        "                # Move the file to the parent subfolder\n",
        "                if os.path.isfile(file_path):\n",
        "                    shutil.move(file_path, class_dir)\n",
        "\n",
        "            # Remove the empty subsubfolder\n",
        "            os.rmdir(subsubfolder_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmTCOr7x0B6u"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import classification_report, confusion_matrix, average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "model_dir = '/content/models500'\n",
        "test_data_dir = '/content/test500'\n",
        "\n",
        "# Initialize ImageDataGenerator for preprocessing\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Store average precision scores for mAP calculation\n",
        "ap_scores = []\n",
        "\n",
        "# Loop through each model file in the models directory\n",
        "for model_file in sorted(os.listdir(model_dir)):\n",
        "    if model_file.endswith(\".h5\"):\n",
        "        print(f\"\\nLoading model {model_file}...\")\n",
        "        model_path = os.path.join(model_dir, model_file)\n",
        "        model = load_model(model_path)\n",
        "        class_name = model_file.replace(\"_binary_model.h5\", \"\")\n",
        "        print(f\"Model for class '{class_name}' loaded successfully.\")\n",
        "\n",
        "        # Create DataFrame for test data with labels as strings\n",
        "        images = []\n",
        "        labels = []\n",
        "        for folder in os.listdir(test_data_dir):\n",
        "            folder_path = os.path.join(test_data_dir, folder)\n",
        "            for image_file in os.listdir(folder_path):\n",
        "                images.append(os.path.join(folder, image_file))\n",
        "                labels.append(str(int(folder == class_name)))  # Convert boolean to int to string\n",
        "\n",
        "        test_df = pd.DataFrame({\n",
        "            'filename': images,\n",
        "            'label': labels  # Labels are now strings\n",
        "        })\n",
        "\n",
        "        # Prepare test generator\n",
        "        test_generator = test_datagen.flow_from_dataframe(\n",
        "            dataframe=test_df,\n",
        "            directory=test_data_dir,\n",
        "            x_col='filename',\n",
        "            y_col='label',\n",
        "            target_size=(224, 224),\n",
        "            batch_size=32,\n",
        "            class_mode='binary',\n",
        "            shuffle=False)\n",
        "\n",
        "        # Predict and evaluate\n",
        "        predictions = model.predict(test_generator, steps=int(np.ceil(len(test_df)/32)))\n",
        "\n",
        "        predicted_labels = (predictions > 0.5).astype(int)\n",
        "        ap_score = average_precision_score(test_generator.classes, predictions)\n",
        "        ap_scores.append(ap_score)\n",
        "        #print(f\"AP score for class '{class_name}': {ap_score:.3f}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-03-27T22:21:53.050274Z",
          "iopub.status.busy": "2024-03-27T22:21:53.049925Z",
          "iopub.status.idle": "2024-03-27T22:21:53.055804Z",
          "shell.execute_reply": "2024-03-27T22:21:53.054847Z",
          "shell.execute_reply.started": "2024-03-27T22:21:53.050249Z"
        },
        "id": "Z6V_Bh4c0B6u",
        "outputId": "59ebb4b9-ade3-49b3-ad05-dc0cb17f0afb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.149\n"
          ]
        }
      ],
      "source": [
        "# Calculate mean Average Precision (mAP)\n",
        "mAP = np.mean(ap_scores)\n",
        "print(f\"\\nMean Average Precision (mAP) across all classes: {mAP:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adaxYNFg0B6u"
      },
      "source": [
        "# A comparison of mAP changes as samples size increase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "execution": {
          "iopub.execute_input": "2024-03-27T22:22:02.836020Z",
          "iopub.status.busy": "2024-03-27T22:22:02.835661Z",
          "iopub.status.idle": "2024-03-27T22:22:03.041459Z",
          "shell.execute_reply": "2024-03-27T22:22:03.040562Z",
          "shell.execute_reply.started": "2024-03-27T22:22:02.835991Z"
        },
        "id": "fKDWYJmT0B6u",
        "outputId": "e755751a-a919-4b03-9b5a-b6e45d8770bd"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sample_sizes = [100, 200, 500]   #Samples\n",
        "mAP_values = [0.145, 0.148, 0.149]  #  mAP values\n",
        "\n",
        "# Plot the graph\n",
        "plt.plot(sample_sizes, mAP_values, marker='o', linestyle='-')\n",
        "plt.title('mAP vs Sample Size')\n",
        "plt.xlabel('Sample Size')\n",
        "plt.ylabel('mAP')\n",
        "plt.grid(True)\n",
        "plt.xticks(sample_sizes)\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 4668815,
          "sourceId": 7941038,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30674,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
