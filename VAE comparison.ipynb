{"cells":[{"cell_type":"markdown","metadata":{},"source":["### In this notebook we see how increasing the data for each class improves the overall accuracy of the binary classifier made of VGG16. The Variational Auto Encoders were trained on the data of each class and generated samples for them. Graph at the end of the notebook compares the accuracy of the VGG16 when trained on extra 100, 200 and 500 samples included in the dataset. "]},{"cell_type":"markdown","metadata":{},"source":["# Preparing the dataset for the training"]},{"cell_type":"markdown","metadata":{},"source":["## Splitting data into train and test folders"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T16:34:57.186221Z","iopub.status.busy":"2024-03-28T16:34:57.185480Z","iopub.status.idle":"2024-03-28T16:35:09.745491Z","shell.execute_reply":"2024-03-28T16:35:09.744698Z","shell.execute_reply.started":"2024-03-28T16:34:57.186189Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-03-28 16:34:58.883213: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-03-28 16:34:58.883310: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-03-28 16:34:59.011038: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["from tensorflow import keras\n","import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import models\n","from tensorflow.keras import layers\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.applications import VGG16\n","from keras.applications.vgg16 import preprocess_input\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","import numpy as np\n","from PIL import Image"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","path= '/content/drive/MyDrive/VOCtrainval_14-Jul-2008.tar'\n","import tarfile\n","with tarfile.open(path, 'r') as tar:\n","    tar.extractall()"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T19:00:43.261096Z","iopub.status.busy":"2024-03-27T19:00:43.260678Z","iopub.status.idle":"2024-03-27T19:01:49.750779Z","shell.execute_reply":"2024-03-27T19:01:49.749928Z","shell.execute_reply.started":"2024-03-27T19:00:43.261064Z"},"trusted":true},"outputs":[],"source":["import shutil\n","import os\n","from sklearn.model_selection import train_test_split\n","\n","folder_path = \"/content/VOCdevkit/VOC2008/JPEGImages\"\n","def extract_positive_images(directory, file_name):\n","    positive_images = []\n","    variations = [\n","        file_name,\n","        file_name.replace(\"_train\", \"_trainval\"),\n","        file_name.replace(\"_train\", \"_val\")\n","    ]\n","\n","    for variation in variations:\n","        file_path = os.path.join(directory, variation)\n","        with open(file_path, \"r\") as file:\n","            lines = file.readlines()\n","\n","        for line in lines:\n","            if line.strip().endswith(\" 1\"):\n","                image_name = line.split()[0] + \".jpg\"\n","                if image_name not in positive_images:\n","                    positive_images.append(image_name)\n","\n","    return positive_images\n","\n","\n","data_directory = \"/content/VOCdevkit/VOC2008/ImageSets/Main\"\n","folder_path = \"/content/VOCdevkit/VOC2008/JPEGImages\"\n","\n","aeroplane_images = extract_positive_images(data_directory, \"aeroplane_train.txt\")\n","bicycle_images = extract_positive_images(data_directory, \"bicycle_train.txt\")\n","bird_images = extract_positive_images(data_directory, \"bird_train.txt\")\n","boat_images = extract_positive_images(data_directory, \"boat_train.txt\")\n","bottle_images = extract_positive_images(data_directory, \"bottle_train.txt\")\n","bus_images = extract_positive_images(data_directory, \"bus_train.txt\")\n","car_images = extract_positive_images(data_directory, \"car_train.txt\")\n","cat_images = extract_positive_images(data_directory, \"cat_train.txt\")\n","chair_images = extract_positive_images(data_directory, \"chair_train.txt\")\n","cow_images = extract_positive_images(data_directory, \"cow_train.txt\")\n","diningtable_images = extract_positive_images(data_directory, \"diningtable_train.txt\")\n","dog_images = extract_positive_images(data_directory, \"dog_train.txt\")\n","horse_images = extract_positive_images(data_directory, \"horse_train.txt\")\n","motorbike_images = extract_positive_images(data_directory, \"motorbike_train.txt\")\n","person_images = extract_positive_images(data_directory, \"person_train.txt\")\n","pottedplant_images = extract_positive_images(data_directory, \"pottedplant_train.txt\")\n","sheep_images = extract_positive_images(data_directory, \"sheep_train.txt\")\n","sofa_images = extract_positive_images(data_directory, \"sofa_train.txt\")\n","train_images = extract_positive_images(data_directory, \"train_train.txt\")\n","tvmonitor_images = extract_positive_images(data_directory, \"tvmonitor_train.txt\")\n","\n","jpg_files = []\n","\n","for file in os.listdir(folder_path):\n","    if file.endswith(\".jpg\"):\n","        jpg_files.append(file)\n","\n","\n","class_data_lists = {\n","    \"Aeroplane\": aeroplane_images,\n","    \"Bicycle\": bicycle_images,\n","    \"Bird\": bird_images,\n","    \"Boat\": boat_images,\n","    \"Bottle\": bottle_images,\n","    \"Bus\": bus_images,\n","    \"Car\": car_images,\n","    \"Cat\": cat_images,\n","    \"Chair\": chair_images,\n","    \"Cow\": cow_images,\n","    \"Diningtable\": diningtable_images,\n","    \"Dog\": dog_images,\n","    \"Horse\": horse_images,\n","    \"Motorbike\": motorbike_images,\n","    \"Person\": person_images,\n","    \"Pottedplant\": pottedplant_images,\n","    \"Sheep\": sheep_images,\n","    \"Sofa\": sofa_images,\n","    \"Train\": train_images,\n","    \"Tvmonitor\": tvmonitor_images\n","}\n","\n","\n","train_data_lists = {class_name: [] for class_name in class_data_lists}\n","test_data_lists = {class_name: [] for class_name in class_data_lists}\n","\n","\n","for class_name, data_list in class_data_lists.items():\n","    train_images, test_images = train_test_split(data_list, test_size=0.2, random_state=42)\n","    train_data_lists[class_name] = train_images\n","    test_data_lists[class_name] = test_images\n","\n","\n","for class_name, train_images in train_data_lists.items():\n","    for file in train_images:\n","        try:\n","            src_path = os.path.join(folder_path, file)\n","            dest_dir = os.path.join(\"/content/train\", class_name)\n","            dest_path = os.path.join(dest_dir, file)\n","            os.makedirs(dest_dir, exist_ok=True)\n","            shutil.copyfile(src_path, dest_path)\n","        except Exception as e:\n","            print(f\"Error copying {file} to {dest_dir}: {e}\")\n","\n","\n","for class_name, test_images in test_data_lists.items():\n","    for file in test_images:\n","        try:\n","            src_path = os.path.join(folder_path, file)\n","            dest_dir = os.path.join(\"/content/test\", class_name)\n","            dest_path = os.path.join(dest_dir, file)\n","            os.makedirs(dest_dir, exist_ok=True)\n","            shutil.copyfile(src_path, dest_path)\n","        except Exception as e:\n","            print(f\"Error copying {file} to {dest_dir}: {e}\")\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T19:01:58.164357Z","iopub.status.busy":"2024-03-27T19:01:58.163572Z","iopub.status.idle":"2024-03-27T19:01:58.173525Z","shell.execute_reply":"2024-03-27T19:01:58.172490Z","shell.execute_reply.started":"2024-03-27T19:01:58.164323Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['Cat',\n"," 'Sofa',\n"," 'Sheep',\n"," 'Diningtable',\n"," 'Horse',\n"," 'Person',\n"," 'Motorbike',\n"," 'Bus',\n"," 'Bicycle',\n"," 'Aeroplane',\n"," 'Train',\n"," 'Bottle',\n"," 'Boat',\n"," 'Car',\n"," 'Cow',\n"," 'Bird',\n"," 'Pottedplant',\n"," 'Tvmonitor',\n"," 'Dog',\n"," 'Chair']"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["train_folder_path = \"/content/train\"\n","class_names = [d for d in os.listdir(train_folder_path) if os.path.isdir(os.path.join(train_folder_path, d))]\n","class_names"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def create_class_subfolders(parent_folder):\n","    # Iterate through each class subfolder\n","    for class_folder in os.listdir(parent_folder):\n","        class_folder_path = os.path.join(parent_folder, class_folder)\n","        if os.path.isdir(class_folder_path):\n","            # Create a new subfolder with the same class name\n","            new_subfolder_path = os.path.join(class_folder_path, class_folder)\n","            os.makedirs(new_subfolder_path, exist_ok=True)\n","\n","            # Copy all images from the class folder to the new subfolder\n","            for file_name in os.listdir(class_folder_path):\n","                file_path = os.path.join(class_folder_path, file_name)\n","                if os.path.isfile(file_path):\n","                    shutil.move(file_path, new_subfolder_path)\n","\n","            print(f\"Created subfolder for class '{class_folder}' in '{class_folder_path}'\")\n","\n","# Define the parent folder containing class subfolders\n","parent_folder = \"/content/train\"\n","\n","# Call the function to create class subfolders and copy images\n","create_class_subfolders(parent_folder)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","import shutil\n","\n","#for Test data\n","\n","def create_class_subfolders(parent_folder):\n","    # Iterate through each class subfolder\n","    for class_folder in os.listdir(parent_folder):\n","        class_folder_path = os.path.join(parent_folder, class_folder)\n","        if os.path.isdir(class_folder_path):\n","            # Create a new subfolder with the same class name\n","            new_subfolder_path = os.path.join(class_folder_path, class_folder)\n","            os.makedirs(new_subfolder_path, exist_ok=True)\n","\n","            # Copy all images from the class folder to the new subfolder\n","            for file_name in os.listdir(class_folder_path):\n","                file_path = os.path.join(class_folder_path, file_name)\n","                if os.path.isfile(file_path):\n","                    shutil.move(file_path, new_subfolder_path)\n","\n","            print(f\"Created subfolder for class '{class_folder}' in '{class_folder_path}'\")\n","\n","\n","\n","# Define the parent folder containing class subfolders\n","parent_folder = \"/content/test\"\n","\n","# Call the function to create class subfolders and copy images\n","create_class_subfolders(parent_folder)"]},{"cell_type":"markdown","metadata":{},"source":["# Building The Variational Auto Encoder"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T16:35:52.708473Z","iopub.status.busy":"2024-03-28T16:35:52.707992Z","iopub.status.idle":"2024-03-28T16:35:52.716859Z","shell.execute_reply":"2024-03-28T16:35:52.715794Z","shell.execute_reply.started":"2024-03-28T16:35:52.708438Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import layers, models, metrics, losses, optimizers, callbacks\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow import keras\n","\n","# Set parameters\n","EMBEDDING_DIM = 2\n","BETA = 1.0  # Weight for KL divergence in VAE loss\n","EPOCHS = 500  # Increase the number of epochs for better training\n","BATCH_SIZE = 16\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T16:35:54.941394Z","iopub.status.busy":"2024-03-28T16:35:54.940456Z","iopub.status.idle":"2024-03-28T16:35:54.946961Z","shell.execute_reply":"2024-03-28T16:35:54.945922Z","shell.execute_reply.started":"2024-03-28T16:35:54.941359Z"},"trusted":true},"outputs":[],"source":["# Define the Sampling layer\n","class Sampling(layers.Layer):\n","    def call(self, inputs):\n","        z_mean, z_log_var = inputs\n","        batch = tf.shape(z_mean)[0]\n","        dim = tf.shape(z_mean)[1]\n","        epsilon = tf.random.normal(shape=(batch, dim))\n","        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n"]},{"cell_type":"markdown","metadata":{},"source":["## Encoder"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T16:35:56.353618Z","iopub.status.busy":"2024-03-28T16:35:56.353275Z","iopub.status.idle":"2024-03-28T16:35:56.438938Z","shell.execute_reply":"2024-03-28T16:35:56.438128Z","shell.execute_reply.started":"2024-03-28T16:35:56.353593Z"},"trusted":true},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"encoder\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"encoder\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,168</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n","│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,616</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16384</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">8,389,120</span> │ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ z_mean (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,026</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ z_log_var (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,026</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ sampling_2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ z_mean[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sampling</span>)          │                   │            │ z_log_var[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m3\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │      \u001b[38;5;34m7,168\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n","│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m1,180,160\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m,      │  \u001b[38;5;34m4,719,616\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","│                     │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16384\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │  \u001b[38;5;34m8,389,120\u001b[0m │ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ z_mean (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │      \u001b[38;5;34m1,026\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ z_log_var (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │      \u001b[38;5;34m1,026\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ sampling_2          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ z_mean[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n","│ (\u001b[38;5;33mSampling\u001b[0m)          │                   │            │ z_log_var[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,298,116</span> (54.54 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,298,116\u001b[0m (54.54 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,298,116</span> (54.54 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,298,116\u001b[0m (54.54 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["# Define the encoder\n","encoder_input = keras.Input(shape=(28, 28, 3))\n","x = layers.Conv2D(256, 3, strides=2, activation=\"relu\", padding=\"same\")(encoder_input)\n","x = layers.Conv2D(512, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n","x = layers.Conv2D(1024, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n","x = layers.Flatten()(x)\n","x = layers.Dense(512, activation=\"relu\")(x)\n","z_mean = layers.Dense(EMBEDDING_DIM, name=\"z_mean\")(x)\n","z_log_var = layers.Dense(EMBEDDING_DIM, name=\"z_log_var\")(x)\n","z = Sampling()([z_mean, z_log_var])\n","\n","encoder = keras.Model(encoder_input, [z_mean, z_log_var, z], name=\"encoder\")\n","\n","\n","\n","encoder.summary()"]},{"cell_type":"markdown","metadata":{},"source":["## Decoder"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T16:36:12.222840Z","iopub.status.busy":"2024-03-28T16:36:12.222456Z","iopub.status.idle":"2024-03-28T16:36:12.292461Z","shell.execute_reply":"2024-03-28T16:36:12.291602Z","shell.execute_reply.started":"2024-03-28T16:36:12.222811Z"},"trusted":true},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"decoder\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"decoder\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50176</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,528</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_transpose                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,104</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_transpose_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_transpose_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,459</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50176\u001b[0m)          │       \u001b[38;5;34m150,528\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_transpose                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m4,719,104\u001b[0m │\n","│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_transpose_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │     \u001b[38;5;34m1,179,904\u001b[0m │\n","│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_transpose_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m295,040\u001b[0m │\n","│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │         \u001b[38;5;34m3,459\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,348,035</span> (24.22 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,348,035\u001b[0m (24.22 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,348,035</span> (24.22 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,348,035\u001b[0m (24.22 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["# Define the decoder\n","decoder_input = keras.Input(shape=(EMBEDDING_DIM,))\n","x = layers.Dense(7 * 7 * 1024, activation=\"relu\")(decoder_input)\n","x = layers.Reshape((7, 7, 1024))(x)\n","x = layers.Conv2DTranspose(512, 3, strides=1, activation=\"relu\", padding=\"same\")(x)\n","x = layers.Conv2DTranspose(256, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n","x = layers.Conv2DTranspose(128, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n","decoder_output = layers.Conv2D(3, 3, strides=1, activation=\"sigmoid\", padding=\"same\")(x)\n","\n","decoder = keras.Model(decoder_input, decoder_output, name=\"decoder\")\n","decoder.summary()\n","\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T16:37:05.971841Z","iopub.status.busy":"2024-03-28T16:37:05.970708Z","iopub.status.idle":"2024-03-28T16:37:05.983417Z","shell.execute_reply":"2024-03-28T16:37:05.982457Z","shell.execute_reply.started":"2024-03-28T16:37:05.971802Z"},"trusted":true},"outputs":[],"source":["# Define the VAE model\n","class VAE(keras.Model):\n","    def __init__(self, encoder, decoder, **kwargs):\n","        super().__init__(**kwargs)\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n","        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n","        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n","\n","    @property\n","    def metrics(self):\n","        return [self.total_loss_tracker, self.reconstruction_loss_tracker, self.kl_loss_tracker]\n","\n","    def call(self, inputs):\n","        z_mean, z_log_var, z = self.encoder(inputs)\n","        reconstruction = self.decoder(z)\n","        return reconstruction\n","\n","    def train_step(self, data):\n","        with tf.GradientTape() as tape:\n","            z_mean, z_log_var, z = self.encoder(data)\n","            reconstruction = self.decoder(z)\n","            reconstruction_loss = tf.reduce_mean(\n","                tf.reduce_sum(\n","                    keras.losses.binary_crossentropy(data, reconstruction),\n","                    axis=(1, 2),\n","                )\n","            )\n","            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n","            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n","            total_loss = reconstruction_loss + kl_loss\n","        grads = tape.gradient(total_loss, self.trainable_weights)\n","        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n","        self.total_loss_tracker.update_state(total_loss)\n","        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n","        self.kl_loss_tracker.update_state(kl_loss)\n","        return {\n","            \"loss\": self.total_loss_tracker.result(),\n","            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n","            \"kl_loss\": self.kl_loss_tracker.result(),\n","        }"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["encoder = keras.Model(encoder)\n","decoder = keras.Model(decoder)\n","vae = VAE(encoder, decoder)\n","vae.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001))"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T16:37:29.303468Z","iopub.status.busy":"2024-03-28T16:37:29.302540Z","iopub.status.idle":"2024-03-28T16:37:29.478074Z","shell.execute_reply":"2024-03-28T16:37:29.477354Z","shell.execute_reply.started":"2024-03-28T16:37:29.303437Z"},"trusted":true},"outputs":[],"source":["import cv2\n","import tensorflow.keras.backend as K\n","from tensorflow.keras import (\n","    layers,\n","    models,\n","    datasets,\n","    callbacks,\n","    losses,\n","    optimizers,\n","    metrics,\n",")\n","IMAGE_SIZE = 28"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T19:08:31.440561Z","iopub.status.busy":"2024-03-27T19:08:31.439783Z","iopub.status.idle":"2024-03-27T20:02:47.903574Z","shell.execute_reply":"2024-03-27T20:02:47.902652Z","shell.execute_reply.started":"2024-03-27T19:08:31.440525Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training VAE for class: Cat\n","Found 262 images belonging to 1 classes.\n","Epoch 1/100\n","\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m56s\u001b[0m 7s/step - kl_loss: 1.5013e-06 - reconstruction_loss: 0.6717 - total_loss: 0.6717"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711566518.500564      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 500ms/step - kl_loss: 2.2978e-04 - reconstruction_loss: 0.6766 - total_loss: 0.6768\n","Epoch 2/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - kl_loss: 3.6186e-05 - reconstruction_loss: 0.6731 - total_loss: 0.6731\n","Epoch 3/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 1.1191e-05 - reconstruction_loss: 0.6740 - total_loss: 0.6740\n","Epoch 4/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 4.7579e-06 - reconstruction_loss: 0.6773 - total_loss: 0.6773\n","Epoch 5/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 1.8554e-06 - reconstruction_loss: 0.6769 - total_loss: 0.6769\n","Epoch 6/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 1.2985e-06 - reconstruction_loss: 0.6771 - total_loss: 0.6771\n","Epoch 7/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 9.1496e-07 - reconstruction_loss: 0.6786 - total_loss: 0.6786\n","Epoch 8/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - kl_loss: 7.9917e-07 - reconstruction_loss: 0.6767 - total_loss: 0.6767\n","Epoch 9/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 7.4970e-07 - reconstruction_loss: 0.6712 - total_loss: 0.6712\n","Epoch 10/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 9.7397e-07 - reconstruction_loss: 0.6771 - total_loss: 0.6771\n","Epoch 11/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 7.0182e-07 - reconstruction_loss: 0.6767 - total_loss: 0.6767\n","Epoch 12/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - kl_loss: 7.1211e-07 - reconstruction_loss: 0.6719 - total_loss: 0.6719\n","Epoch 13/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - kl_loss: 8.3113e-07 - reconstruction_loss: 0.6741 - total_loss: 0.6741\n","Epoch 14/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 6.9168e-07 - reconstruction_loss: 0.6794 - total_loss: 0.6794\n","Epoch 15/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 6.0853e-07 - reconstruction_loss: 0.6776 - total_loss: 0.6776\n","Epoch 16/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 7.7379e-07 - reconstruction_loss: 0.6757 - total_loss: 0.6757\n","Epoch 17/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 115ms/step - kl_loss: 8.2826e-07 - reconstruction_loss: 0.6790 - total_loss: 0.6790\n","Epoch 18/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 7.4173e-07 - reconstruction_loss: 0.6802 - total_loss: 0.6802\n","Epoch 19/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - kl_loss: 7.5676e-07 - reconstruction_loss: 0.6694 - total_loss: 0.6694\n","Epoch 20/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 8.7030e-07 - reconstruction_loss: 0.6743 - total_loss: 0.6743\n","Epoch 21/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 7.5080e-07 - reconstruction_loss: 0.6764 - total_loss: 0.6764\n","Epoch 22/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - kl_loss: 8.0592e-07 - reconstruction_loss: 0.6738 - total_loss: 0.6738\n","Epoch 23/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 7.2118e-07 - reconstruction_loss: 0.6787 - total_loss: 0.6787\n","Epoch 24/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - kl_loss: 8.3936e-07 - reconstruction_loss: 0.6785 - total_loss: 0.6785\n","Epoch 25/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - kl_loss: 8.2008e-07 - reconstruction_loss: 0.6720 - total_loss: 0.6720\n","Epoch 26/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 8.3095e-07 - reconstruction_loss: 0.6719 - total_loss: 0.6719\n","Epoch 27/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - kl_loss: 8.3206e-07 - reconstruction_loss: 0.6783 - total_loss: 0.6783\n","Epoch 28/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - kl_loss: 7.2288e-07 - reconstruction_loss: 0.6733 - total_loss: 0.6733\n","Epoch 29/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - kl_loss: 7.5947e-07 - reconstruction_loss: 0.6728 - total_loss: 0.6728 \n","Epoch 30/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 7.3479e-07 - reconstruction_loss: 0.6774 - total_loss: 0.6774 \n","Epoch 31/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 7.3900e-07 - reconstruction_loss: 0.6768 - total_loss: 0.6768\n","Epoch 32/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - kl_loss: 8.5380e-07 - reconstruction_loss: 0.6815 - total_loss: 0.6815\n","Epoch 33/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 115ms/step - kl_loss: 8.5772e-07 - reconstruction_loss: 0.6760 - total_loss: 0.6760\n","Epoch 34/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - kl_loss: 7.0914e-07 - reconstruction_loss: 0.6781 - total_loss: 0.6781\n","Epoch 35/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - kl_loss: 7.3025e-07 - reconstruction_loss: 0.6749 - total_loss: 0.6749\n","Epoch 36/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - kl_loss: 1.5149e-06 - reconstruction_loss: 0.6759 - total_loss: 0.6759\n","Epoch 37/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - kl_loss: 1.0219e-06 - reconstruction_loss: 0.6827 - total_loss: 0.6827\n","Epoch 38/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - kl_loss: 1.0589e-06 - reconstruction_loss: 0.6767 - total_loss: 0.6767\n","Epoch 39/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 1.2539e-06 - reconstruction_loss: 0.6786 - total_loss: 0.6786\n","Epoch 40/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 1.3762e-06 - reconstruction_loss: 0.6763 - total_loss: 0.6763\n","Epoch 41/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - kl_loss: 1.0675e-06 - reconstruction_loss: 0.6757 - total_loss: 0.6757\n","Epoch 42/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - kl_loss: 8.4543e-07 - reconstruction_loss: 0.6766 - total_loss: 0.6766\n","Epoch 43/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - kl_loss: 9.1182e-07 - reconstruction_loss: 0.6772 - total_loss: 0.6772\n","Epoch 44/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - kl_loss: 1.1255e-06 - reconstruction_loss: 0.6776 - total_loss: 0.6776\n","Epoch 45/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - kl_loss: 1.3381e-06 - reconstruction_loss: 0.6793 - total_loss: 0.6793\n","Epoch 46/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 9.4369e-07 - reconstruction_loss: 0.6776 - total_loss: 0.6776\n","Epoch 47/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - kl_loss: 9.0395e-07 - reconstruction_loss: 0.6796 - total_loss: 0.6796\n","Epoch 48/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - kl_loss: 1.2399e-06 - reconstruction_loss: 0.6763 - total_loss: 0.6763\n","Epoch 49/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - kl_loss: 1.0553e-06 - reconstruction_loss: 0.6815 - total_loss: 0.6815\n","Epoch 50/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 1.3111e-06 - reconstruction_loss: 0.6768 - total_loss: 0.6768\n","Epoch 51/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - kl_loss: 1.1211e-06 - reconstruction_loss: 0.6779 - total_loss: 0.6779\n","Epoch 52/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - kl_loss: 1.3130e-06 - reconstruction_loss: 0.6746 - total_loss: 0.6746\n","Epoch 53/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - kl_loss: 1.0632e-06 - reconstruction_loss: 0.6780 - total_loss: 0.6780\n","Epoch 54/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 8.4841e-07 - reconstruction_loss: 0.6803 - total_loss: 0.6803\n","Epoch 55/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - kl_loss: 7.9913e-07 - reconstruction_loss: 0.6743 - total_loss: 0.6743\n","Epoch 56/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 8.8667e-07 - reconstruction_loss: 0.6740 - total_loss: 0.6740\n","Epoch 57/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 9.2715e-07 - reconstruction_loss: 0.6796 - total_loss: 0.6796\n","Epoch 58/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - kl_loss: 7.9201e-07 - reconstruction_loss: 0.6778 - total_loss: 0.6778\n","Epoch 59/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 8.6752e-07 - reconstruction_loss: 0.6799 - total_loss: 0.6799\n","Epoch 60/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - kl_loss: 9.0195e-07 - reconstruction_loss: 0.6772 - total_loss: 0.6772\n","Epoch 61/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - kl_loss: 1.8696e-06 - reconstruction_loss: 0.6763 - total_loss: 0.6763\n","Epoch 62/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 1.0835e-06 - reconstruction_loss: 0.6789 - total_loss: 0.6789\n","Epoch 63/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - kl_loss: 8.2688e-07 - reconstruction_loss: 0.6750 - total_loss: 0.6750\n","Epoch 64/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 9.4980e-07 - reconstruction_loss: 0.6756 - total_loss: 0.6756\n","Epoch 65/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 9.8542e-07 - reconstruction_loss: 0.6773 - total_loss: 0.6773\n","Epoch 66/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - kl_loss: 1.1150e-06 - reconstruction_loss: 0.6767 - total_loss: 0.6767\n","Epoch 67/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - kl_loss: 1.0318e-06 - reconstruction_loss: 0.6749 - total_loss: 0.6749 \n","Epoch 68/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - kl_loss: 1.0192e-06 - reconstruction_loss: 0.6744 - total_loss: 0.6744\n","Epoch 69/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - kl_loss: 1.3131e-06 - reconstruction_loss: 0.6825 - total_loss: 0.6825\n","Epoch 70/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - kl_loss: 1.1477e-06 - reconstruction_loss: 0.6812 - total_loss: 0.6812\n","Epoch 71/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 9.3079e-07 - reconstruction_loss: 0.6814 - total_loss: 0.6814\n","Epoch 72/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 9.2893e-07 - reconstruction_loss: 0.6765 - total_loss: 0.6765\n","Epoch 73/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - kl_loss: 1.2215e-06 - reconstruction_loss: 0.6786 - total_loss: 0.6786\n","Epoch 74/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - kl_loss: 1.4137e-06 - reconstruction_loss: 0.6767 - total_loss: 0.6767\n","Epoch 75/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - kl_loss: 1.1830e-06 - reconstruction_loss: 0.6767 - total_loss: 0.6767\n","Epoch 76/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - kl_loss: 1.1579e-06 - reconstruction_loss: 0.6796 - total_loss: 0.6796\n","Epoch 77/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - kl_loss: 1.4652e-06 - reconstruction_loss: 0.6781 - total_loss: 0.6781\n","Epoch 78/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - kl_loss: 1.1210e-06 - reconstruction_loss: 0.6760 - total_loss: 0.6760\n","Epoch 79/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - kl_loss: 9.6962e-07 - reconstruction_loss: 0.6763 - total_loss: 0.6763\n","Epoch 80/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - kl_loss: 1.5892e-06 - reconstruction_loss: 0.6780 - total_loss: 0.6780\n","Epoch 81/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - kl_loss: 2.1035e-06 - reconstruction_loss: 0.6738 - total_loss: 0.6738\n","Epoch 82/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - kl_loss: 1.8737e-06 - reconstruction_loss: 0.6822 - total_loss: 0.6822\n","Epoch 83/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - kl_loss: 1.1801e-06 - reconstruction_loss: 0.6760 - total_loss: 0.6760 \n","Epoch 84/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - kl_loss: 9.2300e-07 - reconstruction_loss: 0.6778 - total_loss: 0.6778\n","Epoch 85/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - kl_loss: 8.8932e-07 - reconstruction_loss: 0.6773 - total_loss: 0.6773 \n","Epoch 86/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - kl_loss: 9.0467e-07 - reconstruction_loss: 0.6784 - total_loss: 0.6784\n","Epoch 87/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - kl_loss: 9.2837e-07 - reconstruction_loss: 0.6795 - total_loss: 0.6795\n","Epoch 88/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - kl_loss: 8.7072e-07 - reconstruction_loss: 0.6749 - total_loss: 0.6749 \n","Epoch 89/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 1.0871e-06 - reconstruction_loss: 0.6800 - total_loss: 0.6800\n","Epoch 90/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - kl_loss: 1.0475e-06 - reconstruction_loss: 0.6742 - total_loss: 0.6742\n","Epoch 91/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - kl_loss: 1.0051e-06 - reconstruction_loss: 0.6761 - total_loss: 0.6761\n","Epoch 92/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - kl_loss: 1.1731e-06 - reconstruction_loss: 0.6769 - total_loss: 0.6769\n","Epoch 93/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 1.1990e-06 - reconstruction_loss: 0.6784 - total_loss: 0.6784\n","Epoch 94/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - kl_loss: 1.2351e-06 - reconstruction_loss: 0.6763 - total_loss: 0.6763\n","Epoch 95/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 1.3101e-06 - reconstruction_loss: 0.6738 - total_loss: 0.6738\n","Epoch 96/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 1.0503e-06 - reconstruction_loss: 0.6773 - total_loss: 0.6773\n","Epoch 97/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - kl_loss: 7.3330e-07 - reconstruction_loss: 0.6785 - total_loss: 0.6785\n","Epoch 98/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 8.2842e-07 - reconstruction_loss: 0.6779 - total_loss: 0.6779\n","Epoch 99/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 8.9083e-07 - reconstruction_loss: 0.6727 - total_loss: 0.6727 \n","Epoch 100/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - kl_loss: 1.5273e-06 - reconstruction_loss: 0.6746 - total_loss: 0.6746\n","Found 66 images belonging to 1 classes.\n","\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 865ms/step"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711566689.531893      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 384ms/step\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n","Training VAE for class: Sofa\n","Found 107 images belonging to 1 classes.\n","Epoch 1/100\n","\u001b[1m2/4\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 3s/step - kl_loss: 1.3903e-05 - reconstruction_loss: 0.6791 - total_loss: 0.6792  "]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711566708.460948      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - kl_loss: 1.6849e-05 - reconstruction_loss: 0.6782 - total_loss: 0.6782\n","Epoch 2/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 1.9248e-05 - reconstruction_loss: 0.6767 - total_loss: 0.6767\n","Epoch 3/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 1.2138e-05 - reconstruction_loss: 0.6806 - total_loss: 0.6806 \n","Epoch 4/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 4.4020e-06 - reconstruction_loss: 0.6778 - total_loss: 0.6778\n","Epoch 5/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 2.5253e-06 - reconstruction_loss: 0.6780 - total_loss: 0.6780\n","Epoch 6/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 3.4303e-06 - reconstruction_loss: 0.6782 - total_loss: 0.6782\n","Epoch 7/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 2.1236e-06 - reconstruction_loss: 0.6774 - total_loss: 0.6774\n","Epoch 8/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 9.5854e-07 - reconstruction_loss: 0.6788 - total_loss: 0.6788\n","Epoch 9/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - kl_loss: 1.5416e-06 - reconstruction_loss: 0.6783 - total_loss: 0.6783\n","Epoch 10/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 1.6006e-06 - reconstruction_loss: 0.6753 - total_loss: 0.6753 \n","Epoch 11/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 1.4818e-06 - reconstruction_loss: 0.6772 - total_loss: 0.6772\n","Epoch 12/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 2.0664e-06 - reconstruction_loss: 0.6792 - total_loss: 0.6792\n","Epoch 13/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.8340e-06 - reconstruction_loss: 0.6720 - total_loss: 0.6720\n","Epoch 14/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 1.0480e-06 - reconstruction_loss: 0.6763 - total_loss: 0.6763\n","Epoch 15/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 3.5147e-06 - reconstruction_loss: 0.6772 - total_loss: 0.6772\n","Epoch 16/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 5.2468e-06 - reconstruction_loss: 0.6813 - total_loss: 0.6813\n","Epoch 17/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 7.8944e-06 - reconstruction_loss: 0.6792 - total_loss: 0.6792\n","Epoch 18/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 5.1066e-06 - reconstruction_loss: 0.6733 - total_loss: 0.6733\n","Epoch 19/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 3.3824e-06 - reconstruction_loss: 0.6760 - total_loss: 0.6760\n","Epoch 20/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 5.3971e-06 - reconstruction_loss: 0.6772 - total_loss: 0.6773\n","Epoch 21/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - kl_loss: 8.2192e-06 - reconstruction_loss: 0.6750 - total_loss: 0.6750\n","Epoch 22/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 1.1208e-05 - reconstruction_loss: 0.6743 - total_loss: 0.6743\n","Epoch 23/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 1.1044e-05 - reconstruction_loss: 0.6725 - total_loss: 0.6725\n","Epoch 24/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 1.4547e-05 - reconstruction_loss: 0.6729 - total_loss: 0.6729 \n","Epoch 25/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - kl_loss: 1.3112e-05 - reconstruction_loss: 0.6737 - total_loss: 0.6737\n","Epoch 26/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 1.2693e-05 - reconstruction_loss: 0.6664 - total_loss: 0.6664\n","Epoch 27/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 7.8084e-06 - reconstruction_loss: 0.6721 - total_loss: 0.6721\n","Epoch 28/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 7.2670e-06 - reconstruction_loss: 0.6757 - total_loss: 0.6757\n","Epoch 29/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 1.2575e-05 - reconstruction_loss: 0.6707 - total_loss: 0.6707\n","Epoch 30/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 1.4801e-05 - reconstruction_loss: 0.6673 - total_loss: 0.6673\n","Epoch 31/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 1.5525e-05 - reconstruction_loss: 0.6696 - total_loss: 0.6697\n","Epoch 32/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.4389e-05 - reconstruction_loss: 0.6646 - total_loss: 0.6646\n","Epoch 33/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 1.2704e-05 - reconstruction_loss: 0.6696 - total_loss: 0.6696\n","Epoch 34/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 1.3898e-05 - reconstruction_loss: 0.6721 - total_loss: 0.6721\n","Epoch 35/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 1.1638e-05 - reconstruction_loss: 0.6722 - total_loss: 0.6722 \n","Epoch 36/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 1.0869e-05 - reconstruction_loss: 0.6696 - total_loss: 0.6696\n","Epoch 37/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 1.1044e-05 - reconstruction_loss: 0.6684 - total_loss: 0.6684\n","Epoch 38/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 1.1692e-05 - reconstruction_loss: 0.6703 - total_loss: 0.6703\n","Epoch 39/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 8.8248e-06 - reconstruction_loss: 0.6724 - total_loss: 0.6724\n","Epoch 40/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.0599e-05 - reconstruction_loss: 0.6753 - total_loss: 0.6753\n","Epoch 41/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 1.4025e-05 - reconstruction_loss: 0.6720 - total_loss: 0.6720\n","Epoch 42/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 1.1502e-05 - reconstruction_loss: 0.6724 - total_loss: 0.6724 \n","Epoch 43/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 1.3219e-05 - reconstruction_loss: 0.6736 - total_loss: 0.6736\n","Epoch 44/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 1.2531e-05 - reconstruction_loss: 0.6724 - total_loss: 0.6724\n","Epoch 45/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 1.0112e-05 - reconstruction_loss: 0.6694 - total_loss: 0.6694\n","Epoch 46/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 9.8754e-06 - reconstruction_loss: 0.6703 - total_loss: 0.6703 \n","Epoch 47/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.2644e-05 - reconstruction_loss: 0.6701 - total_loss: 0.6701 \n","Epoch 48/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 1.6167e-05 - reconstruction_loss: 0.6708 - total_loss: 0.6708\n","Epoch 49/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 1.4095e-05 - reconstruction_loss: 0.6674 - total_loss: 0.6674 \n","Epoch 50/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.2340e-05 - reconstruction_loss: 0.6685 - total_loss: 0.6685\n","Epoch 51/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 1.1979e-05 - reconstruction_loss: 0.6696 - total_loss: 0.6696\n","Epoch 52/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 1.3923e-05 - reconstruction_loss: 0.6691 - total_loss: 0.6691\n","Epoch 53/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - kl_loss: 1.0654e-05 - reconstruction_loss: 0.6711 - total_loss: 0.6711\n","Epoch 54/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 1.2888e-05 - reconstruction_loss: 0.6709 - total_loss: 0.6710\n","Epoch 55/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 1.2779e-05 - reconstruction_loss: 0.6712 - total_loss: 0.6713\n","Epoch 56/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 9.1186e-06 - reconstruction_loss: 0.6688 - total_loss: 0.6689\n","Epoch 57/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 7.7659e-06 - reconstruction_loss: 0.6661 - total_loss: 0.6661\n","Epoch 58/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - kl_loss: 1.0225e-05 - reconstruction_loss: 0.6666 - total_loss: 0.6666\n","Epoch 59/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.3718e-05 - reconstruction_loss: 0.6664 - total_loss: 0.6664 \n","Epoch 60/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.5413e-05 - reconstruction_loss: 0.6701 - total_loss: 0.6701 \n","Epoch 61/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 1.2500e-05 - reconstruction_loss: 0.6721 - total_loss: 0.6722\n","Epoch 62/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 8.2104e-06 - reconstruction_loss: 0.6700 - total_loss: 0.6700\n","Epoch 63/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 9.7832e-06 - reconstruction_loss: 0.6711 - total_loss: 0.6711\n","Epoch 64/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 8.7196e-06 - reconstruction_loss: 0.6688 - total_loss: 0.6688\n","Epoch 65/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 9.0297e-06 - reconstruction_loss: 0.6722 - total_loss: 0.6722\n","Epoch 66/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 9.3984e-06 - reconstruction_loss: 0.6731 - total_loss: 0.6731\n","Epoch 67/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 9.2137e-06 - reconstruction_loss: 0.6699 - total_loss: 0.6699 \n","Epoch 68/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.1990e-05 - reconstruction_loss: 0.6717 - total_loss: 0.6717\n","Epoch 69/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - kl_loss: 1.2981e-05 - reconstruction_loss: 0.6677 - total_loss: 0.6677\n","Epoch 70/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 1.3580e-05 - reconstruction_loss: 0.6701 - total_loss: 0.6702\n","Epoch 71/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 1.1392e-05 - reconstruction_loss: 0.6675 - total_loss: 0.6675\n","Epoch 72/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 1.1495e-05 - reconstruction_loss: 0.6696 - total_loss: 0.6696\n","Epoch 73/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 1.3989e-05 - reconstruction_loss: 0.6748 - total_loss: 0.6748\n","Epoch 74/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.2682e-05 - reconstruction_loss: 0.6700 - total_loss: 0.6700\n","Epoch 75/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.1590e-05 - reconstruction_loss: 0.6701 - total_loss: 0.6701\n","Epoch 76/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 1.1649e-05 - reconstruction_loss: 0.6679 - total_loss: 0.6679\n","Epoch 77/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 1.2855e-05 - reconstruction_loss: 0.6705 - total_loss: 0.6705\n","Epoch 78/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.4483e-05 - reconstruction_loss: 0.6688 - total_loss: 0.6689\n","Epoch 79/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.1803e-05 - reconstruction_loss: 0.6690 - total_loss: 0.6690\n","Epoch 80/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 1.2745e-05 - reconstruction_loss: 0.6668 - total_loss: 0.6668\n","Epoch 81/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 1.3745e-05 - reconstruction_loss: 0.6699 - total_loss: 0.6699 \n","Epoch 82/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - kl_loss: 1.7604e-05 - reconstruction_loss: 0.6734 - total_loss: 0.6734\n","Epoch 83/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 1.2502e-05 - reconstruction_loss: 0.6717 - total_loss: 0.6717\n","Epoch 84/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 1.1325e-05 - reconstruction_loss: 0.6697 - total_loss: 0.6697\n","Epoch 85/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 9.4401e-06 - reconstruction_loss: 0.6701 - total_loss: 0.6701\n","Epoch 86/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - kl_loss: 1.1716e-05 - reconstruction_loss: 0.6686 - total_loss: 0.6686\n","Epoch 87/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 1.4800e-05 - reconstruction_loss: 0.6697 - total_loss: 0.6697\n","Epoch 88/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.4821e-05 - reconstruction_loss: 0.6737 - total_loss: 0.6737\n","Epoch 89/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 8.4876e-06 - reconstruction_loss: 0.6716 - total_loss: 0.6716\n","Epoch 90/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - kl_loss: 8.0071e-06 - reconstruction_loss: 0.6728 - total_loss: 0.6728\n","Epoch 91/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 8.6719e-06 - reconstruction_loss: 0.6697 - total_loss: 0.6697\n","Epoch 92/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 1.0981e-05 - reconstruction_loss: 0.6712 - total_loss: 0.6712\n","Epoch 93/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - kl_loss: 1.2507e-05 - reconstruction_loss: 0.6705 - total_loss: 0.6705\n","Epoch 94/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 1.2599e-05 - reconstruction_loss: 0.6706 - total_loss: 0.6706\n","Epoch 95/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.1412e-05 - reconstruction_loss: 0.6691 - total_loss: 0.6691\n","Epoch 96/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 9.8400e-06 - reconstruction_loss: 0.6702 - total_loss: 0.6702\n","Epoch 97/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 9.4838e-06 - reconstruction_loss: 0.6712 - total_loss: 0.6712\n","Epoch 98/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.0156e-05 - reconstruction_loss: 0.6708 - total_loss: 0.6708\n","Epoch 99/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.0135e-05 - reconstruction_loss: 0.6748 - total_loss: 0.6749\n","Epoch 100/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 1.2461e-05 - reconstruction_loss: 0.6694 - total_loss: 0.6694\n","Found 27 images belonging to 1 classes.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547ms/step\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","Training VAE for class: Sheep\n","Found 51 images belonging to 1 classes.\n","Epoch 1/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3s/step - kl_loss: 3.8048e-05 - reconstruction_loss: 0.6765 - total_loss: 0.6765\n","Epoch 2/100\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711566811.057425      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - kl_loss: 1.6610e-05 - reconstruction_loss: 0.6774 - total_loss: 0.6774\n","Epoch 3/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - kl_loss: 4.1295e-05 - reconstruction_loss: 0.6784 - total_loss: 0.6785\n","Epoch 4/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - kl_loss: 1.1132e-05 - reconstruction_loss: 0.6778 - total_loss: 0.6778\n","Epoch 5/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - kl_loss: 1.3407e-05 - reconstruction_loss: 0.6783 - total_loss: 0.6783\n","Epoch 6/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - kl_loss: 2.0096e-05 - reconstruction_loss: 0.6751 - total_loss: 0.6751\n","Epoch 7/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - kl_loss: 8.1338e-06 - reconstruction_loss: 0.6790 - total_loss: 0.6790\n","Epoch 8/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - kl_loss: 8.3561e-06 - reconstruction_loss: 0.6778 - total_loss: 0.6779\n","Epoch 9/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - kl_loss: 1.1109e-05 - reconstruction_loss: 0.6772 - total_loss: 0.6772\n","Epoch 10/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - kl_loss: 7.4266e-06 - reconstruction_loss: 0.6771 - total_loss: 0.6771\n","Epoch 11/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - kl_loss: 5.3598e-06 - reconstruction_loss: 0.6784 - total_loss: 0.6784\n","Epoch 12/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - kl_loss: 5.3914e-06 - reconstruction_loss: 0.6799 - total_loss: 0.6799\n","Epoch 13/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - kl_loss: 5.9923e-06 - reconstruction_loss: 0.6768 - total_loss: 0.6768\n","Epoch 14/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - kl_loss: 5.2161e-06 - reconstruction_loss: 0.6782 - total_loss: 0.6782\n","Epoch 15/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - kl_loss: 5.2391e-06 - reconstruction_loss: 0.6797 - total_loss: 0.6797\n","Epoch 16/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - kl_loss: 4.7654e-06 - reconstruction_loss: 0.6778 - total_loss: 0.6778\n","Epoch 17/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - kl_loss: 4.6194e-06 - reconstruction_loss: 0.6781 - total_loss: 0.6781\n","Epoch 18/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - kl_loss: 4.7537e-06 - reconstruction_loss: 0.6781 - total_loss: 0.6781\n","Epoch 19/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - kl_loss: 5.7028e-06 - reconstruction_loss: 0.6774 - total_loss: 0.6774\n","Epoch 20/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - kl_loss: 5.1154e-06 - reconstruction_loss: 0.6795 - total_loss: 0.6795\n","Epoch 21/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - kl_loss: 4.3590e-06 - reconstruction_loss: 0.6787 - total_loss: 0.6787\n","Epoch 22/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - kl_loss: 4.6976e-06 - reconstruction_loss: 0.6786 - total_loss: 0.6786\n","Epoch 23/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - kl_loss: 3.7599e-06 - reconstruction_loss: 0.6780 - total_loss: 0.6780\n","Epoch 24/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - kl_loss: 3.6817e-06 - reconstruction_loss: 0.6779 - total_loss: 0.6779\n","Epoch 25/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - kl_loss: 3.2009e-06 - reconstruction_loss: 0.6755 - total_loss: 0.6755\n","Epoch 26/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - kl_loss: 2.4201e-06 - reconstruction_loss: 0.6735 - total_loss: 0.6735\n","Epoch 27/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - kl_loss: 2.6936e-06 - reconstruction_loss: 0.6773 - total_loss: 0.6773\n","Epoch 28/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - kl_loss: 3.1085e-06 - reconstruction_loss: 0.6773 - total_loss: 0.6773\n","Epoch 29/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - kl_loss: 3.2435e-06 - reconstruction_loss: 0.6753 - total_loss: 0.6753\n","Epoch 30/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - kl_loss: 4.0586e-06 - reconstruction_loss: 0.6776 - total_loss: 0.6776\n","Epoch 31/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - kl_loss: 5.0301e-06 - reconstruction_loss: 0.6786 - total_loss: 0.6786\n","Epoch 32/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - kl_loss: 4.8820e-06 - reconstruction_loss: 0.6787 - total_loss: 0.6787\n","Epoch 33/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - kl_loss: 6.1938e-06 - reconstruction_loss: 0.6746 - total_loss: 0.6746\n","Epoch 34/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - kl_loss: 6.0428e-06 - reconstruction_loss: 0.6779 - total_loss: 0.6779\n","Epoch 35/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - kl_loss: 5.9405e-06 - reconstruction_loss: 0.6780 - total_loss: 0.6780\n","Epoch 36/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - kl_loss: 6.4646e-06 - reconstruction_loss: 0.6788 - total_loss: 0.6788\n","Epoch 37/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - kl_loss: 5.0101e-06 - reconstruction_loss: 0.6769 - total_loss: 0.6769\n","Epoch 38/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - kl_loss: 4.6016e-06 - reconstruction_loss: 0.6780 - total_loss: 0.6780\n","Epoch 39/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - kl_loss: 5.3277e-06 - reconstruction_loss: 0.6763 - total_loss: 0.6763\n","Epoch 40/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - kl_loss: 5.4183e-06 - reconstruction_loss: 0.6781 - total_loss: 0.6781\n","Epoch 41/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - kl_loss: 4.5915e-06 - reconstruction_loss: 0.6802 - total_loss: 0.6802\n","Epoch 42/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - kl_loss: 4.7587e-06 - reconstruction_loss: 0.6765 - total_loss: 0.6765\n","Epoch 43/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - kl_loss: 4.7297e-06 - reconstruction_loss: 0.6761 - total_loss: 0.6761\n","Epoch 44/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - kl_loss: 4.7684e-06 - reconstruction_loss: 0.6761 - total_loss: 0.6761\n","Epoch 45/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - kl_loss: 4.9145e-06 - reconstruction_loss: 0.6805 - total_loss: 0.6805\n","Epoch 46/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - kl_loss: 6.0800e-06 - reconstruction_loss: 0.6777 - total_loss: 0.6777\n","Epoch 47/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - kl_loss: 5.1267e-06 - reconstruction_loss: 0.6793 - total_loss: 0.6793\n","Epoch 48/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - kl_loss: 6.0053e-06 - reconstruction_loss: 0.6796 - total_loss: 0.6796\n","Epoch 49/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - kl_loss: 6.1907e-06 - reconstruction_loss: 0.6766 - total_loss: 0.6766\n","Epoch 50/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - kl_loss: 8.0063e-06 - reconstruction_loss: 0.6763 - total_loss: 0.6763\n","Epoch 51/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - kl_loss: 7.4862e-06 - reconstruction_loss: 0.6773 - total_loss: 0.6773\n","Epoch 52/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - kl_loss: 8.9277e-06 - reconstruction_loss: 0.6775 - total_loss: 0.6775\n","Epoch 53/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - kl_loss: 1.1507e-05 - reconstruction_loss: 0.6776 - total_loss: 0.6776\n","Epoch 54/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - kl_loss: 1.1744e-05 - reconstruction_loss: 0.6772 - total_loss: 0.6772\n","Epoch 55/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - kl_loss: 9.3551e-06 - reconstruction_loss: 0.6775 - total_loss: 0.6775\n","Epoch 56/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - kl_loss: 7.7169e-06 - reconstruction_loss: 0.6803 - total_loss: 0.6803\n","Epoch 57/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - kl_loss: 8.3165e-06 - reconstruction_loss: 0.6784 - total_loss: 0.6784\n","Epoch 58/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - kl_loss: 7.1744e-06 - reconstruction_loss: 0.6782 - total_loss: 0.6782\n","Epoch 59/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - kl_loss: 7.6905e-06 - reconstruction_loss: 0.6769 - total_loss: 0.6770\n","Epoch 60/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - kl_loss: 7.9377e-06 - reconstruction_loss: 0.6778 - total_loss: 0.6778\n","Epoch 61/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - kl_loss: 6.9196e-06 - reconstruction_loss: 0.6776 - total_loss: 0.6776\n","Epoch 62/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - kl_loss: 6.3069e-06 - reconstruction_loss: 0.6791 - total_loss: 0.6791\n","Epoch 63/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - kl_loss: 6.3020e-06 - reconstruction_loss: 0.6799 - total_loss: 0.6799\n","Epoch 64/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - kl_loss: 6.3593e-06 - reconstruction_loss: 0.6784 - total_loss: 0.6784\n","Epoch 65/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - kl_loss: 7.6019e-06 - reconstruction_loss: 0.6768 - total_loss: 0.6768\n","Epoch 66/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - kl_loss: 7.5240e-06 - reconstruction_loss: 0.6772 - total_loss: 0.6772\n","Epoch 67/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - kl_loss: 8.4291e-06 - reconstruction_loss: 0.6790 - total_loss: 0.6790\n","Epoch 68/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - kl_loss: 8.6033e-06 - reconstruction_loss: 0.6731 - total_loss: 0.6731\n","Epoch 69/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - kl_loss: 8.3548e-06 - reconstruction_loss: 0.6743 - total_loss: 0.6743\n","Epoch 70/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - kl_loss: 8.0340e-06 - reconstruction_loss: 0.6772 - total_loss: 0.6773\n","Epoch 71/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - kl_loss: 7.8326e-06 - reconstruction_loss: 0.6779 - total_loss: 0.6779\n","Epoch 72/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - kl_loss: 9.6830e-06 - reconstruction_loss: 0.6769 - total_loss: 0.6769\n","Epoch 73/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - kl_loss: 1.0301e-05 - reconstruction_loss: 0.6766 - total_loss: 0.6766\n","Epoch 74/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - kl_loss: 9.6091e-06 - reconstruction_loss: 0.6774 - total_loss: 0.6774\n","Epoch 75/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - kl_loss: 8.0687e-06 - reconstruction_loss: 0.6789 - total_loss: 0.6789\n","Epoch 76/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - kl_loss: 7.7226e-06 - reconstruction_loss: 0.6760 - total_loss: 0.6760\n","Epoch 77/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - kl_loss: 7.7297e-06 - reconstruction_loss: 0.6764 - total_loss: 0.6764\n","Epoch 78/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - kl_loss: 8.4333e-06 - reconstruction_loss: 0.6791 - total_loss: 0.6791\n","Epoch 79/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - kl_loss: 7.2905e-06 - reconstruction_loss: 0.6762 - total_loss: 0.6762\n","Epoch 80/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - kl_loss: 7.9178e-06 - reconstruction_loss: 0.6792 - total_loss: 0.6792\n","Epoch 81/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - kl_loss: 1.0883e-05 - reconstruction_loss: 0.6740 - total_loss: 0.6740\n","Epoch 82/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - kl_loss: 6.6921e-06 - reconstruction_loss: 0.6762 - total_loss: 0.6762\n","Epoch 83/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - kl_loss: 7.0608e-06 - reconstruction_loss: 0.6765 - total_loss: 0.6765\n","Epoch 84/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - kl_loss: 9.0657e-06 - reconstruction_loss: 0.6753 - total_loss: 0.6753\n","Epoch 85/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - kl_loss: 9.2011e-06 - reconstruction_loss: 0.6793 - total_loss: 0.6793\n","Epoch 86/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - kl_loss: 1.0481e-05 - reconstruction_loss: 0.6763 - total_loss: 0.6763\n","Epoch 87/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - kl_loss: 1.1137e-05 - reconstruction_loss: 0.6768 - total_loss: 0.6768\n","Epoch 88/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - kl_loss: 1.1988e-05 - reconstruction_loss: 0.6754 - total_loss: 0.6754\n","Epoch 89/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - kl_loss: 1.5820e-05 - reconstruction_loss: 0.6761 - total_loss: 0.6761\n","Epoch 90/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - kl_loss: 1.3891e-05 - reconstruction_loss: 0.6778 - total_loss: 0.6778\n","Epoch 91/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - kl_loss: 1.2933e-05 - reconstruction_loss: 0.6766 - total_loss: 0.6766\n","Epoch 92/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - kl_loss: 1.9851e-05 - reconstruction_loss: 0.6773 - total_loss: 0.6774\n","Epoch 93/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - kl_loss: 1.0555e-05 - reconstruction_loss: 0.6769 - total_loss: 0.6769\n","Epoch 94/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - kl_loss: 9.0202e-06 - reconstruction_loss: 0.6774 - total_loss: 0.6774\n","Epoch 95/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - kl_loss: 9.5977e-06 - reconstruction_loss: 0.6777 - total_loss: 0.6777\n","Epoch 96/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - kl_loss: 8.4738e-06 - reconstruction_loss: 0.6770 - total_loss: 0.6771\n","Epoch 97/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - kl_loss: 7.4924e-06 - reconstruction_loss: 0.6770 - total_loss: 0.6770\n","Epoch 98/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - kl_loss: 7.4397e-06 - reconstruction_loss: 0.6774 - total_loss: 0.6774\n","Epoch 99/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - kl_loss: 6.2346e-06 - reconstruction_loss: 0.6782 - total_loss: 0.6782\n","Epoch 100/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - kl_loss: 5.8674e-06 - reconstruction_loss: 0.6747 - total_loss: 0.6748\n","Found 13 images belonging to 1 classes.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","Training VAE for class: Diningtable\n","Found 84 images belonging to 1 classes.\n","Epoch 1/100\n","\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 6s/step - kl_loss: 4.2170e-06 - reconstruction_loss: 0.6759 - total_loss: 0.6759"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711566861.075391      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - kl_loss: 1.9446e-05 - reconstruction_loss: 0.6768 - total_loss: 0.6768\n","Epoch 2/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - kl_loss: 1.7156e-05 - reconstruction_loss: 0.6732 - total_loss: 0.6732\n","Epoch 3/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 5.3111e-06 - reconstruction_loss: 0.6718 - total_loss: 0.6718\n","Epoch 4/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.0500e-05 - reconstruction_loss: 0.6703 - total_loss: 0.6703\n","Epoch 5/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - kl_loss: 4.0436e-06 - reconstruction_loss: 0.6704 - total_loss: 0.6704\n","Epoch 6/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 5.1209e-06 - reconstruction_loss: 0.6722 - total_loss: 0.6722\n","Epoch 7/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 2.6773e-06 - reconstruction_loss: 0.6738 - total_loss: 0.6738\n","Epoch 8/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 2.9108e-06 - reconstruction_loss: 0.6712 - total_loss: 0.6712\n","Epoch 9/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.7869e-06 - reconstruction_loss: 0.6739 - total_loss: 0.6739\n","Epoch 10/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.5472e-06 - reconstruction_loss: 0.6695 - total_loss: 0.6695\n","Epoch 11/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.1893e-06 - reconstruction_loss: 0.6742 - total_loss: 0.6742\n","Epoch 12/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 1.2885e-06 - reconstruction_loss: 0.6705 - total_loss: 0.6705\n","Epoch 13/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 9.6182e-07 - reconstruction_loss: 0.6721 - total_loss: 0.6721\n","Epoch 14/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.0775e-06 - reconstruction_loss: 0.6729 - total_loss: 0.6729\n","Epoch 15/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 8.1720e-07 - reconstruction_loss: 0.6729 - total_loss: 0.6729\n","Epoch 16/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - kl_loss: 7.7051e-07 - reconstruction_loss: 0.6763 - total_loss: 0.6763\n","Epoch 17/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 7.3968e-07 - reconstruction_loss: 0.6652 - total_loss: 0.6652\n","Epoch 18/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 5.7709e-07 - reconstruction_loss: 0.6703 - total_loss: 0.6703\n","Epoch 19/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 8.4391e-07 - reconstruction_loss: 0.6681 - total_loss: 0.6681\n","Epoch 20/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 8.0169e-07 - reconstruction_loss: 0.6714 - total_loss: 0.6714\n","Epoch 21/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 8.4109e-07 - reconstruction_loss: 0.6712 - total_loss: 0.6712\n","Epoch 22/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 7.3782e-07 - reconstruction_loss: 0.6797 - total_loss: 0.6797\n","Epoch 23/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 5.7953e-07 - reconstruction_loss: 0.6670 - total_loss: 0.6670\n","Epoch 24/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 7.9163e-07 - reconstruction_loss: 0.6709 - total_loss: 0.6709\n","Epoch 25/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 8.6074e-07 - reconstruction_loss: 0.6738 - total_loss: 0.6738\n","Epoch 26/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 7.9093e-07 - reconstruction_loss: 0.6788 - total_loss: 0.6788\n","Epoch 27/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 7.2007e-07 - reconstruction_loss: 0.6660 - total_loss: 0.6660\n","Epoch 28/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 7.1543e-07 - reconstruction_loss: 0.6695 - total_loss: 0.6695\n","Epoch 29/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.1310e-06 - reconstruction_loss: 0.6731 - total_loss: 0.6731\n","Epoch 30/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - kl_loss: 7.5640e-07 - reconstruction_loss: 0.6683 - total_loss: 0.6683\n","Epoch 31/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 7.8610e-07 - reconstruction_loss: 0.6714 - total_loss: 0.6714\n","Epoch 32/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.0928e-06 - reconstruction_loss: 0.6737 - total_loss: 0.6737\n","Epoch 33/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 9.5100e-07 - reconstruction_loss: 0.6717 - total_loss: 0.6717\n","Epoch 34/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 7.4885e-07 - reconstruction_loss: 0.6730 - total_loss: 0.6730\n","Epoch 35/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 9.8409e-07 - reconstruction_loss: 0.6694 - total_loss: 0.6694\n","Epoch 36/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.0222e-06 - reconstruction_loss: 0.6740 - total_loss: 0.6740\n","Epoch 37/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 7.9474e-07 - reconstruction_loss: 0.6680 - total_loss: 0.6680\n","Epoch 38/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 7.8967e-07 - reconstruction_loss: 0.6726 - total_loss: 0.6726\n","Epoch 39/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 6.8078e-07 - reconstruction_loss: 0.6743 - total_loss: 0.6743\n","Epoch 40/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 7.9230e-07 - reconstruction_loss: 0.6729 - total_loss: 0.6729\n","Epoch 41/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 8.8371e-07 - reconstruction_loss: 0.6773 - total_loss: 0.6773\n","Epoch 42/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 9.4993e-07 - reconstruction_loss: 0.6692 - total_loss: 0.6692\n","Epoch 43/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.2059e-06 - reconstruction_loss: 0.6695 - total_loss: 0.6695\n","Epoch 44/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 1.2093e-06 - reconstruction_loss: 0.6719 - total_loss: 0.6719\n","Epoch 45/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.0156e-06 - reconstruction_loss: 0.6682 - total_loss: 0.6682\n","Epoch 46/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.4606e-06 - reconstruction_loss: 0.6753 - total_loss: 0.6753\n","Epoch 47/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.3319e-06 - reconstruction_loss: 0.6710 - total_loss: 0.6710\n","Epoch 48/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 1.3300e-06 - reconstruction_loss: 0.6676 - total_loss: 0.6676\n","Epoch 49/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.3295e-06 - reconstruction_loss: 0.6710 - total_loss: 0.6710\n","Epoch 50/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 1.2192e-06 - reconstruction_loss: 0.6719 - total_loss: 0.6719\n","Epoch 51/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.1913e-06 - reconstruction_loss: 0.6693 - total_loss: 0.6693\n","Epoch 52/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 1.5130e-06 - reconstruction_loss: 0.6702 - total_loss: 0.6702\n","Epoch 53/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 1.2740e-06 - reconstruction_loss: 0.6719 - total_loss: 0.6719\n","Epoch 54/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - kl_loss: 1.3925e-06 - reconstruction_loss: 0.6761 - total_loss: 0.6761\n","Epoch 55/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 1.2657e-06 - reconstruction_loss: 0.6699 - total_loss: 0.6699\n","Epoch 56/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - kl_loss: 1.3304e-06 - reconstruction_loss: 0.6727 - total_loss: 0.6727\n","Epoch 57/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.5968e-06 - reconstruction_loss: 0.6762 - total_loss: 0.6762\n","Epoch 58/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.6490e-06 - reconstruction_loss: 0.6648 - total_loss: 0.6648\n","Epoch 59/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 1.7039e-06 - reconstruction_loss: 0.6715 - total_loss: 0.6715\n","Epoch 60/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 1.6103e-06 - reconstruction_loss: 0.6705 - total_loss: 0.6705\n","Epoch 61/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 1.7618e-06 - reconstruction_loss: 0.6715 - total_loss: 0.6715\n","Epoch 62/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.9463e-06 - reconstruction_loss: 0.6738 - total_loss: 0.6738\n","Epoch 63/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 1.6594e-06 - reconstruction_loss: 0.6715 - total_loss: 0.6715\n","Epoch 64/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.9262e-06 - reconstruction_loss: 0.6736 - total_loss: 0.6736\n","Epoch 65/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 2.0909e-06 - reconstruction_loss: 0.6632 - total_loss: 0.6632\n","Epoch 66/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 2.0051e-06 - reconstruction_loss: 0.6720 - total_loss: 0.6720\n","Epoch 67/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - kl_loss: 1.9688e-06 - reconstruction_loss: 0.6716 - total_loss: 0.6716\n","Epoch 68/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 2.1592e-06 - reconstruction_loss: 0.6717 - total_loss: 0.6717\n","Epoch 69/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 1.5242e-06 - reconstruction_loss: 0.6733 - total_loss: 0.6733\n","Epoch 70/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 1.6967e-06 - reconstruction_loss: 0.6706 - total_loss: 0.6706\n","Epoch 71/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.9914e-06 - reconstruction_loss: 0.6701 - total_loss: 0.6701\n","Epoch 72/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 2.9408e-06 - reconstruction_loss: 0.6651 - total_loss: 0.6651\n","Epoch 73/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 2.7878e-06 - reconstruction_loss: 0.6715 - total_loss: 0.6715\n","Epoch 74/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 2.9222e-06 - reconstruction_loss: 0.6705 - total_loss: 0.6705\n","Epoch 75/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - kl_loss: 2.9803e-06 - reconstruction_loss: 0.6724 - total_loss: 0.6724\n","Epoch 76/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 2.8169e-06 - reconstruction_loss: 0.6723 - total_loss: 0.6723\n","Epoch 77/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 2.9131e-06 - reconstruction_loss: 0.6679 - total_loss: 0.6679\n","Epoch 78/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 3.1722e-06 - reconstruction_loss: 0.6721 - total_loss: 0.6721\n","Epoch 79/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 3.2583e-06 - reconstruction_loss: 0.6751 - total_loss: 0.6751\n","Epoch 80/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 3.3336e-06 - reconstruction_loss: 0.6711 - total_loss: 0.6711\n","Epoch 81/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 2.7749e-06 - reconstruction_loss: 0.6716 - total_loss: 0.6716\n","Epoch 82/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 4.2276e-06 - reconstruction_loss: 0.6750 - total_loss: 0.6750\n","Epoch 83/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - kl_loss: 3.6578e-06 - reconstruction_loss: 0.6683 - total_loss: 0.6683\n","Epoch 84/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 4.4124e-06 - reconstruction_loss: 0.6732 - total_loss: 0.6732\n","Epoch 85/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 8.4587e-06 - reconstruction_loss: 0.6689 - total_loss: 0.6689\n","Epoch 86/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - kl_loss: 2.1657e-06 - reconstruction_loss: 0.6718 - total_loss: 0.6718\n","Epoch 87/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 2.0908e-06 - reconstruction_loss: 0.6693 - total_loss: 0.6693\n","Epoch 88/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 2.2781e-06 - reconstruction_loss: 0.6710 - total_loss: 0.6710\n","Epoch 89/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 2.0519e-06 - reconstruction_loss: 0.6700 - total_loss: 0.6700\n","Epoch 90/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 2.4789e-06 - reconstruction_loss: 0.6731 - total_loss: 0.6731\n","Epoch 91/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 1.7193e-06 - reconstruction_loss: 0.6710 - total_loss: 0.6710\n","Epoch 92/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - kl_loss: 1.8942e-06 - reconstruction_loss: 0.6700 - total_loss: 0.6700\n","Epoch 93/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 2.4892e-06 - reconstruction_loss: 0.6738 - total_loss: 0.6738\n","Epoch 94/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - kl_loss: 2.6893e-06 - reconstruction_loss: 0.6691 - total_loss: 0.6691\n","Epoch 95/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 2.4889e-06 - reconstruction_loss: 0.6708 - total_loss: 0.6708\n","Epoch 96/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - kl_loss: 2.9870e-06 - reconstruction_loss: 0.6684 - total_loss: 0.6684\n","Epoch 97/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - kl_loss: 2.8108e-06 - reconstruction_loss: 0.6714 - total_loss: 0.6714\n","Epoch 98/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 2.3545e-06 - reconstruction_loss: 0.6678 - total_loss: 0.6678\n","Epoch 99/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - kl_loss: 3.8088e-06 - reconstruction_loss: 0.6695 - total_loss: 0.6695\n","Epoch 100/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 3.3355e-06 - reconstruction_loss: 0.6707 - total_loss: 0.6707\n","Found 21 images belonging to 1 classes.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","Training VAE for class: Horse\n","Found 158 images belonging to 1 classes.\n","Epoch 1/100\n","\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 7s/step - kl_loss: 2.5583e-06 - reconstruction_loss: 0.6873 - total_loss: 0.6873"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711566944.627369      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4s/step - kl_loss: 1.9911e-05 - reconstruction_loss: 0.6853 - total_loss: 0.6853\n","Epoch 2/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - kl_loss: 1.1320e-05 - reconstruction_loss: 0.6848 - total_loss: 0.6848\n","Epoch 3/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 5.7050e-06 - reconstruction_loss: 0.6837 - total_loss: 0.6837\n","Epoch 4/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - kl_loss: 4.0819e-06 - reconstruction_loss: 0.6828 - total_loss: 0.6828\n","Epoch 5/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 3.0386e-06 - reconstruction_loss: 0.6839 - total_loss: 0.6839\n","Epoch 6/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - kl_loss: 1.6995e-06 - reconstruction_loss: 0.6818 - total_loss: 0.6818\n","Epoch 7/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 1.6288e-06 - reconstruction_loss: 0.6841 - total_loss: 0.6841\n","Epoch 8/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 1.2401e-06 - reconstruction_loss: 0.6821 - total_loss: 0.6821\n","Epoch 9/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.1615e-06 - reconstruction_loss: 0.6842 - total_loss: 0.6842\n","Epoch 10/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 8.2208e-07 - reconstruction_loss: 0.6827 - total_loss: 0.6827\n","Epoch 11/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - kl_loss: 9.2341e-07 - reconstruction_loss: 0.6798 - total_loss: 0.6798\n","Epoch 12/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 7.0090e-07 - reconstruction_loss: 0.6831 - total_loss: 0.6831\n","Epoch 13/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 8.1844e-07 - reconstruction_loss: 0.6821 - total_loss: 0.6821\n","Epoch 14/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.0801e-06 - reconstruction_loss: 0.6815 - total_loss: 0.6815\n","Epoch 15/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.0006e-06 - reconstruction_loss: 0.6795 - total_loss: 0.6795\n","Epoch 16/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - kl_loss: 1.1860e-06 - reconstruction_loss: 0.6837 - total_loss: 0.6837\n","Epoch 17/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 1.2485e-06 - reconstruction_loss: 0.6816 - total_loss: 0.6816\n","Epoch 18/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 1.2724e-06 - reconstruction_loss: 0.6826 - total_loss: 0.6826\n","Epoch 19/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 2.0506e-06 - reconstruction_loss: 0.6834 - total_loss: 0.6834\n","Epoch 20/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 1.8083e-06 - reconstruction_loss: 0.6815 - total_loss: 0.6815\n","Epoch 21/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 1.5570e-06 - reconstruction_loss: 0.6831 - total_loss: 0.6831\n","Epoch 22/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.4164e-06 - reconstruction_loss: 0.6818 - total_loss: 0.6818\n","Epoch 23/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 1.1270e-06 - reconstruction_loss: 0.6823 - total_loss: 0.6823\n","Epoch 24/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 1.1770e-06 - reconstruction_loss: 0.6806 - total_loss: 0.6806\n","Epoch 25/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.7292e-06 - reconstruction_loss: 0.6818 - total_loss: 0.6818\n","Epoch 26/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 1.8497e-06 - reconstruction_loss: 0.6808 - total_loss: 0.6808\n","Epoch 27/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.7856e-06 - reconstruction_loss: 0.6826 - total_loss: 0.6826\n","Epoch 28/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 2.7753e-06 - reconstruction_loss: 0.6816 - total_loss: 0.6816\n","Epoch 29/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 2.2534e-06 - reconstruction_loss: 0.6822 - total_loss: 0.6822\n","Epoch 30/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.9597e-06 - reconstruction_loss: 0.6831 - total_loss: 0.6831\n","Epoch 31/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.8665e-06 - reconstruction_loss: 0.6820 - total_loss: 0.6820\n","Epoch 32/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.5731e-06 - reconstruction_loss: 0.6828 - total_loss: 0.6828\n","Epoch 33/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 1.8264e-06 - reconstruction_loss: 0.6807 - total_loss: 0.6807\n","Epoch 34/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 2.4306e-06 - reconstruction_loss: 0.6802 - total_loss: 0.6802\n","Epoch 35/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 2.8365e-06 - reconstruction_loss: 0.6805 - total_loss: 0.6805\n","Epoch 36/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 2.6716e-06 - reconstruction_loss: 0.6810 - total_loss: 0.6810\n","Epoch 37/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 2.7658e-06 - reconstruction_loss: 0.6828 - total_loss: 0.6828\n","Epoch 38/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 2.0038e-06 - reconstruction_loss: 0.6799 - total_loss: 0.6799\n","Epoch 39/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 2.2693e-06 - reconstruction_loss: 0.6805 - total_loss: 0.6805\n","Epoch 40/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 2.6508e-06 - reconstruction_loss: 0.6823 - total_loss: 0.6823\n","Epoch 41/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 3.7566e-06 - reconstruction_loss: 0.6823 - total_loss: 0.6823\n","Epoch 42/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 6.6754e-06 - reconstruction_loss: 0.6819 - total_loss: 0.6819\n","Epoch 43/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 4.4694e-06 - reconstruction_loss: 0.6822 - total_loss: 0.6822\n","Epoch 44/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 4.1129e-06 - reconstruction_loss: 0.6805 - total_loss: 0.6805\n","Epoch 45/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 4.6139e-06 - reconstruction_loss: 0.6844 - total_loss: 0.6844\n","Epoch 46/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 3.6976e-06 - reconstruction_loss: 0.6789 - total_loss: 0.6789\n","Epoch 47/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 3.4026e-06 - reconstruction_loss: 0.6811 - total_loss: 0.6811\n","Epoch 48/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 3.2378e-06 - reconstruction_loss: 0.6817 - total_loss: 0.6817\n","Epoch 49/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 3.0260e-06 - reconstruction_loss: 0.6810 - total_loss: 0.6810\n","Epoch 50/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 2.8974e-06 - reconstruction_loss: 0.6820 - total_loss: 0.6820\n","Epoch 51/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 3.5172e-06 - reconstruction_loss: 0.6785 - total_loss: 0.6785\n","Epoch 52/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 5.5668e-06 - reconstruction_loss: 0.6806 - total_loss: 0.6807\n","Epoch 53/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 4.6438e-06 - reconstruction_loss: 0.6803 - total_loss: 0.6804\n","Epoch 54/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 4.0305e-06 - reconstruction_loss: 0.6802 - total_loss: 0.6802\n","Epoch 55/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 4.1591e-06 - reconstruction_loss: 0.6808 - total_loss: 0.6808\n","Epoch 56/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 5.0691e-06 - reconstruction_loss: 0.6818 - total_loss: 0.6818\n","Epoch 57/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 6.1813e-06 - reconstruction_loss: 0.6812 - total_loss: 0.6812\n","Epoch 58/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 5.4407e-06 - reconstruction_loss: 0.6820 - total_loss: 0.6820\n","Epoch 59/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 4.7148e-06 - reconstruction_loss: 0.6802 - total_loss: 0.6802\n","Epoch 60/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 5.1715e-06 - reconstruction_loss: 0.6815 - total_loss: 0.6815\n","Epoch 61/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 4.6819e-06 - reconstruction_loss: 0.6823 - total_loss: 0.6823\n","Epoch 62/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 4.3552e-06 - reconstruction_loss: 0.6830 - total_loss: 0.6830\n","Epoch 63/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 5.2281e-06 - reconstruction_loss: 0.6807 - total_loss: 0.6807\n","Epoch 64/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 4.4408e-06 - reconstruction_loss: 0.6803 - total_loss: 0.6803\n","Epoch 65/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 4.2835e-06 - reconstruction_loss: 0.6824 - total_loss: 0.6824\n","Epoch 66/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 4.3507e-06 - reconstruction_loss: 0.6801 - total_loss: 0.6801\n","Epoch 67/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 4.0044e-06 - reconstruction_loss: 0.6808 - total_loss: 0.6808\n","Epoch 68/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 4.0796e-06 - reconstruction_loss: 0.6801 - total_loss: 0.6801\n","Epoch 69/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 4.0810e-06 - reconstruction_loss: 0.6824 - total_loss: 0.6824\n","Epoch 70/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 3.5910e-06 - reconstruction_loss: 0.6819 - total_loss: 0.6819\n","Epoch 71/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 3.1448e-06 - reconstruction_loss: 0.6822 - total_loss: 0.6822\n","Epoch 72/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 3.4941e-06 - reconstruction_loss: 0.6819 - total_loss: 0.6819\n","Epoch 73/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 3.9296e-06 - reconstruction_loss: 0.6812 - total_loss: 0.6812\n","Epoch 74/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 4.0979e-06 - reconstruction_loss: 0.6805 - total_loss: 0.6805\n","Epoch 75/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 4.4902e-06 - reconstruction_loss: 0.6811 - total_loss: 0.6811\n","Epoch 76/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 4.4338e-06 - reconstruction_loss: 0.6807 - total_loss: 0.6807\n","Epoch 77/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 4.8365e-06 - reconstruction_loss: 0.6807 - total_loss: 0.6807\n","Epoch 78/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 5.3993e-06 - reconstruction_loss: 0.6833 - total_loss: 0.6833\n","Epoch 79/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 4.5212e-06 - reconstruction_loss: 0.6814 - total_loss: 0.6814\n","Epoch 80/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 6.6360e-06 - reconstruction_loss: 0.6820 - total_loss: 0.6820\n","Epoch 81/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 6.7291e-06 - reconstruction_loss: 0.6778 - total_loss: 0.6778\n","Epoch 82/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 5.7338e-06 - reconstruction_loss: 0.6793 - total_loss: 0.6793\n","Epoch 83/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 6.2981e-06 - reconstruction_loss: 0.6824 - total_loss: 0.6824\n","Epoch 84/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 6.1192e-06 - reconstruction_loss: 0.6820 - total_loss: 0.6820\n","Epoch 85/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 4.9522e-06 - reconstruction_loss: 0.6799 - total_loss: 0.6799\n","Epoch 86/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 7.2170e-06 - reconstruction_loss: 0.6797 - total_loss: 0.6797\n","Epoch 87/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 6.0435e-06 - reconstruction_loss: 0.6796 - total_loss: 0.6796\n","Epoch 88/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 5.4433e-06 - reconstruction_loss: 0.6807 - total_loss: 0.6807\n","Epoch 89/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 5.5804e-06 - reconstruction_loss: 0.6799 - total_loss: 0.6799\n","Epoch 90/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 9.3022e-06 - reconstruction_loss: 0.6815 - total_loss: 0.6815\n","Epoch 91/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 6.9641e-06 - reconstruction_loss: 0.6820 - total_loss: 0.6820\n","Epoch 92/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 6.5928e-06 - reconstruction_loss: 0.6796 - total_loss: 0.6796\n","Epoch 93/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 6.6551e-06 - reconstruction_loss: 0.6796 - total_loss: 0.6796\n","Epoch 94/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 5.3658e-06 - reconstruction_loss: 0.6828 - total_loss: 0.6828\n","Epoch 95/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 5.6116e-06 - reconstruction_loss: 0.6802 - total_loss: 0.6802\n","Epoch 96/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 4.1919e-06 - reconstruction_loss: 0.6790 - total_loss: 0.6790\n","Epoch 97/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 5.1150e-06 - reconstruction_loss: 0.6801 - total_loss: 0.6801\n","Epoch 98/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 4.1557e-06 - reconstruction_loss: 0.6809 - total_loss: 0.6809\n","Epoch 99/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 5.2038e-06 - reconstruction_loss: 0.6824 - total_loss: 0.6824\n","Epoch 100/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 3.9072e-06 - reconstruction_loss: 0.6812 - total_loss: 0.6812\n","Found 40 images belonging to 1 classes.\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 891ms/step"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711567069.019792      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step  \n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 433ms/step\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","Training VAE for class: Person\n","Found 1601 images belonging to 1 classes.\n","Epoch 1/100\n","\u001b[1m 1/51\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:41\u001b[0m 7s/step - kl_loss: 3.0939e-06 - reconstruction_loss: 0.6824 - total_loss: 0.6824"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711567080.767260      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 205ms/step - kl_loss: 1.0241e-05 - reconstruction_loss: 0.6767 - total_loss: 0.6767\n","Epoch 2/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 107ms/step - kl_loss: 1.8050e-06 - reconstruction_loss: 0.6747 - total_loss: 0.6747\n","Epoch 3/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 102ms/step - kl_loss: 9.4559e-07 - reconstruction_loss: 0.6777 - total_loss: 0.6777\n","Epoch 4/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 105ms/step - kl_loss: 1.4396e-06 - reconstruction_loss: 0.6754 - total_loss: 0.6755\n","Epoch 5/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 105ms/step - kl_loss: 1.1706e-06 - reconstruction_loss: 0.6781 - total_loss: 0.6781\n","Epoch 6/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 107ms/step - kl_loss: 1.5661e-06 - reconstruction_loss: 0.6771 - total_loss: 0.6771\n","Epoch 7/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 100ms/step - kl_loss: 1.6437e-06 - reconstruction_loss: 0.6748 - total_loss: 0.6748\n","Epoch 8/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - kl_loss: 1.1585e-06 - reconstruction_loss: 0.6754 - total_loss: 0.6754\n","Epoch 9/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step - kl_loss: 9.5997e-07 - reconstruction_loss: 0.6767 - total_loss: 0.6767\n","Epoch 10/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step - kl_loss: 1.1176e-06 - reconstruction_loss: 0.6755 - total_loss: 0.6755\n","Epoch 11/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 102ms/step - kl_loss: 1.4853e-06 - reconstruction_loss: 0.6769 - total_loss: 0.6769\n","Epoch 12/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step - kl_loss: 1.0069e-06 - reconstruction_loss: 0.6749 - total_loss: 0.6749\n","Epoch 13/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 106ms/step - kl_loss: 1.0844e-06 - reconstruction_loss: 0.6755 - total_loss: 0.6755\n","Epoch 14/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step - kl_loss: 9.8184e-07 - reconstruction_loss: 0.6752 - total_loss: 0.6752\n","Epoch 15/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step - kl_loss: 1.0592e-06 - reconstruction_loss: 0.6771 - total_loss: 0.6771\n","Epoch 16/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step - kl_loss: 9.9981e-07 - reconstruction_loss: 0.6747 - total_loss: 0.6747\n","Epoch 17/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step - kl_loss: 1.4638e-06 - reconstruction_loss: 0.6765 - total_loss: 0.6765\n","Epoch 18/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 102ms/step - kl_loss: 1.1952e-06 - reconstruction_loss: 0.6757 - total_loss: 0.6757\n","Epoch 19/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - kl_loss: 1.2509e-06 - reconstruction_loss: 0.6769 - total_loss: 0.6769\n","Epoch 20/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - kl_loss: 1.8129e-06 - reconstruction_loss: 0.6752 - total_loss: 0.6752\n","Epoch 21/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - kl_loss: 1.1538e-06 - reconstruction_loss: 0.6763 - total_loss: 0.6763\n","Epoch 22/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - kl_loss: 1.0763e-06 - reconstruction_loss: 0.6763 - total_loss: 0.6763\n","Epoch 23/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 106ms/step - kl_loss: 8.4628e-07 - reconstruction_loss: 0.6758 - total_loss: 0.6758\n","Epoch 24/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - kl_loss: 1.0372e-06 - reconstruction_loss: 0.6765 - total_loss: 0.6765\n","Epoch 25/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 116ms/step - kl_loss: 1.3099e-06 - reconstruction_loss: 0.6756 - total_loss: 0.6756\n","Epoch 26/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - kl_loss: 9.7426e-07 - reconstruction_loss: 0.6769 - total_loss: 0.6769\n","Epoch 27/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - kl_loss: 1.1001e-06 - reconstruction_loss: 0.6753 - total_loss: 0.6753\n","Epoch 28/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 105ms/step - kl_loss: 9.4831e-07 - reconstruction_loss: 0.6771 - total_loss: 0.6771\n","Epoch 29/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - kl_loss: 2.7045e-06 - reconstruction_loss: 0.6749 - total_loss: 0.6749\n","Epoch 30/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - kl_loss: 8.9228e-07 - reconstruction_loss: 0.6778 - total_loss: 0.6778\n","Epoch 31/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 113ms/step - kl_loss: 1.1539e-06 - reconstruction_loss: 0.6761 - total_loss: 0.6761\n","Epoch 32/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - kl_loss: 1.0432e-06 - reconstruction_loss: 0.6753 - total_loss: 0.6753\n","Epoch 33/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - kl_loss: 1.3934e-06 - reconstruction_loss: 0.6778 - total_loss: 0.6778\n","Epoch 34/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 118ms/step - kl_loss: 8.5677e-07 - reconstruction_loss: 0.6740 - total_loss: 0.6740\n","Epoch 35/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 113ms/step - kl_loss: 8.0563e-07 - reconstruction_loss: 0.6762 - total_loss: 0.6762\n","Epoch 36/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 110ms/step - kl_loss: 1.6318e-06 - reconstruction_loss: 0.6764 - total_loss: 0.6764\n","Epoch 37/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 106ms/step - kl_loss: 8.2271e-07 - reconstruction_loss: 0.6768 - total_loss: 0.6768\n","Epoch 38/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - kl_loss: 1.1304e-06 - reconstruction_loss: 0.6755 - total_loss: 0.6755\n","Epoch 39/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 116ms/step - kl_loss: 4.2892e-06 - reconstruction_loss: 0.6811 - total_loss: 0.6811\n","Epoch 40/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 110ms/step - kl_loss: 1.2489e-06 - reconstruction_loss: 0.6766 - total_loss: 0.6766\n","Epoch 41/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 113ms/step - kl_loss: 1.4068e-06 - reconstruction_loss: 0.6739 - total_loss: 0.6739\n","Epoch 42/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 113ms/step - kl_loss: 1.1842e-06 - reconstruction_loss: 0.6756 - total_loss: 0.6756\n","Epoch 43/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 122ms/step - kl_loss: 1.1449e-06 - reconstruction_loss: 0.6762 - total_loss: 0.6762\n","Epoch 44/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 130ms/step - kl_loss: 1.0176e-06 - reconstruction_loss: 0.6769 - total_loss: 0.6769\n","Epoch 45/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 123ms/step - kl_loss: 1.1768e-06 - reconstruction_loss: 0.6745 - total_loss: 0.6745\n","Epoch 46/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 110ms/step - kl_loss: 8.6939e-07 - reconstruction_loss: 0.6777 - total_loss: 0.6777\n","Epoch 47/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - kl_loss: 1.4893e-06 - reconstruction_loss: 0.6766 - total_loss: 0.6766\n","Epoch 48/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 113ms/step - kl_loss: 2.5517e-06 - reconstruction_loss: 0.6730 - total_loss: 0.6730\n","Epoch 49/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - kl_loss: 9.3866e-07 - reconstruction_loss: 0.6744 - total_loss: 0.6744\n","Epoch 50/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 106ms/step - kl_loss: 1.7485e-06 - reconstruction_loss: 0.6769 - total_loss: 0.6769\n","Epoch 51/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 107ms/step - kl_loss: 4.0592e-06 - reconstruction_loss: 0.6768 - total_loss: 0.6768\n","Epoch 52/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - kl_loss: 8.3141e-07 - reconstruction_loss: 0.6753 - total_loss: 0.6753\n","Epoch 53/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - kl_loss: 8.2423e-07 - reconstruction_loss: 0.6767 - total_loss: 0.6767\n","Epoch 54/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 105ms/step - kl_loss: 7.2672e-07 - reconstruction_loss: 0.6761 - total_loss: 0.6761\n","Epoch 55/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 107ms/step - kl_loss: 1.3409e-06 - reconstruction_loss: 0.6753 - total_loss: 0.6753\n","Epoch 56/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - kl_loss: 6.7587e-07 - reconstruction_loss: 0.6752 - total_loss: 0.6752\n","Epoch 57/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - kl_loss: 1.0698e-06 - reconstruction_loss: 0.6759 - total_loss: 0.6759\n","Epoch 58/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - kl_loss: 9.1789e-07 - reconstruction_loss: 0.6760 - total_loss: 0.6760\n","Epoch 59/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 106ms/step - kl_loss: 8.0303e-07 - reconstruction_loss: 0.6770 - total_loss: 0.6770\n","Epoch 60/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 105ms/step - kl_loss: 8.6795e-07 - reconstruction_loss: 0.6746 - total_loss: 0.6746\n","Epoch 61/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 107ms/step - kl_loss: 9.1506e-07 - reconstruction_loss: 0.6750 - total_loss: 0.6750\n","Epoch 62/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 125ms/step - kl_loss: 9.4043e-07 - reconstruction_loss: 0.6786 - total_loss: 0.6786\n","Epoch 63/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 122ms/step - kl_loss: 7.7391e-07 - reconstruction_loss: 0.6763 - total_loss: 0.6763\n","Epoch 64/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 119ms/step - kl_loss: 1.0359e-06 - reconstruction_loss: 0.6757 - total_loss: 0.6757\n","Epoch 65/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 124ms/step - kl_loss: 1.0399e-06 - reconstruction_loss: 0.6780 - total_loss: 0.6780\n","Epoch 66/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 125ms/step - kl_loss: 1.0026e-06 - reconstruction_loss: 0.6760 - total_loss: 0.6760\n","Epoch 67/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 131ms/step - kl_loss: 8.6184e-07 - reconstruction_loss: 0.6751 - total_loss: 0.6751\n","Epoch 68/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 131ms/step - kl_loss: 9.2147e-07 - reconstruction_loss: 0.6750 - total_loss: 0.6750\n","Epoch 69/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 130ms/step - kl_loss: 9.0557e-07 - reconstruction_loss: 0.6759 - total_loss: 0.6759\n","Epoch 70/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 129ms/step - kl_loss: 1.7389e-06 - reconstruction_loss: 0.6740 - total_loss: 0.6740\n","Epoch 71/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 134ms/step - kl_loss: 1.1592e-06 - reconstruction_loss: 0.6780 - total_loss: 0.6780\n","Epoch 72/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - kl_loss: 9.7515e-07 - reconstruction_loss: 0.6784 - total_loss: 0.6784\n","Epoch 73/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 122ms/step - kl_loss: 8.6986e-07 - reconstruction_loss: 0.6751 - total_loss: 0.6751\n","Epoch 74/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 118ms/step - kl_loss: 1.4375e-06 - reconstruction_loss: 0.6741 - total_loss: 0.6741\n","Epoch 75/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 116ms/step - kl_loss: 8.2426e-07 - reconstruction_loss: 0.6757 - total_loss: 0.6757\n","Epoch 76/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 121ms/step - kl_loss: 8.1121e-07 - reconstruction_loss: 0.6756 - total_loss: 0.6756\n","Epoch 77/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 121ms/step - kl_loss: 8.1665e-07 - reconstruction_loss: 0.6759 - total_loss: 0.6759\n","Epoch 78/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 117ms/step - kl_loss: 8.8611e-07 - reconstruction_loss: 0.6744 - total_loss: 0.6744\n","Epoch 79/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 115ms/step - kl_loss: 7.5687e-07 - reconstruction_loss: 0.6755 - total_loss: 0.6755\n","Epoch 80/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 113ms/step - kl_loss: 8.3226e-07 - reconstruction_loss: 0.6761 - total_loss: 0.6761\n","Epoch 81/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 113ms/step - kl_loss: 1.0482e-06 - reconstruction_loss: 0.6775 - total_loss: 0.6775\n","Epoch 82/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 110ms/step - kl_loss: 1.0418e-06 - reconstruction_loss: 0.6772 - total_loss: 0.6772\n","Epoch 83/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 110ms/step - kl_loss: 6.8491e-07 - reconstruction_loss: 0.6747 - total_loss: 0.6747\n","Epoch 84/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step - kl_loss: 8.2420e-07 - reconstruction_loss: 0.6748 - total_loss: 0.6748\n","Epoch 85/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 107ms/step - kl_loss: 7.5586e-07 - reconstruction_loss: 0.6763 - total_loss: 0.6763\n","Epoch 86/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - kl_loss: 9.2127e-07 - reconstruction_loss: 0.6773 - total_loss: 0.6773\n","Epoch 87/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 119ms/step - kl_loss: 7.4892e-07 - reconstruction_loss: 0.6754 - total_loss: 0.6754\n","Epoch 88/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - kl_loss: 1.0618e-06 - reconstruction_loss: 0.6765 - total_loss: 0.6765\n","Epoch 89/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - kl_loss: 8.5593e-07 - reconstruction_loss: 0.6765 - total_loss: 0.6765\n","Epoch 90/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 115ms/step - kl_loss: 8.4601e-07 - reconstruction_loss: 0.6748 - total_loss: 0.6748\n","Epoch 91/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 111ms/step - kl_loss: 7.2638e-07 - reconstruction_loss: 0.6745 - total_loss: 0.6745\n","Epoch 92/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 106ms/step - kl_loss: 8.9379e-07 - reconstruction_loss: 0.6748 - total_loss: 0.6748\n","Epoch 93/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step - kl_loss: 1.6312e-06 - reconstruction_loss: 0.6759 - total_loss: 0.6759\n","Epoch 94/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 107ms/step - kl_loss: 7.1320e-07 - reconstruction_loss: 0.6752 - total_loss: 0.6752\n","Epoch 95/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - kl_loss: 7.5147e-07 - reconstruction_loss: 0.6763 - total_loss: 0.6763\n","Epoch 96/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 110ms/step - kl_loss: 1.0961e-06 - reconstruction_loss: 0.6768 - total_loss: 0.6768\n","Epoch 97/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 110ms/step - kl_loss: 7.0644e-07 - reconstruction_loss: 0.6748 - total_loss: 0.6748\n","Epoch 98/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 105ms/step - kl_loss: 7.1192e-07 - reconstruction_loss: 0.6753 - total_loss: 0.6753\n","Epoch 99/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 105ms/step - kl_loss: 1.0902e-06 - reconstruction_loss: 0.6724 - total_loss: 0.6724\n","Epoch 100/100\n","\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 115ms/step - kl_loss: 6.7900e-07 - reconstruction_loss: 0.6752 - total_loss: 0.6752\n","Found 401 images belonging to 1 classes.\n","\u001b[1m 3/13\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step  "]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711567744.382571      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 406ms/step\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 131ms/step\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step\n","Training VAE for class: Motorbike\n","Found 163 images belonging to 1 classes.\n","Epoch 1/100\n","\u001b[1m2/6\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 3s/step - kl_loss: 1.5453e-05 - reconstruction_loss: 0.7007 - total_loss: 0.7007 "]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711567767.757623      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 718ms/step - kl_loss: 1.9195e-05 - reconstruction_loss: 0.6949 - total_loss: 0.6949\n","Epoch 2/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 7.3883e-06 - reconstruction_loss: 0.6925 - total_loss: 0.6925\n","Epoch 3/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 4.1185e-06 - reconstruction_loss: 0.6831 - total_loss: 0.6831\n","Epoch 4/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 3.0725e-06 - reconstruction_loss: 0.6835 - total_loss: 0.6836\n","Epoch 5/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 1.3768e-06 - reconstruction_loss: 0.6868 - total_loss: 0.6868\n","Epoch 6/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 9.3473e-07 - reconstruction_loss: 0.6862 - total_loss: 0.6862\n","Epoch 7/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 7.9197e-07 - reconstruction_loss: 0.6850 - total_loss: 0.6850\n","Epoch 8/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 7.6547e-07 - reconstruction_loss: 0.6838 - total_loss: 0.6838\n","Epoch 9/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 6.7991e-07 - reconstruction_loss: 0.6853 - total_loss: 0.6853\n","Epoch 10/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 7.4989e-07 - reconstruction_loss: 0.6848 - total_loss: 0.6848\n","Epoch 11/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.1258e-06 - reconstruction_loss: 0.6948 - total_loss: 0.6948\n","Epoch 12/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.1608e-06 - reconstruction_loss: 0.6903 - total_loss: 0.6903\n","Epoch 13/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 7.8699e-07 - reconstruction_loss: 0.6837 - total_loss: 0.6837 \n","Epoch 14/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 9.4337e-07 - reconstruction_loss: 0.6808 - total_loss: 0.6808\n","Epoch 15/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.0140e-06 - reconstruction_loss: 0.6845 - total_loss: 0.6845\n","Epoch 16/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 5.8955e-07 - reconstruction_loss: 0.6866 - total_loss: 0.6866\n","Epoch 17/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 5.9789e-07 - reconstruction_loss: 0.6849 - total_loss: 0.6849\n","Epoch 18/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 6.9523e-07 - reconstruction_loss: 0.6851 - total_loss: 0.6852\n","Epoch 19/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 7.1878e-07 - reconstruction_loss: 0.6853 - total_loss: 0.6853\n","Epoch 20/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 7.1589e-07 - reconstruction_loss: 0.6804 - total_loss: 0.6804\n","Epoch 21/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 9.0749e-07 - reconstruction_loss: 0.6861 - total_loss: 0.6861\n","Epoch 22/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 9.9149e-07 - reconstruction_loss: 0.6839 - total_loss: 0.6839 \n","Epoch 23/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 1.0353e-06 - reconstruction_loss: 0.6833 - total_loss: 0.6833\n","Epoch 24/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 9.2603e-07 - reconstruction_loss: 0.6850 - total_loss: 0.6850\n","Epoch 25/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 9.2546e-07 - reconstruction_loss: 0.6850 - total_loss: 0.6850\n","Epoch 26/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 9.3104e-07 - reconstruction_loss: 0.6843 - total_loss: 0.6843\n","Epoch 27/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.0338e-06 - reconstruction_loss: 0.6858 - total_loss: 0.6858\n","Epoch 28/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 8.3317e-07 - reconstruction_loss: 0.6879 - total_loss: 0.6879\n","Epoch 29/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 9.0458e-07 - reconstruction_loss: 0.6842 - total_loss: 0.6842\n","Epoch 30/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 1.0484e-06 - reconstruction_loss: 0.6852 - total_loss: 0.6852\n","Epoch 31/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 9.3696e-07 - reconstruction_loss: 0.6855 - total_loss: 0.6855\n","Epoch 32/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.0119e-06 - reconstruction_loss: 0.6849 - total_loss: 0.6849 \n","Epoch 33/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 1.0176e-06 - reconstruction_loss: 0.6841 - total_loss: 0.6841\n","Epoch 34/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 1.0886e-06 - reconstruction_loss: 0.6871 - total_loss: 0.6871\n","Epoch 35/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 9.0805e-07 - reconstruction_loss: 0.6827 - total_loss: 0.6827\n","Epoch 36/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 8.7342e-07 - reconstruction_loss: 0.6849 - total_loss: 0.6849 \n","Epoch 37/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 1.1421e-06 - reconstruction_loss: 0.6834 - total_loss: 0.6834 \n","Epoch 38/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.1857e-06 - reconstruction_loss: 0.6848 - total_loss: 0.6848 \n","Epoch 39/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.7976e-06 - reconstruction_loss: 0.6874 - total_loss: 0.6874\n","Epoch 40/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.1580e-06 - reconstruction_loss: 0.6840 - total_loss: 0.6840\n","Epoch 41/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.3705e-06 - reconstruction_loss: 0.6847 - total_loss: 0.6847\n","Epoch 42/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 1.5611e-06 - reconstruction_loss: 0.6857 - total_loss: 0.6857\n","Epoch 43/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.4313e-06 - reconstruction_loss: 0.6851 - total_loss: 0.6851\n","Epoch 44/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 1.3520e-06 - reconstruction_loss: 0.6856 - total_loss: 0.6856\n","Epoch 45/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 1.1947e-06 - reconstruction_loss: 0.6864 - total_loss: 0.6864 \n","Epoch 46/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.1150e-06 - reconstruction_loss: 0.6835 - total_loss: 0.6835\n","Epoch 47/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.1737e-06 - reconstruction_loss: 0.6881 - total_loss: 0.6881\n","Epoch 48/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 7.8236e-07 - reconstruction_loss: 0.6834 - total_loss: 0.6834\n","Epoch 49/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.1689e-06 - reconstruction_loss: 0.6850 - total_loss: 0.6850\n","Epoch 50/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.2004e-06 - reconstruction_loss: 0.6825 - total_loss: 0.6825\n","Epoch 51/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.0664e-06 - reconstruction_loss: 0.6831 - total_loss: 0.6831\n","Epoch 52/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.3430e-06 - reconstruction_loss: 0.6748 - total_loss: 0.6748\n","Epoch 53/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 9.5907e-07 - reconstruction_loss: 0.6824 - total_loss: 0.6824\n","Epoch 54/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.1809e-06 - reconstruction_loss: 0.6869 - total_loss: 0.6869\n","Epoch 55/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.7581e-06 - reconstruction_loss: 0.6826 - total_loss: 0.6826\n","Epoch 56/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 1.8470e-06 - reconstruction_loss: 0.6830 - total_loss: 0.6830\n","Epoch 57/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.5241e-06 - reconstruction_loss: 0.6895 - total_loss: 0.6895\n","Epoch 58/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.5082e-06 - reconstruction_loss: 0.6845 - total_loss: 0.6845\n","Epoch 59/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 2.2162e-06 - reconstruction_loss: 0.6848 - total_loss: 0.6848\n","Epoch 60/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.6994e-06 - reconstruction_loss: 0.6894 - total_loss: 0.6894\n","Epoch 61/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.2401e-06 - reconstruction_loss: 0.6838 - total_loss: 0.6838\n","Epoch 62/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 1.8072e-06 - reconstruction_loss: 0.6852 - total_loss: 0.6852\n","Epoch 63/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.3813e-06 - reconstruction_loss: 0.6835 - total_loss: 0.6835\n","Epoch 64/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.3488e-06 - reconstruction_loss: 0.6886 - total_loss: 0.6886\n","Epoch 65/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.2442e-06 - reconstruction_loss: 0.6847 - total_loss: 0.6847\n","Epoch 66/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 1.3943e-06 - reconstruction_loss: 0.6905 - total_loss: 0.6905\n","Epoch 67/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.9034e-06 - reconstruction_loss: 0.6863 - total_loss: 0.6863\n","Epoch 68/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.5214e-06 - reconstruction_loss: 0.6842 - total_loss: 0.6842\n","Epoch 69/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.6761e-06 - reconstruction_loss: 0.6851 - total_loss: 0.6851\n","Epoch 70/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.4258e-06 - reconstruction_loss: 0.6841 - total_loss: 0.6841\n","Epoch 71/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.2760e-06 - reconstruction_loss: 0.6872 - total_loss: 0.6872\n","Epoch 72/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 2.4896e-06 - reconstruction_loss: 0.6799 - total_loss: 0.6799\n","Epoch 73/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.9142e-06 - reconstruction_loss: 0.6849 - total_loss: 0.6849 \n","Epoch 74/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.4705e-06 - reconstruction_loss: 0.6863 - total_loss: 0.6863\n","Epoch 75/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.3425e-06 - reconstruction_loss: 0.6907 - total_loss: 0.6907\n","Epoch 76/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.1719e-06 - reconstruction_loss: 0.6843 - total_loss: 0.6844 \n","Epoch 77/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 9.4871e-07 - reconstruction_loss: 0.6848 - total_loss: 0.6848 \n","Epoch 78/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 8.3574e-07 - reconstruction_loss: 0.6840 - total_loss: 0.6840\n","Epoch 79/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.2029e-06 - reconstruction_loss: 0.6830 - total_loss: 0.6830\n","Epoch 80/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.6921e-06 - reconstruction_loss: 0.6893 - total_loss: 0.6893\n","Epoch 81/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.6385e-06 - reconstruction_loss: 0.6842 - total_loss: 0.6842 \n","Epoch 82/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.3309e-06 - reconstruction_loss: 0.6850 - total_loss: 0.6850 \n","Epoch 83/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.7855e-06 - reconstruction_loss: 0.6856 - total_loss: 0.6856 \n","Epoch 84/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 1.0476e-06 - reconstruction_loss: 0.6846 - total_loss: 0.6846\n","Epoch 85/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 9.5403e-07 - reconstruction_loss: 0.6847 - total_loss: 0.6847\n","Epoch 86/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.2026e-06 - reconstruction_loss: 0.6833 - total_loss: 0.6833\n","Epoch 87/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.1130e-06 - reconstruction_loss: 0.6833 - total_loss: 0.6833\n","Epoch 88/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.0084e-06 - reconstruction_loss: 0.6837 - total_loss: 0.6837\n","Epoch 89/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.5029e-06 - reconstruction_loss: 0.6867 - total_loss: 0.6867\n","Epoch 90/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.3285e-06 - reconstruction_loss: 0.6848 - total_loss: 0.6848\n","Epoch 91/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.2580e-06 - reconstruction_loss: 0.6842 - total_loss: 0.6842\n","Epoch 92/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 3.1400e-06 - reconstruction_loss: 0.6836 - total_loss: 0.6836\n","Epoch 93/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.7508e-06 - reconstruction_loss: 0.6815 - total_loss: 0.6815\n","Epoch 94/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.7190e-06 - reconstruction_loss: 0.6859 - total_loss: 0.6860\n","Epoch 95/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.8798e-06 - reconstruction_loss: 0.6847 - total_loss: 0.6847\n","Epoch 96/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 3.0125e-06 - reconstruction_loss: 0.6814 - total_loss: 0.6814\n","Epoch 97/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.7967e-06 - reconstruction_loss: 0.6846 - total_loss: 0.6846\n","Epoch 98/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.5393e-06 - reconstruction_loss: 0.6832 - total_loss: 0.6832\n","Epoch 99/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.3872e-06 - reconstruction_loss: 0.6846 - total_loss: 0.6846 \n","Epoch 100/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 1.3121e-06 - reconstruction_loss: 0.6847 - total_loss: 0.6847\n","Found 41 images belonging to 1 classes.\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 849ms/step"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711567881.640276      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3s/step  \n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 385ms/step\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","Training VAE for class: Bus\n","Found 80 images belonging to 1 classes.\n","Epoch 1/100\n","\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 6s/step - kl_loss: 1.4007e-06 - reconstruction_loss: 0.6708 - total_loss: 0.6708"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711567892.552128      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6s/step - kl_loss: 1.7334e-05 - reconstruction_loss: 0.6745 - total_loss: 0.6745\n","Epoch 2/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - kl_loss: 1.9632e-05 - reconstruction_loss: 0.6750 - total_loss: 0.6750\n","Epoch 3/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 6.4683e-06 - reconstruction_loss: 0.6717 - total_loss: 0.6717\n","Epoch 4/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.1689e-05 - reconstruction_loss: 0.6749 - total_loss: 0.6749\n","Epoch 5/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 4.1313e-06 - reconstruction_loss: 0.6738 - total_loss: 0.6738\n","Epoch 6/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - kl_loss: 4.8491e-06 - reconstruction_loss: 0.6727 - total_loss: 0.6727\n","Epoch 7/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 3.9997e-06 - reconstruction_loss: 0.6717 - total_loss: 0.6717\n","Epoch 8/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - kl_loss: 3.1814e-06 - reconstruction_loss: 0.6752 - total_loss: 0.6752\n","Epoch 9/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 2.3780e-06 - reconstruction_loss: 0.6717 - total_loss: 0.6717\n","Epoch 10/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 2.4959e-06 - reconstruction_loss: 0.6709 - total_loss: 0.6709\n","Epoch 11/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - kl_loss: 2.0688e-06 - reconstruction_loss: 0.6672 - total_loss: 0.6672\n","Epoch 12/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - kl_loss: 1.3039e-06 - reconstruction_loss: 0.6615 - total_loss: 0.6615\n","Epoch 13/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 1.5001e-06 - reconstruction_loss: 0.6689 - total_loss: 0.6689\n","Epoch 14/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 1.5708e-06 - reconstruction_loss: 0.6687 - total_loss: 0.6687\n","Epoch 15/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 1.3299e-06 - reconstruction_loss: 0.6722 - total_loss: 0.6722\n","Epoch 16/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 9.9962e-07 - reconstruction_loss: 0.6715 - total_loss: 0.6715\n","Epoch 17/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 8.6427e-07 - reconstruction_loss: 0.6690 - total_loss: 0.6690\n","Epoch 18/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 9.7478e-07 - reconstruction_loss: 0.6722 - total_loss: 0.6722\n","Epoch 19/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.1350e-06 - reconstruction_loss: 0.6700 - total_loss: 0.6701\n","Epoch 20/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 1.0456e-06 - reconstruction_loss: 0.6707 - total_loss: 0.6707\n","Epoch 21/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 1.1859e-06 - reconstruction_loss: 0.6673 - total_loss: 0.6673\n","Epoch 22/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 1.6565e-06 - reconstruction_loss: 0.6743 - total_loss: 0.6743\n","Epoch 23/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 1.1077e-06 - reconstruction_loss: 0.6691 - total_loss: 0.6691\n","Epoch 24/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - kl_loss: 1.7571e-06 - reconstruction_loss: 0.6710 - total_loss: 0.6710\n","Epoch 25/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.2604e-06 - reconstruction_loss: 0.6714 - total_loss: 0.6714\n","Epoch 26/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.0518e-06 - reconstruction_loss: 0.6704 - total_loss: 0.6704\n","Epoch 27/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.1275e-06 - reconstruction_loss: 0.6719 - total_loss: 0.6719\n","Epoch 28/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.2157e-06 - reconstruction_loss: 0.6730 - total_loss: 0.6730\n","Epoch 29/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 1.3933e-06 - reconstruction_loss: 0.6729 - total_loss: 0.6729\n","Epoch 30/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.0518e-06 - reconstruction_loss: 0.6685 - total_loss: 0.6685\n","Epoch 31/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.2256e-06 - reconstruction_loss: 0.6731 - total_loss: 0.6731\n","Epoch 32/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 1.5423e-06 - reconstruction_loss: 0.6711 - total_loss: 0.6711\n","Epoch 33/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - kl_loss: 1.2269e-06 - reconstruction_loss: 0.6725 - total_loss: 0.6725\n","Epoch 34/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 1.1250e-06 - reconstruction_loss: 0.6696 - total_loss: 0.6696\n","Epoch 35/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.1809e-06 - reconstruction_loss: 0.6719 - total_loss: 0.6719\n","Epoch 36/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 9.2636e-07 - reconstruction_loss: 0.6696 - total_loss: 0.6696\n","Epoch 37/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - kl_loss: 1.5025e-06 - reconstruction_loss: 0.6763 - total_loss: 0.6763\n","Epoch 38/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 1.4429e-06 - reconstruction_loss: 0.6697 - total_loss: 0.6697\n","Epoch 39/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 1.3461e-06 - reconstruction_loss: 0.6705 - total_loss: 0.6705\n","Epoch 40/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 1.1275e-06 - reconstruction_loss: 0.6707 - total_loss: 0.6707\n","Epoch 41/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - kl_loss: 1.3858e-06 - reconstruction_loss: 0.6695 - total_loss: 0.6695\n","Epoch 42/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - kl_loss: 1.0456e-06 - reconstruction_loss: 0.6692 - total_loss: 0.6692\n","Epoch 43/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 1.2070e-06 - reconstruction_loss: 0.6709 - total_loss: 0.6709\n","Epoch 44/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 1.1586e-06 - reconstruction_loss: 0.6691 - total_loss: 0.6691\n","Epoch 45/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.1524e-06 - reconstruction_loss: 0.6708 - total_loss: 0.6708\n","Epoch 46/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 1.0952e-06 - reconstruction_loss: 0.6718 - total_loss: 0.6718\n","Epoch 47/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - kl_loss: 1.3361e-06 - reconstruction_loss: 0.6701 - total_loss: 0.6701\n","Epoch 48/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 1.2716e-06 - reconstruction_loss: 0.6713 - total_loss: 0.6713\n","Epoch 49/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - kl_loss: 1.1983e-06 - reconstruction_loss: 0.6691 - total_loss: 0.6691\n","Epoch 50/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 8.6923e-07 - reconstruction_loss: 0.6758 - total_loss: 0.6758\n","Epoch 51/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 9.9838e-07 - reconstruction_loss: 0.6695 - total_loss: 0.6695\n","Epoch 52/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 1.1064e-06 - reconstruction_loss: 0.6676 - total_loss: 0.6676\n","Epoch 53/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.6031e-06 - reconstruction_loss: 0.6694 - total_loss: 0.6694\n","Epoch 54/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 1.3970e-06 - reconstruction_loss: 0.6710 - total_loss: 0.6710\n","Epoch 55/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - kl_loss: 1.3001e-06 - reconstruction_loss: 0.6707 - total_loss: 0.6707\n","Epoch 56/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 1.0816e-06 - reconstruction_loss: 0.6723 - total_loss: 0.6723\n","Epoch 57/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 1.2331e-06 - reconstruction_loss: 0.6740 - total_loss: 0.6740\n","Epoch 58/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.1772e-06 - reconstruction_loss: 0.6746 - total_loss: 0.6746\n","Epoch 59/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.5646e-06 - reconstruction_loss: 0.6706 - total_loss: 0.6706\n","Epoch 60/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 1.3262e-06 - reconstruction_loss: 0.6693 - total_loss: 0.6693\n","Epoch 61/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.0083e-06 - reconstruction_loss: 0.6693 - total_loss: 0.6693\n","Epoch 62/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - kl_loss: 1.3759e-06 - reconstruction_loss: 0.6669 - total_loss: 0.6670\n","Epoch 63/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 9.2015e-07 - reconstruction_loss: 0.6689 - total_loss: 0.6689\n","Epoch 64/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - kl_loss: 1.5212e-06 - reconstruction_loss: 0.6696 - total_loss: 0.6696\n","Epoch 65/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 9.9217e-07 - reconstruction_loss: 0.6703 - total_loss: 0.6703\n","Epoch 66/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - kl_loss: 1.6714e-06 - reconstruction_loss: 0.6692 - total_loss: 0.6692\n","Epoch 67/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 1.4678e-06 - reconstruction_loss: 0.6724 - total_loss: 0.6724\n","Epoch 68/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - kl_loss: 1.1375e-06 - reconstruction_loss: 0.6690 - total_loss: 0.6690\n","Epoch 69/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.0841e-06 - reconstruction_loss: 0.6623 - total_loss: 0.6623\n","Epoch 70/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.1163e-06 - reconstruction_loss: 0.6675 - total_loss: 0.6675\n","Epoch 71/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 1.1909e-06 - reconstruction_loss: 0.6743 - total_loss: 0.6743\n","Epoch 72/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - kl_loss: 1.2318e-06 - reconstruction_loss: 0.6705 - total_loss: 0.6705\n","Epoch 73/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 1.1548e-06 - reconstruction_loss: 0.6685 - total_loss: 0.6685\n","Epoch 74/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.2380e-06 - reconstruction_loss: 0.6681 - total_loss: 0.6681\n","Epoch 75/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - kl_loss: 1.3473e-06 - reconstruction_loss: 0.6789 - total_loss: 0.6789\n","Epoch 76/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.4640e-06 - reconstruction_loss: 0.6691 - total_loss: 0.6691\n","Epoch 77/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - kl_loss: 1.8887e-06 - reconstruction_loss: 0.6720 - total_loss: 0.6720\n","Epoch 78/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.9247e-06 - reconstruction_loss: 0.6704 - total_loss: 0.6704\n","Epoch 79/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - kl_loss: 1.6131e-06 - reconstruction_loss: 0.6782 - total_loss: 0.6782\n","Epoch 80/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 1.5820e-06 - reconstruction_loss: 0.6704 - total_loss: 0.6704\n","Epoch 81/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - kl_loss: 1.5895e-06 - reconstruction_loss: 0.6710 - total_loss: 0.6710\n","Epoch 82/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - kl_loss: 1.5212e-06 - reconstruction_loss: 0.6665 - total_loss: 0.6665\n","Epoch 83/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 1.1946e-06 - reconstruction_loss: 0.6691 - total_loss: 0.6691\n","Epoch 84/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 8.0963e-07 - reconstruction_loss: 0.6693 - total_loss: 0.6693\n","Epoch 85/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - kl_loss: 1.3510e-06 - reconstruction_loss: 0.6729 - total_loss: 0.6729\n","Epoch 86/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - kl_loss: 1.4876e-06 - reconstruction_loss: 0.6688 - total_loss: 0.6688\n","Epoch 87/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - kl_loss: 2.1135e-06 - reconstruction_loss: 0.6723 - total_loss: 0.6723\n","Epoch 88/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 1.8515e-06 - reconstruction_loss: 0.6788 - total_loss: 0.6788\n","Epoch 89/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - kl_loss: 1.5385e-06 - reconstruction_loss: 0.6683 - total_loss: 0.6683\n","Epoch 90/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 1.2914e-06 - reconstruction_loss: 0.6697 - total_loss: 0.6697\n","Epoch 91/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - kl_loss: 1.6640e-06 - reconstruction_loss: 0.6709 - total_loss: 0.6709\n","Epoch 92/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - kl_loss: 1.8229e-06 - reconstruction_loss: 0.6703 - total_loss: 0.6703\n","Epoch 93/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.1573e-06 - reconstruction_loss: 0.6702 - total_loss: 0.6702\n","Epoch 94/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - kl_loss: 1.4504e-06 - reconstruction_loss: 0.6686 - total_loss: 0.6686\n","Epoch 95/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 1.5361e-06 - reconstruction_loss: 0.6674 - total_loss: 0.6674\n","Epoch 96/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - kl_loss: 1.7397e-06 - reconstruction_loss: 0.6695 - total_loss: 0.6695\n","Epoch 97/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.5187e-06 - reconstruction_loss: 0.6700 - total_loss: 0.6700\n","Epoch 98/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - kl_loss: 1.7223e-06 - reconstruction_loss: 0.6702 - total_loss: 0.6702\n","Epoch 99/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - kl_loss: 1.2058e-06 - reconstruction_loss: 0.6697 - total_loss: 0.6697\n","Epoch 100/100\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - kl_loss: 1.6652e-06 - reconstruction_loss: 0.6697 - total_loss: 0.6697\n","Found 20 images belonging to 1 classes.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 783ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","Training VAE for class: Bicycle\n","Found 153 images belonging to 1 classes.\n","Epoch 1/100\n","\u001b[1m2/5\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 3s/step - kl_loss: 1.4529e-05 - reconstruction_loss: 0.6911 - total_loss: 0.6911   "]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711567989.086299      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 857ms/step - kl_loss: 1.8335e-05 - reconstruction_loss: 0.6900 - total_loss: 0.6900\n","Epoch 2/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - kl_loss: 1.0833e-05 - reconstruction_loss: 0.6880 - total_loss: 0.6880\n","Epoch 3/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 6.1025e-06 - reconstruction_loss: 0.6857 - total_loss: 0.6857\n","Epoch 4/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - kl_loss: 4.2317e-06 - reconstruction_loss: 0.6863 - total_loss: 0.6863\n","Epoch 5/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 2.4938e-06 - reconstruction_loss: 0.6854 - total_loss: 0.6854\n","Epoch 6/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.5722e-06 - reconstruction_loss: 0.6873 - total_loss: 0.6873\n","Epoch 7/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - kl_loss: 8.0822e-07 - reconstruction_loss: 0.6849 - total_loss: 0.6849\n","Epoch 8/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - kl_loss: 8.1037e-07 - reconstruction_loss: 0.6854 - total_loss: 0.6854\n","Epoch 9/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - kl_loss: 5.6889e-07 - reconstruction_loss: 0.6857 - total_loss: 0.6857\n","Epoch 10/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - kl_loss: 5.7568e-07 - reconstruction_loss: 0.6859 - total_loss: 0.6859\n","Epoch 11/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 3.3793e-07 - reconstruction_loss: 0.6834 - total_loss: 0.6834\n","Epoch 12/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - kl_loss: 5.7717e-07 - reconstruction_loss: 0.6825 - total_loss: 0.6825\n","Epoch 13/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 5.0879e-07 - reconstruction_loss: 0.6843 - total_loss: 0.6843\n","Epoch 14/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - kl_loss: 6.4870e-07 - reconstruction_loss: 0.6859 - total_loss: 0.6859\n","Epoch 15/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 5.1964e-07 - reconstruction_loss: 0.6867 - total_loss: 0.6867\n","Epoch 16/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - kl_loss: 6.1699e-07 - reconstruction_loss: 0.6855 - total_loss: 0.6855\n","Epoch 17/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - kl_loss: 4.7833e-07 - reconstruction_loss: 0.6866 - total_loss: 0.6866\n","Epoch 18/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - kl_loss: 6.3214e-07 - reconstruction_loss: 0.6850 - total_loss: 0.6850\n","Epoch 19/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 2.9728e-07 - reconstruction_loss: 0.6860 - total_loss: 0.6860\n","Epoch 20/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - kl_loss: 6.9075e-07 - reconstruction_loss: 0.6872 - total_loss: 0.6872\n","Epoch 21/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - kl_loss: 4.9199e-07 - reconstruction_loss: 0.6844 - total_loss: 0.6844\n","Epoch 22/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 5.2469e-07 - reconstruction_loss: 0.6868 - total_loss: 0.6868\n","Epoch 23/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - kl_loss: 8.3811e-07 - reconstruction_loss: 0.6854 - total_loss: 0.6854\n","Epoch 24/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 6.0383e-07 - reconstruction_loss: 0.6840 - total_loss: 0.6840\n","Epoch 25/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 7.0772e-07 - reconstruction_loss: 0.6870 - total_loss: 0.6870\n","Epoch 26/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 6.2585e-07 - reconstruction_loss: 0.6874 - total_loss: 0.6874\n","Epoch 27/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 5.2328e-07 - reconstruction_loss: 0.6870 - total_loss: 0.6870\n","Epoch 28/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 5.4455e-07 - reconstruction_loss: 0.6857 - total_loss: 0.6857\n","Epoch 29/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 4.6276e-07 - reconstruction_loss: 0.6846 - total_loss: 0.6846\n","Epoch 30/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - kl_loss: 6.5540e-07 - reconstruction_loss: 0.6839 - total_loss: 0.6839\n","Epoch 31/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 7.2022e-07 - reconstruction_loss: 0.6865 - total_loss: 0.6865\n","Epoch 32/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 5.1798e-07 - reconstruction_loss: 0.6844 - total_loss: 0.6844\n","Epoch 33/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - kl_loss: 7.8413e-07 - reconstruction_loss: 0.6857 - total_loss: 0.6857\n","Epoch 34/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 5.5068e-07 - reconstruction_loss: 0.6823 - total_loss: 0.6823\n","Epoch 35/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 6.8388e-07 - reconstruction_loss: 0.6873 - total_loss: 0.6873\n","Epoch 36/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 6.8595e-07 - reconstruction_loss: 0.6842 - total_loss: 0.6842\n","Epoch 37/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - kl_loss: 7.7743e-07 - reconstruction_loss: 0.6850 - total_loss: 0.6850\n","Epoch 38/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 5.9812e-07 - reconstruction_loss: 0.6861 - total_loss: 0.6861\n","Epoch 39/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 6.4539e-07 - reconstruction_loss: 0.6866 - total_loss: 0.6866\n","Epoch 40/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 9.0020e-07 - reconstruction_loss: 0.6851 - total_loss: 0.6851\n","Epoch 41/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - kl_loss: 9.3165e-07 - reconstruction_loss: 0.6856 - total_loss: 0.6856\n","Epoch 42/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - kl_loss: 6.4936e-07 - reconstruction_loss: 0.6857 - total_loss: 0.6857\n","Epoch 43/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 7.8397e-07 - reconstruction_loss: 0.6826 - total_loss: 0.6826\n","Epoch 44/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 3.9389e-07 - reconstruction_loss: 0.6853 - total_loss: 0.6853\n","Epoch 45/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 6.5772e-07 - reconstruction_loss: 0.6868 - total_loss: 0.6868\n","Epoch 46/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - kl_loss: 5.9373e-07 - reconstruction_loss: 0.6876 - total_loss: 0.6876\n","Epoch 47/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - kl_loss: 5.8065e-07 - reconstruction_loss: 0.6841 - total_loss: 0.6841\n","Epoch 48/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - kl_loss: 6.0267e-07 - reconstruction_loss: 0.6870 - total_loss: 0.6870\n","Epoch 49/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - kl_loss: 7.3728e-07 - reconstruction_loss: 0.6852 - total_loss: 0.6852\n","Epoch 50/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - kl_loss: 8.7793e-07 - reconstruction_loss: 0.6846 - total_loss: 0.6846\n","Epoch 51/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - kl_loss: 6.6674e-07 - reconstruction_loss: 0.6868 - total_loss: 0.6868\n","Epoch 52/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - kl_loss: 5.9472e-07 - reconstruction_loss: 0.6838 - total_loss: 0.6838\n","Epoch 53/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - kl_loss: 6.3611e-07 - reconstruction_loss: 0.6857 - total_loss: 0.6857\n","Epoch 54/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 5.9216e-07 - reconstruction_loss: 0.6849 - total_loss: 0.6849\n","Epoch 55/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - kl_loss: 7.3024e-07 - reconstruction_loss: 0.6858 - total_loss: 0.6858\n","Epoch 56/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - kl_loss: 4.9108e-07 - reconstruction_loss: 0.6864 - total_loss: 0.6864\n","Epoch 57/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - kl_loss: 3.7683e-07 - reconstruction_loss: 0.6827 - total_loss: 0.6827\n","Epoch 58/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 7.7345e-07 - reconstruction_loss: 0.6833 - total_loss: 0.6833\n","Epoch 59/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - kl_loss: 7.8272e-07 - reconstruction_loss: 0.6860 - total_loss: 0.6860\n","Epoch 60/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 7.3496e-07 - reconstruction_loss: 0.6856 - total_loss: 0.6856\n","Epoch 61/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 4.9091e-07 - reconstruction_loss: 0.6841 - total_loss: 0.6841\n","Epoch 62/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - kl_loss: 5.1566e-07 - reconstruction_loss: 0.6875 - total_loss: 0.6875\n","Epoch 63/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - kl_loss: 6.6832e-07 - reconstruction_loss: 0.6870 - total_loss: 0.6870\n","Epoch 64/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - kl_loss: 5.0921e-07 - reconstruction_loss: 0.6839 - total_loss: 0.6839\n","Epoch 65/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 5.5523e-07 - reconstruction_loss: 0.6845 - total_loss: 0.6845\n","Epoch 66/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - kl_loss: 7.9680e-07 - reconstruction_loss: 0.6879 - total_loss: 0.6879\n","Epoch 67/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 5.8280e-07 - reconstruction_loss: 0.6855 - total_loss: 0.6855\n","Epoch 68/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - kl_loss: 6.8032e-07 - reconstruction_loss: 0.6865 - total_loss: 0.6865\n","Epoch 69/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 7.1178e-07 - reconstruction_loss: 0.6839 - total_loss: 0.6839\n","Epoch 70/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - kl_loss: 6.2386e-07 - reconstruction_loss: 0.6857 - total_loss: 0.6857\n","Epoch 71/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 6.2419e-07 - reconstruction_loss: 0.6862 - total_loss: 0.6862\n","Epoch 72/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - kl_loss: 6.7900e-07 - reconstruction_loss: 0.6852 - total_loss: 0.6852\n","Epoch 73/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - kl_loss: 7.2113e-07 - reconstruction_loss: 0.6865 - total_loss: 0.6865\n","Epoch 74/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 8.2892e-07 - reconstruction_loss: 0.6849 - total_loss: 0.6849\n","Epoch 75/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - kl_loss: 4.5349e-07 - reconstruction_loss: 0.6854 - total_loss: 0.6854\n","Epoch 76/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - kl_loss: 6.9530e-07 - reconstruction_loss: 0.6863 - total_loss: 0.6863\n","Epoch 77/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - kl_loss: 7.5814e-07 - reconstruction_loss: 0.6848 - total_loss: 0.6848\n","Epoch 78/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - kl_loss: 3.0887e-07 - reconstruction_loss: 0.6858 - total_loss: 0.6858\n","Epoch 79/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - kl_loss: 6.6774e-07 - reconstruction_loss: 0.6867 - total_loss: 0.6867\n","Epoch 80/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - kl_loss: 5.9381e-07 - reconstruction_loss: 0.6837 - total_loss: 0.6837\n","Epoch 81/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - kl_loss: 5.7055e-07 - reconstruction_loss: 0.6836 - total_loss: 0.6836\n","Epoch 82/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - kl_loss: 5.9787e-07 - reconstruction_loss: 0.6828 - total_loss: 0.6828\n","Epoch 83/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - kl_loss: 6.1807e-07 - reconstruction_loss: 0.6835 - total_loss: 0.6835\n","Epoch 84/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - kl_loss: 7.1997e-07 - reconstruction_loss: 0.6870 - total_loss: 0.6870\n","Epoch 85/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 6.3462e-07 - reconstruction_loss: 0.6848 - total_loss: 0.6848\n","Epoch 86/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - kl_loss: 6.2254e-07 - reconstruction_loss: 0.6852 - total_loss: 0.6852\n","Epoch 87/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - kl_loss: 7.7519e-07 - reconstruction_loss: 0.6869 - total_loss: 0.6869\n","Epoch 88/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 7.1964e-07 - reconstruction_loss: 0.6864 - total_loss: 0.6864\n","Epoch 89/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - kl_loss: 7.0350e-07 - reconstruction_loss: 0.6853 - total_loss: 0.6853\n","Epoch 90/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 8.7263e-07 - reconstruction_loss: 0.6845 - total_loss: 0.6845\n","Epoch 91/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 5.9274e-07 - reconstruction_loss: 0.6847 - total_loss: 0.6847\n","Epoch 92/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - kl_loss: 7.4655e-07 - reconstruction_loss: 0.6859 - total_loss: 0.6859\n","Epoch 93/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - kl_loss: 6.6608e-07 - reconstruction_loss: 0.6838 - total_loss: 0.6838\n","Epoch 94/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 8.8049e-07 - reconstruction_loss: 0.6842 - total_loss: 0.6842\n","Epoch 95/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - kl_loss: 5.9679e-07 - reconstruction_loss: 0.6879 - total_loss: 0.6879\n","Epoch 96/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - kl_loss: 7.0259e-07 - reconstruction_loss: 0.6841 - total_loss: 0.6841\n","Epoch 97/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 8.8480e-07 - reconstruction_loss: 0.6861 - total_loss: 0.6861\n","Epoch 98/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 8.7743e-07 - reconstruction_loss: 0.6845 - total_loss: 0.6845\n","Epoch 99/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - kl_loss: 7.6600e-07 - reconstruction_loss: 0.6857 - total_loss: 0.6857\n","Epoch 100/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - kl_loss: 7.0921e-07 - reconstruction_loss: 0.6838 - total_loss: 0.6838\n","Found 39 images belonging to 1 classes.\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 845ms/step"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711568097.456511      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step  \n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 416ms/step\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","Training VAE for class: Aeroplane\n","Found 188 images belonging to 1 classes.\n","Epoch 1/100\n","\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 7s/step - kl_loss: 4.1723e-07 - reconstruction_loss: 0.7027 - total_loss: 0.7027"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711568109.450546      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3s/step - kl_loss: 1.8537e-05 - reconstruction_loss: 0.6990 - total_loss: 0.6990\n","Epoch 2/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 7.1751e-06 - reconstruction_loss: 0.6913 - total_loss: 0.6913\n","Epoch 3/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 3.7732e-06 - reconstruction_loss: 0.6858 - total_loss: 0.6858\n","Epoch 4/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 3.7300e-06 - reconstruction_loss: 0.6839 - total_loss: 0.6839\n","Epoch 5/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 5.5546e-06 - reconstruction_loss: 0.6845 - total_loss: 0.6845\n","Epoch 6/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 3.6577e-06 - reconstruction_loss: 0.6822 - total_loss: 0.6823\n","Epoch 7/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.8973e-06 - reconstruction_loss: 0.6794 - total_loss: 0.6794\n","Epoch 8/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 1.7642e-06 - reconstruction_loss: 0.6827 - total_loss: 0.6827\n","Epoch 9/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.3697e-06 - reconstruction_loss: 0.6812 - total_loss: 0.6812\n","Epoch 10/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 1.2183e-06 - reconstruction_loss: 0.6825 - total_loss: 0.6825\n","Epoch 11/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.1766e-06 - reconstruction_loss: 0.6818 - total_loss: 0.6818\n","Epoch 12/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 1.0737e-06 - reconstruction_loss: 0.6814 - total_loss: 0.6814\n","Epoch 13/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.4071e-06 - reconstruction_loss: 0.6818 - total_loss: 0.6818\n","Epoch 14/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 1.1438e-06 - reconstruction_loss: 0.6818 - total_loss: 0.6818\n","Epoch 15/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 7.5152e-07 - reconstruction_loss: 0.6807 - total_loss: 0.6807\n","Epoch 16/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 9.8674e-07 - reconstruction_loss: 0.6818 - total_loss: 0.6818\n","Epoch 17/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 9.7014e-07 - reconstruction_loss: 0.6802 - total_loss: 0.6802\n","Epoch 18/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 1.0593e-06 - reconstruction_loss: 0.6838 - total_loss: 0.6838\n","Epoch 19/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 1.1480e-06 - reconstruction_loss: 0.6803 - total_loss: 0.6803\n","Epoch 20/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 1.4902e-06 - reconstruction_loss: 0.6796 - total_loss: 0.6796\n","Epoch 21/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 1.3991e-06 - reconstruction_loss: 0.6799 - total_loss: 0.6799\n","Epoch 22/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 2.1727e-06 - reconstruction_loss: 0.6802 - total_loss: 0.6802\n","Epoch 23/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 1.7659e-06 - reconstruction_loss: 0.6804 - total_loss: 0.6804\n","Epoch 24/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.6428e-06 - reconstruction_loss: 0.6805 - total_loss: 0.6805\n","Epoch 25/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 1.3364e-06 - reconstruction_loss: 0.6832 - total_loss: 0.6832\n","Epoch 26/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 1.1304e-06 - reconstruction_loss: 0.6800 - total_loss: 0.6800\n","Epoch 27/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 1.1385e-06 - reconstruction_loss: 0.6819 - total_loss: 0.6819\n","Epoch 28/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.0387e-06 - reconstruction_loss: 0.6823 - total_loss: 0.6823\n","Epoch 29/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 1.2789e-06 - reconstruction_loss: 0.6800 - total_loss: 0.6800\n","Epoch 30/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 1.2097e-06 - reconstruction_loss: 0.6816 - total_loss: 0.6816\n","Epoch 31/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 1.8284e-06 - reconstruction_loss: 0.6836 - total_loss: 0.6836\n","Epoch 32/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 2.8788e-06 - reconstruction_loss: 0.6814 - total_loss: 0.6814\n","Epoch 33/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 1.3090e-06 - reconstruction_loss: 0.6811 - total_loss: 0.6811\n","Epoch 34/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 1.1152e-06 - reconstruction_loss: 0.6810 - total_loss: 0.6810\n","Epoch 35/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.2682e-06 - reconstruction_loss: 0.6815 - total_loss: 0.6815\n","Epoch 36/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 1.0192e-06 - reconstruction_loss: 0.6818 - total_loss: 0.6818\n","Epoch 37/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 8.2269e-07 - reconstruction_loss: 0.6821 - total_loss: 0.6821\n","Epoch 38/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.1891e-06 - reconstruction_loss: 0.6783 - total_loss: 0.6783\n","Epoch 39/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 1.8628e-06 - reconstruction_loss: 0.6760 - total_loss: 0.6760\n","Epoch 40/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 2.7728e-06 - reconstruction_loss: 0.6811 - total_loss: 0.6811\n","Epoch 41/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 2.5859e-06 - reconstruction_loss: 0.6805 - total_loss: 0.6805\n","Epoch 42/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.6093e-06 - reconstruction_loss: 0.6793 - total_loss: 0.6793\n","Epoch 43/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.5927e-06 - reconstruction_loss: 0.6834 - total_loss: 0.6834\n","Epoch 44/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 1.7706e-06 - reconstruction_loss: 0.6835 - total_loss: 0.6835\n","Epoch 45/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 1.2477e-06 - reconstruction_loss: 0.6800 - total_loss: 0.6800\n","Epoch 46/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.2638e-06 - reconstruction_loss: 0.6818 - total_loss: 0.6818\n","Epoch 47/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.1566e-06 - reconstruction_loss: 0.6794 - total_loss: 0.6794\n","Epoch 48/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 9.4211e-07 - reconstruction_loss: 0.6819 - total_loss: 0.6819\n","Epoch 49/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 9.7574e-07 - reconstruction_loss: 0.6792 - total_loss: 0.6792\n","Epoch 50/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 9.2621e-07 - reconstruction_loss: 0.6773 - total_loss: 0.6773\n","Epoch 51/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 1.7588e-06 - reconstruction_loss: 0.6807 - total_loss: 0.6807\n","Epoch 52/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 1.4769e-06 - reconstruction_loss: 0.6815 - total_loss: 0.6815\n","Epoch 53/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.5565e-06 - reconstruction_loss: 0.6817 - total_loss: 0.6818\n","Epoch 54/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 1.2336e-06 - reconstruction_loss: 0.6806 - total_loss: 0.6806\n","Epoch 55/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.2898e-06 - reconstruction_loss: 0.6798 - total_loss: 0.6798\n","Epoch 56/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 1.3884e-06 - reconstruction_loss: 0.6804 - total_loss: 0.6804\n","Epoch 57/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 8.9144e-07 - reconstruction_loss: 0.6804 - total_loss: 0.6804\n","Epoch 58/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.2809e-06 - reconstruction_loss: 0.6809 - total_loss: 0.6809\n","Epoch 59/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 1.1133e-06 - reconstruction_loss: 0.6811 - total_loss: 0.6811\n","Epoch 60/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 1.0294e-06 - reconstruction_loss: 0.6808 - total_loss: 0.6808\n","Epoch 61/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.2389e-06 - reconstruction_loss: 0.6805 - total_loss: 0.6805\n","Epoch 62/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 9.2245e-07 - reconstruction_loss: 0.6801 - total_loss: 0.6801\n","Epoch 63/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 1.0724e-06 - reconstruction_loss: 0.6808 - total_loss: 0.6808\n","Epoch 64/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - kl_loss: 1.5499e-06 - reconstruction_loss: 0.6811 - total_loss: 0.6811\n","Epoch 65/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 1.1496e-06 - reconstruction_loss: 0.6816 - total_loss: 0.6816\n","Epoch 66/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 1.1855e-06 - reconstruction_loss: 0.6795 - total_loss: 0.6795\n","Epoch 67/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 9.4743e-07 - reconstruction_loss: 0.6784 - total_loss: 0.6784\n","Epoch 68/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 1.4461e-06 - reconstruction_loss: 0.6799 - total_loss: 0.6799\n","Epoch 69/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 1.6215e-06 - reconstruction_loss: 0.6811 - total_loss: 0.6811\n","Epoch 70/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 1.0855e-06 - reconstruction_loss: 0.6794 - total_loss: 0.6794\n","Epoch 71/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 9.6900e-07 - reconstruction_loss: 0.6827 - total_loss: 0.6827\n","Epoch 72/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 1.4466e-06 - reconstruction_loss: 0.6806 - total_loss: 0.6806\n","Epoch 73/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.6567e-06 - reconstruction_loss: 0.6811 - total_loss: 0.6811\n","Epoch 74/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 1.3010e-06 - reconstruction_loss: 0.6828 - total_loss: 0.6828\n","Epoch 75/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 1.1924e-06 - reconstruction_loss: 0.6830 - total_loss: 0.6830\n","Epoch 76/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.5755e-06 - reconstruction_loss: 0.6786 - total_loss: 0.6786\n","Epoch 77/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.1907e-06 - reconstruction_loss: 0.6805 - total_loss: 0.6805\n","Epoch 78/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.3638e-06 - reconstruction_loss: 0.6827 - total_loss: 0.6827\n","Epoch 79/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - kl_loss: 1.3462e-06 - reconstruction_loss: 0.6815 - total_loss: 0.6815\n","Epoch 80/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - kl_loss: 8.8350e-07 - reconstruction_loss: 0.6826 - total_loss: 0.6826\n","Epoch 81/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 1.1360e-06 - reconstruction_loss: 0.6795 - total_loss: 0.6795\n","Epoch 82/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 1.0693e-06 - reconstruction_loss: 0.6803 - total_loss: 0.6803\n","Epoch 83/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - kl_loss: 1.0888e-06 - reconstruction_loss: 0.6795 - total_loss: 0.6795\n","Epoch 84/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 1.0663e-06 - reconstruction_loss: 0.6794 - total_loss: 0.6794\n","Epoch 85/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - kl_loss: 9.4374e-07 - reconstruction_loss: 0.6826 - total_loss: 0.6826\n","Epoch 86/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 1.0342e-06 - reconstruction_loss: 0.6807 - total_loss: 0.6807\n","Epoch 87/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 9.6950e-07 - reconstruction_loss: 0.6798 - total_loss: 0.6798\n","Epoch 88/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 7.7890e-07 - reconstruction_loss: 0.6808 - total_loss: 0.6808\n","Epoch 89/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 1.1751e-06 - reconstruction_loss: 0.6816 - total_loss: 0.6816\n","Epoch 90/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - kl_loss: 7.9019e-07 - reconstruction_loss: 0.6801 - total_loss: 0.6801\n","Epoch 91/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 1.0070e-06 - reconstruction_loss: 0.6827 - total_loss: 0.6827\n","Epoch 92/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 1.2426e-06 - reconstruction_loss: 0.6825 - total_loss: 0.6825\n","Epoch 93/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.4715e-06 - reconstruction_loss: 0.6782 - total_loss: 0.6782\n","Epoch 94/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 1.3774e-06 - reconstruction_loss: 0.6796 - total_loss: 0.6796\n","Epoch 95/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - kl_loss: 1.4745e-06 - reconstruction_loss: 0.6792 - total_loss: 0.6792\n","Epoch 96/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 1.2152e-06 - reconstruction_loss: 0.6793 - total_loss: 0.6793\n","Epoch 97/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 1.0746e-06 - reconstruction_loss: 0.6807 - total_loss: 0.6807\n","Epoch 98/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 1.0161e-06 - reconstruction_loss: 0.6789 - total_loss: 0.6789\n","Epoch 99/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 8.9073e-07 - reconstruction_loss: 0.6797 - total_loss: 0.6797\n","Epoch 100/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 7.0319e-07 - reconstruction_loss: 0.6786 - total_loss: 0.6786\n","Found 48 images belonging to 1 classes.\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 899ms/step"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711568244.375363      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 756ms/step\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 448ms/step\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step\n","Training VAE for class: Train\n","Found 120 images belonging to 1 classes.\n","Epoch 1/100\n","\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 6s/step - kl_loss: 6.5565e-07 - reconstruction_loss: 0.6704 - total_loss: 0.6704"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711568253.988977      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5s/step - kl_loss: 1.8294e-05 - reconstruction_loss: 0.6728 - total_loss: 0.6728\n","Epoch 2/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.7204e-05 - reconstruction_loss: 0.6676 - total_loss: 0.6677\n","Epoch 3/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 1.3765e-05 - reconstruction_loss: 0.6673 - total_loss: 0.6673\n","Epoch 4/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - kl_loss: 4.4058e-06 - reconstruction_loss: 0.6641 - total_loss: 0.6641\n","Epoch 5/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - kl_loss: 3.1461e-06 - reconstruction_loss: 0.6652 - total_loss: 0.6652\n","Epoch 6/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - kl_loss: 3.2534e-06 - reconstruction_loss: 0.6670 - total_loss: 0.6670\n","Epoch 7/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.9928e-06 - reconstruction_loss: 0.6619 - total_loss: 0.6620\n","Epoch 8/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - kl_loss: 1.2616e-06 - reconstruction_loss: 0.6662 - total_loss: 0.6662\n","Epoch 9/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - kl_loss: 1.2954e-06 - reconstruction_loss: 0.6661 - total_loss: 0.6661\n","Epoch 10/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - kl_loss: 1.4345e-06 - reconstruction_loss: 0.6674 - total_loss: 0.6674\n","Epoch 11/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - kl_loss: 1.4404e-06 - reconstruction_loss: 0.6637 - total_loss: 0.6637\n","Epoch 12/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - kl_loss: 1.1265e-06 - reconstruction_loss: 0.6656 - total_loss: 0.6656\n","Epoch 13/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.0322e-06 - reconstruction_loss: 0.6592 - total_loss: 0.6592\n","Epoch 14/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - kl_loss: 7.8579e-07 - reconstruction_loss: 0.6638 - total_loss: 0.6638\n","Epoch 15/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - kl_loss: 1.0699e-06 - reconstruction_loss: 0.6632 - total_loss: 0.6632\n","Epoch 16/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - kl_loss: 1.0024e-06 - reconstruction_loss: 0.6611 - total_loss: 0.6611\n","Epoch 17/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - kl_loss: 1.1067e-06 - reconstruction_loss: 0.6634 - total_loss: 0.6634\n","Epoch 18/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - kl_loss: 1.0977e-06 - reconstruction_loss: 0.6655 - total_loss: 0.6655\n","Epoch 19/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - kl_loss: 9.8944e-07 - reconstruction_loss: 0.6618 - total_loss: 0.6618\n","Epoch 20/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - kl_loss: 1.0202e-06 - reconstruction_loss: 0.6643 - total_loss: 0.6643\n","Epoch 21/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 9.8745e-07 - reconstruction_loss: 0.6642 - total_loss: 0.6642\n","Epoch 22/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - kl_loss: 7.6195e-07 - reconstruction_loss: 0.6650 - total_loss: 0.6650\n","Epoch 23/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - kl_loss: 1.2904e-06 - reconstruction_loss: 0.6629 - total_loss: 0.6629\n","Epoch 24/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 8.3347e-07 - reconstruction_loss: 0.6586 - total_loss: 0.6586\n","Epoch 25/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - kl_loss: 9.7156e-07 - reconstruction_loss: 0.6638 - total_loss: 0.6638\n","Epoch 26/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.0928e-06 - reconstruction_loss: 0.6571 - total_loss: 0.6571\n","Epoch 27/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - kl_loss: 1.1663e-06 - reconstruction_loss: 0.6655 - total_loss: 0.6655\n","Epoch 28/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - kl_loss: 1.1663e-06 - reconstruction_loss: 0.6620 - total_loss: 0.6620\n","Epoch 29/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.0759e-06 - reconstruction_loss: 0.6628 - total_loss: 0.6628\n","Epoch 30/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - kl_loss: 1.4246e-06 - reconstruction_loss: 0.6599 - total_loss: 0.6599\n","Epoch 31/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - kl_loss: 1.9670e-06 - reconstruction_loss: 0.6628 - total_loss: 0.6628\n","Epoch 32/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - kl_loss: 1.8398e-06 - reconstruction_loss: 0.6631 - total_loss: 0.6631\n","Epoch 33/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - kl_loss: 1.7981e-06 - reconstruction_loss: 0.6589 - total_loss: 0.6589\n","Epoch 34/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - kl_loss: 1.5636e-06 - reconstruction_loss: 0.6672 - total_loss: 0.6672\n","Epoch 35/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - kl_loss: 1.4484e-06 - reconstruction_loss: 0.6636 - total_loss: 0.6636\n","Epoch 36/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - kl_loss: 1.6540e-06 - reconstruction_loss: 0.6607 - total_loss: 0.6607\n","Epoch 37/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - kl_loss: 1.2328e-06 - reconstruction_loss: 0.6611 - total_loss: 0.6611\n","Epoch 38/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - kl_loss: 1.3709e-06 - reconstruction_loss: 0.6625 - total_loss: 0.6625\n","Epoch 39/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - kl_loss: 1.0928e-06 - reconstruction_loss: 0.6587 - total_loss: 0.6587\n","Epoch 40/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - kl_loss: 1.0987e-06 - reconstruction_loss: 0.6591 - total_loss: 0.6591\n","Epoch 41/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - kl_loss: 7.6890e-07 - reconstruction_loss: 0.6629 - total_loss: 0.6629\n","Epoch 42/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - kl_loss: 1.0798e-06 - reconstruction_loss: 0.6631 - total_loss: 0.6631\n","Epoch 43/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 9.6361e-07 - reconstruction_loss: 0.6638 - total_loss: 0.6638\n","Epoch 44/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - kl_loss: 1.0868e-06 - reconstruction_loss: 0.6621 - total_loss: 0.6621\n","Epoch 45/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - kl_loss: 1.2606e-06 - reconstruction_loss: 0.6647 - total_loss: 0.6647\n","Epoch 46/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - kl_loss: 1.3550e-06 - reconstruction_loss: 0.6578 - total_loss: 0.6578\n","Epoch 47/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - kl_loss: 1.2795e-06 - reconstruction_loss: 0.6622 - total_loss: 0.6622\n","Epoch 48/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - kl_loss: 1.7295e-06 - reconstruction_loss: 0.6603 - total_loss: 0.6603\n","Epoch 49/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - kl_loss: 1.3322e-06 - reconstruction_loss: 0.6626 - total_loss: 0.6626\n","Epoch 50/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - kl_loss: 1.2885e-06 - reconstruction_loss: 0.6619 - total_loss: 0.6619\n","Epoch 51/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - kl_loss: 1.1861e-06 - reconstruction_loss: 0.6646 - total_loss: 0.6646\n","Epoch 52/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - kl_loss: 1.2050e-06 - reconstruction_loss: 0.6605 - total_loss: 0.6605\n","Epoch 53/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - kl_loss: 1.1683e-06 - reconstruction_loss: 0.6580 - total_loss: 0.6580\n","Epoch 54/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.2269e-06 - reconstruction_loss: 0.6594 - total_loss: 0.6594\n","Epoch 55/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - kl_loss: 1.3024e-06 - reconstruction_loss: 0.6624 - total_loss: 0.6624\n","Epoch 56/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - kl_loss: 1.9580e-06 - reconstruction_loss: 0.6641 - total_loss: 0.6641\n","Epoch 57/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - kl_loss: 1.3779e-06 - reconstruction_loss: 0.6632 - total_loss: 0.6632\n","Epoch 58/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.6282e-06 - reconstruction_loss: 0.6584 - total_loss: 0.6584\n","Epoch 59/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - kl_loss: 1.3918e-06 - reconstruction_loss: 0.6645 - total_loss: 0.6645\n","Epoch 60/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - kl_loss: 1.5050e-06 - reconstruction_loss: 0.6645 - total_loss: 0.6645\n","Epoch 61/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - kl_loss: 1.7156e-06 - reconstruction_loss: 0.6626 - total_loss: 0.6626\n","Epoch 62/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - kl_loss: 1.4216e-06 - reconstruction_loss: 0.6683 - total_loss: 0.6683\n","Epoch 63/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - kl_loss: 1.1494e-06 - reconstruction_loss: 0.6588 - total_loss: 0.6588\n","Epoch 64/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - kl_loss: 1.3957e-06 - reconstruction_loss: 0.6629 - total_loss: 0.6629\n","Epoch 65/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - kl_loss: 1.7405e-06 - reconstruction_loss: 0.6612 - total_loss: 0.6612\n","Epoch 66/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 2.3454e-06 - reconstruction_loss: 0.6627 - total_loss: 0.6627\n","Epoch 67/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 1.8080e-06 - reconstruction_loss: 0.6611 - total_loss: 0.6611\n","Epoch 68/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - kl_loss: 1.8527e-06 - reconstruction_loss: 0.6626 - total_loss: 0.6626\n","Epoch 69/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - kl_loss: 1.4285e-06 - reconstruction_loss: 0.6654 - total_loss: 0.6654\n","Epoch 70/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - kl_loss: 1.3004e-06 - reconstruction_loss: 0.6604 - total_loss: 0.6604\n","Epoch 71/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - kl_loss: 1.0103e-06 - reconstruction_loss: 0.6617 - total_loss: 0.6617\n","Epoch 72/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - kl_loss: 1.4365e-06 - reconstruction_loss: 0.6620 - total_loss: 0.6620\n","Epoch 73/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.9540e-06 - reconstruction_loss: 0.6590 - total_loss: 0.6591\n","Epoch 74/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - kl_loss: 2.2441e-06 - reconstruction_loss: 0.6589 - total_loss: 0.6589\n","Epoch 75/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - kl_loss: 1.9809e-06 - reconstruction_loss: 0.6595 - total_loss: 0.6595\n","Epoch 76/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - kl_loss: 2.0891e-06 - reconstruction_loss: 0.6643 - total_loss: 0.6643\n","Epoch 77/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - kl_loss: 1.9640e-06 - reconstruction_loss: 0.6668 - total_loss: 0.6668\n","Epoch 78/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - kl_loss: 2.2600e-06 - reconstruction_loss: 0.6608 - total_loss: 0.6608\n","Epoch 79/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - kl_loss: 1.5646e-06 - reconstruction_loss: 0.6613 - total_loss: 0.6613\n","Epoch 80/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - kl_loss: 1.4633e-06 - reconstruction_loss: 0.6603 - total_loss: 0.6603\n","Epoch 81/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - kl_loss: 1.1106e-06 - reconstruction_loss: 0.6650 - total_loss: 0.6650\n","Epoch 82/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - kl_loss: 1.2894e-06 - reconstruction_loss: 0.6645 - total_loss: 0.6645\n","Epoch 83/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - kl_loss: 1.2398e-06 - reconstruction_loss: 0.6616 - total_loss: 0.6616\n","Epoch 84/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 1.2964e-06 - reconstruction_loss: 0.6637 - total_loss: 0.6637\n","Epoch 85/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - kl_loss: 1.1077e-06 - reconstruction_loss: 0.6593 - total_loss: 0.6593\n","Epoch 86/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - kl_loss: 1.1772e-06 - reconstruction_loss: 0.6597 - total_loss: 0.6597\n","Epoch 87/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - kl_loss: 1.6858e-06 - reconstruction_loss: 0.6638 - total_loss: 0.6638\n","Epoch 88/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - kl_loss: 1.2964e-06 - reconstruction_loss: 0.6630 - total_loss: 0.6630\n","Epoch 89/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - kl_loss: 1.1990e-06 - reconstruction_loss: 0.6627 - total_loss: 0.6627\n","Epoch 90/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - kl_loss: 1.4236e-06 - reconstruction_loss: 0.6657 - total_loss: 0.6657\n","Epoch 91/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - kl_loss: 1.3481e-06 - reconstruction_loss: 0.6627 - total_loss: 0.6628\n","Epoch 92/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - kl_loss: 1.2974e-06 - reconstruction_loss: 0.6630 - total_loss: 0.6631\n","Epoch 93/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - kl_loss: 1.3133e-06 - reconstruction_loss: 0.6642 - total_loss: 0.6642\n","Epoch 94/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.4335e-06 - reconstruction_loss: 0.6652 - total_loss: 0.6653\n","Epoch 95/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - kl_loss: 1.4265e-06 - reconstruction_loss: 0.6645 - total_loss: 0.6645\n","Epoch 96/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - kl_loss: 1.0957e-06 - reconstruction_loss: 0.6653 - total_loss: 0.6653\n","Epoch 97/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - kl_loss: 1.3332e-06 - reconstruction_loss: 0.6596 - total_loss: 0.6596\n","Epoch 98/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - kl_loss: 1.4683e-06 - reconstruction_loss: 0.6596 - total_loss: 0.6596\n","Epoch 99/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - kl_loss: 1.6193e-06 - reconstruction_loss: 0.6601 - total_loss: 0.6601\n","Epoch 100/100\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - kl_loss: 1.6123e-06 - reconstruction_loss: 0.6586 - total_loss: 0.6586\n","Found 31 images belonging to 1 classes.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566ms/step\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","Training VAE for class: Bottle\n","Found 194 images belonging to 1 classes.\n","Epoch 1/100\n","\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m43s\u001b[0m 7s/step - kl_loss: 1.6093e-06 - reconstruction_loss: 0.7034 - total_loss: 0.7034"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711568368.406425      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 843ms/step - kl_loss: 2.0395e-05 - reconstruction_loss: 0.6964 - total_loss: 0.6964\n","Epoch 2/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 7.1496e-06 - reconstruction_loss: 0.6755 - total_loss: 0.6755 \n","Epoch 3/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 5.4147e-06 - reconstruction_loss: 0.6655 - total_loss: 0.6655\n","Epoch 4/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 2.5206e-06 - reconstruction_loss: 0.6679 - total_loss: 0.6679\n","Epoch 5/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 1.1729e-06 - reconstruction_loss: 0.6667 - total_loss: 0.6667\n","Epoch 6/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.0009e-06 - reconstruction_loss: 0.6614 - total_loss: 0.6614\n","Epoch 7/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 9.1269e-07 - reconstruction_loss: 0.6596 - total_loss: 0.6596\n","Epoch 8/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 1.0745e-06 - reconstruction_loss: 0.6698 - total_loss: 0.6698\n","Epoch 9/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 1.0080e-06 - reconstruction_loss: 0.6601 - total_loss: 0.6601\n","Epoch 10/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 8.8296e-07 - reconstruction_loss: 0.6642 - total_loss: 0.6642\n","Epoch 11/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 7.7798e-07 - reconstruction_loss: 0.6614 - total_loss: 0.6614\n","Epoch 12/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 1.1828e-06 - reconstruction_loss: 0.6548 - total_loss: 0.6548\n","Epoch 13/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 1.2873e-06 - reconstruction_loss: 0.6609 - total_loss: 0.6609\n","Epoch 14/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 1.7024e-06 - reconstruction_loss: 0.6371 - total_loss: 0.6371\n","Epoch 15/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 2.1234e-06 - reconstruction_loss: 0.6515 - total_loss: 0.6515\n","Epoch 16/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 4.0961e-06 - reconstruction_loss: 0.6577 - total_loss: 0.6577\n","Epoch 17/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 2.6479e-06 - reconstruction_loss: 0.6623 - total_loss: 0.6623\n","Epoch 18/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.8259e-06 - reconstruction_loss: 0.6554 - total_loss: 0.6554\n","Epoch 19/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.5129e-06 - reconstruction_loss: 0.6611 - total_loss: 0.6611\n","Epoch 20/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 2.0696e-06 - reconstruction_loss: 0.6681 - total_loss: 0.6681\n","Epoch 21/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.3749e-06 - reconstruction_loss: 0.6674 - total_loss: 0.6674\n","Epoch 22/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.5696e-06 - reconstruction_loss: 0.6614 - total_loss: 0.6614\n","Epoch 23/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 1.3560e-06 - reconstruction_loss: 0.6650 - total_loss: 0.6650\n","Epoch 24/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 2.2608e-06 - reconstruction_loss: 0.6543 - total_loss: 0.6543\n","Epoch 25/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.8308e-06 - reconstruction_loss: 0.6614 - total_loss: 0.6614\n","Epoch 26/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - kl_loss: 1.4013e-06 - reconstruction_loss: 0.6679 - total_loss: 0.6679\n","Epoch 27/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 1.4449e-06 - reconstruction_loss: 0.6643 - total_loss: 0.6643\n","Epoch 28/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.7585e-06 - reconstruction_loss: 0.6723 - total_loss: 0.6723\n","Epoch 29/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.5233e-06 - reconstruction_loss: 0.6674 - total_loss: 0.6674\n","Epoch 30/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 9.5422e-07 - reconstruction_loss: 0.6741 - total_loss: 0.6741\n","Epoch 31/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 9.9780e-07 - reconstruction_loss: 0.6579 - total_loss: 0.6579\n","Epoch 32/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.0408e-06 - reconstruction_loss: 0.6659 - total_loss: 0.6659\n","Epoch 33/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 9.1622e-06 - reconstruction_loss: 0.6633 - total_loss: 0.6633\n","Epoch 34/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 3.6614e-06 - reconstruction_loss: 0.6628 - total_loss: 0.6628\n","Epoch 35/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 2.5449e-06 - reconstruction_loss: 0.6522 - total_loss: 0.6522\n","Epoch 36/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.3303e-06 - reconstruction_loss: 0.6664 - total_loss: 0.6664\n","Epoch 37/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.2651e-06 - reconstruction_loss: 0.6636 - total_loss: 0.6636\n","Epoch 38/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 8.6709e-07 - reconstruction_loss: 0.6663 - total_loss: 0.6663\n","Epoch 39/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.3998e-06 - reconstruction_loss: 0.6575 - total_loss: 0.6575\n","Epoch 40/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.4138e-06 - reconstruction_loss: 0.6535 - total_loss: 0.6535\n","Epoch 41/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 9.8765e-07 - reconstruction_loss: 0.6634 - total_loss: 0.6634\n","Epoch 42/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.4053e-06 - reconstruction_loss: 0.6521 - total_loss: 0.6521\n","Epoch 43/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.4830e-06 - reconstruction_loss: 0.6764 - total_loss: 0.6764\n","Epoch 44/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.5580e-06 - reconstruction_loss: 0.6655 - total_loss: 0.6655\n","Epoch 45/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.6340e-06 - reconstruction_loss: 0.6779 - total_loss: 0.6779\n","Epoch 46/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 1.3040e-06 - reconstruction_loss: 0.6638 - total_loss: 0.6638\n","Epoch 47/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.0376e-06 - reconstruction_loss: 0.6606 - total_loss: 0.6606\n","Epoch 48/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 9.6968e-07 - reconstruction_loss: 0.6691 - total_loss: 0.6691\n","Epoch 49/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 1.0537e-06 - reconstruction_loss: 0.6607 - total_loss: 0.6607\n","Epoch 50/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.3555e-06 - reconstruction_loss: 0.6654 - total_loss: 0.6654\n","Epoch 51/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.7420e-06 - reconstruction_loss: 0.6691 - total_loss: 0.6691\n","Epoch 52/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 1.5589e-06 - reconstruction_loss: 0.6686 - total_loss: 0.6686\n","Epoch 53/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 2.2926e-06 - reconstruction_loss: 0.6549 - total_loss: 0.6549\n","Epoch 54/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 2.0690e-06 - reconstruction_loss: 0.6560 - total_loss: 0.6560\n","Epoch 55/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 2.5275e-06 - reconstruction_loss: 0.6578 - total_loss: 0.6578\n","Epoch 56/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 6.8828e-06 - reconstruction_loss: 0.6737 - total_loss: 0.6737\n","Epoch 57/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 7.3928e-06 - reconstruction_loss: 0.6645 - total_loss: 0.6645\n","Epoch 58/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - kl_loss: 3.7700e-06 - reconstruction_loss: 0.6627 - total_loss: 0.6627\n","Epoch 59/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 3.5259e-06 - reconstruction_loss: 0.6418 - total_loss: 0.6418\n","Epoch 60/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 2.1901e-06 - reconstruction_loss: 0.6577 - total_loss: 0.6577\n","Epoch 61/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - kl_loss: 1.8910e-06 - reconstruction_loss: 0.6581 - total_loss: 0.6581\n","Epoch 62/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.9005e-06 - reconstruction_loss: 0.6626 - total_loss: 0.6626\n","Epoch 63/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 1.5742e-06 - reconstruction_loss: 0.6660 - total_loss: 0.6660\n","Epoch 64/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 1.8745e-06 - reconstruction_loss: 0.6576 - total_loss: 0.6576\n","Epoch 65/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 2.9531e-06 - reconstruction_loss: 0.6696 - total_loss: 0.6696\n","Epoch 66/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 2.8187e-06 - reconstruction_loss: 0.6727 - total_loss: 0.6727\n","Epoch 67/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 2.4103e-06 - reconstruction_loss: 0.6636 - total_loss: 0.6636 \n","Epoch 68/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 1.8638e-06 - reconstruction_loss: 0.6629 - total_loss: 0.6629\n","Epoch 69/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 1.4073e-06 - reconstruction_loss: 0.6610 - total_loss: 0.6610\n","Epoch 70/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 1.1002e-06 - reconstruction_loss: 0.6679 - total_loss: 0.6679\n","Epoch 71/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.1594e-06 - reconstruction_loss: 0.6596 - total_loss: 0.6596\n","Epoch 72/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.0400e-06 - reconstruction_loss: 0.6607 - total_loss: 0.6607\n","Epoch 73/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.6377e-06 - reconstruction_loss: 0.6637 - total_loss: 0.6637\n","Epoch 74/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.4604e-06 - reconstruction_loss: 0.6561 - total_loss: 0.6561\n","Epoch 75/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.7148e-06 - reconstruction_loss: 0.6566 - total_loss: 0.6566\n","Epoch 76/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 1.4661e-06 - reconstruction_loss: 0.6551 - total_loss: 0.6551\n","Epoch 77/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 1.7778e-06 - reconstruction_loss: 0.6572 - total_loss: 0.6572\n","Epoch 78/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.4044e-06 - reconstruction_loss: 0.6586 - total_loss: 0.6586\n","Epoch 79/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.5775e-06 - reconstruction_loss: 0.6605 - total_loss: 0.6605\n","Epoch 80/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 1.8133e-06 - reconstruction_loss: 0.6574 - total_loss: 0.6574\n","Epoch 81/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 3.0722e-06 - reconstruction_loss: 0.6617 - total_loss: 0.6617\n","Epoch 82/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 4.8459e-06 - reconstruction_loss: 0.6529 - total_loss: 0.6529\n","Epoch 83/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 4.0874e-06 - reconstruction_loss: 0.6500 - total_loss: 0.6500\n","Epoch 84/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 6.1518e-06 - reconstruction_loss: 0.6680 - total_loss: 0.6680\n","Epoch 85/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - kl_loss: 3.3168e-06 - reconstruction_loss: 0.6604 - total_loss: 0.6604\n","Epoch 86/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 2.9977e-06 - reconstruction_loss: 0.6658 - total_loss: 0.6658\n","Epoch 87/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 2.7141e-06 - reconstruction_loss: 0.6586 - total_loss: 0.6586\n","Epoch 88/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 2.3889e-06 - reconstruction_loss: 0.6601 - total_loss: 0.6601\n","Epoch 89/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 1.5959e-06 - reconstruction_loss: 0.6641 - total_loss: 0.6641\n","Epoch 90/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.1270e-06 - reconstruction_loss: 0.6568 - total_loss: 0.6568\n","Epoch 91/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.0632e-06 - reconstruction_loss: 0.6616 - total_loss: 0.6616 \n","Epoch 92/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 1.6225e-06 - reconstruction_loss: 0.6667 - total_loss: 0.6667\n","Epoch 93/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.0569e-06 - reconstruction_loss: 0.6740 - total_loss: 0.6740\n","Epoch 94/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.5960e-06 - reconstruction_loss: 0.6769 - total_loss: 0.6769\n","Epoch 95/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 2.0835e-06 - reconstruction_loss: 0.6589 - total_loss: 0.6589\n","Epoch 96/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 2.8304e-06 - reconstruction_loss: 0.6746 - total_loss: 0.6746\n","Epoch 97/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 2.3662e-06 - reconstruction_loss: 0.6643 - total_loss: 0.6643\n","Epoch 98/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 2.1122e-06 - reconstruction_loss: 0.6618 - total_loss: 0.6618\n","Epoch 99/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 2.6463e-06 - reconstruction_loss: 0.6597 - total_loss: 0.6597 \n","Epoch 100/100\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 6.4205e-06 - reconstruction_loss: 0.6513 - total_loss: 0.6513\n","Found 49 images belonging to 1 classes.\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1s/step"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711568502.250808      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 781ms/step\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step\n","Training VAE for class: Boat\n","Found 165 images belonging to 1 classes.\n","Epoch 1/100\n","\u001b[1m2/6\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 3s/step - kl_loss: 1.5788e-05 - reconstruction_loss: 0.6871 - total_loss: 0.6871 "]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711568519.787999      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 708ms/step - kl_loss: 2.0221e-05 - reconstruction_loss: 0.7101 - total_loss: 0.7101\n","Epoch 2/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.4929e-05 - reconstruction_loss: 0.7143 - total_loss: 0.7143\n","Epoch 3/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 4.8036e-06 - reconstruction_loss: 0.6996 - total_loss: 0.6997\n","Epoch 4/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 3.6620e-06 - reconstruction_loss: 0.6995 - total_loss: 0.6995\n","Epoch 5/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 2.1092e-06 - reconstruction_loss: 0.6901 - total_loss: 0.6901\n","Epoch 6/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.4740e-06 - reconstruction_loss: 0.6857 - total_loss: 0.6857\n","Epoch 7/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 2.2133e-06 - reconstruction_loss: 0.6826 - total_loss: 0.6826\n","Epoch 8/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 2.4740e-06 - reconstruction_loss: 0.6833 - total_loss: 0.6833\n","Epoch 9/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 2.9707e-06 - reconstruction_loss: 0.6789 - total_loss: 0.6789\n","Epoch 10/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.7204e-06 - reconstruction_loss: 0.6770 - total_loss: 0.6770\n","Epoch 11/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.3371e-06 - reconstruction_loss: 0.6761 - total_loss: 0.6761\n","Epoch 12/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.4785e-06 - reconstruction_loss: 0.6825 - total_loss: 0.6825\n","Epoch 13/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 2.0468e-06 - reconstruction_loss: 0.6807 - total_loss: 0.6807\n","Epoch 14/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.4997e-06 - reconstruction_loss: 0.6808 - total_loss: 0.6808\n","Epoch 15/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 1.9179e-06 - reconstruction_loss: 0.6803 - total_loss: 0.6803\n","Epoch 16/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.9518e-06 - reconstruction_loss: 0.6837 - total_loss: 0.6837\n","Epoch 17/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 1.5033e-06 - reconstruction_loss: 0.6822 - total_loss: 0.6822\n","Epoch 18/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 1.3112e-06 - reconstruction_loss: 0.6785 - total_loss: 0.6785\n","Epoch 19/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 1.3805e-06 - reconstruction_loss: 0.6810 - total_loss: 0.6810\n","Epoch 20/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.8057e-06 - reconstruction_loss: 0.6799 - total_loss: 0.6799\n","Epoch 21/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.9154e-06 - reconstruction_loss: 0.6779 - total_loss: 0.6779\n","Epoch 22/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 2.0412e-06 - reconstruction_loss: 0.6801 - total_loss: 0.6801\n","Epoch 23/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 2.0148e-06 - reconstruction_loss: 0.6799 - total_loss: 0.6799\n","Epoch 24/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.9399e-06 - reconstruction_loss: 0.6788 - total_loss: 0.6789\n","Epoch 25/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 1.8025e-06 - reconstruction_loss: 0.6784 - total_loss: 0.6784 \n","Epoch 26/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 2.2311e-06 - reconstruction_loss: 0.6822 - total_loss: 0.6822\n","Epoch 27/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.7065e-06 - reconstruction_loss: 0.6805 - total_loss: 0.6805\n","Epoch 28/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.6173e-06 - reconstruction_loss: 0.6808 - total_loss: 0.6808\n","Epoch 29/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 2.0635e-06 - reconstruction_loss: 0.6798 - total_loss: 0.6798\n","Epoch 30/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 2.0712e-06 - reconstruction_loss: 0.6772 - total_loss: 0.6772\n","Epoch 31/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.8000e-06 - reconstruction_loss: 0.6785 - total_loss: 0.6785\n","Epoch 32/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.3477e-06 - reconstruction_loss: 0.6762 - total_loss: 0.6762\n","Epoch 33/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.3986e-06 - reconstruction_loss: 0.6820 - total_loss: 0.6820\n","Epoch 34/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.6118e-06 - reconstruction_loss: 0.6747 - total_loss: 0.6747\n","Epoch 35/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.4299e-06 - reconstruction_loss: 0.6783 - total_loss: 0.6783\n","Epoch 36/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.7950e-06 - reconstruction_loss: 0.6797 - total_loss: 0.6797 \n","Epoch 37/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 1.4715e-06 - reconstruction_loss: 0.6817 - total_loss: 0.6817 \n","Epoch 38/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.2823e-06 - reconstruction_loss: 0.6800 - total_loss: 0.6800\n","Epoch 39/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 2.7893e-06 - reconstruction_loss: 0.6797 - total_loss: 0.6797\n","Epoch 40/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 2.5970e-06 - reconstruction_loss: 0.6741 - total_loss: 0.6741\n","Epoch 41/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 2.7948e-06 - reconstruction_loss: 0.6806 - total_loss: 0.6806\n","Epoch 42/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 2.7370e-06 - reconstruction_loss: 0.6811 - total_loss: 0.6811\n","Epoch 43/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.4619e-06 - reconstruction_loss: 0.6774 - total_loss: 0.6774\n","Epoch 44/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.3999e-06 - reconstruction_loss: 0.6810 - total_loss: 0.6810\n","Epoch 45/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 1.7632e-06 - reconstruction_loss: 0.6776 - total_loss: 0.6776\n","Epoch 46/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 2.3421e-06 - reconstruction_loss: 0.6775 - total_loss: 0.6775\n","Epoch 47/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 3.0007e-06 - reconstruction_loss: 0.6812 - total_loss: 0.6812\n","Epoch 48/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 2.5323e-06 - reconstruction_loss: 0.6740 - total_loss: 0.6740\n","Epoch 49/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 2.8053e-06 - reconstruction_loss: 0.6775 - total_loss: 0.6775\n","Epoch 50/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 3.9949e-06 - reconstruction_loss: 0.6886 - total_loss: 0.6886\n","Epoch 51/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 3.4859e-06 - reconstruction_loss: 0.6784 - total_loss: 0.6784\n","Epoch 52/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 2.3253e-06 - reconstruction_loss: 0.6803 - total_loss: 0.6803 \n","Epoch 53/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 3.8745e-06 - reconstruction_loss: 0.6798 - total_loss: 0.6798\n","Epoch 54/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 2.1976e-06 - reconstruction_loss: 0.6806 - total_loss: 0.6806\n","Epoch 55/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.9310e-06 - reconstruction_loss: 0.6814 - total_loss: 0.6814\n","Epoch 56/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - kl_loss: 2.0988e-06 - reconstruction_loss: 0.6784 - total_loss: 0.6784 \n","Epoch 57/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 3.3992e-06 - reconstruction_loss: 0.6820 - total_loss: 0.6820\n","Epoch 58/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 3.2025e-06 - reconstruction_loss: 0.6842 - total_loss: 0.6842\n","Epoch 59/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 3.3701e-06 - reconstruction_loss: 0.6805 - total_loss: 0.6805\n","Epoch 60/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 2.4006e-06 - reconstruction_loss: 0.6800 - total_loss: 0.6800\n","Epoch 61/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 2.3309e-06 - reconstruction_loss: 0.6804 - total_loss: 0.6804 \n","Epoch 62/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 2.8842e-06 - reconstruction_loss: 0.6788 - total_loss: 0.6788\n","Epoch 63/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 2.5380e-06 - reconstruction_loss: 0.6808 - total_loss: 0.6808\n","Epoch 64/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 4.9137e-06 - reconstruction_loss: 0.6760 - total_loss: 0.6760\n","Epoch 65/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 3.5832e-06 - reconstruction_loss: 0.6906 - total_loss: 0.6906\n","Epoch 66/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 2.3507e-06 - reconstruction_loss: 0.6813 - total_loss: 0.6813\n","Epoch 67/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 2.3766e-06 - reconstruction_loss: 0.6819 - total_loss: 0.6819\n","Epoch 68/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.8425e-06 - reconstruction_loss: 0.6769 - total_loss: 0.6769\n","Epoch 69/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.7590e-06 - reconstruction_loss: 0.6822 - total_loss: 0.6822\n","Epoch 70/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.7654e-06 - reconstruction_loss: 0.6796 - total_loss: 0.6796 \n","Epoch 71/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 3.2186e-06 - reconstruction_loss: 0.6784 - total_loss: 0.6784\n","Epoch 72/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 2.1287e-06 - reconstruction_loss: 0.6806 - total_loss: 0.6806\n","Epoch 73/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.9119e-06 - reconstruction_loss: 0.6834 - total_loss: 0.6835\n","Epoch 74/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.7993e-06 - reconstruction_loss: 0.6819 - total_loss: 0.6819\n","Epoch 75/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.8802e-06 - reconstruction_loss: 0.6808 - total_loss: 0.6808\n","Epoch 76/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 3.2472e-06 - reconstruction_loss: 0.6764 - total_loss: 0.6764\n","Epoch 77/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 3.8937e-06 - reconstruction_loss: 0.6815 - total_loss: 0.6815\n","Epoch 78/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 2.3327e-06 - reconstruction_loss: 0.6772 - total_loss: 0.6772 \n","Epoch 79/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.9127e-06 - reconstruction_loss: 0.6797 - total_loss: 0.6797 \n","Epoch 80/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 2.1440e-06 - reconstruction_loss: 0.6825 - total_loss: 0.6825\n","Epoch 81/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.7114e-06 - reconstruction_loss: 0.6782 - total_loss: 0.6782\n","Epoch 82/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.6502e-06 - reconstruction_loss: 0.6789 - total_loss: 0.6789\n","Epoch 83/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 2.1430e-06 - reconstruction_loss: 0.6756 - total_loss: 0.6756\n","Epoch 84/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.9376e-06 - reconstruction_loss: 0.6790 - total_loss: 0.6790\n","Epoch 85/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.9733e-06 - reconstruction_loss: 0.6751 - total_loss: 0.6751\n","Epoch 86/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - kl_loss: 1.6874e-06 - reconstruction_loss: 0.6737 - total_loss: 0.6737\n","Epoch 87/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 3.2724e-06 - reconstruction_loss: 0.6789 - total_loss: 0.6789\n","Epoch 88/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - kl_loss: 2.4742e-06 - reconstruction_loss: 0.6840 - total_loss: 0.6840\n","Epoch 89/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 2.0963e-06 - reconstruction_loss: 0.6857 - total_loss: 0.6857\n","Epoch 90/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 2.6424e-06 - reconstruction_loss: 0.6809 - total_loss: 0.6809\n","Epoch 91/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.8662e-06 - reconstruction_loss: 0.6791 - total_loss: 0.6791\n","Epoch 92/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.7812e-06 - reconstruction_loss: 0.6762 - total_loss: 0.6762\n","Epoch 93/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.6428e-06 - reconstruction_loss: 0.6830 - total_loss: 0.6830\n","Epoch 94/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 1.5194e-06 - reconstruction_loss: 0.6775 - total_loss: 0.6775 \n","Epoch 95/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - kl_loss: 3.1197e-06 - reconstruction_loss: 0.6816 - total_loss: 0.6816 \n","Epoch 96/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 2.8919e-06 - reconstruction_loss: 0.6766 - total_loss: 0.6766\n","Epoch 97/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 2.6486e-06 - reconstruction_loss: 0.6795 - total_loss: 0.6795\n","Epoch 98/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - kl_loss: 2.2010e-06 - reconstruction_loss: 0.6777 - total_loss: 0.6777\n","Epoch 99/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.8963e-06 - reconstruction_loss: 0.6798 - total_loss: 0.6798\n","Epoch 100/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - kl_loss: 1.8939e-06 - reconstruction_loss: 0.6784 - total_loss: 0.6784\n","Found 42 images belonging to 1 classes.\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 820ms/step"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711568631.345564      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3s/step  \n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 403ms/step\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","Training VAE for class: Car\n","Found 372 images belonging to 1 classes.\n","Epoch 1/100\n","\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:13\u001b[0m 7s/step - kl_loss: 2.2352e-06 - reconstruction_loss: 0.6939 - total_loss: 0.6939"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711568643.124080      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 378ms/step - kl_loss: 1.8257e-05 - reconstruction_loss: 0.6878 - total_loss: 0.6878\n","Epoch 2/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 4.2033e-06 - reconstruction_loss: 0.6809 - total_loss: 0.6809\n","Epoch 3/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 1.3537e-06 - reconstruction_loss: 0.6820 - total_loss: 0.6820\n","Epoch 4/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 7.0579e-07 - reconstruction_loss: 0.6831 - total_loss: 0.6831\n","Epoch 5/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - kl_loss: 7.7908e-07 - reconstruction_loss: 0.6813 - total_loss: 0.6813\n","Epoch 6/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 7.6797e-07 - reconstruction_loss: 0.6805 - total_loss: 0.6805\n","Epoch 7/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - kl_loss: 6.1150e-07 - reconstruction_loss: 0.6830 - total_loss: 0.6830\n","Epoch 8/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - kl_loss: 6.7491e-07 - reconstruction_loss: 0.6834 - total_loss: 0.6834\n","Epoch 9/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - kl_loss: 6.4100e-07 - reconstruction_loss: 0.6813 - total_loss: 0.6813\n","Epoch 10/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - kl_loss: 6.7493e-07 - reconstruction_loss: 0.6827 - total_loss: 0.6827\n","Epoch 11/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - kl_loss: 4.9902e-07 - reconstruction_loss: 0.6833 - total_loss: 0.6833\n","Epoch 12/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - kl_loss: 8.3625e-07 - reconstruction_loss: 0.6820 - total_loss: 0.6820\n","Epoch 13/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - kl_loss: 8.0917e-07 - reconstruction_loss: 0.6822 - total_loss: 0.6822\n","Epoch 14/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - kl_loss: 7.9691e-07 - reconstruction_loss: 0.6810 - total_loss: 0.6810\n","Epoch 15/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - kl_loss: 4.9440e-07 - reconstruction_loss: 0.6836 - total_loss: 0.6836\n","Epoch 16/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - kl_loss: 6.5409e-07 - reconstruction_loss: 0.6799 - total_loss: 0.6799\n","Epoch 17/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - kl_loss: 7.6708e-07 - reconstruction_loss: 0.6844 - total_loss: 0.6844\n","Epoch 18/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - kl_loss: 6.6441e-07 - reconstruction_loss: 0.6810 - total_loss: 0.6810\n","Epoch 19/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - kl_loss: 7.6927e-07 - reconstruction_loss: 0.6817 - total_loss: 0.6817\n","Epoch 20/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - kl_loss: 7.2456e-07 - reconstruction_loss: 0.6821 - total_loss: 0.6821\n","Epoch 21/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - kl_loss: 7.9546e-07 - reconstruction_loss: 0.6833 - total_loss: 0.6833\n","Epoch 22/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - kl_loss: 7.6048e-07 - reconstruction_loss: 0.6848 - total_loss: 0.6848\n","Epoch 23/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - kl_loss: 7.7024e-07 - reconstruction_loss: 0.6816 - total_loss: 0.6816\n","Epoch 24/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - kl_loss: 5.9807e-07 - reconstruction_loss: 0.6821 - total_loss: 0.6821\n","Epoch 25/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - kl_loss: 8.3690e-07 - reconstruction_loss: 0.6842 - total_loss: 0.6842\n","Epoch 26/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 6.9774e-07 - reconstruction_loss: 0.6831 - total_loss: 0.6831\n","Epoch 27/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - kl_loss: 1.1127e-06 - reconstruction_loss: 0.6832 - total_loss: 0.6832\n","Epoch 28/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 8.7444e-07 - reconstruction_loss: 0.6816 - total_loss: 0.6816\n","Epoch 29/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - kl_loss: 1.1228e-06 - reconstruction_loss: 0.6816 - total_loss: 0.6816\n","Epoch 30/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 6.4807e-07 - reconstruction_loss: 0.6827 - total_loss: 0.6827\n","Epoch 31/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - kl_loss: 8.7377e-07 - reconstruction_loss: 0.6811 - total_loss: 0.6811\n","Epoch 32/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 7.1633e-07 - reconstruction_loss: 0.6818 - total_loss: 0.6818\n","Epoch 33/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - kl_loss: 8.7984e-07 - reconstruction_loss: 0.6832 - total_loss: 0.6832\n","Epoch 34/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - kl_loss: 8.8339e-07 - reconstruction_loss: 0.6840 - total_loss: 0.6840\n","Epoch 35/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 7.7410e-07 - reconstruction_loss: 0.6824 - total_loss: 0.6824\n","Epoch 36/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 6.2486e-07 - reconstruction_loss: 0.6822 - total_loss: 0.6822\n","Epoch 37/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - kl_loss: 6.8801e-07 - reconstruction_loss: 0.6795 - total_loss: 0.6795\n","Epoch 38/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 1.1173e-06 - reconstruction_loss: 0.6837 - total_loss: 0.6837\n","Epoch 39/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - kl_loss: 9.0768e-07 - reconstruction_loss: 0.6823 - total_loss: 0.6823\n","Epoch 40/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 7.1525e-07 - reconstruction_loss: 0.6815 - total_loss: 0.6815\n","Epoch 41/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - kl_loss: 1.0319e-06 - reconstruction_loss: 0.6803 - total_loss: 0.6803\n","Epoch 42/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 9.9110e-07 - reconstruction_loss: 0.6811 - total_loss: 0.6811\n","Epoch 43/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - kl_loss: 9.2613e-07 - reconstruction_loss: 0.6817 - total_loss: 0.6817\n","Epoch 44/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 8.9185e-07 - reconstruction_loss: 0.6822 - total_loss: 0.6822\n","Epoch 45/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 9.2591e-07 - reconstruction_loss: 0.6817 - total_loss: 0.6817\n","Epoch 46/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - kl_loss: 8.0374e-07 - reconstruction_loss: 0.6815 - total_loss: 0.6815\n","Epoch 47/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - kl_loss: 7.8786e-07 - reconstruction_loss: 0.6833 - total_loss: 0.6833\n","Epoch 48/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - kl_loss: 8.2555e-07 - reconstruction_loss: 0.6810 - total_loss: 0.6810\n","Epoch 49/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - kl_loss: 7.8811e-07 - reconstruction_loss: 0.6825 - total_loss: 0.6825\n","Epoch 50/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - kl_loss: 9.5518e-07 - reconstruction_loss: 0.6832 - total_loss: 0.6832\n","Epoch 51/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - kl_loss: 9.5363e-07 - reconstruction_loss: 0.6830 - total_loss: 0.6830\n","Epoch 52/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - kl_loss: 1.0060e-06 - reconstruction_loss: 0.6829 - total_loss: 0.6829\n","Epoch 53/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 7.6776e-07 - reconstruction_loss: 0.6830 - total_loss: 0.6830\n","Epoch 54/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - kl_loss: 9.0097e-07 - reconstruction_loss: 0.6794 - total_loss: 0.6794\n","Epoch 55/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 1.8409e-06 - reconstruction_loss: 0.6819 - total_loss: 0.6819\n","Epoch 56/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - kl_loss: 1.3166e-06 - reconstruction_loss: 0.6827 - total_loss: 0.6827\n","Epoch 57/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 1.1477e-06 - reconstruction_loss: 0.6823 - total_loss: 0.6823\n","Epoch 58/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - kl_loss: 1.4477e-06 - reconstruction_loss: 0.6830 - total_loss: 0.6830\n","Epoch 59/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - kl_loss: 1.0121e-06 - reconstruction_loss: 0.6808 - total_loss: 0.6808\n","Epoch 60/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 1.1897e-06 - reconstruction_loss: 0.6807 - total_loss: 0.6807\n","Epoch 61/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - kl_loss: 1.3860e-06 - reconstruction_loss: 0.6857 - total_loss: 0.6857\n","Epoch 62/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - kl_loss: 9.5844e-07 - reconstruction_loss: 0.6820 - total_loss: 0.6820\n","Epoch 63/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 1.1249e-06 - reconstruction_loss: 0.6834 - total_loss: 0.6834\n","Epoch 64/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - kl_loss: 9.1052e-07 - reconstruction_loss: 0.6818 - total_loss: 0.6818\n","Epoch 65/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 1.0441e-06 - reconstruction_loss: 0.6819 - total_loss: 0.6819\n","Epoch 66/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - kl_loss: 1.1995e-06 - reconstruction_loss: 0.6823 - total_loss: 0.6823\n","Epoch 67/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 8.7594e-07 - reconstruction_loss: 0.6819 - total_loss: 0.6819\n","Epoch 68/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 7.7801e-07 - reconstruction_loss: 0.6821 - total_loss: 0.6821\n","Epoch 69/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 7.2686e-07 - reconstruction_loss: 0.6821 - total_loss: 0.6821\n","Epoch 70/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 6.8011e-07 - reconstruction_loss: 0.6816 - total_loss: 0.6816\n","Epoch 71/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 9.1583e-07 - reconstruction_loss: 0.6805 - total_loss: 0.6805\n","Epoch 72/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - kl_loss: 7.5572e-07 - reconstruction_loss: 0.6819 - total_loss: 0.6819\n","Epoch 73/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 9.3548e-07 - reconstruction_loss: 0.6812 - total_loss: 0.6812\n","Epoch 74/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 8.8775e-07 - reconstruction_loss: 0.6812 - total_loss: 0.6812\n","Epoch 75/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - kl_loss: 8.9765e-07 - reconstruction_loss: 0.6820 - total_loss: 0.6820\n","Epoch 76/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - kl_loss: 9.8139e-07 - reconstruction_loss: 0.6817 - total_loss: 0.6817\n","Epoch 77/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - kl_loss: 9.7689e-07 - reconstruction_loss: 0.6844 - total_loss: 0.6844\n","Epoch 78/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 7.2026e-07 - reconstruction_loss: 0.6809 - total_loss: 0.6809\n","Epoch 79/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - kl_loss: 7.6721e-07 - reconstruction_loss: 0.6808 - total_loss: 0.6808\n","Epoch 80/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 9.4807e-07 - reconstruction_loss: 0.6795 - total_loss: 0.6795\n","Epoch 81/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 8.8317e-07 - reconstruction_loss: 0.6821 - total_loss: 0.6821\n","Epoch 82/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - kl_loss: 8.6956e-07 - reconstruction_loss: 0.6802 - total_loss: 0.6802\n","Epoch 83/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - kl_loss: 1.0094e-06 - reconstruction_loss: 0.6814 - total_loss: 0.6814\n","Epoch 84/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 9.3113e-07 - reconstruction_loss: 0.6822 - total_loss: 0.6822\n","Epoch 85/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 1.0147e-06 - reconstruction_loss: 0.6831 - total_loss: 0.6831\n","Epoch 86/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - kl_loss: 9.5752e-07 - reconstruction_loss: 0.6818 - total_loss: 0.6818\n","Epoch 87/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - kl_loss: 7.5606e-07 - reconstruction_loss: 0.6798 - total_loss: 0.6798\n","Epoch 88/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - kl_loss: 7.8246e-07 - reconstruction_loss: 0.6816 - total_loss: 0.6816\n","Epoch 89/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - kl_loss: 9.8143e-07 - reconstruction_loss: 0.6804 - total_loss: 0.6804\n","Epoch 90/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - kl_loss: 1.0466e-06 - reconstruction_loss: 0.6815 - total_loss: 0.6815\n","Epoch 91/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - kl_loss: 1.0692e-06 - reconstruction_loss: 0.6830 - total_loss: 0.6830\n","Epoch 92/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 8.9141e-07 - reconstruction_loss: 0.6797 - total_loss: 0.6797\n","Epoch 93/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - kl_loss: 1.0305e-06 - reconstruction_loss: 0.6803 - total_loss: 0.6803\n","Epoch 94/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 9.1311e-07 - reconstruction_loss: 0.6831 - total_loss: 0.6831\n","Epoch 95/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 8.1809e-07 - reconstruction_loss: 0.6808 - total_loss: 0.6808\n","Epoch 96/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - kl_loss: 9.3596e-07 - reconstruction_loss: 0.6801 - total_loss: 0.6801\n","Epoch 97/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - kl_loss: 1.0241e-06 - reconstruction_loss: 0.6817 - total_loss: 0.6818\n","Epoch 98/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - kl_loss: 9.4281e-07 - reconstruction_loss: 0.6825 - total_loss: 0.6825\n","Epoch 99/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 8.6550e-07 - reconstruction_loss: 0.6832 - total_loss: 0.6832\n","Epoch 100/100\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 1.0134e-06 - reconstruction_loss: 0.6806 - total_loss: 0.6806\n","Found 94 images belonging to 1 classes.\n","\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 857ms/step"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711568857.261886      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 419ms/step\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 293ms/step\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step\n","Training VAE for class: Cow\n","Found 59 images belonging to 1 classes.\n","Epoch 1/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - kl_loss: 1.7275e-05 - reconstruction_loss: 0.6797 - total_loss: 0.6797\n","Epoch 2/100\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711568878.865116      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - kl_loss: 8.0268e-06 - reconstruction_loss: 0.6787 - total_loss: 0.6787\n","Epoch 3/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - kl_loss: 2.4974e-05 - reconstruction_loss: 0.6801 - total_loss: 0.6801\n","Epoch 4/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - kl_loss: 3.6359e-06 - reconstruction_loss: 0.6793 - total_loss: 0.6793\n","Epoch 5/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - kl_loss: 1.3421e-05 - reconstruction_loss: 0.6792 - total_loss: 0.6792\n","Epoch 6/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - kl_loss: 6.7055e-06 - reconstruction_loss: 0.6789 - total_loss: 0.6789\n","Epoch 7/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - kl_loss: 3.4273e-06 - reconstruction_loss: 0.6778 - total_loss: 0.6779\n","Epoch 8/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - kl_loss: 7.7387e-06 - reconstruction_loss: 0.6785 - total_loss: 0.6785\n","Epoch 9/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - kl_loss: 2.5928e-06 - reconstruction_loss: 0.6795 - total_loss: 0.6795\n","Epoch 10/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - kl_loss: 2.3246e-06 - reconstruction_loss: 0.6774 - total_loss: 0.6774\n","Epoch 11/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - kl_loss: 4.3412e-06 - reconstruction_loss: 0.6772 - total_loss: 0.6772\n","Epoch 12/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - kl_loss: 1.0828e-06 - reconstruction_loss: 0.6786 - total_loss: 0.6786\n","Epoch 13/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - kl_loss: 1.9471e-06 - reconstruction_loss: 0.6775 - total_loss: 0.6775\n","Epoch 14/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - kl_loss: 1.6093e-06 - reconstruction_loss: 0.6770 - total_loss: 0.6770\n","Epoch 15/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - kl_loss: 5.5631e-07 - reconstruction_loss: 0.6785 - total_loss: 0.6785\n","Epoch 16/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - kl_loss: 9.5367e-07 - reconstruction_loss: 0.6792 - total_loss: 0.6792\n","Epoch 17/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - kl_loss: 6.6559e-07 - reconstruction_loss: 0.6776 - total_loss: 0.6776\n","Epoch 18/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - kl_loss: 7.3512e-07 - reconstruction_loss: 0.6799 - total_loss: 0.6799\n","Epoch 19/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - kl_loss: 8.5433e-07 - reconstruction_loss: 0.6783 - total_loss: 0.6783\n","Epoch 20/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - kl_loss: 6.8545e-07 - reconstruction_loss: 0.6786 - total_loss: 0.6786\n","Epoch 21/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - kl_loss: 8.5433e-07 - reconstruction_loss: 0.6787 - total_loss: 0.6787\n","Epoch 22/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - kl_loss: 8.2453e-07 - reconstruction_loss: 0.6776 - total_loss: 0.6776\n","Epoch 23/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - kl_loss: 5.9605e-07 - reconstruction_loss: 0.6770 - total_loss: 0.6770\n","Epoch 24/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - kl_loss: 6.3578e-07 - reconstruction_loss: 0.6776 - total_loss: 0.6776\n","Epoch 25/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - kl_loss: 8.8414e-07 - reconstruction_loss: 0.6783 - total_loss: 0.6783\n","Epoch 26/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - kl_loss: 6.6559e-07 - reconstruction_loss: 0.6777 - total_loss: 0.6777\n","Epoch 27/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - kl_loss: 5.6624e-07 - reconstruction_loss: 0.6765 - total_loss: 0.6765\n","Epoch 28/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - kl_loss: 6.1591e-07 - reconstruction_loss: 0.6758 - total_loss: 0.6758\n","Epoch 29/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - kl_loss: 6.9539e-07 - reconstruction_loss: 0.6757 - total_loss: 0.6757\n","Epoch 30/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - kl_loss: 7.0532e-07 - reconstruction_loss: 0.6805 - total_loss: 0.6806\n","Epoch 31/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - kl_loss: 6.9539e-07 - reconstruction_loss: 0.6814 - total_loss: 0.6814\n","Epoch 32/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - kl_loss: 5.7618e-07 - reconstruction_loss: 0.6762 - total_loss: 0.6762\n","Epoch 33/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - kl_loss: 5.2651e-07 - reconstruction_loss: 0.6780 - total_loss: 0.6780\n","Epoch 34/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - kl_loss: 5.3644e-07 - reconstruction_loss: 0.6782 - total_loss: 0.6782\n","Epoch 35/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - kl_loss: 4.4703e-07 - reconstruction_loss: 0.6771 - total_loss: 0.6771\n","Epoch 36/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - kl_loss: 5.2651e-07 - reconstruction_loss: 0.6770 - total_loss: 0.6770\n","Epoch 37/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - kl_loss: 7.7486e-07 - reconstruction_loss: 0.6803 - total_loss: 0.6803\n","Epoch 38/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - kl_loss: 4.2717e-07 - reconstruction_loss: 0.6778 - total_loss: 0.6778\n","Epoch 39/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - kl_loss: 4.9671e-07 - reconstruction_loss: 0.6786 - total_loss: 0.6786\n","Epoch 40/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - kl_loss: 7.8479e-07 - reconstruction_loss: 0.6784 - total_loss: 0.6784\n","Epoch 41/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - kl_loss: 7.9473e-07 - reconstruction_loss: 0.6791 - total_loss: 0.6791\n","Epoch 42/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - kl_loss: 7.0532e-07 - reconstruction_loss: 0.6761 - total_loss: 0.6761\n","Epoch 43/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - kl_loss: 4.4703e-07 - reconstruction_loss: 0.6784 - total_loss: 0.6784\n","Epoch 44/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - kl_loss: 6.1591e-07 - reconstruction_loss: 0.6755 - total_loss: 0.6755\n","Epoch 45/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - kl_loss: 8.5433e-07 - reconstruction_loss: 0.6765 - total_loss: 0.6765\n","Epoch 46/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - kl_loss: 6.7552e-07 - reconstruction_loss: 0.6772 - total_loss: 0.6772\n","Epoch 47/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - kl_loss: 1.0033e-06 - reconstruction_loss: 0.6773 - total_loss: 0.6773\n","Epoch 48/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - kl_loss: 7.5499e-07 - reconstruction_loss: 0.6783 - total_loss: 0.6783\n","Epoch 49/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - kl_loss: 8.8414e-07 - reconstruction_loss: 0.6773 - total_loss: 0.6773\n","Epoch 50/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - kl_loss: 7.4506e-07 - reconstruction_loss: 0.6790 - total_loss: 0.6790\n","Epoch 51/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - kl_loss: 6.9539e-07 - reconstruction_loss: 0.6781 - total_loss: 0.6781\n","Epoch 52/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - kl_loss: 6.0598e-07 - reconstruction_loss: 0.6791 - total_loss: 0.6791\n","Epoch 53/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - kl_loss: 1.0729e-06 - reconstruction_loss: 0.6782 - total_loss: 0.6782\n","Epoch 54/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - kl_loss: 4.3710e-07 - reconstruction_loss: 0.6765 - total_loss: 0.6765\n","Epoch 55/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - kl_loss: 7.6493e-07 - reconstruction_loss: 0.6794 - total_loss: 0.6794\n","Epoch 56/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - kl_loss: 7.5499e-07 - reconstruction_loss: 0.6793 - total_loss: 0.6793\n","Epoch 57/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - kl_loss: 8.4440e-07 - reconstruction_loss: 0.6773 - total_loss: 0.6773\n","Epoch 58/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - kl_loss: 8.9407e-07 - reconstruction_loss: 0.6784 - total_loss: 0.6784\n","Epoch 59/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - kl_loss: 8.4440e-07 - reconstruction_loss: 0.6755 - total_loss: 0.6755\n","Epoch 60/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - kl_loss: 7.4506e-07 - reconstruction_loss: 0.6799 - total_loss: 0.6799\n","Epoch 61/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - kl_loss: 8.7420e-07 - reconstruction_loss: 0.6780 - total_loss: 0.6780\n","Epoch 62/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - kl_loss: 1.0629e-06 - reconstruction_loss: 0.6780 - total_loss: 0.6780\n","Epoch 63/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - kl_loss: 5.4638e-07 - reconstruction_loss: 0.6808 - total_loss: 0.6808\n","Epoch 64/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - kl_loss: 6.5565e-07 - reconstruction_loss: 0.6799 - total_loss: 0.6799\n","Epoch 65/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - kl_loss: 6.1591e-07 - reconstruction_loss: 0.6753 - total_loss: 0.6753\n","Epoch 66/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - kl_loss: 5.8611e-07 - reconstruction_loss: 0.6792 - total_loss: 0.6792\n","Epoch 67/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - kl_loss: 7.5499e-07 - reconstruction_loss: 0.6781 - total_loss: 0.6781\n","Epoch 68/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - kl_loss: 5.8611e-07 - reconstruction_loss: 0.6780 - total_loss: 0.6780\n","Epoch 69/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - kl_loss: 6.5565e-07 - reconstruction_loss: 0.6778 - total_loss: 0.6778\n","Epoch 70/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - kl_loss: 8.6427e-07 - reconstruction_loss: 0.6782 - total_loss: 0.6782\n","Epoch 71/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - kl_loss: 7.4506e-07 - reconstruction_loss: 0.6754 - total_loss: 0.6754\n","Epoch 72/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - kl_loss: 1.0133e-06 - reconstruction_loss: 0.6786 - total_loss: 0.6786\n","Epoch 73/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - kl_loss: 1.0331e-06 - reconstruction_loss: 0.6764 - total_loss: 0.6764\n","Epoch 74/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - kl_loss: 7.0532e-07 - reconstruction_loss: 0.6773 - total_loss: 0.6773\n","Epoch 75/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - kl_loss: 8.6427e-07 - reconstruction_loss: 0.6775 - total_loss: 0.6775\n","Epoch 76/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - kl_loss: 6.8545e-07 - reconstruction_loss: 0.6784 - total_loss: 0.6784\n","Epoch 77/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - kl_loss: 8.9407e-07 - reconstruction_loss: 0.6795 - total_loss: 0.6795\n","Epoch 78/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - kl_loss: 6.0598e-07 - reconstruction_loss: 0.6763 - total_loss: 0.6763\n","Epoch 79/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - kl_loss: 6.4572e-07 - reconstruction_loss: 0.6774 - total_loss: 0.6774\n","Epoch 80/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - kl_loss: 6.9539e-07 - reconstruction_loss: 0.6786 - total_loss: 0.6786\n","Epoch 81/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - kl_loss: 9.8348e-07 - reconstruction_loss: 0.6781 - total_loss: 0.6781\n","Epoch 82/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - kl_loss: 4.8677e-07 - reconstruction_loss: 0.6781 - total_loss: 0.6781\n","Epoch 83/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - kl_loss: 6.6559e-07 - reconstruction_loss: 0.6786 - total_loss: 0.6786\n","Epoch 84/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - kl_loss: 7.6493e-07 - reconstruction_loss: 0.6776 - total_loss: 0.6776\n","Epoch 85/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - kl_loss: 7.3512e-07 - reconstruction_loss: 0.6768 - total_loss: 0.6768\n","Epoch 86/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - kl_loss: 9.7354e-07 - reconstruction_loss: 0.6778 - total_loss: 0.6778\n","Epoch 87/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - kl_loss: 5.9605e-07 - reconstruction_loss: 0.6774 - total_loss: 0.6774\n","Epoch 88/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - kl_loss: 1.0232e-06 - reconstruction_loss: 0.6742 - total_loss: 0.6742\n","Epoch 89/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - kl_loss: 7.7486e-07 - reconstruction_loss: 0.6781 - total_loss: 0.6781\n","Epoch 90/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - kl_loss: 5.8611e-07 - reconstruction_loss: 0.6769 - total_loss: 0.6769\n","Epoch 91/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - kl_loss: 7.6493e-07 - reconstruction_loss: 0.6768 - total_loss: 0.6768\n","Epoch 92/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - kl_loss: 8.1460e-07 - reconstruction_loss: 0.6783 - total_loss: 0.6783\n","Epoch 93/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - kl_loss: 4.4703e-07 - reconstruction_loss: 0.6763 - total_loss: 0.6763\n","Epoch 94/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - kl_loss: 7.0532e-07 - reconstruction_loss: 0.6781 - total_loss: 0.6781\n","Epoch 95/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - kl_loss: 7.6493e-07 - reconstruction_loss: 0.6785 - total_loss: 0.6785\n","Epoch 96/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - kl_loss: 5.9605e-07 - reconstruction_loss: 0.6781 - total_loss: 0.6781\n","Epoch 97/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - kl_loss: 8.3447e-07 - reconstruction_loss: 0.6777 - total_loss: 0.6777\n","Epoch 98/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - kl_loss: 5.9605e-07 - reconstruction_loss: 0.6773 - total_loss: 0.6773\n","Epoch 99/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - kl_loss: 7.0532e-07 - reconstruction_loss: 0.6763 - total_loss: 0.6763\n","Epoch 100/100\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - kl_loss: 4.6690e-07 - reconstruction_loss: 0.6784 - total_loss: 0.6784\n","Found 15 images belonging to 1 classes.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","Training VAE for class: Bird\n","Found 244 images belonging to 1 classes.\n","Epoch 1/100\n","\u001b[1m1/8\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m49s\u001b[0m 7s/step - kl_loss: 5.6718e-07 - reconstruction_loss: 0.6929 - total_loss: 0.6929"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711568934.375700      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 555ms/step - kl_loss: 1.7520e-05 - reconstruction_loss: 0.6929 - total_loss: 0.6929\n","Epoch 2/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - kl_loss: 1.0098e-05 - reconstruction_loss: 0.6882 - total_loss: 0.6882\n","Epoch 3/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - kl_loss: 2.9597e-06 - reconstruction_loss: 0.6873 - total_loss: 0.6873\n","Epoch 4/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - kl_loss: 1.7537e-06 - reconstruction_loss: 0.6898 - total_loss: 0.6898\n","Epoch 5/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - kl_loss: 8.1523e-07 - reconstruction_loss: 0.6871 - total_loss: 0.6871\n","Epoch 6/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - kl_loss: 7.1771e-07 - reconstruction_loss: 0.6881 - total_loss: 0.6881\n","Epoch 7/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 6.5680e-07 - reconstruction_loss: 0.6875 - total_loss: 0.6875\n","Epoch 8/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - kl_loss: 6.7430e-07 - reconstruction_loss: 0.6869 - total_loss: 0.6869\n","Epoch 9/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 6.2794e-07 - reconstruction_loss: 0.6891 - total_loss: 0.6891\n","Epoch 10/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 5.7501e-07 - reconstruction_loss: 0.6887 - total_loss: 0.6887\n","Epoch 11/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 5.5301e-07 - reconstruction_loss: 0.6881 - total_loss: 0.6881\n","Epoch 12/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 6.4466e-07 - reconstruction_loss: 0.6884 - total_loss: 0.6884\n","Epoch 13/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 5.1911e-07 - reconstruction_loss: 0.6881 - total_loss: 0.6881\n","Epoch 14/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 4.7104e-07 - reconstruction_loss: 0.6891 - total_loss: 0.6891\n","Epoch 15/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 5.8061e-07 - reconstruction_loss: 0.6883 - total_loss: 0.6883\n","Epoch 16/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 5.5833e-07 - reconstruction_loss: 0.6881 - total_loss: 0.6881\n","Epoch 17/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 5.5911e-07 - reconstruction_loss: 0.6890 - total_loss: 0.6890\n","Epoch 18/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 5.3490e-07 - reconstruction_loss: 0.6886 - total_loss: 0.6886\n","Epoch 19/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 5.9078e-07 - reconstruction_loss: 0.6884 - total_loss: 0.6884\n","Epoch 20/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 6.5889e-07 - reconstruction_loss: 0.6885 - total_loss: 0.6885\n","Epoch 21/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 4.5133e-07 - reconstruction_loss: 0.6885 - total_loss: 0.6885\n","Epoch 22/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 6.5076e-07 - reconstruction_loss: 0.6888 - total_loss: 0.6888\n","Epoch 23/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 6.2477e-07 - reconstruction_loss: 0.6883 - total_loss: 0.6883\n","Epoch 24/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 7.3259e-07 - reconstruction_loss: 0.6867 - total_loss: 0.6867\n","Epoch 25/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 6.6723e-07 - reconstruction_loss: 0.6878 - total_loss: 0.6878\n","Epoch 26/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - kl_loss: 5.8400e-07 - reconstruction_loss: 0.6894 - total_loss: 0.6894\n","Epoch 27/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 6.7762e-07 - reconstruction_loss: 0.6869 - total_loss: 0.6869\n","Epoch 28/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 5.2393e-07 - reconstruction_loss: 0.6869 - total_loss: 0.6869\n","Epoch 29/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 6.7513e-07 - reconstruction_loss: 0.6890 - total_loss: 0.6890\n","Epoch 30/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 5.7962e-07 - reconstruction_loss: 0.6869 - total_loss: 0.6869\n","Epoch 31/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - kl_loss: 7.5929e-07 - reconstruction_loss: 0.6901 - total_loss: 0.6901\n","Epoch 32/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - kl_loss: 5.4249e-07 - reconstruction_loss: 0.6883 - total_loss: 0.6883\n","Epoch 33/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 5.9760e-07 - reconstruction_loss: 0.6889 - total_loss: 0.6889\n","Epoch 34/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 4.9456e-07 - reconstruction_loss: 0.6869 - total_loss: 0.6869\n","Epoch 35/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 6.6892e-07 - reconstruction_loss: 0.6874 - total_loss: 0.6874\n","Epoch 36/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 5.3081e-07 - reconstruction_loss: 0.6878 - total_loss: 0.6878\n","Epoch 37/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 4.0252e-07 - reconstruction_loss: 0.6882 - total_loss: 0.6882\n","Epoch 38/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 6.8120e-07 - reconstruction_loss: 0.6887 - total_loss: 0.6887\n","Epoch 39/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 4.5040e-07 - reconstruction_loss: 0.6900 - total_loss: 0.6900\n","Epoch 40/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 6.2288e-07 - reconstruction_loss: 0.6883 - total_loss: 0.6883\n","Epoch 41/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 6.2742e-07 - reconstruction_loss: 0.6897 - total_loss: 0.6897\n","Epoch 42/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 4.2937e-07 - reconstruction_loss: 0.6885 - total_loss: 0.6885\n","Epoch 43/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 5.9090e-07 - reconstruction_loss: 0.6902 - total_loss: 0.6902\n","Epoch 44/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 6.1290e-07 - reconstruction_loss: 0.6867 - total_loss: 0.6867\n","Epoch 45/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 6.3229e-07 - reconstruction_loss: 0.6885 - total_loss: 0.6885\n","Epoch 46/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 5.6175e-07 - reconstruction_loss: 0.6886 - total_loss: 0.6886\n","Epoch 47/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 6.2126e-07 - reconstruction_loss: 0.6887 - total_loss: 0.6887\n","Epoch 48/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 6.3354e-07 - reconstruction_loss: 0.6868 - total_loss: 0.6868\n","Epoch 49/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 5.9659e-07 - reconstruction_loss: 0.6875 - total_loss: 0.6875\n","Epoch 50/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 5.2517e-07 - reconstruction_loss: 0.6879 - total_loss: 0.6879\n","Epoch 51/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 5.6423e-07 - reconstruction_loss: 0.6874 - total_loss: 0.6874\n","Epoch 52/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 5.1833e-07 - reconstruction_loss: 0.6880 - total_loss: 0.6880\n","Epoch 53/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 4.0042e-07 - reconstruction_loss: 0.6877 - total_loss: 0.6877\n","Epoch 54/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 4.9661e-07 - reconstruction_loss: 0.6870 - total_loss: 0.6870\n","Epoch 55/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 4.4803e-07 - reconstruction_loss: 0.6883 - total_loss: 0.6883\n","Epoch 56/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 5.9082e-07 - reconstruction_loss: 0.6874 - total_loss: 0.6874\n","Epoch 57/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 6.0305e-07 - reconstruction_loss: 0.6879 - total_loss: 0.6879\n","Epoch 58/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 6.0329e-07 - reconstruction_loss: 0.6879 - total_loss: 0.6879\n","Epoch 59/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 7.2607e-07 - reconstruction_loss: 0.6862 - total_loss: 0.6862\n","Epoch 60/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 6.5434e-07 - reconstruction_loss: 0.6883 - total_loss: 0.6883\n","Epoch 61/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 6.8777e-07 - reconstruction_loss: 0.6886 - total_loss: 0.6886\n","Epoch 62/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 5.3489e-07 - reconstruction_loss: 0.6869 - total_loss: 0.6869\n","Epoch 63/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 6.6853e-07 - reconstruction_loss: 0.6884 - total_loss: 0.6884\n","Epoch 64/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 6.0484e-07 - reconstruction_loss: 0.6887 - total_loss: 0.6887\n","Epoch 65/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 6.3388e-07 - reconstruction_loss: 0.6882 - total_loss: 0.6882\n","Epoch 66/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 6.6165e-07 - reconstruction_loss: 0.6878 - total_loss: 0.6878\n","Epoch 67/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 6.8875e-07 - reconstruction_loss: 0.6891 - total_loss: 0.6891\n","Epoch 68/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 5.2324e-07 - reconstruction_loss: 0.6889 - total_loss: 0.6889\n","Epoch 69/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 4.8747e-07 - reconstruction_loss: 0.6872 - total_loss: 0.6872\n","Epoch 70/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 6.0945e-07 - reconstruction_loss: 0.6888 - total_loss: 0.6888\n","Epoch 71/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 5.7484e-07 - reconstruction_loss: 0.6864 - total_loss: 0.6864\n","Epoch 72/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 6.0482e-07 - reconstruction_loss: 0.6887 - total_loss: 0.6887\n","Epoch 73/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 5.8225e-07 - reconstruction_loss: 0.6890 - total_loss: 0.6890\n","Epoch 74/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 6.9632e-07 - reconstruction_loss: 0.6891 - total_loss: 0.6891\n","Epoch 75/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - kl_loss: 5.8978e-07 - reconstruction_loss: 0.6886 - total_loss: 0.6886\n","Epoch 76/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 5.2840e-07 - reconstruction_loss: 0.6868 - total_loss: 0.6868\n","Epoch 77/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 5.1909e-07 - reconstruction_loss: 0.6909 - total_loss: 0.6909\n","Epoch 78/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 6.1289e-07 - reconstruction_loss: 0.6887 - total_loss: 0.6887\n","Epoch 79/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 5.5001e-07 - reconstruction_loss: 0.6880 - total_loss: 0.6880\n","Epoch 80/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 5.9416e-07 - reconstruction_loss: 0.6878 - total_loss: 0.6878\n","Epoch 81/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 5.6524e-07 - reconstruction_loss: 0.6887 - total_loss: 0.6887\n","Epoch 82/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - kl_loss: 6.9296e-07 - reconstruction_loss: 0.6868 - total_loss: 0.6868\n","Epoch 83/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 6.9431e-07 - reconstruction_loss: 0.6880 - total_loss: 0.6880\n","Epoch 84/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 4.0526e-07 - reconstruction_loss: 0.6872 - total_loss: 0.6872\n","Epoch 85/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 7.2670e-07 - reconstruction_loss: 0.6861 - total_loss: 0.6861\n","Epoch 86/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 6.0388e-07 - reconstruction_loss: 0.6904 - total_loss: 0.6904\n","Epoch 87/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 7.8141e-07 - reconstruction_loss: 0.6889 - total_loss: 0.6889\n","Epoch 88/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 7.0893e-07 - reconstruction_loss: 0.6878 - total_loss: 0.6878\n","Epoch 89/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 8.0863e-07 - reconstruction_loss: 0.6888 - total_loss: 0.6888\n","Epoch 90/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - kl_loss: 5.4341e-07 - reconstruction_loss: 0.6880 - total_loss: 0.6880\n","Epoch 91/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 5.8197e-07 - reconstruction_loss: 0.6879 - total_loss: 0.6879\n","Epoch 92/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 4.9116e-07 - reconstruction_loss: 0.6878 - total_loss: 0.6878\n","Epoch 93/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - kl_loss: 7.0619e-07 - reconstruction_loss: 0.6907 - total_loss: 0.6907\n","Epoch 94/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 6.0991e-07 - reconstruction_loss: 0.6874 - total_loss: 0.6874\n","Epoch 95/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 4.5578e-07 - reconstruction_loss: 0.6886 - total_loss: 0.6886\n","Epoch 96/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 7.0013e-07 - reconstruction_loss: 0.6872 - total_loss: 0.6872\n","Epoch 97/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 6.5395e-07 - reconstruction_loss: 0.6884 - total_loss: 0.6884\n","Epoch 98/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - kl_loss: 7.1959e-07 - reconstruction_loss: 0.6869 - total_loss: 0.6869\n","Epoch 99/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - kl_loss: 6.1411e-07 - reconstruction_loss: 0.6878 - total_loss: 0.6878\n","Epoch 100/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 5.8195e-07 - reconstruction_loss: 0.6880 - total_loss: 0.6880\n","Found 61 images belonging to 1 classes.\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 896ms/step"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711569105.757426      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5s/step  \n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 481ms/step\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","Training VAE for class: Pottedplant\n","Found 144 images belonging to 1 classes.\n","Epoch 1/100\n","\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 7s/step - kl_loss: 8.3447e-07 - reconstruction_loss: 0.6860 - total_loss: 0.6860"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711569119.569494      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 861ms/step - kl_loss: 1.6526e-05 - reconstruction_loss: 0.6820 - total_loss: 0.6820\n","Epoch 2/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 1.0190e-05 - reconstruction_loss: 0.6809 - total_loss: 0.6809\n","Epoch 3/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - kl_loss: 5.4793e-06 - reconstruction_loss: 0.6779 - total_loss: 0.6779\n","Epoch 4/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 3.8523e-06 - reconstruction_loss: 0.6789 - total_loss: 0.6789\n","Epoch 5/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 2.8794e-06 - reconstruction_loss: 0.6843 - total_loss: 0.6843\n","Epoch 6/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.6442e-06 - reconstruction_loss: 0.6758 - total_loss: 0.6758\n","Epoch 7/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - kl_loss: 1.1450e-06 - reconstruction_loss: 0.6787 - total_loss: 0.6787\n","Epoch 8/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 8.5665e-07 - reconstruction_loss: 0.6766 - total_loss: 0.6766\n","Epoch 9/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 9.0640e-07 - reconstruction_loss: 0.6773 - total_loss: 0.6773\n","Epoch 10/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - kl_loss: 7.7312e-07 - reconstruction_loss: 0.6780 - total_loss: 0.6780\n","Epoch 11/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 7.0689e-07 - reconstruction_loss: 0.6760 - total_loss: 0.6760\n","Epoch 12/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 5.6434e-07 - reconstruction_loss: 0.6789 - total_loss: 0.6789\n","Epoch 13/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 6.0275e-07 - reconstruction_loss: 0.6837 - total_loss: 0.6837\n","Epoch 14/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 5.7775e-07 - reconstruction_loss: 0.6726 - total_loss: 0.6726\n","Epoch 15/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 6.3694e-07 - reconstruction_loss: 0.6757 - total_loss: 0.6757\n","Epoch 16/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 6.2717e-07 - reconstruction_loss: 0.6811 - total_loss: 0.6811\n","Epoch 17/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 7.0971e-07 - reconstruction_loss: 0.6794 - total_loss: 0.6794\n","Epoch 18/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - kl_loss: 4.6624e-07 - reconstruction_loss: 0.6770 - total_loss: 0.6770\n","Epoch 19/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 5.3346e-07 - reconstruction_loss: 0.6774 - total_loss: 0.6774\n","Epoch 20/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 6.9771e-07 - reconstruction_loss: 0.6801 - total_loss: 0.6801\n","Epoch 21/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 3.8826e-07 - reconstruction_loss: 0.6776 - total_loss: 0.6776\n","Epoch 22/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 4.1798e-07 - reconstruction_loss: 0.6766 - total_loss: 0.6766\n","Epoch 23/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 5.2071e-07 - reconstruction_loss: 0.6763 - total_loss: 0.6763\n","Epoch 24/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - kl_loss: 5.8769e-07 - reconstruction_loss: 0.6784 - total_loss: 0.6784\n","Epoch 25/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 6.9737e-07 - reconstruction_loss: 0.6758 - total_loss: 0.6758\n","Epoch 26/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - kl_loss: 5.1310e-07 - reconstruction_loss: 0.6749 - total_loss: 0.6749\n","Epoch 27/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 7.0242e-07 - reconstruction_loss: 0.6781 - total_loss: 0.6781\n","Epoch 28/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - kl_loss: 6.8446e-07 - reconstruction_loss: 0.6784 - total_loss: 0.6784\n","Epoch 29/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - kl_loss: 5.6964e-07 - reconstruction_loss: 0.6777 - total_loss: 0.6777\n","Epoch 30/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 6.7469e-07 - reconstruction_loss: 0.6783 - total_loss: 0.6783\n","Epoch 31/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - kl_loss: 7.4589e-07 - reconstruction_loss: 0.6767 - total_loss: 0.6767\n","Epoch 32/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 5.4075e-07 - reconstruction_loss: 0.6782 - total_loss: 0.6782\n","Epoch 33/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - kl_loss: 6.0358e-07 - reconstruction_loss: 0.6762 - total_loss: 0.6762\n","Epoch 34/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - kl_loss: 5.1450e-07 - reconstruction_loss: 0.6786 - total_loss: 0.6786\n","Epoch 35/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - kl_loss: 5.5068e-07 - reconstruction_loss: 0.6762 - total_loss: 0.6762\n","Epoch 36/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 6.4108e-07 - reconstruction_loss: 0.6824 - total_loss: 0.6824\n","Epoch 37/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - kl_loss: 6.9837e-07 - reconstruction_loss: 0.6783 - total_loss: 0.6783\n","Epoch 38/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 5.4273e-07 - reconstruction_loss: 0.6767 - total_loss: 0.6767\n","Epoch 39/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 7.7147e-07 - reconstruction_loss: 0.6769 - total_loss: 0.6769\n","Epoch 40/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - kl_loss: 5.7245e-07 - reconstruction_loss: 0.6753 - total_loss: 0.6753\n","Epoch 41/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - kl_loss: 7.5094e-07 - reconstruction_loss: 0.6748 - total_loss: 0.6748\n","Epoch 42/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 9.4109e-07 - reconstruction_loss: 0.6771 - total_loss: 0.6771\n","Epoch 43/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - kl_loss: 5.7725e-07 - reconstruction_loss: 0.6765 - total_loss: 0.6765\n","Epoch 44/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 7.2039e-07 - reconstruction_loss: 0.6832 - total_loss: 0.6832\n","Epoch 45/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 5.8148e-07 - reconstruction_loss: 0.6759 - total_loss: 0.6759\n","Epoch 46/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - kl_loss: 7.7594e-07 - reconstruction_loss: 0.6771 - total_loss: 0.6771\n","Epoch 47/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 7.4233e-07 - reconstruction_loss: 0.6747 - total_loss: 0.6747\n","Epoch 48/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - kl_loss: 8.0077e-07 - reconstruction_loss: 0.6775 - total_loss: 0.6775\n","Epoch 49/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 7.1633e-07 - reconstruction_loss: 0.6768 - total_loss: 0.6768\n","Epoch 50/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 5.3950e-07 - reconstruction_loss: 0.6768 - total_loss: 0.6768\n","Epoch 51/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 6.5673e-07 - reconstruction_loss: 0.6758 - total_loss: 0.6758\n","Epoch 52/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 6.4588e-07 - reconstruction_loss: 0.6790 - total_loss: 0.6790\n","Epoch 53/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 5.4803e-07 - reconstruction_loss: 0.6773 - total_loss: 0.6773\n","Epoch 54/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - kl_loss: 7.3901e-07 - reconstruction_loss: 0.6776 - total_loss: 0.6776\n","Epoch 55/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 6.5126e-07 - reconstruction_loss: 0.6762 - total_loss: 0.6762\n","Epoch 56/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - kl_loss: 6.4299e-07 - reconstruction_loss: 0.6771 - total_loss: 0.6771\n","Epoch 57/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 6.0242e-07 - reconstruction_loss: 0.6772 - total_loss: 0.6772\n","Epoch 58/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 4.0688e-07 - reconstruction_loss: 0.6769 - total_loss: 0.6769\n","Epoch 59/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - kl_loss: 5.8984e-07 - reconstruction_loss: 0.6781 - total_loss: 0.6781\n","Epoch 60/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - kl_loss: 5.7386e-07 - reconstruction_loss: 0.6787 - total_loss: 0.6787\n","Epoch 61/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 5.6070e-07 - reconstruction_loss: 0.6785 - total_loss: 0.6785\n","Epoch 62/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - kl_loss: 6.6426e-07 - reconstruction_loss: 0.6759 - total_loss: 0.6759\n","Epoch 63/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 5.9191e-07 - reconstruction_loss: 0.6769 - total_loss: 0.6769\n","Epoch 64/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 6.0101e-07 - reconstruction_loss: 0.6775 - total_loss: 0.6775\n","Epoch 65/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - kl_loss: 5.9505e-07 - reconstruction_loss: 0.6800 - total_loss: 0.6800\n","Epoch 66/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 6.1070e-07 - reconstruction_loss: 0.6766 - total_loss: 0.6766\n","Epoch 67/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 6.0962e-07 - reconstruction_loss: 0.6801 - total_loss: 0.6801\n","Epoch 68/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 6.3951e-07 - reconstruction_loss: 0.6774 - total_loss: 0.6774\n","Epoch 69/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 5.7386e-07 - reconstruction_loss: 0.6756 - total_loss: 0.6756\n","Epoch 70/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - kl_loss: 6.9870e-07 - reconstruction_loss: 0.6770 - total_loss: 0.6770\n","Epoch 71/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 2.9968e-07 - reconstruction_loss: 0.6767 - total_loss: 0.6767\n","Epoch 72/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 7.0077e-07 - reconstruction_loss: 0.6797 - total_loss: 0.6797\n","Epoch 73/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 4.7344e-07 - reconstruction_loss: 0.6776 - total_loss: 0.6776\n","Epoch 74/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 7.1832e-07 - reconstruction_loss: 0.6775 - total_loss: 0.6775\n","Epoch 75/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 5.5167e-07 - reconstruction_loss: 0.6795 - total_loss: 0.6795\n","Epoch 76/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - kl_loss: 7.1103e-07 - reconstruction_loss: 0.6756 - total_loss: 0.6756\n","Epoch 77/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 8.1137e-07 - reconstruction_loss: 0.6796 - total_loss: 0.6796\n","Epoch 78/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 7.0574e-07 - reconstruction_loss: 0.6744 - total_loss: 0.6744\n","Epoch 79/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 6.0565e-07 - reconstruction_loss: 0.6743 - total_loss: 0.6743\n","Epoch 80/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 6.2817e-07 - reconstruction_loss: 0.6769 - total_loss: 0.6769\n","Epoch 81/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 7.4133e-07 - reconstruction_loss: 0.6778 - total_loss: 0.6778\n","Epoch 82/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 6.2701e-07 - reconstruction_loss: 0.6773 - total_loss: 0.6773\n","Epoch 83/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 6.8438e-07 - reconstruction_loss: 0.6786 - total_loss: 0.6786\n","Epoch 84/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 8.3422e-07 - reconstruction_loss: 0.6747 - total_loss: 0.6747\n","Epoch 85/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 8.1766e-07 - reconstruction_loss: 0.6755 - total_loss: 0.6755\n","Epoch 86/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - kl_loss: 6.7999e-07 - reconstruction_loss: 0.6771 - total_loss: 0.6771\n","Epoch 87/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - kl_loss: 5.8868e-07 - reconstruction_loss: 0.6758 - total_loss: 0.6758\n","Epoch 88/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 9.2197e-07 - reconstruction_loss: 0.6764 - total_loss: 0.6764\n","Epoch 89/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 8.1898e-07 - reconstruction_loss: 0.6736 - total_loss: 0.6736\n","Epoch 90/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 7.7436e-07 - reconstruction_loss: 0.6778 - total_loss: 0.6778\n","Epoch 91/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 9.2677e-07 - reconstruction_loss: 0.6750 - total_loss: 0.6750\n","Epoch 92/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 8.0168e-07 - reconstruction_loss: 0.6737 - total_loss: 0.6737\n","Epoch 93/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 6.6111e-07 - reconstruction_loss: 0.6745 - total_loss: 0.6745\n","Epoch 94/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 6.9390e-07 - reconstruction_loss: 0.6777 - total_loss: 0.6777\n","Epoch 95/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 6.5102e-07 - reconstruction_loss: 0.6772 - total_loss: 0.6772\n","Epoch 96/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 5.9547e-07 - reconstruction_loss: 0.6785 - total_loss: 0.6785\n","Epoch 97/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - kl_loss: 6.6368e-07 - reconstruction_loss: 0.6773 - total_loss: 0.6773\n","Epoch 98/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 7.4721e-07 - reconstruction_loss: 0.6803 - total_loss: 0.6803\n","Epoch 99/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 7.8008e-07 - reconstruction_loss: 0.6746 - total_loss: 0.6746\n","Epoch 100/100\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 6.8769e-07 - reconstruction_loss: 0.6794 - total_loss: 0.6794\n","Found 36 images belonging to 1 classes.\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 833ms/step"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711569222.875381      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2s/step  \n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 392ms/step\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","Training VAE for class: Tvmonitor\n","Found 172 images belonging to 1 classes.\n","Epoch 1/100\n","\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 6s/step - kl_loss: 7.7486e-07 - reconstruction_loss: 0.6619 - total_loss: 0.6619"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711569233.732483      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - kl_loss: 1.8230e-05 - reconstruction_loss: 0.6678 - total_loss: 0.6678\n","Epoch 2/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - kl_loss: 6.7061e-06 - reconstruction_loss: 0.6695 - total_loss: 0.6695\n","Epoch 3/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 4.4120e-06 - reconstruction_loss: 0.6661 - total_loss: 0.6661\n","Epoch 4/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - kl_loss: 2.9511e-06 - reconstruction_loss: 0.6678 - total_loss: 0.6678\n","Epoch 5/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 1.6442e-06 - reconstruction_loss: 0.6728 - total_loss: 0.6728\n","Epoch 6/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 7.4414e-07 - reconstruction_loss: 0.6644 - total_loss: 0.6644\n","Epoch 7/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 6.0030e-07 - reconstruction_loss: 0.6688 - total_loss: 0.6688\n","Epoch 8/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 6.2847e-07 - reconstruction_loss: 0.6714 - total_loss: 0.6714\n","Epoch 9/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - kl_loss: 6.5061e-07 - reconstruction_loss: 0.6690 - total_loss: 0.6690\n","Epoch 10/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 7.6152e-07 - reconstruction_loss: 0.6666 - total_loss: 0.6666\n","Epoch 11/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 6.4664e-07 - reconstruction_loss: 0.6689 - total_loss: 0.6689\n","Epoch 12/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 5.5581e-07 - reconstruction_loss: 0.6686 - total_loss: 0.6686\n","Epoch 13/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 5.7887e-07 - reconstruction_loss: 0.6661 - total_loss: 0.6661\n","Epoch 14/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - kl_loss: 4.6761e-07 - reconstruction_loss: 0.6650 - total_loss: 0.6650\n","Epoch 15/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 5.6007e-07 - reconstruction_loss: 0.6660 - total_loss: 0.6660\n","Epoch 16/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - kl_loss: 6.8538e-07 - reconstruction_loss: 0.6667 - total_loss: 0.6667\n","Epoch 17/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - kl_loss: 6.9021e-07 - reconstruction_loss: 0.6652 - total_loss: 0.6652\n","Epoch 18/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 5.5752e-07 - reconstruction_loss: 0.6620 - total_loss: 0.6620\n","Epoch 19/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - kl_loss: 7.1469e-07 - reconstruction_loss: 0.6638 - total_loss: 0.6638\n","Epoch 20/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 3.0193e-07 - reconstruction_loss: 0.6709 - total_loss: 0.6709\n","Epoch 21/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - kl_loss: 7.2888e-07 - reconstruction_loss: 0.6652 - total_loss: 0.6652\n","Epoch 22/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 7.8586e-07 - reconstruction_loss: 0.6659 - total_loss: 0.6659\n","Epoch 23/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - kl_loss: 3.4180e-07 - reconstruction_loss: 0.6689 - total_loss: 0.6689\n","Epoch 24/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 7.5215e-07 - reconstruction_loss: 0.6657 - total_loss: 0.6657\n","Epoch 25/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 4.7591e-07 - reconstruction_loss: 0.6706 - total_loss: 0.6706\n","Epoch 26/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 6.4181e-07 - reconstruction_loss: 0.6669 - total_loss: 0.6669\n","Epoch 27/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 6.5501e-07 - reconstruction_loss: 0.6626 - total_loss: 0.6626\n","Epoch 28/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 8.8243e-07 - reconstruction_loss: 0.6668 - total_loss: 0.6668\n","Epoch 29/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 6.1265e-07 - reconstruction_loss: 0.6652 - total_loss: 0.6652\n","Epoch 30/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 6.4032e-07 - reconstruction_loss: 0.6654 - total_loss: 0.6654\n","Epoch 31/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - kl_loss: 7.8288e-07 - reconstruction_loss: 0.6668 - total_loss: 0.6668\n","Epoch 32/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 6.6459e-07 - reconstruction_loss: 0.6665 - total_loss: 0.6665\n","Epoch 33/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 9.4878e-07 - reconstruction_loss: 0.6631 - total_loss: 0.6631\n","Epoch 34/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - kl_loss: 6.7055e-07 - reconstruction_loss: 0.6631 - total_loss: 0.6631\n","Epoch 35/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 7.4399e-07 - reconstruction_loss: 0.6642 - total_loss: 0.6642 \n","Epoch 36/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 6.2564e-07 - reconstruction_loss: 0.6591 - total_loss: 0.6591\n","Epoch 37/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 8.8641e-07 - reconstruction_loss: 0.6638 - total_loss: 0.6638\n","Epoch 38/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 8.5483e-07 - reconstruction_loss: 0.6647 - total_loss: 0.6647\n","Epoch 39/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - kl_loss: 8.7555e-07 - reconstruction_loss: 0.6626 - total_loss: 0.6626\n","Epoch 40/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 7.6088e-07 - reconstruction_loss: 0.6634 - total_loss: 0.6634\n","Epoch 41/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - kl_loss: 7.1951e-07 - reconstruction_loss: 0.6669 - total_loss: 0.6669\n","Epoch 42/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 8.3113e-07 - reconstruction_loss: 0.6690 - total_loss: 0.6690\n","Epoch 43/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 5.3559e-07 - reconstruction_loss: 0.6660 - total_loss: 0.6660\n","Epoch 44/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 4.0794e-07 - reconstruction_loss: 0.6614 - total_loss: 0.6614\n","Epoch 45/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - kl_loss: 6.3869e-07 - reconstruction_loss: 0.6643 - total_loss: 0.6643\n","Epoch 46/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - kl_loss: 7.1597e-07 - reconstruction_loss: 0.6617 - total_loss: 0.6617\n","Epoch 47/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 6.2365e-07 - reconstruction_loss: 0.6646 - total_loss: 0.6646\n","Epoch 48/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - kl_loss: 8.0459e-07 - reconstruction_loss: 0.6616 - total_loss: 0.6616\n","Epoch 49/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 6.9269e-07 - reconstruction_loss: 0.6685 - total_loss: 0.6685\n","Epoch 50/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 5.9803e-07 - reconstruction_loss: 0.6584 - total_loss: 0.6584\n","Epoch 51/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 8.9010e-07 - reconstruction_loss: 0.6663 - total_loss: 0.6663\n","Epoch 52/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 5.8271e-07 - reconstruction_loss: 0.6687 - total_loss: 0.6687\n","Epoch 53/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 6.2571e-07 - reconstruction_loss: 0.6720 - total_loss: 0.6720\n","Epoch 54/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 6.0321e-07 - reconstruction_loss: 0.6663 - total_loss: 0.6663\n","Epoch 55/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 7.5662e-07 - reconstruction_loss: 0.6640 - total_loss: 0.6640\n","Epoch 56/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 8.2254e-07 - reconstruction_loss: 0.6680 - total_loss: 0.6680\n","Epoch 57/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - kl_loss: 7.9168e-07 - reconstruction_loss: 0.6646 - total_loss: 0.6646\n","Epoch 58/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 6.8013e-07 - reconstruction_loss: 0.6655 - total_loss: 0.6655\n","Epoch 59/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 7.6556e-07 - reconstruction_loss: 0.6623 - total_loss: 0.6623\n","Epoch 60/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - kl_loss: 7.5819e-07 - reconstruction_loss: 0.6664 - total_loss: 0.6664\n","Epoch 61/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 8.5299e-07 - reconstruction_loss: 0.6690 - total_loss: 0.6690\n","Epoch 62/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - kl_loss: 7.5499e-07 - reconstruction_loss: 0.6671 - total_loss: 0.6671\n","Epoch 63/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 8.3525e-07 - reconstruction_loss: 0.6660 - total_loss: 0.6660\n","Epoch 64/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - kl_loss: 1.2846e-06 - reconstruction_loss: 0.6639 - total_loss: 0.6639\n","Epoch 65/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 8.7661e-07 - reconstruction_loss: 0.6688 - total_loss: 0.6688\n","Epoch 66/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 9.5176e-07 - reconstruction_loss: 0.6689 - total_loss: 0.6689\n","Epoch 67/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - kl_loss: 8.7576e-07 - reconstruction_loss: 0.6660 - total_loss: 0.6660\n","Epoch 68/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 8.8463e-07 - reconstruction_loss: 0.6631 - total_loss: 0.6631\n","Epoch 69/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 9.3686e-07 - reconstruction_loss: 0.6669 - total_loss: 0.6669\n","Epoch 70/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 8.4561e-07 - reconstruction_loss: 0.6663 - total_loss: 0.6663\n","Epoch 71/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 9.4871e-07 - reconstruction_loss: 0.6628 - total_loss: 0.6628\n","Epoch 72/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 1.0876e-06 - reconstruction_loss: 0.6622 - total_loss: 0.6622\n","Epoch 73/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 1.7221e-06 - reconstruction_loss: 0.6630 - total_loss: 0.6630\n","Epoch 74/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 1.6225e-06 - reconstruction_loss: 0.6655 - total_loss: 0.6655\n","Epoch 75/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 1.2179e-06 - reconstruction_loss: 0.6687 - total_loss: 0.6687\n","Epoch 76/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 7.6691e-07 - reconstruction_loss: 0.6636 - total_loss: 0.6636\n","Epoch 77/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - kl_loss: 9.4452e-07 - reconstruction_loss: 0.6682 - total_loss: 0.6682\n","Epoch 78/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 1.0286e-06 - reconstruction_loss: 0.6687 - total_loss: 0.6687\n","Epoch 79/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - kl_loss: 9.2330e-07 - reconstruction_loss: 0.6651 - total_loss: 0.6651\n","Epoch 80/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 9.7560e-07 - reconstruction_loss: 0.6658 - total_loss: 0.6658\n","Epoch 81/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 1.0276e-06 - reconstruction_loss: 0.6667 - total_loss: 0.6667\n","Epoch 82/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 9.2295e-07 - reconstruction_loss: 0.6668 - total_loss: 0.6668\n","Epoch 83/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - kl_loss: 9.9015e-07 - reconstruction_loss: 0.6683 - total_loss: 0.6683\n","Epoch 84/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - kl_loss: 9.3778e-07 - reconstruction_loss: 0.6671 - total_loss: 0.6671\n","Epoch 85/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - kl_loss: 1.0649e-06 - reconstruction_loss: 0.6651 - total_loss: 0.6651\n","Epoch 86/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 6.4799e-07 - reconstruction_loss: 0.6657 - total_loss: 0.6657\n","Epoch 87/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 9.7496e-07 - reconstruction_loss: 0.6638 - total_loss: 0.6638\n","Epoch 88/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 8.7732e-07 - reconstruction_loss: 0.6659 - total_loss: 0.6659\n","Epoch 89/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - kl_loss: 9.4913e-07 - reconstruction_loss: 0.6639 - total_loss: 0.6639\n","Epoch 90/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - kl_loss: 8.4412e-07 - reconstruction_loss: 0.6707 - total_loss: 0.6707\n","Epoch 91/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - kl_loss: 9.4871e-07 - reconstruction_loss: 0.6655 - total_loss: 0.6655\n","Epoch 92/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 7.3938e-07 - reconstruction_loss: 0.6636 - total_loss: 0.6636\n","Epoch 93/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - kl_loss: 9.8057e-07 - reconstruction_loss: 0.6672 - total_loss: 0.6672\n","Epoch 94/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - kl_loss: 9.6950e-07 - reconstruction_loss: 0.6639 - total_loss: 0.6639\n","Epoch 95/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 6.6622e-07 - reconstruction_loss: 0.6657 - total_loss: 0.6657\n","Epoch 96/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - kl_loss: 9.0450e-07 - reconstruction_loss: 0.6626 - total_loss: 0.6626\n","Epoch 97/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 8.8123e-07 - reconstruction_loss: 0.6650 - total_loss: 0.6650\n","Epoch 98/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 7.9374e-07 - reconstruction_loss: 0.6664 - total_loss: 0.6664\n","Epoch 99/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - kl_loss: 8.0637e-07 - reconstruction_loss: 0.6682 - total_loss: 0.6682\n","Epoch 100/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - kl_loss: 8.1502e-07 - reconstruction_loss: 0.6717 - total_loss: 0.6717\n","Found 43 images belonging to 1 classes.\n","\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 904ms/step"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711569359.003998      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 757ms/step\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 419ms/step\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n","Training VAE for class: Dog\n","Found 310 images belonging to 1 classes.\n","Epoch 1/100\n","\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:03\u001b[0m 7s/step - kl_loss: 6.8545e-07 - reconstruction_loss: 0.6867 - total_loss: 0.6867"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711569369.184225      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - kl_loss: 1.7440e-05 - reconstruction_loss: 0.6854 - total_loss: 0.6854\n","Epoch 2/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 5.8478e-06 - reconstruction_loss: 0.6805 - total_loss: 0.6805\n","Epoch 3/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - kl_loss: 2.8811e-06 - reconstruction_loss: 0.6809 - total_loss: 0.6809\n","Epoch 4/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 1.1535e-06 - reconstruction_loss: 0.6832 - total_loss: 0.6832\n","Epoch 5/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 7.4161e-07 - reconstruction_loss: 0.6832 - total_loss: 0.6832\n","Epoch 6/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - kl_loss: 6.8702e-07 - reconstruction_loss: 0.6778 - total_loss: 0.6778\n","Epoch 7/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 5.5685e-07 - reconstruction_loss: 0.6801 - total_loss: 0.6801\n","Epoch 8/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 6.2242e-07 - reconstruction_loss: 0.6813 - total_loss: 0.6813\n","Epoch 9/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - kl_loss: 5.4556e-07 - reconstruction_loss: 0.6835 - total_loss: 0.6835\n","Epoch 10/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - kl_loss: 6.4675e-07 - reconstruction_loss: 0.6823 - total_loss: 0.6823\n","Epoch 11/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 7.0339e-07 - reconstruction_loss: 0.6807 - total_loss: 0.6807\n","Epoch 12/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - kl_loss: 6.2940e-07 - reconstruction_loss: 0.6797 - total_loss: 0.6797\n","Epoch 13/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 5.3369e-07 - reconstruction_loss: 0.6797 - total_loss: 0.6797\n","Epoch 14/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 5.1646e-07 - reconstruction_loss: 0.6824 - total_loss: 0.6824\n","Epoch 15/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - kl_loss: 6.5703e-07 - reconstruction_loss: 0.6819 - total_loss: 0.6819\n","Epoch 16/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 6.4448e-07 - reconstruction_loss: 0.6799 - total_loss: 0.6799\n","Epoch 17/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 7.0185e-07 - reconstruction_loss: 0.6799 - total_loss: 0.6799\n","Epoch 18/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 7.7134e-07 - reconstruction_loss: 0.6828 - total_loss: 0.6828\n","Epoch 19/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 5.7064e-07 - reconstruction_loss: 0.6815 - total_loss: 0.6815\n","Epoch 20/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 7.2407e-07 - reconstruction_loss: 0.6814 - total_loss: 0.6814\n","Epoch 21/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 6.3375e-07 - reconstruction_loss: 0.6805 - total_loss: 0.6805\n","Epoch 22/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 5.8382e-07 - reconstruction_loss: 0.6811 - total_loss: 0.6811\n","Epoch 23/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 6.6868e-07 - reconstruction_loss: 0.6809 - total_loss: 0.6809\n","Epoch 24/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - kl_loss: 7.5371e-07 - reconstruction_loss: 0.6785 - total_loss: 0.6785\n","Epoch 25/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 7.7346e-07 - reconstruction_loss: 0.6811 - total_loss: 0.6811\n","Epoch 26/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - kl_loss: 6.5308e-07 - reconstruction_loss: 0.6798 - total_loss: 0.6798\n","Epoch 27/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - kl_loss: 6.2808e-07 - reconstruction_loss: 0.6805 - total_loss: 0.6805\n","Epoch 28/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 5.9354e-07 - reconstruction_loss: 0.6819 - total_loss: 0.6819\n","Epoch 29/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 7.1735e-07 - reconstruction_loss: 0.6805 - total_loss: 0.6805\n","Epoch 30/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 6.9977e-07 - reconstruction_loss: 0.6797 - total_loss: 0.6797\n","Epoch 31/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - kl_loss: 6.2306e-07 - reconstruction_loss: 0.6811 - total_loss: 0.6811\n","Epoch 32/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 6.3496e-07 - reconstruction_loss: 0.6788 - total_loss: 0.6788\n","Epoch 33/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 6.9333e-07 - reconstruction_loss: 0.6796 - total_loss: 0.6796\n","Epoch 34/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 6.0271e-07 - reconstruction_loss: 0.6847 - total_loss: 0.6847\n","Epoch 35/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - kl_loss: 7.2808e-07 - reconstruction_loss: 0.6803 - total_loss: 0.6803\n","Epoch 36/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - kl_loss: 6.7133e-07 - reconstruction_loss: 0.6796 - total_loss: 0.6796\n","Epoch 37/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 8.5830e-07 - reconstruction_loss: 0.6815 - total_loss: 0.6815\n","Epoch 38/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - kl_loss: 7.3067e-07 - reconstruction_loss: 0.6822 - total_loss: 0.6822\n","Epoch 39/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 6.7388e-07 - reconstruction_loss: 0.6796 - total_loss: 0.6796\n","Epoch 40/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 6.4140e-07 - reconstruction_loss: 0.6817 - total_loss: 0.6817\n","Epoch 41/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 6.9883e-07 - reconstruction_loss: 0.6812 - total_loss: 0.6812\n","Epoch 42/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 7.8099e-07 - reconstruction_loss: 0.6789 - total_loss: 0.6789\n","Epoch 43/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 6.9626e-07 - reconstruction_loss: 0.6818 - total_loss: 0.6818\n","Epoch 44/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - kl_loss: 7.1276e-07 - reconstruction_loss: 0.6819 - total_loss: 0.6819\n","Epoch 45/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - kl_loss: 7.3510e-07 - reconstruction_loss: 0.6782 - total_loss: 0.6782\n","Epoch 46/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 6.1207e-07 - reconstruction_loss: 0.6806 - total_loss: 0.6806\n","Epoch 47/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 8.0355e-07 - reconstruction_loss: 0.6797 - total_loss: 0.6797\n","Epoch 48/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - kl_loss: 7.7786e-07 - reconstruction_loss: 0.6830 - total_loss: 0.6830\n","Epoch 49/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - kl_loss: 7.1308e-07 - reconstruction_loss: 0.6804 - total_loss: 0.6804\n","Epoch 50/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - kl_loss: 7.1881e-07 - reconstruction_loss: 0.6799 - total_loss: 0.6799\n","Epoch 51/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 6.4561e-07 - reconstruction_loss: 0.6802 - total_loss: 0.6802\n","Epoch 52/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - kl_loss: 7.1782e-07 - reconstruction_loss: 0.6822 - total_loss: 0.6822\n","Epoch 53/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 7.4117e-07 - reconstruction_loss: 0.6797 - total_loss: 0.6797\n","Epoch 54/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 8.8117e-07 - reconstruction_loss: 0.6788 - total_loss: 0.6788\n","Epoch 55/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 8.6625e-07 - reconstruction_loss: 0.6799 - total_loss: 0.6799\n","Epoch 56/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 7.4707e-07 - reconstruction_loss: 0.6838 - total_loss: 0.6838\n","Epoch 57/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 7.9439e-07 - reconstruction_loss: 0.6794 - total_loss: 0.6794\n","Epoch 58/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - kl_loss: 9.4915e-07 - reconstruction_loss: 0.6807 - total_loss: 0.6807\n","Epoch 59/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - kl_loss: 9.4863e-07 - reconstruction_loss: 0.6812 - total_loss: 0.6812\n","Epoch 60/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - kl_loss: 8.2434e-07 - reconstruction_loss: 0.6804 - total_loss: 0.6804\n","Epoch 61/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 8.7205e-07 - reconstruction_loss: 0.6810 - total_loss: 0.6810\n","Epoch 62/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - kl_loss: 9.1596e-07 - reconstruction_loss: 0.6756 - total_loss: 0.6756\n","Epoch 63/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 7.1394e-07 - reconstruction_loss: 0.6808 - total_loss: 0.6808\n","Epoch 64/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 6.9181e-07 - reconstruction_loss: 0.6830 - total_loss: 0.6830\n","Epoch 65/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - kl_loss: 7.5432e-07 - reconstruction_loss: 0.6819 - total_loss: 0.6819\n","Epoch 66/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - kl_loss: 7.4222e-07 - reconstruction_loss: 0.6808 - total_loss: 0.6808\n","Epoch 67/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 7.4103e-07 - reconstruction_loss: 0.6813 - total_loss: 0.6813\n","Epoch 68/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - kl_loss: 7.8350e-07 - reconstruction_loss: 0.6786 - total_loss: 0.6786\n","Epoch 69/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 8.2419e-07 - reconstruction_loss: 0.6796 - total_loss: 0.6796\n","Epoch 70/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 7.2906e-07 - reconstruction_loss: 0.6805 - total_loss: 0.6805\n","Epoch 71/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 1.0202e-06 - reconstruction_loss: 0.6788 - total_loss: 0.6788\n","Epoch 72/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - kl_loss: 1.1114e-06 - reconstruction_loss: 0.6814 - total_loss: 0.6814\n","Epoch 73/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 7.4755e-07 - reconstruction_loss: 0.6807 - total_loss: 0.6807\n","Epoch 74/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 7.2617e-07 - reconstruction_loss: 0.6814 - total_loss: 0.6814\n","Epoch 75/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 7.4020e-07 - reconstruction_loss: 0.6798 - total_loss: 0.6798\n","Epoch 76/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - kl_loss: 7.4276e-07 - reconstruction_loss: 0.6808 - total_loss: 0.6808\n","Epoch 77/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 7.9438e-07 - reconstruction_loss: 0.6828 - total_loss: 0.6828\n","Epoch 78/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 6.3777e-07 - reconstruction_loss: 0.6808 - total_loss: 0.6808\n","Epoch 79/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - kl_loss: 6.2453e-07 - reconstruction_loss: 0.6806 - total_loss: 0.6806\n","Epoch 80/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 8.5453e-07 - reconstruction_loss: 0.6823 - total_loss: 0.6823\n","Epoch 81/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 7.5771e-07 - reconstruction_loss: 0.6776 - total_loss: 0.6776\n","Epoch 82/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 9.4483e-07 - reconstruction_loss: 0.6788 - total_loss: 0.6788\n","Epoch 83/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 8.9997e-07 - reconstruction_loss: 0.6809 - total_loss: 0.6809\n","Epoch 84/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 1.0093e-06 - reconstruction_loss: 0.6803 - total_loss: 0.6803\n","Epoch 85/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - kl_loss: 6.9789e-07 - reconstruction_loss: 0.6823 - total_loss: 0.6823\n","Epoch 86/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - kl_loss: 6.1272e-07 - reconstruction_loss: 0.6828 - total_loss: 0.6828\n","Epoch 87/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 8.3635e-07 - reconstruction_loss: 0.6848 - total_loss: 0.6848\n","Epoch 88/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - kl_loss: 1.0318e-06 - reconstruction_loss: 0.6794 - total_loss: 0.6794\n","Epoch 89/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 8.6696e-07 - reconstruction_loss: 0.6809 - total_loss: 0.6809\n","Epoch 90/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 6.3745e-07 - reconstruction_loss: 0.6803 - total_loss: 0.6803\n","Epoch 91/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - kl_loss: 6.5311e-07 - reconstruction_loss: 0.6784 - total_loss: 0.6784\n","Epoch 92/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - kl_loss: 9.0401e-07 - reconstruction_loss: 0.6811 - total_loss: 0.6811\n","Epoch 93/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - kl_loss: 7.2912e-07 - reconstruction_loss: 0.6788 - total_loss: 0.6788\n","Epoch 94/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 6.8743e-07 - reconstruction_loss: 0.6802 - total_loss: 0.6802\n","Epoch 95/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 9.4437e-07 - reconstruction_loss: 0.6828 - total_loss: 0.6828\n","Epoch 96/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 7.6568e-07 - reconstruction_loss: 0.6802 - total_loss: 0.6802\n","Epoch 97/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - kl_loss: 7.3131e-07 - reconstruction_loss: 0.6808 - total_loss: 0.6808\n","Epoch 98/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 8.5707e-07 - reconstruction_loss: 0.6807 - total_loss: 0.6807\n","Epoch 99/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 9.5032e-07 - reconstruction_loss: 0.6822 - total_loss: 0.6822\n","Epoch 100/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 7.4708e-07 - reconstruction_loss: 0.6808 - total_loss: 0.6808\n","Found 78 images belonging to 1 classes.\n","\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 888ms/step"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711569572.324787      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step  \n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 280ms/step\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","Training VAE for class: Chair\n","Found 280 images belonging to 1 classes.\n","Epoch 1/100\n","\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m59s\u001b[0m 7s/step - kl_loss: 1.0431e-06 - reconstruction_loss: 0.6723 - total_loss: 0.6723"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711569585.393867      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 485ms/step - kl_loss: 1.7081e-05 - reconstruction_loss: 0.6766 - total_loss: 0.6767\n","Epoch 2/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 8.7193e-06 - reconstruction_loss: 0.6763 - total_loss: 0.6763\n","Epoch 3/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 2.5231e-06 - reconstruction_loss: 0.6732 - total_loss: 0.6732\n","Epoch 4/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 1.0356e-06 - reconstruction_loss: 0.6731 - total_loss: 0.6731\n","Epoch 5/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - kl_loss: 8.7150e-07 - reconstruction_loss: 0.6697 - total_loss: 0.6697\n","Epoch 6/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 7.3747e-07 - reconstruction_loss: 0.6730 - total_loss: 0.6730\n","Epoch 7/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 6.6441e-07 - reconstruction_loss: 0.6717 - total_loss: 0.6717\n","Epoch 8/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 6.3908e-07 - reconstruction_loss: 0.6723 - total_loss: 0.6723\n","Epoch 9/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 6.5681e-07 - reconstruction_loss: 0.6693 - total_loss: 0.6693\n","Epoch 10/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - kl_loss: 4.7759e-07 - reconstruction_loss: 0.6713 - total_loss: 0.6713\n","Epoch 11/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 6.9190e-07 - reconstruction_loss: 0.6729 - total_loss: 0.6729\n","Epoch 12/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 8.8788e-07 - reconstruction_loss: 0.6683 - total_loss: 0.6683\n","Epoch 13/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - kl_loss: 1.0282e-06 - reconstruction_loss: 0.6684 - total_loss: 0.6684\n","Epoch 14/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - kl_loss: 6.4331e-07 - reconstruction_loss: 0.6726 - total_loss: 0.6726\n","Epoch 15/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - kl_loss: 7.4815e-07 - reconstruction_loss: 0.6685 - total_loss: 0.6685\n","Epoch 16/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 7.1709e-07 - reconstruction_loss: 0.6735 - total_loss: 0.6735\n","Epoch 17/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 7.3192e-07 - reconstruction_loss: 0.6722 - total_loss: 0.6722\n","Epoch 18/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 9.1399e-07 - reconstruction_loss: 0.6688 - total_loss: 0.6688\n","Epoch 19/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 7.2503e-07 - reconstruction_loss: 0.6729 - total_loss: 0.6729\n","Epoch 20/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 7.1363e-07 - reconstruction_loss: 0.6714 - total_loss: 0.6714\n","Epoch 21/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 6.5337e-07 - reconstruction_loss: 0.6692 - total_loss: 0.6692\n","Epoch 22/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 7.9808e-07 - reconstruction_loss: 0.6732 - total_loss: 0.6732\n","Epoch 23/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 6.3259e-07 - reconstruction_loss: 0.6717 - total_loss: 0.6717\n","Epoch 24/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - kl_loss: 7.6579e-07 - reconstruction_loss: 0.6704 - total_loss: 0.6704\n","Epoch 25/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - kl_loss: 7.7520e-07 - reconstruction_loss: 0.6701 - total_loss: 0.6701\n","Epoch 26/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 6.4071e-07 - reconstruction_loss: 0.6717 - total_loss: 0.6717\n","Epoch 27/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 6.1368e-07 - reconstruction_loss: 0.6727 - total_loss: 0.6727\n","Epoch 28/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 8.8350e-07 - reconstruction_loss: 0.6744 - total_loss: 0.6744\n","Epoch 29/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - kl_loss: 7.8160e-07 - reconstruction_loss: 0.6722 - total_loss: 0.6722\n","Epoch 30/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 8.5259e-07 - reconstruction_loss: 0.6696 - total_loss: 0.6696\n","Epoch 31/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 7.3643e-07 - reconstruction_loss: 0.6697 - total_loss: 0.6697\n","Epoch 32/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 9.3251e-07 - reconstruction_loss: 0.6686 - total_loss: 0.6686\n","Epoch 33/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 7.6937e-07 - reconstruction_loss: 0.6714 - total_loss: 0.6714\n","Epoch 34/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - kl_loss: 8.3433e-07 - reconstruction_loss: 0.6711 - total_loss: 0.6711\n","Epoch 35/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - kl_loss: 9.6779e-07 - reconstruction_loss: 0.6721 - total_loss: 0.6721\n","Epoch 36/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 1.1054e-06 - reconstruction_loss: 0.6720 - total_loss: 0.6720\n","Epoch 37/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 1.3788e-06 - reconstruction_loss: 0.6707 - total_loss: 0.6707\n","Epoch 38/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 7.6564e-07 - reconstruction_loss: 0.6694 - total_loss: 0.6694\n","Epoch 39/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 8.3339e-07 - reconstruction_loss: 0.6720 - total_loss: 0.6720\n","Epoch 40/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 7.7334e-07 - reconstruction_loss: 0.6720 - total_loss: 0.6720\n","Epoch 41/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - kl_loss: 8.3947e-07 - reconstruction_loss: 0.6713 - total_loss: 0.6713\n","Epoch 42/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - kl_loss: 8.7413e-07 - reconstruction_loss: 0.6718 - total_loss: 0.6718\n","Epoch 43/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - kl_loss: 7.3822e-07 - reconstruction_loss: 0.6689 - total_loss: 0.6689\n","Epoch 44/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 7.7092e-07 - reconstruction_loss: 0.6730 - total_loss: 0.6730\n","Epoch 45/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 6.6207e-07 - reconstruction_loss: 0.6699 - total_loss: 0.6699\n","Epoch 46/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 7.5813e-07 - reconstruction_loss: 0.6707 - total_loss: 0.6707\n","Epoch 47/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 7.0917e-07 - reconstruction_loss: 0.6708 - total_loss: 0.6708\n","Epoch 48/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - kl_loss: 8.2130e-07 - reconstruction_loss: 0.6715 - total_loss: 0.6715\n","Epoch 49/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - kl_loss: 6.1404e-07 - reconstruction_loss: 0.6691 - total_loss: 0.6691\n","Epoch 50/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 6.9861e-07 - reconstruction_loss: 0.6709 - total_loss: 0.6709\n","Epoch 51/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 6.0002e-07 - reconstruction_loss: 0.6711 - total_loss: 0.6711\n","Epoch 52/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 7.6019e-07 - reconstruction_loss: 0.6729 - total_loss: 0.6729\n","Epoch 53/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 9.5249e-07 - reconstruction_loss: 0.6725 - total_loss: 0.6725\n","Epoch 54/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 8.5533e-07 - reconstruction_loss: 0.6680 - total_loss: 0.6680\n","Epoch 55/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 7.3471e-07 - reconstruction_loss: 0.6721 - total_loss: 0.6721\n","Epoch 56/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 8.9547e-07 - reconstruction_loss: 0.6721 - total_loss: 0.6721\n","Epoch 57/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 8.7162e-07 - reconstruction_loss: 0.6727 - total_loss: 0.6727\n","Epoch 58/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 8.1696e-07 - reconstruction_loss: 0.6691 - total_loss: 0.6691\n","Epoch 59/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - kl_loss: 1.0344e-06 - reconstruction_loss: 0.6749 - total_loss: 0.6749\n","Epoch 60/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 9.0500e-07 - reconstruction_loss: 0.6719 - total_loss: 0.6719\n","Epoch 61/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - kl_loss: 8.6615e-07 - reconstruction_loss: 0.6731 - total_loss: 0.6731\n","Epoch 62/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - kl_loss: 5.8780e-07 - reconstruction_loss: 0.6716 - total_loss: 0.6716\n","Epoch 63/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 1.0427e-06 - reconstruction_loss: 0.6688 - total_loss: 0.6688\n","Epoch 64/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 7.5099e-07 - reconstruction_loss: 0.6720 - total_loss: 0.6720\n","Epoch 65/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 7.3735e-07 - reconstruction_loss: 0.6706 - total_loss: 0.6706\n","Epoch 66/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 7.9230e-07 - reconstruction_loss: 0.6687 - total_loss: 0.6687\n","Epoch 67/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 6.3267e-07 - reconstruction_loss: 0.6708 - total_loss: 0.6708\n","Epoch 68/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 6.8021e-07 - reconstruction_loss: 0.6724 - total_loss: 0.6724\n","Epoch 69/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - kl_loss: 6.3284e-07 - reconstruction_loss: 0.6739 - total_loss: 0.6739\n","Epoch 70/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 6.7701e-07 - reconstruction_loss: 0.6746 - total_loss: 0.6746\n","Epoch 71/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 8.4209e-07 - reconstruction_loss: 0.6683 - total_loss: 0.6683\n","Epoch 72/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 8.9125e-07 - reconstruction_loss: 0.6703 - total_loss: 0.6703\n","Epoch 73/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - kl_loss: 6.6572e-07 - reconstruction_loss: 0.6714 - total_loss: 0.6714\n","Epoch 74/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 7.2696e-07 - reconstruction_loss: 0.6702 - total_loss: 0.6702\n","Epoch 75/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - kl_loss: 6.6096e-07 - reconstruction_loss: 0.6696 - total_loss: 0.6696\n","Epoch 76/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - kl_loss: 8.4840e-07 - reconstruction_loss: 0.6743 - total_loss: 0.6743\n","Epoch 77/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 7.0743e-07 - reconstruction_loss: 0.6712 - total_loss: 0.6712\n","Epoch 78/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 6.4869e-07 - reconstruction_loss: 0.6723 - total_loss: 0.6723\n","Epoch 79/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 5.8425e-07 - reconstruction_loss: 0.6731 - total_loss: 0.6731\n","Epoch 80/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 8.2509e-07 - reconstruction_loss: 0.6735 - total_loss: 0.6735\n","Epoch 81/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - kl_loss: 8.4290e-07 - reconstruction_loss: 0.6725 - total_loss: 0.6725\n","Epoch 82/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 7.9557e-07 - reconstruction_loss: 0.6721 - total_loss: 0.6721\n","Epoch 83/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 6.7283e-07 - reconstruction_loss: 0.6706 - total_loss: 0.6706\n","Epoch 84/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - kl_loss: 6.6375e-07 - reconstruction_loss: 0.6706 - total_loss: 0.6706\n","Epoch 85/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - kl_loss: 8.2938e-07 - reconstruction_loss: 0.6726 - total_loss: 0.6726\n","Epoch 86/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 4.6265e-07 - reconstruction_loss: 0.6699 - total_loss: 0.6699\n","Epoch 87/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - kl_loss: 8.1804e-07 - reconstruction_loss: 0.6691 - total_loss: 0.6691\n","Epoch 88/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - kl_loss: 1.0756e-06 - reconstruction_loss: 0.6661 - total_loss: 0.6661\n","Epoch 89/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 7.8301e-07 - reconstruction_loss: 0.6729 - total_loss: 0.6729\n","Epoch 90/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 8.2805e-07 - reconstruction_loss: 0.6738 - total_loss: 0.6738\n","Epoch 91/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 7.8745e-07 - reconstruction_loss: 0.6697 - total_loss: 0.6697\n","Epoch 92/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 6.3702e-07 - reconstruction_loss: 0.6708 - total_loss: 0.6708\n","Epoch 93/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - kl_loss: 6.9156e-07 - reconstruction_loss: 0.6726 - total_loss: 0.6726\n","Epoch 94/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 5.5936e-07 - reconstruction_loss: 0.6703 - total_loss: 0.6703\n","Epoch 95/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 7.4585e-07 - reconstruction_loss: 0.6718 - total_loss: 0.6718\n","Epoch 96/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - kl_loss: 8.3433e-07 - reconstruction_loss: 0.6703 - total_loss: 0.6703\n","Epoch 97/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - kl_loss: 7.3323e-07 - reconstruction_loss: 0.6691 - total_loss: 0.6691\n","Epoch 98/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - kl_loss: 7.0999e-07 - reconstruction_loss: 0.6722 - total_loss: 0.6722\n","Epoch 99/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - kl_loss: 6.4033e-07 - reconstruction_loss: 0.6712 - total_loss: 0.6712\n","Epoch 100/100\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - kl_loss: 8.6178e-07 - reconstruction_loss: 0.6715 - total_loss: 0.6715\n","Found 71 images belonging to 1 classes.\n","\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 905ms/step"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711569765.107495      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 382ms/step\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step \n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n"]}],"source":["\n","output_folder_path= \"/content/generated_data-500samples\"\n","output_folder= \"/content/generated_data-500samples\"\n","# Loop through each class and train the VAE model\n","for class_name in class_names:\n","    print(f\"Training VAE for class: {class_name}\")\n"," \n","    # Create a VAE instance\n","    vae = VAE(encoder, decoder)\n","\n","    # Compile the VAE model\n","    optimizer = optimizers.Adam(learning_rate=0.001)\n","    vae.compile(optimizer=optimizer)\n","\n","    # Create output folder if it doesn't exist\n","    os.makedirs(output_folder_path, exist_ok=True)\n","\n","    # Configure the ImageDataGenerator for loading training data\n","    train_datagen = ImageDataGenerator(rescale=1./255)\n","\n","    # Define the path to the class directory\n","    class_folder_path = os.path.join(train_folder_path, class_name)\n","\n","    # Configure the ImageDataGenerator for loading training data\n","    train_datagen = ImageDataGenerator(rescale=1./255)\n","\n","    # Load training data for the current class\n","    train_generator = train_datagen.flow_from_directory(\n","        directory=class_folder_path,\n","        classes=[class_name],\n","        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n","        batch_size=16,\n","        class_mode=None,  # No labels needed, only images\n","        shuffle=True\n","    )\n","\n","\n","    # Train the VAE model\n","    vae.fit(train_generator, epochs=100)\n","    test_folder_path = \"/content/test\"\n","    test_folder_path = os.path.join(test_folder_path, class_name)\n","\n","    # target_size = (224, 224)\n","\n","\n","    test_datagen = ImageDataGenerator(rescale=1./255)  # Normalize pixel values to [0,1]\n","\n","    test_generator = test_datagen.flow_from_directory(\n","    directory=test_folder_path,\n","    classes=[class_name],\n","    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n","    batch_size=16,\n","    class_mode=None,  # No labels needed, only images\n","    shuffle=True\n","    )\n","\n","\n","    latent_dim = 2  #latent space dimension is 2\n","    grid_width, grid_height = (50, 10)  #500 samples *50x10=500*\n","    z_sample = np.random.normal(size=(grid_width * grid_height, EMBEDDING_DIM))\n","\n","    # Decode the sampled points\n","    reconstructions = vae.decoder.predict(z_sample)\n","\n","\n","    # Create output subfolder for the current class\n","    class_output_folder = os.path.join(output_folder, class_name)\n","    os.makedirs(class_output_folder, exist_ok=True)\n","\n","    # Save the resized images\n","    for i, image in enumerate(reconstructions):\n","        image_path = os.path.join(class_output_folder, f\"image_{i+1}.jpg\")\n","        # Convert image to uint8 format\n","        image_uint8 = (image * 255).astype(np.uint8)\n","        # Create PIL image from numpy array\n","        pil_image = Image.fromarray(image_uint8)\n","        # Save the image\n","        pil_image.save(image_path)\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Copying the 100 generated images into the train folder"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","import random\n","\n","\n","# Define paths\n","samples_folder = '/content/generated_data-500samples'\n","train_folder = '/content/train'\n","\n","# Ensure the train folder exists\n","os.makedirs(train_folder, exist_ok=True)\n","\n","# Iterate through each class folder in the 500 samples folder\n","for class_name in os.listdir(samples_folder):\n","    class_folder = os.path.join(samples_folder, class_name)\n","    \n","    # Ensure it's a directory\n","    if os.path.isdir(class_folder):\n","        # Create the corresponding class subfolder in the train folder\n","        class_train_folder = os.path.join(train_folder, class_name, class_name)\n","        os.makedirs(class_train_folder, exist_ok=True)\n","        \n","        # Get a list of all images in the class folder\n","        images = os.listdir(class_folder)\n","        \n","        # Randomly select 100 images\n","        selected_images = random.sample(images, 100)\n","        \n","        # Copy selected images to the train folder\n","        for image in selected_images:\n","            src_path = os.path.join(class_folder, image)\n","            dest_path = os.path.join(class_train_folder, image)\n","            shutil.copy(src_path, dest_path)\n","            print(f\"Copied {image} to {class_train_folder}\")\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T20:15:32.082646Z","iopub.status.busy":"2024-03-27T20:15:32.082261Z","iopub.status.idle":"2024-03-27T20:15:33.271403Z","shell.execute_reply":"2024-03-27T20:15:33.270389Z","shell.execute_reply.started":"2024-03-27T20:15:32.082615Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 800x800 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["from scipy.stats import norm\n","import matplotlib.pyplot as plt\n","# Sample some points in the latent space, from the standard normal distribution\n","grid_width, grid_height = (50, 10)\n","z_sample = np.random.normal(size=(grid_width * grid_height, 100))\n","# Decode the sampled points\n","reconstructions = vae.decoder.predict(z_sample)\n","# Convert original embeddings and sampled embeddings to p-values\n","p = norm.cdf(z)\n","p_sample = norm.cdf(z_sample)\n","# Draw a plot of...\n","figsize = 8\n","plt.figure(figsize=(figsize, figsize))\n","\n","# ... the original embeddings ...\n","plt.scatter(z[:, 0], z[:, 1], c=\"black\", alpha=0.5, s=2)\n","\n","# ... and the newly generated points in the latent space\n","plt.scatter(z_sample[:, 0], z_sample[:, 1], c=\"#00B0F0\", alpha=1, s=40)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Training the Binary Classifier"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T20:17:09.263917Z","iopub.status.busy":"2024-03-27T20:17:09.263114Z","iopub.status.idle":"2024-03-27T20:17:09.644665Z","shell.execute_reply":"2024-03-27T20:17:09.643644Z","shell.execute_reply.started":"2024-03-27T20:17:09.263881Z"},"trusted":true},"outputs":[],"source":["import os\n","import shutil\n","\n","# Define the path to the train directory\n","train_dir = \"/content/train\"\n","\n","# Iterate over each subfolder in the train directory\n","for class_name in os.listdir(train_dir):\n","    class_dir = os.path.join(train_dir, class_name)\n","    \n","    # Check if the item in the directory is a subfolder\n","    if os.path.isdir(class_dir):\n","        # Define the path to the subsubfolder\n","        subsubfolder_dir = os.path.join(class_dir, class_name)\n","        \n","        # Check if the subsubfolder exists\n","        if os.path.exists(subsubfolder_dir):\n","            # Iterate over each file in the subsubfolder\n","            for file_name in os.listdir(subsubfolder_dir):\n","                file_path = os.path.join(subsubfolder_dir, file_name)\n","                \n","                # Move the file to the parent subfolder\n","                if os.path.isfile(file_path):\n","                    shutil.move(file_path, class_dir)\n","            \n","            # Remove the empty subsubfolder\n","            os.rmdir(subsubfolder_dir)\n"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T20:17:31.487717Z","iopub.status.busy":"2024-03-27T20:17:31.487327Z","iopub.status.idle":"2024-03-27T20:17:31.524670Z","shell.execute_reply":"2024-03-27T20:17:31.523660Z","shell.execute_reply.started":"2024-03-27T20:17:31.487686Z"},"trusted":true},"outputs":[],"source":["import os\n","import pandas as pd\n","import random\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications.vgg16 import VGG16\n","from tensorflow.keras.layers import Input, Flatten, Dense\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","\n","# Set the paths to the train and test directories\n","train_folder_path = \"/content/train\"\n","\n","# Each class has its own directory within the train directory\n","class_names = [d for d in os.listdir(train_folder_path) if os.path.isdir(os.path.join(train_folder_path, d))]\n","\n","# Create a dictionary to hold our training image paths\n","train_data_lists = {class_name: [os.path.join(train_folder_path, class_name, img)\n","                                 for img in os.listdir(os.path.join(train_folder_path, class_name))]\n","                    for class_name in class_names}\n","\n","def build_binary_classification_model():\n","    base_model = VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n","    x = Flatten()(base_model.output)\n","    x = Dense(256, activation='relu')(x)\n","    x = Dense(1, activation='sigmoid')(x)\n","    model = Model(inputs=base_model.input, outputs=x)\n","    model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","# Configure the ImageDataGenerator for training data augmentation\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True\n",")"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T20:21:47.273429Z","iopub.status.busy":"2024-03-27T20:21:47.273071Z","iopub.status.idle":"2024-03-27T20:53:42.064272Z","shell.execute_reply":"2024-03-27T20:53:42.063265Z","shell.execute_reply.started":"2024-03-27T20:21:47.273402Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training for class: Cat\n","Number of positive samples for Cat: 362\n","Number of negative samples before balancing: 6545\n","Number of negative samples after balancing: 362\n","Found 579 validated image filenames belonging to 2 classes.\n","Found 145 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711570916.501287      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m 8/18\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 3s/step - accuracy: 0.4938 - loss: 0.9617  "]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711570936.761835      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5191 - loss: 0.8871"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711570941.792594      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5217 - loss: 0.8812 - val_accuracy: 0.6484 - val_loss: 0.5867\n","Epoch 2/10\n","\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 383ms/step - accuracy: 0.7188 - loss: 0.5770"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.7188 - loss: 0.5770 - val_accuracy: 0.7059 - val_loss: 0.5906\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711570961.017522      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 428ms/step - accuracy: 0.6867 - loss: 0.5625 - val_accuracy: 0.6562 - val_loss: 0.5932\n","Epoch 4/10\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6875 - loss: 0.5134 - val_accuracy: 0.6471 - val_loss: 0.5891\n","Epoch 5/10\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 407ms/step - accuracy: 0.7436 - loss: 0.5249 - val_accuracy: 0.7344 - val_loss: 0.5545\n","Epoch 6/10\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6250 - loss: 0.6533 - val_accuracy: 0.5294 - val_loss: 0.8044\n","Epoch 7/10\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 423ms/step - accuracy: 0.6746 - loss: 0.5584 - val_accuracy: 0.7109 - val_loss: 0.5042\n","Epoch 8/10\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7500 - loss: 0.4272 - val_accuracy: 0.8235 - val_loss: 0.3720\n","Epoch 9/10\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 424ms/step - accuracy: 0.7845 - loss: 0.4247 - val_accuracy: 0.7109 - val_loss: 0.5479\n","Epoch 10/10\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8125 - loss: 0.4178 - val_accuracy: 0.6471 - val_loss: 0.5339\n","Finished training for class: Cat\n","Training for class: Sofa\n","Number of positive samples for Sofa: 207\n","Number of negative samples before balancing: 6700\n","Number of negative samples after balancing: 207\n","Found 331 validated image filenames belonging to 2 classes.\n","Found 83 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711571014.100407      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m 3/10\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 386ms/step - accuracy: 0.5295 - loss: 0.7479"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711571050.326675      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5549 - loss: 0.7680"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711571053.809749      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 4s/step - accuracy: 0.5553 - loss: 0.7666 - val_accuracy: 0.4531 - val_loss: 0.7341\n","Epoch 2/10\n","\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 386ms/step - accuracy: 0.5312 - loss: 0.6805"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.5312 - loss: 0.6805 - val_accuracy: 0.4737 - val_loss: 0.7439\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711571074.503574      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 397ms/step - accuracy: 0.6421 - loss: 0.6428 - val_accuracy: 0.6875 - val_loss: 0.6200\n","Epoch 4/10\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6562 - loss: 0.5688 - val_accuracy: 0.5789 - val_loss: 0.8273\n","Epoch 5/10\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 402ms/step - accuracy: 0.6065 - loss: 0.5823 - val_accuracy: 0.6406 - val_loss: 0.6074\n","Epoch 6/10\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5625 - loss: 0.6379 - val_accuracy: 0.6316 - val_loss: 0.7440\n","Epoch 7/10\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 400ms/step - accuracy: 0.6550 - loss: 0.6012 - val_accuracy: 0.6094 - val_loss: 0.6891\n","Epoch 8/10\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6250 - loss: 0.5143 - val_accuracy: 0.4211 - val_loss: 0.8428\n","Epoch 9/10\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 424ms/step - accuracy: 0.7167 - loss: 0.5636 - val_accuracy: 0.5469 - val_loss: 0.8696\n","Epoch 10/10\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7188 - loss: 0.6686 - val_accuracy: 0.5789 - val_loss: 0.6471\n","Finished training for class: Sofa\n","Training for class: Sheep\n","Number of positive samples for Sheep: 151\n","Number of negative samples before balancing: 6756\n","Number of negative samples after balancing: 151\n","Found 241 validated image filenames belonging to 2 classes.\n","Found 61 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711571113.188959      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m6/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - accuracy: 0.4996 - loss: 0.8278"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711571145.198617      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 5s/step - accuracy: 0.5194 - loss: 0.8053 - val_accuracy: 0.7188 - val_loss: 0.5355\n","Epoch 2/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711571146.384614      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 384ms/step - accuracy: 0.6562 - loss: 0.6293"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5s/step - accuracy: 0.6562 - loss: 0.6293 - val_accuracy: 0.7586 - val_loss: 0.4675\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711571175.031345      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 388ms/step - accuracy: 0.6562 - loss: 0.6878 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n","Epoch 4/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.7500 - loss: 0.5950 - val_accuracy: 0.7500 - val_loss: 0.5275\n","Epoch 5/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 384ms/step - accuracy: 0.7189 - loss: 0.5963 - val_accuracy: 0.7241 - val_loss: 0.5799\n","Epoch 6/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8750 - loss: 0.3106 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n","Epoch 7/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 400ms/step - accuracy: 0.7621 - loss: 0.5076 - val_accuracy: 0.8125 - val_loss: 0.4280\n","Epoch 8/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8125 - loss: 0.4568 - val_accuracy: 0.7586 - val_loss: 0.4376\n","Epoch 9/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 367ms/step - accuracy: 0.7752 - loss: 0.5181 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n","Epoch 10/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9375 - loss: 0.3766 - val_accuracy: 0.8438 - val_loss: 0.4327\n","Finished training for class: Sheep\n","Training for class: Diningtable\n","Number of positive samples for Diningtable: 184\n","Number of negative samples before balancing: 6723\n","Number of negative samples after balancing: 184\n","Found 294 validated image filenames belonging to 2 classes.\n","Found 74 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711571209.674637      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m2/9\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:49\u001b[0m 24s/step - accuracy: 0.5888 - loss: 0.8137"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711571234.224046      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5383 - loss: 0.8424"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711571238.046211      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4s/step - accuracy: 0.5356 - loss: 0.8387 - val_accuracy: 0.5312 - val_loss: 0.7117\n","Epoch 2/10\n","\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 390ms/step - accuracy: 0.5000 - loss: 0.7512"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.5000 - loss: 0.7512 - val_accuracy: 0.6000 - val_loss: 0.6834\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711571250.798737      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 397ms/step - accuracy: 0.6117 - loss: 0.6532 - val_accuracy: 0.6094 - val_loss: 0.6394\n","Epoch 4/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6562 - loss: 0.6257 - val_accuracy: 0.7000 - val_loss: 0.5908\n","Epoch 5/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 452ms/step - accuracy: 0.6699 - loss: 0.5983 - val_accuracy: 0.5938 - val_loss: 0.6632\n","Epoch 6/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5625 - loss: 0.6633 - val_accuracy: 0.5000 - val_loss: 0.6944\n","Epoch 7/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 391ms/step - accuracy: 0.6076 - loss: 0.6695 - val_accuracy: 0.5312 - val_loss: 0.6755\n","Epoch 8/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5625 - loss: 0.6767 - val_accuracy: 0.5000 - val_loss: 0.6867\n","Epoch 9/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 395ms/step - accuracy: 0.6502 - loss: 0.6478 - val_accuracy: 0.5625 - val_loss: 0.6631\n","Epoch 10/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7188 - loss: 0.5501 - val_accuracy: 0.8000 - val_loss: 0.5401\n","Finished training for class: Diningtable\n","Training for class: Horse\n","Number of positive samples for Horse: 258\n","Number of negative samples before balancing: 6649\n","Number of negative samples after balancing: 258\n","Found 412 validated image filenames belonging to 2 classes.\n","Found 104 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711571354.679989      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14:02\u001b[0m 77s/step - accuracy: 0.4643 - loss: 0.7181"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711571357.291683      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591ms/step - accuracy: 0.5419 - loss: 0.8757"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711571362.484510      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 703ms/step - accuracy: 0.5421 - loss: 0.8685 - val_accuracy: 0.5625 - val_loss: 0.6925\n","Epoch 2/10\n","\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 381ms/step - accuracy: 0.5000 - loss: 0.7061"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 883ms/step - accuracy: 0.5000 - loss: 0.7061 - val_accuracy: 0.7500 - val_loss: 0.5664\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711571372.894466      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 430ms/step - accuracy: 0.4850 - loss: 0.7178 - val_accuracy: 0.4479 - val_loss: 0.7046\n","Epoch 4/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4286 - loss: 0.7080 - val_accuracy: 0.2500 - val_loss: 0.7212\n","Epoch 5/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 431ms/step - accuracy: 0.5426 - loss: 0.6882 - val_accuracy: 0.5833 - val_loss: 0.6767\n","Epoch 6/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6071 - loss: 0.6630 - val_accuracy: 0.2500 - val_loss: 0.8170\n","Epoch 7/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 430ms/step - accuracy: 0.5006 - loss: 0.7044 - val_accuracy: 0.5729 - val_loss: 0.6901\n","Epoch 8/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5000 - loss: 0.6938 - val_accuracy: 0.5000 - val_loss: 0.6985\n","Epoch 9/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 440ms/step - accuracy: 0.5551 - loss: 0.6859 - val_accuracy: 0.6875 - val_loss: 0.6824\n","Epoch 10/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7812 - loss: 0.6750 - val_accuracy: 0.3750 - val_loss: 0.7336\n","Finished training for class: Horse\n","Training for class: Person\n","Number of positive samples for Person: 1701\n","Number of negative samples before balancing: 5206\n","Number of negative samples after balancing: 1701\n","Found 2721 validated image filenames belonging to 2 classes.\n","Found 681 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711571417.140117      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521ms/step - accuracy: 0.6186 - loss: 0.6734"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711571462.277415      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 563ms/step - accuracy: 0.6187 - loss: 0.6730 - val_accuracy: 0.6369 - val_loss: 0.6182\n","Epoch 2/10\n","\u001b[1m 1/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 386ms/step - accuracy: 0.7500 - loss: 0.5503"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 133ms/step - accuracy: 0.7500 - loss: 0.5503 - val_accuracy: 0.6667 - val_loss: 0.6861\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711571476.328152      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 424ms/step - accuracy: 0.6623 - loss: 0.6200 - val_accuracy: 0.6354 - val_loss: 0.6155\n","Epoch 4/10\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - accuracy: 0.7812 - loss: 0.5221 - val_accuracy: 0.8889 - val_loss: 0.4870\n","Epoch 5/10\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 428ms/step - accuracy: 0.6856 - loss: 0.5949 - val_accuracy: 0.6473 - val_loss: 0.6047\n","Epoch 6/10\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.6250 - loss: 0.6696 - val_accuracy: 0.6667 - val_loss: 0.7906\n","Epoch 7/10\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 423ms/step - accuracy: 0.6648 - loss: 0.6126 - val_accuracy: 0.6503 - val_loss: 0.6055\n","Epoch 8/10\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.5625 - loss: 0.6710 - val_accuracy: 0.6667 - val_loss: 0.4902\n","Epoch 9/10\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 424ms/step - accuracy: 0.6807 - loss: 0.6015 - val_accuracy: 0.6562 - val_loss: 0.6038\n","Epoch 10/10\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.7812 - loss: 0.5761 - val_accuracy: 0.7778 - val_loss: 0.4347\n","Finished training for class: Person\n","Training for class: Motorbike\n","Number of positive samples for Motorbike: 263\n","Number of negative samples before balancing: 6644\n","Number of negative samples after balancing: 263\n","Found 420 validated image filenames belonging to 2 classes.\n","Found 106 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711571644.799887      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m 4/13\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:02\u001b[0m 7s/step - accuracy: 0.5460 - loss: 0.8535 "]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711571666.021081      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5414 - loss: 0.8163"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711571670.660013      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2s/step - accuracy: 0.5432 - loss: 0.8122 - val_accuracy: 0.6146 - val_loss: 0.6784\n","Epoch 2/10\n","\u001b[1m 1/13\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 387ms/step - accuracy: 0.5938 - loss: 0.6796"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5938 - loss: 0.6796 - val_accuracy: 0.9000 - val_loss: 0.4975\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711571671.847429      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 428ms/step - accuracy: 0.5519 - loss: 0.6925 - val_accuracy: 0.6979 - val_loss: 0.6604\n","Epoch 4/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6250 - loss: 0.6568 - val_accuracy: 0.8000 - val_loss: 0.5918\n","Epoch 5/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 435ms/step - accuracy: 0.6503 - loss: 0.6456 - val_accuracy: 0.7188 - val_loss: 0.6136\n","Epoch 6/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.4086 - val_accuracy: 0.9000 - val_loss: 0.4654\n","Epoch 7/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 433ms/step - accuracy: 0.5889 - loss: 0.6314 - val_accuracy: 0.6771 - val_loss: 0.6082\n","Epoch 8/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7500 - loss: 0.5709 - val_accuracy: 0.7000 - val_loss: 0.7489\n","Epoch 9/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 434ms/step - accuracy: 0.6856 - loss: 0.5801 - val_accuracy: 0.7188 - val_loss: 0.5924\n","Epoch 10/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7500 - loss: 0.5267 - val_accuracy: 0.6000 - val_loss: 0.8626\n","Finished training for class: Motorbike\n","Training for class: Bus\n","Number of positive samples for Bus: 180\n","Number of negative samples before balancing: 6727\n","Number of negative samples after balancing: 180\n","Found 288 validated image filenames belonging to 2 classes.\n","Found 72 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711571717.178711      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - accuracy: 0.5624 - loss: 0.8048"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711571721.619044      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 532ms/step - accuracy: 0.5593 - loss: 0.8010 - val_accuracy: 0.4688 - val_loss: 0.7091\n","Epoch 2/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.7500 - val_loss: 0.6392\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711571722.257669      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 440ms/step - accuracy: 0.5491 - loss: 0.6739 - val_accuracy: 0.5781 - val_loss: 0.7113\n","Epoch 4/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.7500 - val_loss: 0.6450\n","Epoch 5/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 441ms/step - accuracy: 0.6273 - loss: 0.6410 - val_accuracy: 0.7031 - val_loss: 0.6150\n","Epoch 6/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.7500 - val_loss: 0.5073\n","Epoch 7/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 445ms/step - accuracy: 0.7042 - loss: 0.5655 - val_accuracy: 0.7969 - val_loss: 0.4391\n","Epoch 8/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.8750 - val_loss: 0.3703\n","Epoch 9/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 448ms/step - accuracy: 0.7146 - loss: 0.5398 - val_accuracy: 0.7812 - val_loss: 0.5399\n","Epoch 10/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.2500 - val_loss: 0.9993\n","Finished training for class: Bus\n","Training for class: Bicycle\n","Number of positive samples for Bicycle: 253\n","Number of negative samples before balancing: 6654\n","Number of negative samples after balancing: 253\n","Found 404 validated image filenames belonging to 2 classes.\n","Found 102 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711571759.352243      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m 6/12\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 398ms/step - accuracy: 0.5259 - loss: 0.9273"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711571814.755423      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.5330 - loss: 0.8436"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711571817.850344      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 5s/step - accuracy: 0.5327 - loss: 0.8361 - val_accuracy: 0.5833 - val_loss: 0.6850\n","Epoch 2/10\n","\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 383ms/step - accuracy: 0.3750 - loss: 0.7898"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.3750 - loss: 0.7898 - val_accuracy: 0.5000 - val_loss: 0.7044\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711571819.102821      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 426ms/step - accuracy: 0.4764 - loss: 0.7034 - val_accuracy: 0.4167 - val_loss: 0.7551\n","Epoch 4/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4688 - loss: 0.7270 - val_accuracy: 0.5000 - val_loss: 0.7058\n","Epoch 5/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 426ms/step - accuracy: 0.5224 - loss: 0.6956 - val_accuracy: 0.4583 - val_loss: 0.6964\n","Epoch 6/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5000 - loss: 0.6889 - val_accuracy: 0.6667 - val_loss: 0.6882\n","Epoch 7/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 425ms/step - accuracy: 0.5511 - loss: 0.6885 - val_accuracy: 0.4479 - val_loss: 0.6986\n","Epoch 8/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6562 - loss: 0.6391 - val_accuracy: 0.6667 - val_loss: 0.6800\n","Epoch 9/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 426ms/step - accuracy: 0.6059 - loss: 0.6591 - val_accuracy: 0.7292 - val_loss: 0.6183\n","Epoch 10/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4688 - loss: 0.7020 - val_accuracy: 0.3333 - val_loss: 0.8034\n","Finished training for class: Bicycle\n","Training for class: Aeroplane\n","Number of positive samples for Aeroplane: 288\n","Number of negative samples before balancing: 6619\n","Number of negative samples after balancing: 288\n","Found 460 validated image filenames belonging to 2 classes.\n","Found 116 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711571861.581381      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m11/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1s\u001b[0m 398ms/step - accuracy: 0.5793 - loss: 0.6737"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711571903.313635      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5913 - loss: 0.6603 "]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711571905.354552      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 3s/step - accuracy: 0.5945 - loss: 0.6564 - val_accuracy: 0.7500 - val_loss: 0.5326\n","Epoch 2/10\n","\u001b[1m 1/14\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 385ms/step - accuracy: 0.7188 - loss: 0.5538"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7188 - loss: 0.5538 - val_accuracy: 0.7000 - val_loss: 0.4758\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711571906.622061      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 440ms/step - accuracy: 0.7383 - loss: 0.4880 - val_accuracy: 0.7292 - val_loss: 0.5302\n","Epoch 4/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5938 - loss: 0.6280 - val_accuracy: 0.8000 - val_loss: 0.4710\n","Epoch 5/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 407ms/step - accuracy: 0.7383 - loss: 0.4566 - val_accuracy: 0.7708 - val_loss: 0.6459\n","Epoch 6/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7812 - loss: 0.4679 - val_accuracy: 0.7000 - val_loss: 0.6551\n","Epoch 7/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 428ms/step - accuracy: 0.7398 - loss: 0.4839 - val_accuracy: 0.7188 - val_loss: 0.5852\n","Epoch 8/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9167 - loss: 0.2034 - val_accuracy: 0.8500 - val_loss: 0.2832\n","Epoch 9/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 420ms/step - accuracy: 0.8493 - loss: 0.3243 - val_accuracy: 0.7083 - val_loss: 0.4849\n","Epoch 10/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.4380 - val_accuracy: 1.0000 - val_loss: 0.1366\n","Finished training for class: Aeroplane\n","Training for class: Train\n","Number of positive samples for Train: 220\n","Number of negative samples before balancing: 6687\n","Number of negative samples after balancing: 220\n","Found 352 validated image filenames belonging to 2 classes.\n","Found 88 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711571953.088263      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - accuracy: 0.4937 - loss: 0.7840"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711571958.380502      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 508ms/step - accuracy: 0.4921 - loss: 0.7816 - val_accuracy: 0.5312 - val_loss: 0.6846\n","Epoch 2/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2s/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.3750 - val_loss: 0.6991\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711571982.721479      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 429ms/step - accuracy: 0.5429 - loss: 0.6924 - val_accuracy: 0.5312 - val_loss: 0.6845\n","Epoch 4/10\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.4583 - val_loss: 0.7069\n","Epoch 5/10\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 425ms/step - accuracy: 0.5249 - loss: 0.6875 - val_accuracy: 0.5469 - val_loss: 0.6452\n","Epoch 6/10\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.3750 - val_loss: 0.7084\n","Epoch 7/10\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 424ms/step - accuracy: 0.5586 - loss: 0.6599 - val_accuracy: 0.5625 - val_loss: 0.6411\n","Epoch 8/10\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.5417 - val_loss: 0.6586\n","Epoch 9/10\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 423ms/step - accuracy: 0.6959 - loss: 0.6217 - val_accuracy: 0.6719 - val_loss: 0.5787\n","Epoch 10/10\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.5417 - val_loss: 0.6585\n","Finished training for class: Train\n","Training for class: Bottle\n","Number of positive samples for Bottle: 294\n","Number of negative samples before balancing: 6613\n","Number of negative samples after balancing: 294\n","Found 470 validated image filenames belonging to 2 classes.\n","Found 118 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711572023.586427      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m 2/14\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 385ms/step - accuracy: 0.4219 - loss: 0.9128"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711572082.153071      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.4845 - loss: 0.8627"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711572087.729426      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 5s/step - accuracy: 0.4881 - loss: 0.8565 - val_accuracy: 0.4167 - val_loss: 0.7417\n","Epoch 2/10\n","\u001b[1m 1/14\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 380ms/step - accuracy: 0.5312 - loss: 0.6619"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.5312 - loss: 0.6619 - val_accuracy: 0.5455 - val_loss: 0.6836\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711572088.982528      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 426ms/step - accuracy: 0.5475 - loss: 0.7045 - val_accuracy: 0.5729 - val_loss: 0.6811\n","Epoch 4/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - loss: 0.6830 - val_accuracy: 0.5455 - val_loss: 0.6831\n","Epoch 5/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 420ms/step - accuracy: 0.5927 - loss: 0.6808 - val_accuracy: 0.5104 - val_loss: 0.7057\n","Epoch 6/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5000 - loss: 0.6925 - val_accuracy: 0.5455 - val_loss: 0.6553\n","Epoch 7/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 420ms/step - accuracy: 0.5952 - loss: 0.6641 - val_accuracy: 0.5104 - val_loss: 0.6866\n","Epoch 8/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5938 - loss: 0.6255 - val_accuracy: 0.5455 - val_loss: 0.6681\n","Epoch 9/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 427ms/step - accuracy: 0.6464 - loss: 0.6427 - val_accuracy: 0.6667 - val_loss: 0.6096\n","Epoch 10/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7188 - loss: 0.5866 - val_accuracy: 0.6364 - val_loss: 0.6718\n","Finished training for class: Bottle\n","Training for class: Boat\n","Number of positive samples for Boat: 265\n","Number of negative samples before balancing: 6642\n","Number of negative samples after balancing: 265\n","Found 424 validated image filenames belonging to 2 classes.\n","Found 106 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711572136.108766      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5623 - loss: 0.7461   "]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711572159.344049      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","W0000 00:00:1711572160.500477      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.5626 - loss: 0.7441 - val_accuracy: 0.7083 - val_loss: 0.6221\n","Epoch 2/10\n","\u001b[1m 1/13\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 390ms/step - accuracy: 0.7500 - loss: 0.5905"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7500 - loss: 0.5905 - val_accuracy: 0.5000 - val_loss: 0.6290\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711572161.654392      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 449ms/step - accuracy: 0.6431 - loss: 0.6678 - val_accuracy: 0.7083 - val_loss: 0.5174\n","Epoch 4/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8125 - loss: 0.4297 - val_accuracy: 0.6000 - val_loss: 1.0867\n","Epoch 5/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 412ms/step - accuracy: 0.6638 - loss: 0.6294 - val_accuracy: 0.7396 - val_loss: 0.6389\n","Epoch 6/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7500 - loss: 0.6295 - val_accuracy: 0.9000 - val_loss: 0.4935\n","Epoch 7/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 428ms/step - accuracy: 0.6377 - loss: 0.5948 - val_accuracy: 0.7396 - val_loss: 0.5202\n","Epoch 8/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7500 - loss: 0.4879 - val_accuracy: 0.7000 - val_loss: 0.6937\n","Epoch 9/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 425ms/step - accuracy: 0.7162 - loss: 0.5238 - val_accuracy: 0.7188 - val_loss: 0.5661\n","Epoch 10/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7188 - loss: 0.6184 - val_accuracy: 0.7000 - val_loss: 0.5540\n","Finished training for class: Boat\n","Training for class: Car\n","Number of positive samples for Car: 472\n","Number of negative samples before balancing: 6435\n","Number of negative samples after balancing: 472\n","Found 755 validated image filenames belonging to 2 classes.\n","Found 189 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711572206.299000      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m20/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 391ms/step - accuracy: 0.5103 - loss: 0.8133"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711572246.461983      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5145 - loss: 0.8027 "]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711572248.436425      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step - accuracy: 0.5157 - loss: 0.7997 - val_accuracy: 0.5000 - val_loss: 0.7348\n","Epoch 2/10\n","\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 407ms/step - accuracy: 0.4062 - loss: 0.8562"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4062 - loss: 0.8562 - val_accuracy: 0.6207 - val_loss: 0.6484\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711572249.910416      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 416ms/step - accuracy: 0.5411 - loss: 0.6856 - val_accuracy: 0.7063 - val_loss: 0.6072\n","Epoch 4/10\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5938 - loss: 0.6892 - val_accuracy: 0.6207 - val_loss: 0.6560\n","Epoch 5/10\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 423ms/step - accuracy: 0.6326 - loss: 0.6430 - val_accuracy: 0.6500 - val_loss: 0.6247\n","Epoch 6/10\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6250 - loss: 0.6460 - val_accuracy: 0.6207 - val_loss: 0.6153\n","Epoch 7/10\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 432ms/step - accuracy: 0.6974 - loss: 0.6070 - val_accuracy: 0.7000 - val_loss: 0.6527\n","Epoch 8/10\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8125 - loss: 0.6252 - val_accuracy: 0.5517 - val_loss: 0.6650\n","Epoch 9/10\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 426ms/step - accuracy: 0.5832 - loss: 0.6709 - val_accuracy: 0.6750 - val_loss: 0.5888\n","Epoch 10/10\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6875 - loss: 0.5699 - val_accuracy: 0.7241 - val_loss: 0.5573\n","Finished training for class: Car\n","Training for class: Cow\n","Number of positive samples for Cow: 159\n","Number of negative samples before balancing: 6748\n","Number of negative samples after balancing: 159\n","Found 254 validated image filenames belonging to 2 classes.\n","Found 64 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711572346.335240      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m2/7\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 382ms/step - accuracy: 0.4531 - loss: 0.8992"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711572419.933160      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - accuracy: 0.4669 - loss: 0.8801 "]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711572422.802455      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 13s/step - accuracy: 0.4682 - loss: 0.8708 - val_accuracy: 0.5781 - val_loss: 0.8528\n","Epoch 2/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6250 - loss: 0.7638 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 439ms/step - accuracy: 0.6923 - loss: 0.6264 - val_accuracy: 0.5469 - val_loss: 0.8443\n","Epoch 4/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7812 - loss: 0.6363 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n","Epoch 5/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 440ms/step - accuracy: 0.7362 - loss: 0.5886 - val_accuracy: 0.5625 - val_loss: 0.6771\n","Epoch 6/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6875 - loss: 0.5744 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n","Epoch 7/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 436ms/step - accuracy: 0.7163 - loss: 0.5697 - val_accuracy: 0.6875 - val_loss: 0.5927\n","Epoch 8/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7500 - loss: 0.4794 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n","Epoch 9/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 442ms/step - accuracy: 0.7485 - loss: 0.5261 - val_accuracy: 0.7500 - val_loss: 0.5752\n","Epoch 10/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7188 - loss: 0.5969 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n","Finished training for class: Cow\n","Training for class: Bird\n","Number of positive samples for Bird: 344\n","Number of negative samples before balancing: 6563\n","Number of negative samples after balancing: 344\n","Found 550 validated image filenames belonging to 2 classes.\n","Found 138 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711572458.933041      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m14/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1s\u001b[0m 552ms/step - accuracy: 0.4971 - loss: 0.7963"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711572466.395120      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523ms/step - accuracy: 0.4991 - loss: 0.7859"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711572468.703270      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 613ms/step - accuracy: 0.4996 - loss: 0.7830 - val_accuracy: 0.4609 - val_loss: 0.6838\n","Epoch 2/10\n","\u001b[1m 1/17\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 401ms/step - accuracy: 0.3438 - loss: 0.7488"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.3438 - loss: 0.7488 - val_accuracy: 0.5000 - val_loss: 0.6855\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711572470.035750      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 415ms/step - accuracy: 0.5559 - loss: 0.6856 - val_accuracy: 0.5469 - val_loss: 0.7028\n","Epoch 4/10\n","\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6250 - loss: 0.5998 - val_accuracy: 0.7000 - val_loss: 0.5800\n","Epoch 5/10\n","\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 422ms/step - accuracy: 0.6593 - loss: 0.5892 - val_accuracy: 0.6250 - val_loss: 0.6579\n","Epoch 6/10\n","\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5938 - loss: 0.5560 - val_accuracy: 0.4000 - val_loss: 0.6322\n","Epoch 7/10\n","\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 434ms/step - accuracy: 0.6162 - loss: 0.6177 - val_accuracy: 0.4922 - val_loss: 0.7070\n","Epoch 8/10\n","\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4375 - loss: 0.7144 - val_accuracy: 0.3000 - val_loss: 0.6875\n","Epoch 9/10\n","\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 428ms/step - accuracy: 0.5996 - loss: 0.6635 - val_accuracy: 0.3906 - val_loss: 0.8267\n","Epoch 10/10\n","\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6250 - loss: 0.6743 - val_accuracy: 0.6000 - val_loss: 0.5558\n","Finished training for class: Bird\n","Training for class: Pottedplant\n","Number of positive samples for Pottedplant: 244\n","Number of negative samples before balancing: 6663\n","Number of negative samples after balancing: 244\n","Found 390 validated image filenames belonging to 2 classes.\n","Found 98 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711572522.264415      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 588ms/step - accuracy: 0.4942 - loss: 0.8066"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711572528.404535      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572ms/step - accuracy: 0.4947 - loss: 0.8019"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711572529.868858      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 685ms/step - accuracy: 0.4951 - loss: 0.7979 - val_accuracy: 0.4688 - val_loss: 0.7129\n","Epoch 2/10\n","\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 380ms/step - accuracy: 0.5938 - loss: 0.6756"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 422ms/step - accuracy: 0.5938 - loss: 0.6756 - val_accuracy: 0.5000 - val_loss: 0.6867\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711572535.223115      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 437ms/step - accuracy: 0.5191 - loss: 0.6958 - val_accuracy: 0.5104 - val_loss: 0.6921\n","Epoch 4/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8333 - loss: 0.6647 - val_accuracy: 1.0000 - val_loss: 0.6227\n","Epoch 5/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 436ms/step - accuracy: 0.4794 - loss: 0.6959 - val_accuracy: 0.5417 - val_loss: 0.6854\n","Epoch 6/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6667 - loss: 0.6817 - val_accuracy: 0.5000 - val_loss: 0.7250\n","Epoch 7/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 413ms/step - accuracy: 0.5585 - loss: 0.6882 - val_accuracy: 0.4896 - val_loss: 0.7102\n","Epoch 8/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6250 - loss: 0.6595 - val_accuracy: 0.0000e+00 - val_loss: 0.9641\n","Epoch 9/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 448ms/step - accuracy: 0.4975 - loss: 0.7028 - val_accuracy: 0.5625 - val_loss: 0.6835\n","Epoch 10/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5625 - loss: 0.6723 - val_accuracy: 1.0000 - val_loss: 0.5530\n","Finished training for class: Pottedplant\n","Training for class: Tvmonitor\n","Number of positive samples for Tvmonitor: 272\n","Number of negative samples before balancing: 6635\n","Number of negative samples after balancing: 272\n","Found 435 validated image filenames belonging to 2 classes.\n","Found 109 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711572577.617179      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m 4/13\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 399ms/step - accuracy: 0.5371 - loss: 0.9297"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711572581.408187      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568ms/step - accuracy: 0.5546 - loss: 0.8453"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711572585.768620      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 671ms/step - accuracy: 0.5543 - loss: 0.8398 - val_accuracy: 0.5625 - val_loss: 0.6721\n","Epoch 2/10\n","\u001b[1m 1/13\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 383ms/step - accuracy: 0.6250 - loss: 0.6559"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.6250 - loss: 0.6559 - val_accuracy: 0.7692 - val_loss: 0.5718\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711572601.187788      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 430ms/step - accuracy: 0.6280 - loss: 0.6724 - val_accuracy: 0.5000 - val_loss: 0.6854\n","Epoch 4/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4688 - loss: 0.7277 - val_accuracy: 0.6154 - val_loss: 0.6074\n","Epoch 5/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 431ms/step - accuracy: 0.6130 - loss: 0.6178 - val_accuracy: 0.6042 - val_loss: 0.6601\n","Epoch 6/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5000 - loss: 0.7205 - val_accuracy: 0.6154 - val_loss: 0.6381\n","Epoch 7/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 431ms/step - accuracy: 0.5477 - loss: 0.6822 - val_accuracy: 0.6979 - val_loss: 0.6172\n","Epoch 8/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5000 - loss: 0.6805 - val_accuracy: 0.6154 - val_loss: 0.6700\n","Epoch 9/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 424ms/step - accuracy: 0.6295 - loss: 0.6252 - val_accuracy: 0.6458 - val_loss: 0.6078\n","Epoch 10/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7188 - loss: 0.5335 - val_accuracy: 0.4615 - val_loss: 0.8468\n","Finished training for class: Tvmonitor\n","Training for class: Dog\n","Number of positive samples for Dog: 410\n","Number of negative samples before balancing: 6497\n","Number of negative samples after balancing: 410\n","Found 656 validated image filenames belonging to 2 classes.\n","Found 164 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711572646.460872      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m 8/20\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 391ms/step - accuracy: 0.5361 - loss: 0.7658"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711572694.112199      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5232 - loss: 0.7370"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711572699.521955      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 3s/step - accuracy: 0.5224 - loss: 0.7358 - val_accuracy: 0.4938 - val_loss: 0.6950\n","Epoch 2/10\n","\u001b[1m 1/20\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 403ms/step - accuracy: 0.5625 - loss: 0.6915"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5625 - loss: 0.6915 - val_accuracy: 0.5000 - val_loss: 0.7055\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711572701.025577      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 415ms/step - accuracy: 0.5049 - loss: 0.6936 - val_accuracy: 0.5063 - val_loss: 0.6917\n","Epoch 4/10\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4375 - loss: 0.7054 - val_accuracy: 0.5000 - val_loss: 0.6877\n","Epoch 5/10\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 434ms/step - accuracy: 0.5103 - loss: 0.6916 - val_accuracy: 0.5938 - val_loss: 0.6667\n","Epoch 6/10\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6250 - loss: 0.6601 - val_accuracy: 0.5000 - val_loss: 0.6917\n","Epoch 7/10\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 427ms/step - accuracy: 0.5396 - loss: 0.6947 - val_accuracy: 0.5188 - val_loss: 0.6932\n","Epoch 8/10\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4688 - loss: 0.6949 - val_accuracy: 0.5000 - val_loss: 0.6947\n","Epoch 9/10\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 439ms/step - accuracy: 0.4829 - loss: 0.6935 - val_accuracy: 0.5250 - val_loss: 0.6930\n","Epoch 10/10\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4062 - loss: 0.6934 - val_accuracy: 0.7500 - val_loss: 0.6927\n","Finished training for class: Dog\n","Training for class: Chair\n","Number of positive samples for Chair: 380\n","Number of negative samples before balancing: 6527\n","Number of negative samples after balancing: 380\n","Found 608 validated image filenames belonging to 2 classes.\n","Found 152 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711572766.768344      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - accuracy: 0.5681 - loss: 0.6950"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711572775.406732      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 484ms/step - accuracy: 0.5661 - loss: 0.6953 - val_accuracy: 0.5625 - val_loss: 0.6887\n","Epoch 2/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.6667 - val_loss: 0.6896\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711572776.301141      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 449ms/step - accuracy: 0.5216 - loss: 0.6947 - val_accuracy: 0.5234 - val_loss: 0.6818\n","Epoch 4/10\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.4583 - val_loss: 0.6790\n","Epoch 5/10\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 430ms/step - accuracy: 0.5617 - loss: 0.6791 - val_accuracy: 0.5391 - val_loss: 0.6776\n","Epoch 6/10\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.6250 - val_loss: 0.6626\n","Epoch 7/10\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 427ms/step - accuracy: 0.6542 - loss: 0.6205 - val_accuracy: 0.7266 - val_loss: 0.5977\n","Epoch 8/10\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.8750 - val_loss: 0.5503\n","Epoch 9/10\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 440ms/step - accuracy: 0.7197 - loss: 0.5359 - val_accuracy: 0.6875 - val_loss: 0.6185\n","Epoch 10/10\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.8333 - val_loss: 0.4722\n","Finished training for class: Chair\n"]}],"source":["# Loop through each class and train a binary classification model\n","for class_name in class_names:\n","    print(f\"Training for class: {class_name}\")\n","\n","    # Retrieve the list of image paths for the positive class\n","    positive_images = train_data_lists[class_name]\n","    if not positive_images:\n","        print(f\"No images found for class {class_name}. Skipping this class.\")\n","        continue\n","    positive_labels = [1] * len(positive_images)\n","\n","    # Build a list of image paths for the negative class (all other classes)\n","    negative_images = []\n","    for other_class_name, image_paths in train_data_lists.items():\n","        if other_class_name != class_name:\n","            negative_images.extend(image_paths)\n","\n","    print(f\"Number of positive samples for {class_name}: {len(positive_images)}\")\n","    print(f\"Number of negative samples before balancing: {len(negative_images)}\")\n","\n","\n","    random.shuffle(negative_images)  # Shuffle the negative images\n","    negative_images = negative_images[:len(positive_images)]  # Balance the positive and negative datasets\n","    negative_labels = [0] * len(negative_images)\n","    print(f\"Number of negative samples after balancing: {len(negative_images)}\")\n","\n","    # Combine and shuffle the positive and negative samples\n","    combined_images = positive_images + negative_images\n","    combined_labels = positive_labels + negative_labels\n","    combined_list = list(zip(combined_images, combined_labels))\n","    random.shuffle(combined_list)\n","    combined_images, combined_labels = zip(*combined_list)\n","\n","    # Split the data into training and validation sets\n","    X_train, X_val, y_train, y_val = train_test_split(combined_images, combined_labels, test_size=0.2, random_state=42)\n","\n","    # Create DataFrames for the training and validation sets\n","    train_df = pd.DataFrame({\n","    'filename': X_train,\n","    'label': [str(label) for label in y_train]  # Convert labels to strings\n","})\n","    val_df = pd.DataFrame({\n","    'filename': X_val,\n","    'label': [str(label) for label in y_val]  # Convert labels to strings\n","})\n","\n","    # Create data generators for training and validation\n","    train_generator = train_datagen.flow_from_dataframe(\n","        train_df,\n","        x_col='filename',\n","        y_col='label',\n","        target_size=(224, 224),\n","        batch_size=32,\n","        class_mode='binary'\n","    )\n","\n","    val_datagen = ImageDataGenerator(rescale=1./255)\n","    val_generator = val_datagen.flow_from_dataframe(\n","        val_df,\n","        x_col='filename',\n","        y_col='label',\n","        target_size=(224, 224),\n","        batch_size=32,\n","        class_mode='binary'\n","    )\n","\n","    #Build the binary classification model\n","    model = build_binary_classification_model()\n","\n","    # Train the model on the data\n","    history = model.fit(\n","        train_generator,\n","        steps_per_epoch=len(X_train) // 32,\n","        validation_data=val_generator,\n","        validation_steps=len(X_val) // 32,\n","        epochs=10\n","    )\n","\n","    # Save the trained model\n","    model_save_path = os.path.join('models', f\"{class_name}_binary_model.h5\")\n","    os.makedirs('models', exist_ok=True)\n","    model.save(model_save_path)\n","\n","    print(f\"Finished training for class: {class_name}\")"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T21:06:11.405655Z","iopub.status.busy":"2024-03-27T21:06:11.405248Z","iopub.status.idle":"2024-03-27T21:06:11.476224Z","shell.execute_reply":"2024-03-27T21:06:11.475260Z","shell.execute_reply.started":"2024-03-27T21:06:11.405622Z"},"trusted":true},"outputs":[],"source":["import os\n","import shutil\n","\n","# Define the path to the train directory\n","train_dir = \"/content/test\"\n","\n","# Iterate over each subfolder in the train directory\n","for class_name in os.listdir(train_dir):\n","    class_dir = os.path.join(train_dir, class_name)\n","    \n","    # Check if the item in the directory is a subfolder\n","    if os.path.isdir(class_dir):\n","        # Define the path to the subsubfolder\n","        subsubfolder_dir = os.path.join(class_dir, class_name)\n","        \n","        # Check if the subsubfolder exists\n","        if os.path.exists(subsubfolder_dir):\n","            # Iterate over each file in the subsubfolder\n","            for file_name in os.listdir(subsubfolder_dir):\n","                file_path = os.path.join(subsubfolder_dir, file_name)\n","                \n","                # Move the file to the parent subfolder\n","                if os.path.isfile(file_path):\n","                    shutil.move(file_path, class_dir)\n","            \n","            # Remove the empty subsubfolder\n","            os.rmdir(subsubfolder_dir)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","from sklearn.metrics import classification_report, confusion_matrix, average_precision_score\n","import matplotlib.pyplot as plt\n","from PIL import Image, ImageDraw, ImageFont\n","\n","model_dir = '/content/models'\n","test_data_dir = '/content/test'\n","\n","# Initialize ImageDataGenerator for preprocessing\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Store average precision scores for mAP calculation\n","ap_scores = []\n","\n","# Loop through each model file in the models directory\n","for model_file in sorted(os.listdir(model_dir)):\n","    if model_file.endswith(\".h5\"):\n","        print(f\"\\nLoading model {model_file}...\")\n","        model_path = os.path.join(model_dir, model_file)\n","        model = load_model(model_path)\n","        class_name = model_file.replace(\"_binary_model.h5\", \"\")\n","        print(f\"Model for class '{class_name}' loaded successfully.\")\n","\n","        # Create DataFrame for test data with labels as strings\n","        images = []\n","        labels = []\n","        for folder in os.listdir(test_data_dir):\n","            folder_path = os.path.join(test_data_dir, folder)\n","            for image_file in os.listdir(folder_path):\n","                images.append(os.path.join(folder, image_file))\n","                labels.append(str(int(folder == class_name)))  # Convert boolean to int to string\n","\n","        test_df = pd.DataFrame({\n","            'filename': images,\n","            'label': labels  # Labels are now strings\n","        })\n","\n","        # Prepare test generator\n","        test_generator = test_datagen.flow_from_dataframe(\n","            dataframe=test_df,\n","            directory=test_data_dir,\n","            x_col='filename',\n","            y_col='label',\n","            target_size=(224, 224),\n","            batch_size=32,\n","            class_mode='binary',\n","            shuffle=False)\n","\n","        # Predict and evaluate\n","        predictions = model.predict(test_generator, steps=int(np.ceil(len(test_df)/32)))\n","\n","        predicted_labels = (predictions > 0.5).astype(int)\n","        ap_score = average_precision_score(test_generator.classes, predictions)\n","        ap_scores.append(ap_score)\n","        #print(f\"AP score for class '{class_name}': {ap_score:.3f}\")\n","\n","\n","\n"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T21:08:41.987215Z","iopub.status.busy":"2024-03-27T21:08:41.986753Z","iopub.status.idle":"2024-03-27T21:08:41.993626Z","shell.execute_reply":"2024-03-27T21:08:41.992480Z","shell.execute_reply.started":"2024-03-27T21:08:41.987178Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Mean Average Precision (mAP) across all classes: 0.147\n"]}],"source":["# Calculate mean Average Precision (mAP)\n","mAP = np.mean(ap_scores)\n","print(f\"\\nMean Average Precision (mAP) across all classes: {mAP:.3f}\")"]},{"cell_type":"markdown","metadata":{},"source":["# Now for 200 samples "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","import random\n","\n","\n","# Define paths\n","samples_folder = '/content/generated_data-500samples'\n","train_folder = '/content/train'\n","\n","# Ensure the train folder exists\n","os.makedirs(train_folder, exist_ok=True)\n","\n","# Iterate through each class folder in the 500 samples folder\n","for class_name in os.listdir(samples_folder):\n","    class_folder = os.path.join(samples_folder, class_name)\n","    \n","    # Ensure it's a directory\n","    if os.path.isdir(class_folder):\n","        # Create the corresponding class subfolder in the train folder\n","        class_train_folder = os.path.join(train_folder, class_name, class_name)\n","        os.makedirs(class_train_folder, exist_ok=True)\n","        \n","        # Get a list of all images in the class folder\n","        images = os.listdir(class_folder)\n","        \n","        # Randomly select 100 images   *100 images already moved in the previous cells  100+100=200* \n","        selected_images = random.sample(images, 100)\n","        \n","        # Copy selected images to the train folder\n","        for image in selected_images:\n","            src_path = os.path.join(class_folder, image)\n","            dest_path = os.path.join(class_train_folder, image)\n","            shutil.copy(src_path, dest_path)\n","            print(f\"Copied {image} to {class_train_folder}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","import shutil\n","\n","# Define the train folder path\n","train_folder = '/content/train'\n","\n","# Iterate through each class subfolder in the train folder\n","for class_folder in os.listdir(train_folder):\n","    class_subfolder = os.path.join(train_folder, class_folder)\n","    \n","    # Ensure it's a directory\n","    if os.path.isdir(class_subfolder):\n","        # Get the path of the second subfolder\n","        second_subfolder = os.path.join(class_subfolder, class_folder)\n","        \n","        # Ensure the second subfolder exists\n","        if os.path.exists(second_subfolder):\n","            # Move images from the second subfolder to the first subfolder\n","            for image_file in os.listdir(second_subfolder):\n","                src_path = os.path.join(second_subfolder, image_file)\n","                dest_path = os.path.join(class_subfolder, image_file)\n","                shutil.move(src_path, dest_path)\n","                print(f\"Moved {image_file} from {second_subfolder} to {class_subfolder}\")\n","            \n","            # Remove the second subfolder\n","            os.rmdir(second_subfolder)\n","            print(f\"Removed {second_subfolder}\")\n"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T21:15:18.542242Z","iopub.status.busy":"2024-03-27T21:15:18.541531Z","iopub.status.idle":"2024-03-27T21:35:51.808480Z","shell.execute_reply":"2024-03-27T21:35:51.807400Z","shell.execute_reply.started":"2024-03-27T21:15:18.542202Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training for class: Cat\n","Number of positive samples for Cat: 362\n","Number of negative samples before balancing: 6545\n","Number of negative samples after balancing: 362\n","Found 579 validated image filenames belonging to 2 classes.\n","Found 145 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711574127.402241      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m 5/18\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 884ms/step - accuracy: 0.5273 - loss: 0.7811"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574131.296019      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512ms/step - accuracy: 0.5222 - loss: 0.7661"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574137.395853      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 590ms/step - accuracy: 0.5223 - loss: 0.7644 - val_accuracy: 0.5312 - val_loss: 0.6899\n","Epoch 2/10\n","\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 393ms/step - accuracy: 0.3438 - loss: 0.7563"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.3438 - loss: 0.7563 - val_accuracy: 0.5294 - val_loss: 0.6874\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574138.662644      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 416ms/step - accuracy: 0.5359 - loss: 0.6836 - val_accuracy: 0.4844 - val_loss: 0.7002\n","Epoch 4/10\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3750 - loss: 0.7556 - val_accuracy: 0.3529 - val_loss: 0.7069\n","Epoch 5/10\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 417ms/step - accuracy: 0.6469 - loss: 0.6623 - val_accuracy: 0.5156 - val_loss: 0.8700\n","Epoch 6/10\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4688 - loss: 0.9322 - val_accuracy: 0.6471 - val_loss: 0.6387\n","Epoch 7/10\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 410ms/step - accuracy: 0.5538 - loss: 0.7076 - val_accuracy: 0.8047 - val_loss: 0.6521\n","Epoch 8/10\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6562 - loss: 0.6698 - val_accuracy: 0.5882 - val_loss: 0.6753\n","Epoch 9/10\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 422ms/step - accuracy: 0.6570 - loss: 0.6303 - val_accuracy: 0.5156 - val_loss: 0.7166\n","Epoch 10/10\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4688 - loss: 0.7945 - val_accuracy: 0.5294 - val_loss: 0.7385\n","Finished training for class: Cat\n","Training for class: Sofa\n","Number of positive samples for Sofa: 207\n","Number of negative samples before balancing: 6700\n","Number of negative samples after balancing: 207\n","Found 331 validated image filenames belonging to 2 classes.\n","Found 83 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711574192.403895      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m 3/10\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 383ms/step - accuracy: 0.5156 - loss: 0.7867"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574195.657187      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593ms/step - accuracy: 0.5453 - loss: 0.7546"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574199.034521      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 712ms/step - accuracy: 0.5478 - loss: 0.7511 - val_accuracy: 0.5156 - val_loss: 0.7254\n","Epoch 2/10\n","\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 380ms/step - accuracy: 0.5312 - loss: 0.6835"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.5312 - loss: 0.6835 - val_accuracy: 0.5263 - val_loss: 0.7311\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574200.053993      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 401ms/step - accuracy: 0.6701 - loss: 0.6593 - val_accuracy: 0.5000 - val_loss: 0.6983\n","Epoch 4/10\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5312 - loss: 0.6950 - val_accuracy: 0.6842 - val_loss: 0.6585\n","Epoch 5/10\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 426ms/step - accuracy: 0.5471 - loss: 0.6963 - val_accuracy: 0.5312 - val_loss: 0.7081\n","Epoch 6/10\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7273 - loss: 0.6293 - val_accuracy: 0.5263 - val_loss: 0.7712\n","Epoch 7/10\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 425ms/step - accuracy: 0.6656 - loss: 0.6357 - val_accuracy: 0.5469 - val_loss: 0.7262\n","Epoch 8/10\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6562 - loss: 0.5929 - val_accuracy: 0.4737 - val_loss: 0.7639\n","Epoch 9/10\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 407ms/step - accuracy: 0.7086 - loss: 0.5863 - val_accuracy: 0.5781 - val_loss: 0.7250\n","Epoch 10/10\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7500 - loss: 0.4971 - val_accuracy: 0.6842 - val_loss: 0.5549\n","Finished training for class: Sofa\n","Training for class: Sheep\n","Number of positive samples for Sheep: 151\n","Number of negative samples before balancing: 6756\n","Number of negative samples after balancing: 151\n","Found 241 validated image filenames belonging to 2 classes.\n","Found 61 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711574238.418736      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m3/7\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 395ms/step - accuracy: 0.4635 - loss: 0.8472"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574241.748669      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 884ms/step - accuracy: 0.5366 - loss: 0.7779 - val_accuracy: 0.6875 - val_loss: 0.6893\n","Epoch 2/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574244.055770      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 385ms/step - accuracy: 0.6875 - loss: 0.7131"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.6875 - loss: 0.7131 - val_accuracy: 0.6207 - val_loss: 0.6349\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574244.939538      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 373ms/step - accuracy: 0.6870 - loss: 0.6138 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n","Epoch 4/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.7188 - loss: 0.5545 - val_accuracy: 0.6250 - val_loss: 0.6670\n","Epoch 5/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 394ms/step - accuracy: 0.7564 - loss: 0.5587 - val_accuracy: 0.8276 - val_loss: 0.5386\n","Epoch 6/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7188 - loss: 0.5703 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n","Epoch 7/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 407ms/step - accuracy: 0.7888 - loss: 0.4375 - val_accuracy: 0.7812 - val_loss: 0.5118\n","Epoch 8/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8125 - loss: 0.4915 - val_accuracy: 0.6897 - val_loss: 0.6070\n","Epoch 9/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 395ms/step - accuracy: 0.7879 - loss: 0.4753 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n","Epoch 10/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8125 - loss: 0.3940 - val_accuracy: 0.8125 - val_loss: 0.4209\n","Finished training for class: Sheep\n","Training for class: Diningtable\n","Number of positive samples for Diningtable: 184\n","Number of negative samples before balancing: 6723\n","Number of negative samples after balancing: 184\n","Found 294 validated image filenames belonging to 2 classes.\n","Found 74 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711574278.080256      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m8/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 665ms/step - accuracy: 0.4918 - loss: 0.8128"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574283.027690      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630ms/step - accuracy: 0.4927 - loss: 0.8090"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574284.471493      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 772ms/step - accuracy: 0.4935 - loss: 0.8059 - val_accuracy: 0.4531 - val_loss: 0.7187\n","Epoch 2/10\n","\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 380ms/step - accuracy: 0.6250 - loss: 0.6648"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.6250 - loss: 0.6648 - val_accuracy: 0.3000 - val_loss: 0.8512\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574285.469477      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 394ms/step - accuracy: 0.5330 - loss: 0.7018 - val_accuracy: 0.5781 - val_loss: 0.6796\n","Epoch 4/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5938 - loss: 0.6768 - val_accuracy: 0.5000 - val_loss: 0.6646\n","Epoch 5/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 395ms/step - accuracy: 0.5107 - loss: 0.6924 - val_accuracy: 0.5625 - val_loss: 0.6985\n","Epoch 6/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4062 - loss: 0.7557 - val_accuracy: 0.5000 - val_loss: 0.6910\n","Epoch 7/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 401ms/step - accuracy: 0.5591 - loss: 0.6832 - val_accuracy: 0.6094 - val_loss: 0.6610\n","Epoch 8/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5938 - loss: 0.6779 - val_accuracy: 0.6000 - val_loss: 0.6720\n","Epoch 9/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 438ms/step - accuracy: 0.6428 - loss: 0.6562 - val_accuracy: 0.5312 - val_loss: 0.6495\n","Epoch 10/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6667 - loss: 0.6207 - val_accuracy: 0.8000 - val_loss: 0.5747\n","Finished training for class: Diningtable\n","Training for class: Horse\n","Number of positive samples for Horse: 258\n","Number of negative samples before balancing: 6649\n","Number of negative samples after balancing: 258\n","Found 412 validated image filenames belonging to 2 classes.\n","Found 104 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711574321.262377      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m 9/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1s\u001b[0m 394ms/step - accuracy: 0.5114 - loss: 0.7751"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574326.913705      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581ms/step - accuracy: 0.5165 - loss: 0.7633"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574328.939382      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 690ms/step - accuracy: 0.5185 - loss: 0.7600 - val_accuracy: 0.5729 - val_loss: 0.6682\n","Epoch 2/10\n","\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 385ms/step - accuracy: 0.4062 - loss: 0.7530"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.4062 - loss: 0.7530 - val_accuracy: 0.3750 - val_loss: 0.7272\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574330.106219      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 432ms/step - accuracy: 0.5383 - loss: 0.6921 - val_accuracy: 0.7292 - val_loss: 0.6287\n","Epoch 4/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5938 - loss: 0.6737 - val_accuracy: 0.2500 - val_loss: 0.8180\n","Epoch 5/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 438ms/step - accuracy: 0.6147 - loss: 0.6549 - val_accuracy: 0.6354 - val_loss: 0.6362\n","Epoch 6/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6562 - loss: 0.6217 - val_accuracy: 0.5000 - val_loss: 0.6945\n","Epoch 7/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 434ms/step - accuracy: 0.5777 - loss: 0.6693 - val_accuracy: 0.6771 - val_loss: 0.5717\n","Epoch 8/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6562 - loss: 0.6001 - val_accuracy: 1.0000 - val_loss: 0.4383\n","Epoch 9/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 436ms/step - accuracy: 0.6681 - loss: 0.5771 - val_accuracy: 0.6667 - val_loss: 0.5682\n","Epoch 10/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.6875 - loss: 0.6412 - val_accuracy: 0.5000 - val_loss: 0.4938\n","Finished training for class: Horse\n","Training for class: Person\n","Number of positive samples for Person: 1701\n","Number of negative samples before balancing: 5206\n","Number of negative samples after balancing: 1701\n","Found 2721 validated image filenames belonging to 2 classes.\n","Found 681 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711574374.836734      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.5875 - loss: 0.6682"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574411.445425      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 461ms/step - accuracy: 0.5880 - loss: 0.6679 - val_accuracy: 0.6399 - val_loss: 0.6219\n","Epoch 2/10\n","\u001b[1m 1/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 388ms/step - accuracy: 0.8438 - loss: 0.4823"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8438 - loss: 0.4823 - val_accuracy: 0.4444 - val_loss: 0.6308\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574414.816383      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 423ms/step - accuracy: 0.6621 - loss: 0.6172 - val_accuracy: 0.6592 - val_loss: 0.6084\n","Epoch 4/10\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.7812 - loss: 0.5619 - val_accuracy: 0.6667 - val_loss: 0.5460\n","Epoch 5/10\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 427ms/step - accuracy: 0.6661 - loss: 0.5950 - val_accuracy: 0.6682 - val_loss: 0.5979\n","Epoch 6/10\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.5938 - loss: 0.6406 - val_accuracy: 0.8889 - val_loss: 0.5604\n","Epoch 7/10\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 424ms/step - accuracy: 0.6815 - loss: 0.5813 - val_accuracy: 0.6637 - val_loss: 0.6120\n","Epoch 8/10\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - accuracy: 0.7188 - loss: 0.5788 - val_accuracy: 0.5556 - val_loss: 0.7340\n","Epoch 9/10\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 422ms/step - accuracy: 0.6944 - loss: 0.5835 - val_accuracy: 0.7024 - val_loss: 0.5891\n","Epoch 10/10\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - accuracy: 0.6562 - loss: 0.5485 - val_accuracy: 0.5556 - val_loss: 0.6724\n","Finished training for class: Person\n","Training for class: Motorbike\n","Number of positive samples for Motorbike: 263\n","Number of negative samples before balancing: 6644\n","Number of negative samples after balancing: 263\n","Found 420 validated image filenames belonging to 2 classes.\n","Found 106 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m 1/13\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44\u001b[0m 9s/step - accuracy: 0.5000 - loss: 0.7324"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574581.523537      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","W0000 00:00:1711574583.795007      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569ms/step - accuracy: 0.5105 - loss: 0.8031"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574589.353379      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 672ms/step - accuracy: 0.5112 - loss: 0.8002 - val_accuracy: 0.5104 - val_loss: 0.7017\n","Epoch 2/10\n","\u001b[1m 1/13\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 382ms/step - accuracy: 0.4688 - loss: 0.7115"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.4688 - loss: 0.7115 - val_accuracy: 0.4000 - val_loss: 0.7684\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574590.494241      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 398ms/step - accuracy: 0.4518 - loss: 0.7040 - val_accuracy: 0.5104 - val_loss: 0.6954\n","Epoch 4/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5000 - loss: 0.6949 - val_accuracy: 0.4000 - val_loss: 0.7077\n","Epoch 5/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 454ms/step - accuracy: 0.4602 - loss: 0.7031 - val_accuracy: 0.4896 - val_loss: 0.6946\n","Epoch 6/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5938 - loss: 0.6928 - val_accuracy: 0.6000 - val_loss: 0.6733\n","Epoch 7/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 458ms/step - accuracy: 0.5148 - loss: 0.6980 - val_accuracy: 0.4896 - val_loss: 0.6970\n","Epoch 8/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4062 - loss: 0.6950 - val_accuracy: 0.7000 - val_loss: 0.6739\n","Epoch 9/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 412ms/step - accuracy: 0.4890 - loss: 0.6897 - val_accuracy: 0.5417 - val_loss: 0.6980\n","Epoch 10/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5312 - loss: 0.7080 - val_accuracy: 0.7000 - val_loss: 0.7281\n","Finished training for class: Motorbike\n","Training for class: Bus\n","Number of positive samples for Bus: 180\n","Number of negative samples before balancing: 6727\n","Number of negative samples after balancing: 180\n","Found 288 validated image filenames belonging to 2 classes.\n","Found 72 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711574634.552725      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - accuracy: 0.5300 - loss: 0.7354"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574638.981746      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 528ms/step - accuracy: 0.5291 - loss: 0.7351 - val_accuracy: 0.4531 - val_loss: 0.6553\n","Epoch 2/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.6250 - val_loss: 0.6044\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574639.604206      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 433ms/step - accuracy: 0.6709 - loss: 0.6232 - val_accuracy: 0.7344 - val_loss: 0.6164\n","Epoch 4/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.5000 - val_loss: 0.9117\n","Epoch 5/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 433ms/step - accuracy: 0.7324 - loss: 0.5692 - val_accuracy: 0.8281 - val_loss: 0.4715\n","Epoch 6/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.7500 - val_loss: 0.3992\n","Epoch 7/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 434ms/step - accuracy: 0.7492 - loss: 0.4812 - val_accuracy: 0.7969 - val_loss: 0.5285\n","Epoch 8/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.8750 - val_loss: 0.4015\n","Epoch 9/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 437ms/step - accuracy: 0.7313 - loss: 0.5799 - val_accuracy: 0.7969 - val_loss: 0.5634\n","Epoch 10/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.8750 - val_loss: 0.4643\n","Finished training for class: Bus\n","Training for class: Bicycle\n","Number of positive samples for Bicycle: 253\n","Number of negative samples before balancing: 6654\n","Number of negative samples after balancing: 253\n","Found 404 validated image filenames belonging to 2 classes.\n","Found 102 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711574676.564544      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m 5/12\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 393ms/step - accuracy: 0.6001 - loss: 0.8125"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574680.666613      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580ms/step - accuracy: 0.5713 - loss: 0.7799"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574684.263776      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 693ms/step - accuracy: 0.5687 - loss: 0.7775 - val_accuracy: 0.4792 - val_loss: 0.7238\n","Epoch 2/10\n","\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 389ms/step - accuracy: 0.4688 - loss: 0.7313"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.4688 - loss: 0.7313 - val_accuracy: 0.1667 - val_loss: 0.7842\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574685.399101      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 430ms/step - accuracy: 0.5400 - loss: 0.6926 - val_accuracy: 0.5417 - val_loss: 0.6921\n","Epoch 4/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3750 - loss: 0.7135 - val_accuracy: 0.5000 - val_loss: 0.7009\n","Epoch 5/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 436ms/step - accuracy: 0.4913 - loss: 0.6955 - val_accuracy: 0.4583 - val_loss: 0.6993\n","Epoch 6/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4375 - loss: 0.7017 - val_accuracy: 0.5000 - val_loss: 0.6961\n","Epoch 7/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 446ms/step - accuracy: 0.5021 - loss: 0.6943 - val_accuracy: 0.5625 - val_loss: 0.6905\n","Epoch 8/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4000 - loss: 0.6967 - val_accuracy: 0.8333 - val_loss: 0.6839\n","Epoch 9/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 429ms/step - accuracy: 0.5254 - loss: 0.6904 - val_accuracy: 0.5000 - val_loss: 0.6927\n","Epoch 10/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5312 - loss: 0.6903 - val_accuracy: 0.6667 - val_loss: 0.6707\n","Finished training for class: Bicycle\n","Training for class: Aeroplane\n","Number of positive samples for Aeroplane: 288\n","Number of negative samples before balancing: 6619\n","Number of negative samples after balancing: 288\n","Found 460 validated image filenames belonging to 2 classes.\n","Found 116 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711574731.645535      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m 7/14\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 391ms/step - accuracy: 0.6055 - loss: 0.7459"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574736.519536      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538ms/step - accuracy: 0.6307 - loss: 0.7235"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574739.979107      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 634ms/step - accuracy: 0.6332 - loss: 0.7205 - val_accuracy: 0.6458 - val_loss: 0.6445\n","Epoch 2/10\n","\u001b[1m 1/14\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 383ms/step - accuracy: 0.6250 - loss: 0.5768"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.6250 - loss: 0.5768 - val_accuracy: 0.7500 - val_loss: 0.5122\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574741.115478      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 411ms/step - accuracy: 0.7074 - loss: 0.5456 - val_accuracy: 0.7083 - val_loss: 0.5642\n","Epoch 4/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.5962 - val_accuracy: 0.5000 - val_loss: 0.6486\n","Epoch 5/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 431ms/step - accuracy: 0.8009 - loss: 0.4528 - val_accuracy: 0.6875 - val_loss: 0.7358\n","Epoch 6/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7812 - loss: 0.5137 - val_accuracy: 0.6500 - val_loss: 0.7626\n","Epoch 7/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 430ms/step - accuracy: 0.7854 - loss: 0.4338 - val_accuracy: 0.6875 - val_loss: 0.5019\n","Epoch 8/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8125 - loss: 0.3801 - val_accuracy: 0.6500 - val_loss: 0.8850\n","Epoch 9/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 414ms/step - accuracy: 0.8330 - loss: 0.3605 - val_accuracy: 0.6771 - val_loss: 0.7085\n","Epoch 10/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6875 - loss: 0.5863 - val_accuracy: 0.8000 - val_loss: 0.5086\n","Finished training for class: Aeroplane\n","Training for class: Train\n","Number of positive samples for Train: 220\n","Number of negative samples before balancing: 6687\n","Number of negative samples after balancing: 220\n","Found 352 validated image filenames belonging to 2 classes.\n","Found 88 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711574787.387718      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.5077 - loss: 0.7621"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574792.610956      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 501ms/step - accuracy: 0.5104 - loss: 0.7580 - val_accuracy: 0.5469 - val_loss: 0.6897\n","Epoch 2/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.4583 - val_loss: 0.7194\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574793.223356      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 423ms/step - accuracy: 0.5820 - loss: 0.6804 - val_accuracy: 0.4531 - val_loss: 0.7581\n","Epoch 4/10\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.6667 - val_loss: 0.5879\n","Epoch 5/10\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 428ms/step - accuracy: 0.6189 - loss: 0.6368 - val_accuracy: 0.6875 - val_loss: 0.5971\n","Epoch 6/10\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.6667 - val_loss: 0.6157\n","Epoch 7/10\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 430ms/step - accuracy: 0.7051 - loss: 0.5535 - val_accuracy: 0.6719 - val_loss: 0.5550\n","Epoch 8/10\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.7917 - val_loss: 0.4595\n","Epoch 9/10\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 429ms/step - accuracy: 0.7380 - loss: 0.5083 - val_accuracy: 0.8125 - val_loss: 0.3920\n","Epoch 10/10\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.7500 - val_loss: 0.6728\n","Finished training for class: Train\n","Training for class: Bottle\n","Number of positive samples for Bottle: 294\n","Number of negative samples before balancing: 6613\n","Number of negative samples after balancing: 294\n","Found 470 validated image filenames belonging to 2 classes.\n","Found 118 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711574833.799260      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m10/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 392ms/step - accuracy: 0.5573 - loss: 0.8388"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574839.915761      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553ms/step - accuracy: 0.5519 - loss: 0.8187"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574842.278507      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 645ms/step - accuracy: 0.5507 - loss: 0.8149 - val_accuracy: 0.5521 - val_loss: 0.6819\n","Epoch 2/10\n","\u001b[1m 1/14\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 384ms/step - accuracy: 0.5625 - loss: 0.6852"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5625 - loss: 0.6852 - val_accuracy: 0.4545 - val_loss: 0.7069\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574843.408071      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 430ms/step - accuracy: 0.5136 - loss: 0.7062 - val_accuracy: 0.5208 - val_loss: 0.6879\n","Epoch 4/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 0.6827 - val_accuracy: 0.5455 - val_loss: 0.6879\n","Epoch 5/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 427ms/step - accuracy: 0.5436 - loss: 0.6934 - val_accuracy: 0.4896 - val_loss: 0.6896\n","Epoch 6/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7812 - loss: 0.6575 - val_accuracy: 0.6818 - val_loss: 0.6498\n","Epoch 7/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 425ms/step - accuracy: 0.5779 - loss: 0.6739 - val_accuracy: 0.5104 - val_loss: 0.6861\n","Epoch 8/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5000 - loss: 0.6609 - val_accuracy: 0.6818 - val_loss: 0.6284\n","Epoch 9/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 424ms/step - accuracy: 0.5294 - loss: 0.6794 - val_accuracy: 0.5000 - val_loss: 0.6797\n","Epoch 10/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 0.6433 - val_accuracy: 0.5455 - val_loss: 0.6723\n","Finished training for class: Bottle\n","Training for class: Boat\n","Number of positive samples for Boat: 265\n","Number of negative samples before balancing: 6642\n","Number of negative samples after balancing: 265\n","Found 424 validated image filenames belonging to 2 classes.\n","Found 106 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711574890.814882      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m10/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1s\u001b[0m 608ms/step - accuracy: 0.5860 - loss: 0.7079"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574896.534746      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554ms/step - accuracy: 0.5892 - loss: 0.7013"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574898.797968      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 658ms/step - accuracy: 0.5903 - loss: 0.6992 - val_accuracy: 0.6667 - val_loss: 0.6198\n","Epoch 2/10\n","\u001b[1m 1/13\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 385ms/step - accuracy: 0.5312 - loss: 0.8833"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5312 - loss: 0.8833 - val_accuracy: 0.5000 - val_loss: 0.6210\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574899.961291      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 427ms/step - accuracy: 0.7235 - loss: 0.5173 - val_accuracy: 0.6979 - val_loss: 0.5952\n","Epoch 4/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7188 - loss: 0.4977 - val_accuracy: 0.9000 - val_loss: 0.3036\n","Epoch 5/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 432ms/step - accuracy: 0.7841 - loss: 0.4278 - val_accuracy: 0.8438 - val_loss: 0.4374\n","Epoch 6/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8750 - loss: 0.3316 - val_accuracy: 0.7000 - val_loss: 0.5113\n","Epoch 7/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 419ms/step - accuracy: 0.8585 - loss: 0.3169 - val_accuracy: 0.8646 - val_loss: 0.6251\n","Epoch 8/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7812 - loss: 0.6328 - val_accuracy: 0.6000 - val_loss: 0.8683\n","Epoch 9/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 417ms/step - accuracy: 0.8144 - loss: 0.4149 - val_accuracy: 0.8438 - val_loss: 0.3784\n","Epoch 10/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9062 - loss: 0.2088 - val_accuracy: 0.7000 - val_loss: 0.4819\n","Finished training for class: Boat\n","Training for class: Car\n","Number of positive samples for Car: 472\n","Number of negative samples before balancing: 6435\n","Number of negative samples after balancing: 472\n","Found 755 validated image filenames belonging to 2 classes.\n","Found 189 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711574944.658757      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:24\u001b[0m 9s/step - accuracy: 0.4062 - loss: 0.8347"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574947.191735      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - accuracy: 0.5308 - loss: 0.8276"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574956.715473      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 556ms/step - accuracy: 0.5321 - loss: 0.8240 - val_accuracy: 0.5437 - val_loss: 0.6636\n","Epoch 2/10\n","\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 399ms/step - accuracy: 0.4062 - loss: 0.7166"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.4062 - loss: 0.7166 - val_accuracy: 0.5172 - val_loss: 0.6882\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711574958.110709      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 426ms/step - accuracy: 0.6101 - loss: 0.6490 - val_accuracy: 0.6500 - val_loss: 0.6144\n","Epoch 4/10\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5938 - loss: 0.6026 - val_accuracy: 0.7931 - val_loss: 0.5522\n","Epoch 5/10\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 433ms/step - accuracy: 0.6998 - loss: 0.5950 - val_accuracy: 0.6750 - val_loss: 0.6084\n","Epoch 6/10\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7188 - loss: 0.5294 - val_accuracy: 0.7586 - val_loss: 0.5149\n","Epoch 7/10\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 427ms/step - accuracy: 0.6977 - loss: 0.6060 - val_accuracy: 0.6438 - val_loss: 0.5878\n","Epoch 8/10\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6875 - loss: 0.5796 - val_accuracy: 0.7241 - val_loss: 0.6449\n","Epoch 9/10\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 434ms/step - accuracy: 0.6429 - loss: 0.6353 - val_accuracy: 0.6062 - val_loss: 0.6391\n","Epoch 10/10\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7188 - loss: 0.6148 - val_accuracy: 0.7931 - val_loss: 0.5608\n","Finished training for class: Car\n","Training for class: Cow\n","Number of positive samples for Cow: 159\n","Number of negative samples before balancing: 6748\n","Number of negative samples after balancing: 159\n","Found 254 validated image filenames belonging to 2 classes.\n","Found 64 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711575020.860581      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m6/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - accuracy: 0.5342 - loss: 0.7957"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711575025.309710      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741ms/step - accuracy: 0.5293 - loss: 0.7962"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711575026.628403      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 926ms/step - accuracy: 0.5257 - loss: 0.7966 - val_accuracy: 0.5469 - val_loss: 0.6570\n","Epoch 2/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5625 - loss: 0.6821 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 441ms/step - accuracy: 0.6209 - loss: 0.6652 - val_accuracy: 0.5938 - val_loss: 0.6290\n","Epoch 4/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6562 - loss: 0.6553 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n","Epoch 5/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 439ms/step - accuracy: 0.6577 - loss: 0.6502 - val_accuracy: 0.7500 - val_loss: 0.5865\n","Epoch 6/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6250 - loss: 0.6399 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n","Epoch 7/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 448ms/step - accuracy: 0.6466 - loss: 0.6121 - val_accuracy: 0.7656 - val_loss: 0.6052\n","Epoch 8/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7188 - loss: 0.5694 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n","Epoch 9/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 449ms/step - accuracy: 0.7053 - loss: 0.5868 - val_accuracy: 0.7344 - val_loss: 0.5709\n","Epoch 10/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4688 - loss: 0.7184 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n","Finished training for class: Cow\n","Training for class: Bird\n","Number of positive samples for Bird: 344\n","Number of negative samples before balancing: 6563\n","Number of negative samples after balancing: 344\n","Found 550 validated image filenames belonging to 2 classes.\n","Found 138 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711575061.817307      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m10/17\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 613ms/step - accuracy: 0.5844 - loss: 0.8183"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711575067.625712      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521ms/step - accuracy: 0.5734 - loss: 0.7863"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711575071.486536      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 606ms/step - accuracy: 0.5726 - loss: 0.7830 - val_accuracy: 0.5391 - val_loss: 0.6832\n","Epoch 2/10\n","\u001b[1m 1/17\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 395ms/step - accuracy: 0.7812 - loss: 0.6048"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7812 - loss: 0.6048 - val_accuracy: 0.7000 - val_loss: 0.5930\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711575072.749532      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 423ms/step - accuracy: 0.5069 - loss: 0.7232 - val_accuracy: 0.6016 - val_loss: 0.6815\n","Epoch 4/10\n","\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6875 - loss: 0.6653 - val_accuracy: 0.7000 - val_loss: 0.6627\n","Epoch 5/10\n","\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 435ms/step - accuracy: 0.6165 - loss: 0.6718 - val_accuracy: 0.6328 - val_loss: 0.5974\n","Epoch 6/10\n","\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3333 - loss: 0.7724 - val_accuracy: 0.5000 - val_loss: 0.7073\n","Epoch 7/10\n","\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 430ms/step - accuracy: 0.6355 - loss: 0.6392 - val_accuracy: 0.7266 - val_loss: 0.6054\n","Epoch 8/10\n","\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5938 - loss: 0.8084 - val_accuracy: 0.5000 - val_loss: 0.9992\n","Epoch 9/10\n","\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 412ms/step - accuracy: 0.6714 - loss: 0.6022 - val_accuracy: 0.5625 - val_loss: 0.6700\n","Epoch 10/10\n","\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4375 - loss: 0.7483 - val_accuracy: 0.8000 - val_loss: 0.5570\n","Finished training for class: Bird\n","Training for class: Pottedplant\n","Number of positive samples for Pottedplant: 244\n","Number of negative samples before balancing: 6663\n","Number of negative samples after balancing: 244\n","Found 390 validated image filenames belonging to 2 classes.\n","Found 98 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711575124.556848      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m 6/12\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 772ms/step - accuracy: 0.4921 - loss: 0.9007"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711575128.691281      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561ms/step - accuracy: 0.4906 - loss: 0.8467"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711575132.086433      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 677ms/step - accuracy: 0.4914 - loss: 0.8408 - val_accuracy: 0.5729 - val_loss: 0.6906\n","Epoch 2/10\n","\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 382ms/step - accuracy: 0.4062 - loss: 0.6953"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.4062 - loss: 0.6953 - val_accuracy: 1.0000 - val_loss: 0.6638\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711575133.217279      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 403ms/step - accuracy: 0.5141 - loss: 0.6930 - val_accuracy: 0.5521 - val_loss: 0.6892\n","Epoch 4/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4688 - loss: 0.6949 - val_accuracy: 0.0000e+00 - val_loss: 0.7224\n","Epoch 5/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 426ms/step - accuracy: 0.5120 - loss: 0.6884 - val_accuracy: 0.5521 - val_loss: 0.6829\n","Epoch 6/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6562 - loss: 0.6367 - val_accuracy: 0.0000e+00 - val_loss: 0.7056\n","Epoch 7/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 434ms/step - accuracy: 0.4900 - loss: 0.6975 - val_accuracy: 0.6042 - val_loss: 0.6692\n","Epoch 8/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6250 - loss: 0.6635 - val_accuracy: 0.5000 - val_loss: 0.7266\n","Epoch 9/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 415ms/step - accuracy: 0.5889 - loss: 0.6825 - val_accuracy: 0.5625 - val_loss: 0.6814\n","Epoch 10/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5938 - loss: 0.6456 - val_accuracy: 1.0000 - val_loss: 0.6620\n","Finished training for class: Pottedplant\n","Training for class: Tvmonitor\n","Number of positive samples for Tvmonitor: 272\n","Number of negative samples before balancing: 6635\n","Number of negative samples after balancing: 272\n","Found 435 validated image filenames belonging to 2 classes.\n","Found 109 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711575175.365452      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m 3/13\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 394ms/step - accuracy: 0.5278 - loss: 0.8411"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711575178.629940      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561ms/step - accuracy: 0.5402 - loss: 0.7739"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711575183.425936      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 666ms/step - accuracy: 0.5413 - loss: 0.7701 - val_accuracy: 0.5000 - val_loss: 0.8469\n","Epoch 2/10\n","\u001b[1m 1/13\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 386ms/step - accuracy: 0.5625 - loss: 0.8268"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5625 - loss: 0.8268 - val_accuracy: 0.7692 - val_loss: 0.5608\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711575184.576172      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 422ms/step - accuracy: 0.5918 - loss: 0.6470 - val_accuracy: 0.6458 - val_loss: 0.6116\n","Epoch 4/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6875 - loss: 0.6376 - val_accuracy: 0.6154 - val_loss: 0.5401\n","Epoch 5/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 430ms/step - accuracy: 0.7386 - loss: 0.5632 - val_accuracy: 0.7083 - val_loss: 0.5082\n","Epoch 6/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6875 - loss: 0.6036 - val_accuracy: 0.6154 - val_loss: 0.7806\n","Epoch 7/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 426ms/step - accuracy: 0.6963 - loss: 0.5447 - val_accuracy: 0.7083 - val_loss: 0.5048\n","Epoch 8/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7188 - loss: 0.5029 - val_accuracy: 0.7692 - val_loss: 0.3709\n","Epoch 9/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 433ms/step - accuracy: 0.7872 - loss: 0.4532 - val_accuracy: 0.6875 - val_loss: 0.7090\n","Epoch 10/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7188 - loss: 0.8198 - val_accuracy: 0.8462 - val_loss: 0.4634\n","Finished training for class: Tvmonitor\n","Training for class: Dog\n","Number of positive samples for Dog: 410\n","Number of negative samples before balancing: 6497\n","Number of negative samples after balancing: 410\n","Found 656 validated image filenames belonging to 2 classes.\n","Found 164 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711575229.009741      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m 1/20\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:48\u001b[0m 9s/step - accuracy: 0.4062 - loss: 0.9716"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711575231.528096      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step - accuracy: 0.4856 - loss: 0.8074"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711575239.665948      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 570ms/step - accuracy: 0.4865 - loss: 0.8042 - val_accuracy: 0.5250 - val_loss: 0.6921\n","Epoch 2/10\n","\u001b[1m 1/20\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 393ms/step - accuracy: 0.4375 - loss: 0.7249"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4375 - loss: 0.7249 - val_accuracy: 0.5000 - val_loss: 0.6974\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711575241.050834      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 426ms/step - accuracy: 0.5250 - loss: 0.6985 - val_accuracy: 0.4812 - val_loss: 0.6982\n","Epoch 4/10\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5312 - loss: 0.6889 - val_accuracy: 0.2500 - val_loss: 0.7280\n","Epoch 5/10\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 428ms/step - accuracy: 0.4977 - loss: 0.6941 - val_accuracy: 0.4688 - val_loss: 0.6942\n","Epoch 6/10\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3750 - loss: 0.7028 - val_accuracy: 0.5000 - val_loss: 0.6865\n","Epoch 7/10\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 429ms/step - accuracy: 0.5359 - loss: 0.6880 - val_accuracy: 0.5188 - val_loss: 0.6922\n","Epoch 8/10\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5312 - loss: 0.6900 - val_accuracy: 0.7500 - val_loss: 0.6674\n","Epoch 9/10\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 412ms/step - accuracy: 0.5119 - loss: 0.6919 - val_accuracy: 0.4875 - val_loss: 0.6929\n","Epoch 10/10\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5000 - loss: 0.6958 - val_accuracy: 1.0000 - val_loss: 0.6625\n","Finished training for class: Dog\n","Training for class: Chair\n","Number of positive samples for Chair: 380\n","Number of negative samples before balancing: 6527\n","Number of negative samples after balancing: 380\n","Found 608 validated image filenames belonging to 2 classes.\n","Found 152 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711575297.600196      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - accuracy: 0.5100 - loss: 0.9386"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711575305.876939      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 461ms/step - accuracy: 0.5110 - loss: 0.9314 - val_accuracy: 0.4922 - val_loss: 0.6911\n","Epoch 2/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.5417 - val_loss: 0.6850\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711575306.740065      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 424ms/step - accuracy: 0.5146 - loss: 0.6945 - val_accuracy: 0.4922 - val_loss: 0.7018\n","Epoch 4/10\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.5000 - val_loss: 0.7040\n","Epoch 5/10\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 428ms/step - accuracy: 0.5918 - loss: 0.6825 - val_accuracy: 0.5000 - val_loss: 0.7006\n","Epoch 6/10\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.5833 - val_loss: 0.6798\n","Epoch 7/10\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 430ms/step - accuracy: 0.5734 - loss: 0.6822 - val_accuracy: 0.5391 - val_loss: 0.6812\n","Epoch 8/10\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.7083 - val_loss: 0.6423\n","Epoch 9/10\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 428ms/step - accuracy: 0.5688 - loss: 0.6857 - val_accuracy: 0.5703 - val_loss: 0.6809\n","Epoch 10/10\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.2500 - val_loss: 0.8988\n","Finished training for class: Chair\n"]}],"source":["# Loop through each class and train a binary classification model\n","for class_name in class_names:\n","    print(f\"Training for class: {class_name}\")\n","\n","    # Retrieve the list of image paths for the positive class\n","    positive_images = train_data_lists[class_name]\n","    if not positive_images:\n","        print(f\"No images found for class {class_name}. Skipping this class.\")\n","        continue\n","    positive_labels = [1] * len(positive_images)\n","\n","    # Build a list of image paths for the negative class (all other classes)\n","    negative_images = []\n","    for other_class_name, image_paths in train_data_lists.items():\n","        if other_class_name != class_name:\n","            negative_images.extend(image_paths)\n","\n","    print(f\"Number of positive samples for {class_name}: {len(positive_images)}\")\n","    print(f\"Number of negative samples before balancing: {len(negative_images)}\")\n","\n","\n","    random.shuffle(negative_images)  # Shuffle the negative images\n","    negative_images = negative_images[:len(positive_images)]  # Balance the positive and negative datasets\n","    negative_labels = [0] * len(negative_images)\n","    print(f\"Number of negative samples after balancing: {len(negative_images)}\")\n","\n","    # Combine and shuffle the positive and negative samples\n","    combined_images = positive_images + negative_images\n","    combined_labels = positive_labels + negative_labels\n","    combined_list = list(zip(combined_images, combined_labels))\n","    random.shuffle(combined_list)\n","    combined_images, combined_labels = zip(*combined_list)\n","\n","    # Split the data into training and validation sets\n","    X_train, X_val, y_train, y_val = train_test_split(combined_images, combined_labels, test_size=0.2, random_state=42)\n","\n","    # Create DataFrames for the training and validation sets\n","    train_df = pd.DataFrame({\n","    'filename': X_train,\n","    'label': [str(label) for label in y_train]  # Convert labels to strings\n","})\n","    val_df = pd.DataFrame({\n","    'filename': X_val,\n","    'label': [str(label) for label in y_val]  # Convert labels to strings\n","})\n","\n","    # Create data generators for training and validation\n","    train_generator = train_datagen.flow_from_dataframe(\n","        train_df,\n","        x_col='filename',\n","        y_col='label',\n","        target_size=(224, 224),\n","        batch_size=32,\n","        class_mode='binary'\n","    )\n","\n","    val_datagen = ImageDataGenerator(rescale=1./255)\n","    val_generator = val_datagen.flow_from_dataframe(\n","        val_df,\n","        x_col='filename',\n","        y_col='label',\n","        target_size=(224, 224),\n","        batch_size=32,\n","        class_mode='binary'\n","    )\n","\n","    #Build the binary classification model\n","    model = build_binary_classification_model()\n","\n","    # Train the model on the data\n","    history = model.fit(\n","        train_generator,\n","        steps_per_epoch=len(X_train) // 32,\n","        validation_data=val_generator,\n","        validation_steps=len(X_val) // 32,\n","        epochs=10\n","    )\n","\n","    # Save the trained model\n","    model_save_path = os.path.join('models', f\"{class_name}_binary_model.h5\")\n","    os.makedirs('models2', exist_ok=True)\n","    model.save(model_save_path)\n","\n","    print(f\"Finished training for class: {class_name}\")"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T21:49:51.737736Z","iopub.status.busy":"2024-03-27T21:49:51.737359Z","iopub.status.idle":"2024-03-27T21:49:51.746418Z","shell.execute_reply":"2024-03-27T21:49:51.745495Z","shell.execute_reply.started":"2024-03-27T21:49:51.737705Z"},"trusted":true},"outputs":[],"source":["import os\n","import shutil\n","\n","# Define the path to the train directory\n","train_dir = \"/content/test\"\n","\n","# Iterate over each subfolder in the train directory\n","for class_name in os.listdir(train_dir):\n","    class_dir = os.path.join(train_dir, class_name)\n","    \n","    # Check if the item in the directory is a subfolder\n","    if os.path.isdir(class_dir):\n","        # Define the path to the subsubfolder\n","        subsubfolder_dir = os.path.join(class_dir, class_name)\n","        \n","        # Check if the subsubfolder exists\n","        if os.path.exists(subsubfolder_dir):\n","            # Iterate over each file in the subsubfolder\n","            for file_name in os.listdir(subsubfolder_dir):\n","                file_path = os.path.join(subsubfolder_dir, file_name)\n","                \n","                # Move the file to the parent subfolder\n","                if os.path.isfile(file_path):\n","                    shutil.move(file_path, class_dir)\n","            \n","            # Remove the empty subsubfolder\n","            os.rmdir(subsubfolder_dir)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","from sklearn.metrics import classification_report, confusion_matrix, average_precision_score\n","import matplotlib.pyplot as plt\n","from PIL import Image, ImageDraw, ImageFont\n","\n","model_dir = '/content/models'\n","test_data_dir = '/content/test'\n","\n","# Initialize ImageDataGenerator for preprocessing\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Store average precision scores for mAP calculation\n","ap_scores = []\n","\n","# Loop through each model file in the models directory\n","for model_file in sorted(os.listdir(model_dir)):\n","    if model_file.endswith(\".h5\"):\n","        print(f\"\\nLoading model {model_file}...\")\n","        model_path = os.path.join(model_dir, model_file)\n","        model = load_model(model_path)\n","        class_name = model_file.replace(\"_binary_model.h5\", \"\")\n","        print(f\"Model for class '{class_name}' loaded successfully.\")\n","\n","        # Create DataFrame for test data with labels as strings\n","        images = []\n","        labels = []\n","        for folder in os.listdir(test_data_dir):\n","            folder_path = os.path.join(test_data_dir, folder)\n","            for image_file in os.listdir(folder_path):\n","                images.append(os.path.join(folder, image_file))\n","                labels.append(str(int(folder == class_name)))  # Convert boolean to int to string\n","\n","        test_df = pd.DataFrame({\n","            'filename': images,\n","            'label': labels  # Labels are now strings\n","        })\n","\n","        # Prepare test generator\n","        test_generator = test_datagen.flow_from_dataframe(\n","            dataframe=test_df,\n","            directory=test_data_dir,\n","            x_col='filename',\n","            y_col='label',\n","            target_size=(224, 224),\n","            batch_size=32,\n","            class_mode='binary',\n","            shuffle=False)\n","\n","        # Predict and evaluate\n","        predictions = model.predict(test_generator, steps=int(np.ceil(len(test_df)/32)))\n","\n","        predicted_labels = (predictions > 0.5).astype(int)\n","        ap_score = average_precision_score(test_generator.classes, predictions)\n","        ap_scores.append(ap_score)\n","        #print(f\"AP score for class '{class_name}': {ap_score:.3f}\")\n","\n","\n","\n"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T21:53:28.075873Z","iopub.status.busy":"2024-03-27T21:53:28.074936Z","iopub.status.idle":"2024-03-27T21:53:28.080789Z","shell.execute_reply":"2024-03-27T21:53:28.079887Z","shell.execute_reply.started":"2024-03-27T21:53:28.075838Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Mean Average Precision (mAP) across all classes: 0.152\n"]}],"source":["# Calculate mean Average Precision (mAP)\n","mAP = np.mean(ap_scores)\n","print(f\"\\nMean Average Precision (mAP) across all classes: {mAP:.3f}\")"]},{"cell_type":"markdown","metadata":{},"source":["# 500 samples"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import random\n","\n","\n","# Define paths\n","samples_folder = '/content/generated_data-500samples'\n","train_folder = '/content/train'\n","\n","# Ensure the train folder exists\n","os.makedirs(train_folder, exist_ok=True)\n","\n","# Iterate through each class folder in the 500 samples folder\n","for class_name in os.listdir(samples_folder):\n","    class_folder = os.path.join(samples_folder, class_name)\n","    \n","    # Ensure it's a directory\n","    if os.path.isdir(class_folder):\n","        # Create the corresponding class subfolder in the train folder\n","        class_train_folder = os.path.join(train_folder, class_name, class_name)\n","        os.makedirs(class_train_folder, exist_ok=True)\n","        \n","        # Get a list of all images in the class folder\n","        images = os.listdir(class_folder)\n","        \n","        # Randomly select 300 images  *200 images already moved in the previous cells  200+300=500* \n","        selected_images = random.sample(images, 300)    \n","        \n","        # Copy selected images to the train folder\n","        for image in selected_images:\n","            src_path = os.path.join(class_folder, image)\n","            dest_path = os.path.join(class_train_folder, image)\n","            shutil.copy(src_path, dest_path)\n","            print(f\"Copied {image} to {class_train_folder}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","import shutil\n","\n","# Define the train folder path\n","train_folder = '/content/train'\n","\n","# Iterate through each class subfolder in the train folder\n","for class_folder in os.listdir(train_folder):\n","    class_subfolder = os.path.join(train_folder, class_folder)\n","    \n","    # Ensure it's a directory\n","    if os.path.isdir(class_subfolder):\n","        # Get the path of the second subfolder\n","        second_subfolder = os.path.join(class_subfolder, class_folder)\n","        \n","        # Ensure the second subfolder exists\n","        if os.path.exists(second_subfolder):\n","            # Move images from the second subfolder to the first subfolder\n","            for image_file in os.listdir(second_subfolder):\n","                src_path = os.path.join(second_subfolder, image_file)\n","                dest_path = os.path.join(class_subfolder, image_file)\n","                shutil.move(src_path, dest_path)\n","                print(f\"Moved {image_file} from {second_subfolder} to {class_subfolder}\")\n","            \n","            # Remove the second subfolder\n","            os.rmdir(second_subfolder)\n","            print(f\"Removed {second_subfolder}\")\n"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T21:56:53.640850Z","iopub.status.busy":"2024-03-27T21:56:53.640158Z","iopub.status.idle":"2024-03-27T22:17:20.673738Z","shell.execute_reply":"2024-03-27T22:17:20.672311Z","shell.execute_reply.started":"2024-03-27T21:56:53.640814Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training for class: Cat\n","Number of positive samples for Cat: 362\n","Number of negative samples before balancing: 6545\n","Number of negative samples after balancing: 362\n","Found 579 validated image filenames belonging to 2 classes.\n","Found 145 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711576622.490901      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m 6/18\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 764ms/step - accuracy: 0.5324 - loss: 0.7583"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711576626.658146      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506ms/step - accuracy: 0.5265 - loss: 0.7366"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711576632.398010      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 585ms/step - accuracy: 0.5269 - loss: 0.7353 - val_accuracy: 0.4453 - val_loss: 0.7308\n","Epoch 2/10\n","\u001b[1m 1/18\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 389ms/step - accuracy: 0.5000 - loss: 0.7112"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5000 - loss: 0.7112 - val_accuracy: 0.7059 - val_loss: 0.6428\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711576633.663911      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 429ms/step - accuracy: 0.4949 - loss: 0.6986 - val_accuracy: 0.5078 - val_loss: 0.6921\n","Epoch 4/10\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4375 - loss: 0.6932 - val_accuracy: 0.5882 - val_loss: 0.6889\n","Epoch 5/10\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 428ms/step - accuracy: 0.4967 - loss: 0.6922 - val_accuracy: 0.5312 - val_loss: 0.6885\n","Epoch 6/10\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6250 - loss: 0.6852 - val_accuracy: 0.5294 - val_loss: 0.6885\n","Epoch 7/10\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 424ms/step - accuracy: 0.5377 - loss: 0.6831 - val_accuracy: 0.5078 - val_loss: 0.6902\n","Epoch 8/10\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5625 - loss: 0.6641 - val_accuracy: 0.5882 - val_loss: 0.6816\n","Epoch 9/10\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 405ms/step - accuracy: 0.6166 - loss: 0.6451 - val_accuracy: 0.6641 - val_loss: 0.5856\n","Epoch 10/10\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6562 - loss: 0.6419 - val_accuracy: 0.6471 - val_loss: 0.5831\n","Finished training for class: Cat\n","Training for class: Sofa\n","Number of positive samples for Sofa: 207\n","Number of negative samples before balancing: 6700\n","Number of negative samples after balancing: 207\n","Found 331 validated image filenames belonging to 2 classes.\n","Found 83 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711576686.574617      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m 6/10\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 767ms/step - accuracy: 0.4160 - loss: 0.9969"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711576690.629105      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599ms/step - accuracy: 0.4329 - loss: 0.9223"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711576693.282307      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 724ms/step - accuracy: 0.4364 - loss: 0.9106 - val_accuracy: 0.5781 - val_loss: 0.6870\n","Epoch 2/10\n","\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 381ms/step - accuracy: 0.5000 - loss: 0.7025"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.5000 - loss: 0.7025 - val_accuracy: 0.4211 - val_loss: 0.7169\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711576694.304403      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 400ms/step - accuracy: 0.5183 - loss: 0.6986 - val_accuracy: 0.5781 - val_loss: 0.6704\n","Epoch 4/10\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4688 - loss: 0.6974 - val_accuracy: 0.4211 - val_loss: 0.6902\n","Epoch 5/10\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 430ms/step - accuracy: 0.5403 - loss: 0.6885 - val_accuracy: 0.5781 - val_loss: 0.6719\n","Epoch 6/10\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4545 - loss: 0.7070 - val_accuracy: 0.5263 - val_loss: 0.6914\n","Epoch 7/10\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 430ms/step - accuracy: 0.5958 - loss: 0.6633 - val_accuracy: 0.6719 - val_loss: 0.6464\n","Epoch 8/10\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6250 - loss: 0.6238 - val_accuracy: 0.7368 - val_loss: 0.5883\n","Epoch 9/10\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 441ms/step - accuracy: 0.6105 - loss: 0.6671 - val_accuracy: 0.6719 - val_loss: 0.6438\n","Epoch 10/10\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6364 - loss: 0.5860 - val_accuracy: 0.7895 - val_loss: 0.5242\n","Finished training for class: Sofa\n","Training for class: Sheep\n","Number of positive samples for Sheep: 151\n","Number of negative samples before balancing: 6756\n","Number of negative samples after balancing: 151\n","Found 241 validated image filenames belonging to 2 classes.\n","Found 61 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711576732.949735      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m4/7\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 400ms/step - accuracy: 0.4603 - loss: 0.8154"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711576736.634594      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 890ms/step - accuracy: 0.5218 - loss: 0.7748 - val_accuracy: 0.6875 - val_loss: 0.5234\n","Epoch 2/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711576738.605317      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 391ms/step - accuracy: 0.6562 - loss: 0.6238"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.6562 - loss: 0.6238 - val_accuracy: 0.8621 - val_loss: 0.4696\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711576739.494381      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 378ms/step - accuracy: 0.6702 - loss: 0.5961 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n","Epoch 4/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.6562 - loss: 0.6696 - val_accuracy: 0.7812 - val_loss: 0.5443\n","Epoch 5/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 397ms/step - accuracy: 0.7304 - loss: 0.5591 - val_accuracy: 0.7586 - val_loss: 0.5129\n","Epoch 6/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6875 - loss: 0.6132 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n","Epoch 7/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 431ms/step - accuracy: 0.7573 - loss: 0.5226 - val_accuracy: 0.8438 - val_loss: 0.4365\n","Epoch 8/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7812 - loss: 0.3717 - val_accuracy: 0.8276 - val_loss: 0.4595\n","Epoch 9/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 377ms/step - accuracy: 0.8046 - loss: 0.4489 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n","Epoch 10/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8125 - loss: 0.3346 - val_accuracy: 0.8750 - val_loss: 0.2647\n","Finished training for class: Sheep\n","Training for class: Diningtable\n","Number of positive samples for Diningtable: 184\n","Number of negative samples before balancing: 6723\n","Number of negative samples after balancing: 184\n","Found 294 validated image filenames belonging to 2 classes.\n","Found 74 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711576772.603175      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m4/9\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.5671 - loss: 0.7204   "]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711576775.944273      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632ms/step - accuracy: 0.5561 - loss: 0.7176"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711576778.934285      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 766ms/step - accuracy: 0.5566 - loss: 0.7157 - val_accuracy: 0.6406 - val_loss: 0.5923\n","Epoch 2/10\n","\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 383ms/step - accuracy: 0.7500 - loss: 0.5748"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.5748 - val_accuracy: 0.7000 - val_loss: 0.6120\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711576779.968999      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 404ms/step - accuracy: 0.6762 - loss: 0.6204 - val_accuracy: 0.7656 - val_loss: 0.5174\n","Epoch 4/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5625 - loss: 0.6016 - val_accuracy: 0.9000 - val_loss: 0.2240\n","Epoch 5/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 402ms/step - accuracy: 0.7201 - loss: 0.5348 - val_accuracy: 0.6562 - val_loss: 0.5712\n","Epoch 6/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6875 - loss: 0.6598 - val_accuracy: 0.9000 - val_loss: 0.5158\n","Epoch 7/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 409ms/step - accuracy: 0.7071 - loss: 0.6056 - val_accuracy: 0.7500 - val_loss: 0.5556\n","Epoch 8/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7188 - loss: 0.5706 - val_accuracy: 0.9000 - val_loss: 0.4271\n","Epoch 9/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 409ms/step - accuracy: 0.7025 - loss: 0.5589 - val_accuracy: 0.7188 - val_loss: 0.5387\n","Epoch 10/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5938 - loss: 0.6604 - val_accuracy: 0.9000 - val_loss: 0.4919\n","Finished training for class: Diningtable\n","Training for class: Horse\n","Number of positive samples for Horse: 258\n","Number of negative samples before balancing: 6649\n","Number of negative samples after balancing: 258\n","Found 412 validated image filenames belonging to 2 classes.\n","Found 104 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711576816.434020      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m 5/12\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 397ms/step - accuracy: 0.4994 - loss: 0.9413"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711576820.656954      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595ms/step - accuracy: 0.5030 - loss: 0.8645"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711576824.256043      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 704ms/step - accuracy: 0.5036 - loss: 0.8575 - val_accuracy: 0.5000 - val_loss: 0.6968\n","Epoch 2/10\n","\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 391ms/step - accuracy: 0.4688 - loss: 0.7081"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.4688 - loss: 0.7081 - val_accuracy: 0.3750 - val_loss: 0.7455\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711576825.391088      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 436ms/step - accuracy: 0.6421 - loss: 0.6609 - val_accuracy: 0.5521 - val_loss: 0.6766\n","Epoch 4/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6562 - loss: 0.6260 - val_accuracy: 0.5000 - val_loss: 0.5753\n","Epoch 5/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 440ms/step - accuracy: 0.6646 - loss: 0.6276 - val_accuracy: 0.6146 - val_loss: 0.6239\n","Epoch 6/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5312 - loss: 0.6103 - val_accuracy: 0.6250 - val_loss: 0.7476\n","Epoch 7/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 440ms/step - accuracy: 0.7836 - loss: 0.4846 - val_accuracy: 0.8229 - val_loss: 0.5440\n","Epoch 8/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9062 - loss: 0.4825 - val_accuracy: 0.7500 - val_loss: 0.4788\n","Epoch 9/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 439ms/step - accuracy: 0.8369 - loss: 0.4201 - val_accuracy: 0.7708 - val_loss: 0.5419\n","Epoch 10/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8438 - loss: 0.5036 - val_accuracy: 0.7500 - val_loss: 0.3298\n","Finished training for class: Horse\n","Training for class: Person\n","Number of positive samples for Person: 1701\n","Number of negative samples before balancing: 5206\n","Number of negative samples after balancing: 1701\n","Found 2721 validated image filenames belonging to 2 classes.\n","Found 681 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711576870.160006      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step - accuracy: 0.6077 - loss: 0.7087"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711576905.039973      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 441ms/step - accuracy: 0.6081 - loss: 0.7080 - val_accuracy: 0.6845 - val_loss: 0.5879\n","Epoch 2/10\n","\u001b[1m 1/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:50\u001b[0m 2s/step - accuracy: 0.0000e+00 - loss: 1.3178"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 1.3178 - val_accuracy: 1.0000 - val_loss: 0.3490\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711576910.121157      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 424ms/step - accuracy: 0.6224 - loss: 0.6337 - val_accuracy: 0.6920 - val_loss: 0.5923\n","Epoch 4/10\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - accuracy: 0.7500 - loss: 0.5015 - val_accuracy: 0.7778 - val_loss: 0.4613\n","Epoch 5/10\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 422ms/step - accuracy: 0.6760 - loss: 0.6062 - val_accuracy: 0.6920 - val_loss: 0.6198\n","Epoch 6/10\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - accuracy: 0.5938 - loss: 0.6139 - val_accuracy: 0.7778 - val_loss: 0.6453\n","Epoch 7/10\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 420ms/step - accuracy: 0.6677 - loss: 0.6120 - val_accuracy: 0.6905 - val_loss: 0.5632\n","Epoch 8/10\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - accuracy: 0.5625 - loss: 0.6418 - val_accuracy: 0.4444 - val_loss: 0.6250\n","Epoch 9/10\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 422ms/step - accuracy: 0.6903 - loss: 0.5855 - val_accuracy: 0.6949 - val_loss: 0.5725\n","Epoch 10/10\n","\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - accuracy: 0.6562 - loss: 0.6149 - val_accuracy: 0.5556 - val_loss: 0.6255\n","Finished training for class: Person\n","Training for class: Motorbike\n","Number of positive samples for Motorbike: 263\n","Number of negative samples before balancing: 6644\n","Number of negative samples after balancing: 263\n","Found 420 validated image filenames belonging to 2 classes.\n","Found 106 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711577076.433646      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m 2/13\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 2s/step - accuracy: 0.5295 - loss: 0.7412 "]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577079.101978      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556ms/step - accuracy: 0.5816 - loss: 0.7128"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577084.396810      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 658ms/step - accuracy: 0.5828 - loss: 0.7109 - val_accuracy: 0.5833 - val_loss: 0.6502\n","Epoch 2/10\n","\u001b[1m 1/13\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 381ms/step - accuracy: 0.5000 - loss: 0.7009"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.7009 - val_accuracy: 0.6000 - val_loss: 0.6285\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577085.518831      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 426ms/step - accuracy: 0.6182 - loss: 0.6264 - val_accuracy: 0.5833 - val_loss: 0.6635\n","Epoch 4/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5938 - loss: 0.6696 - val_accuracy: 1.0000 - val_loss: 0.5606\n","Epoch 5/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 436ms/step - accuracy: 0.6257 - loss: 0.6195 - val_accuracy: 0.7500 - val_loss: 0.6989\n","Epoch 6/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.6429 - val_accuracy: 0.5000 - val_loss: 0.7955\n","Epoch 7/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 434ms/step - accuracy: 0.7001 - loss: 0.5274 - val_accuracy: 0.6354 - val_loss: 0.6119\n","Epoch 8/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6875 - loss: 0.5518 - val_accuracy: 0.4000 - val_loss: 1.0077\n","Epoch 9/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 458ms/step - accuracy: 0.7669 - loss: 0.4617 - val_accuracy: 0.8542 - val_loss: 0.6161\n","Epoch 10/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7188 - loss: 0.5588 - val_accuracy: 0.9000 - val_loss: 0.5867\n","Finished training for class: Motorbike\n","Training for class: Bus\n","Number of positive samples for Bus: 180\n","Number of negative samples before balancing: 6727\n","Number of negative samples after balancing: 180\n","Found 288 validated image filenames belonging to 2 classes.\n","Found 72 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711577129.266599      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.5646 - loss: 0.8224"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577133.692867      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 528ms/step - accuracy: 0.5668 - loss: 0.8153 - val_accuracy: 0.4844 - val_loss: 0.7224\n","Epoch 2/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.5000 - val_loss: 0.7656\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577134.328411      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 431ms/step - accuracy: 0.5784 - loss: 0.6602 - val_accuracy: 0.6250 - val_loss: 0.6176\n","Epoch 4/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.8750 - val_loss: 0.4929\n","Epoch 5/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 432ms/step - accuracy: 0.6625 - loss: 0.5903 - val_accuracy: 0.5938 - val_loss: 0.6194\n","Epoch 6/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.7500 - val_loss: 0.5846\n","Epoch 7/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 437ms/step - accuracy: 0.6862 - loss: 0.5848 - val_accuracy: 0.7031 - val_loss: 0.4921\n","Epoch 8/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.6250 - val_loss: 0.4706\n","Epoch 9/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 437ms/step - accuracy: 0.7433 - loss: 0.4746 - val_accuracy: 0.7344 - val_loss: 0.4602\n","Epoch 10/10\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.6250 - val_loss: 0.5246\n","Finished training for class: Bus\n","Training for class: Bicycle\n","Number of positive samples for Bicycle: 253\n","Number of negative samples before balancing: 6654\n","Number of negative samples after balancing: 253\n","Found 404 validated image filenames belonging to 2 classes.\n","Found 102 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711577170.775194      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m 4/12\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 392ms/step - accuracy: 0.4349 - loss: 0.7499"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577174.452517      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573ms/step - accuracy: 0.4755 - loss: 0.7344"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577178.347209      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 681ms/step - accuracy: 0.4774 - loss: 0.7331 - val_accuracy: 0.5312 - val_loss: 0.7042\n","Epoch 2/10\n","\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 386ms/step - accuracy: 0.6250 - loss: 0.6403"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.6250 - loss: 0.6403 - val_accuracy: 0.3333 - val_loss: 0.7328\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577179.480811      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 427ms/step - accuracy: 0.5786 - loss: 0.6580 - val_accuracy: 0.4688 - val_loss: 0.7551\n","Epoch 4/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6250 - loss: 0.6403 - val_accuracy: 0.5000 - val_loss: 0.7273\n","Epoch 5/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 441ms/step - accuracy: 0.5699 - loss: 0.6828 - val_accuracy: 0.6250 - val_loss: 0.6386\n","Epoch 6/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5312 - loss: 0.6996 - val_accuracy: 0.3333 - val_loss: 0.7233\n","Epoch 7/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 431ms/step - accuracy: 0.6275 - loss: 0.6327 - val_accuracy: 0.4688 - val_loss: 0.7789\n","Epoch 8/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5625 - loss: 0.6637 - val_accuracy: 0.5000 - val_loss: 0.7899\n","Epoch 9/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 432ms/step - accuracy: 0.6101 - loss: 0.6685 - val_accuracy: 0.4375 - val_loss: 0.7490\n","Epoch 10/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3750 - loss: 0.7591 - val_accuracy: 0.6667 - val_loss: 0.6755\n","Finished training for class: Bicycle\n","Training for class: Aeroplane\n","Number of positive samples for Aeroplane: 288\n","Number of negative samples before balancing: 6619\n","Number of negative samples after balancing: 288\n","Found 460 validated image filenames belonging to 2 classes.\n","Found 116 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711577223.141706      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m 4/14\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 390ms/step - accuracy: 0.5410 - loss: 1.0036"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577226.863572      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538ms/step - accuracy: 0.5921 - loss: 0.8618"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577231.472120      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 633ms/step - accuracy: 0.5959 - loss: 0.8533 - val_accuracy: 0.7708 - val_loss: 0.5621\n","Epoch 2/10\n","\u001b[1m 1/14\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 381ms/step - accuracy: 0.7812 - loss: 0.5264"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.7812 - loss: 0.5264 - val_accuracy: 0.6500 - val_loss: 0.5806\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577232.594757      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 427ms/step - accuracy: 0.7076 - loss: 0.5512 - val_accuracy: 0.5833 - val_loss: 0.6347\n","Epoch 4/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8333 - loss: 0.4275 - val_accuracy: 0.8000 - val_loss: 0.4637\n","Epoch 5/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 426ms/step - accuracy: 0.7044 - loss: 0.5021 - val_accuracy: 0.7812 - val_loss: 0.4580\n","Epoch 6/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8125 - loss: 0.3795 - val_accuracy: 0.8000 - val_loss: 0.4537\n","Epoch 7/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 430ms/step - accuracy: 0.7627 - loss: 0.4617 - val_accuracy: 0.7604 - val_loss: 0.6804\n","Epoch 8/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8438 - loss: 0.4152 - val_accuracy: 0.8000 - val_loss: 0.4942\n","Epoch 9/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 416ms/step - accuracy: 0.8195 - loss: 0.4139 - val_accuracy: 0.7812 - val_loss: 0.4379\n","Epoch 10/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8438 - loss: 0.3903 - val_accuracy: 0.9000 - val_loss: 0.1863\n","Finished training for class: Aeroplane\n","Training for class: Train\n","Number of positive samples for Train: 220\n","Number of negative samples before balancing: 6687\n","Number of negative samples after balancing: 220\n","Found 352 validated image filenames belonging to 2 classes.\n","Found 88 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711577278.572017      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - accuracy: 0.5049 - loss: 0.8501"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577283.731624      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 497ms/step - accuracy: 0.5080 - loss: 0.8443 - val_accuracy: 0.6562 - val_loss: 0.6728\n","Epoch 2/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.5417 - val_loss: 0.6864\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577284.355421      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 423ms/step - accuracy: 0.6593 - loss: 0.6514 - val_accuracy: 0.5312 - val_loss: 0.7065\n","Epoch 4/10\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.7083 - val_loss: 0.6278\n","Epoch 5/10\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 428ms/step - accuracy: 0.7097 - loss: 0.6030 - val_accuracy: 0.8750 - val_loss: 0.5702\n","Epoch 6/10\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.8333 - val_loss: 0.5598\n","Epoch 7/10\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 428ms/step - accuracy: 0.7882 - loss: 0.5310 - val_accuracy: 0.4844 - val_loss: 0.8699\n","Epoch 8/10\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.7083 - val_loss: 0.7756\n","Epoch 9/10\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 429ms/step - accuracy: 0.7851 - loss: 0.4356 - val_accuracy: 0.8281 - val_loss: 0.3997\n","Epoch 10/10\n","\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.7917 - val_loss: 0.4262\n","Finished training for class: Train\n","Training for class: Bottle\n","Number of positive samples for Bottle: 294\n","Number of negative samples before balancing: 6613\n","Number of negative samples after balancing: 294\n","Found 470 validated image filenames belonging to 2 classes.\n","Found 118 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711577324.708192      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m 3/14\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 390ms/step - accuracy: 0.4774 - loss: 0.9114"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577327.992069      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545ms/step - accuracy: 0.4504 - loss: 0.8381"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577333.058026      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 636ms/step - accuracy: 0.4513 - loss: 0.8347 - val_accuracy: 0.6042 - val_loss: 0.6779\n","Epoch 2/10\n","\u001b[1m 1/14\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 384ms/step - accuracy: 0.6250 - loss: 0.6790"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.6250 - loss: 0.6790 - val_accuracy: 0.6818 - val_loss: 0.6491\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577334.181500      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 426ms/step - accuracy: 0.5059 - loss: 0.6966 - val_accuracy: 0.6458 - val_loss: 0.6674\n","Epoch 4/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4688 - loss: 0.6965 - val_accuracy: 0.6364 - val_loss: 0.6541\n","Epoch 5/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 425ms/step - accuracy: 0.5368 - loss: 0.6855 - val_accuracy: 0.5521 - val_loss: 0.6632\n","Epoch 6/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5625 - loss: 0.6836 - val_accuracy: 0.6364 - val_loss: 0.6469\n","Epoch 7/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 427ms/step - accuracy: 0.6217 - loss: 0.6642 - val_accuracy: 0.5625 - val_loss: 0.6597\n","Epoch 8/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6562 - loss: 0.6415 - val_accuracy: 0.4545 - val_loss: 0.7363\n","Epoch 9/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 425ms/step - accuracy: 0.5268 - loss: 0.6892 - val_accuracy: 0.7396 - val_loss: 0.5906\n","Epoch 10/10\n","\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7188 - loss: 0.6069 - val_accuracy: 0.9091 - val_loss: 0.4895\n","Finished training for class: Bottle\n","Training for class: Boat\n","Number of positive samples for Boat: 265\n","Number of negative samples before balancing: 6642\n","Number of negative samples after balancing: 265\n","Found 424 validated image filenames belonging to 2 classes.\n","Found 106 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711577381.375232      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m 9/13\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 654ms/step - accuracy: 0.5774 - loss: 0.7404"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577386.851908      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566ms/step - accuracy: 0.5894 - loss: 0.7191"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577389.504167      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 669ms/step - accuracy: 0.5925 - loss: 0.7146 - val_accuracy: 0.6771 - val_loss: 0.5608\n","Epoch 2/10\n","\u001b[1m 1/13\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 386ms/step - accuracy: 0.5000 - loss: 0.7840"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5000 - loss: 0.7840 - val_accuracy: 0.7000 - val_loss: 0.6139\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577390.640177      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 411ms/step - accuracy: 0.7305 - loss: 0.5619 - val_accuracy: 0.7396 - val_loss: 0.6375\n","Epoch 4/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7500 - loss: 0.5607 - val_accuracy: 0.7000 - val_loss: 0.7236\n","Epoch 5/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 449ms/step - accuracy: 0.7114 - loss: 0.5595 - val_accuracy: 0.7188 - val_loss: 0.5365\n","Epoch 6/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8125 - loss: 0.4943 - val_accuracy: 0.7000 - val_loss: 0.5336\n","Epoch 7/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 417ms/step - accuracy: 0.7475 - loss: 0.5117 - val_accuracy: 0.7396 - val_loss: 0.5355\n","Epoch 8/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6875 - loss: 0.4777 - val_accuracy: 0.8000 - val_loss: 0.4617\n","Epoch 9/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 416ms/step - accuracy: 0.7506 - loss: 0.4841 - val_accuracy: 0.7292 - val_loss: 0.5308\n","Epoch 10/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6562 - loss: 0.6723 - val_accuracy: 0.8000 - val_loss: 0.5351\n","Finished training for class: Boat\n","Training for class: Car\n","Number of positive samples for Car: 472\n","Number of negative samples before balancing: 6435\n","Number of negative samples after balancing: 472\n","Found 755 validated image filenames belonging to 2 classes.\n","Found 189 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711577434.666767      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m16/23\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 395ms/step - accuracy: 0.5903 - loss: 0.6883"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577443.059711      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step - accuracy: 0.5945 - loss: 0.6837"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577446.704728      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 555ms/step - accuracy: 0.5950 - loss: 0.6831 - val_accuracy: 0.7063 - val_loss: 0.6016\n","Epoch 2/10\n","\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 414ms/step - accuracy: 0.7500 - loss: 0.5048"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7500 - loss: 0.5048 - val_accuracy: 0.7586 - val_loss: 0.5047\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577448.106968      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 426ms/step - accuracy: 0.6538 - loss: 0.6208 - val_accuracy: 0.5562 - val_loss: 0.6791\n","Epoch 4/10\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5312 - loss: 0.6866 - val_accuracy: 0.4828 - val_loss: 0.6959\n","Epoch 5/10\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 423ms/step - accuracy: 0.5545 - loss: 0.6845 - val_accuracy: 0.5063 - val_loss: 0.7164\n","Epoch 6/10\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6250 - loss: 0.6429 - val_accuracy: 0.5172 - val_loss: 0.7430\n","Epoch 7/10\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 429ms/step - accuracy: 0.5964 - loss: 0.6547 - val_accuracy: 0.6812 - val_loss: 0.5844\n","Epoch 8/10\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5000 - loss: 0.7652 - val_accuracy: 0.7241 - val_loss: 0.4947\n","Epoch 9/10\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 428ms/step - accuracy: 0.6962 - loss: 0.5724 - val_accuracy: 0.7500 - val_loss: 0.5526\n","Epoch 10/10\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6250 - loss: 0.5873 - val_accuracy: 0.7241 - val_loss: 0.5466\n","Finished training for class: Car\n","Training for class: Cow\n","Number of positive samples for Cow: 159\n","Number of negative samples before balancing: 6748\n","Number of negative samples after balancing: 159\n","Found 254 validated image filenames belonging to 2 classes.\n","Found 64 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711577510.172630      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m2/7\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 385ms/step - accuracy: 0.4844 - loss: 0.7474"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577513.097575      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739ms/step - accuracy: 0.4984 - loss: 0.7773"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577515.875255      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 913ms/step - accuracy: 0.4969 - loss: 0.7783 - val_accuracy: 0.6094 - val_loss: 0.6555\n","Epoch 2/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7188 - loss: 0.6185 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 443ms/step - accuracy: 0.6684 - loss: 0.6269 - val_accuracy: 0.6094 - val_loss: 0.6634\n","Epoch 4/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5625 - loss: 0.6417 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n","Epoch 5/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 444ms/step - accuracy: 0.7042 - loss: 0.5801 - val_accuracy: 0.5312 - val_loss: 0.7303\n","Epoch 6/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6562 - loss: 0.6352 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n","Epoch 7/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 453ms/step - accuracy: 0.7803 - loss: 0.4889 - val_accuracy: 0.6875 - val_loss: 0.5972\n","Epoch 8/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7188 - loss: 0.5303 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n","Epoch 9/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 454ms/step - accuracy: 0.7196 - loss: 0.5318 - val_accuracy: 0.6562 - val_loss: 0.7661\n","Epoch 10/10\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6875 - loss: 0.6085 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n","Finished training for class: Cow\n","Training for class: Bird\n","Number of positive samples for Bird: 344\n","Number of negative samples before balancing: 6563\n","Number of negative samples after balancing: 344\n","Found 550 validated image filenames belonging to 2 classes.\n","Found 138 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711577550.657943      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 556ms/step - accuracy: 0.5135 - loss: 0.7414"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577557.630531      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515ms/step - accuracy: 0.5119 - loss: 0.7386"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577560.259722      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 602ms/step - accuracy: 0.5113 - loss: 0.7379 - val_accuracy: 0.5391 - val_loss: 0.6820\n","Epoch 2/10\n","\u001b[1m 1/17\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 388ms/step - accuracy: 0.3438 - loss: 0.6991"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.3438 - loss: 0.6991 - val_accuracy: 0.9000 - val_loss: 0.6338\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577561.515278      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 431ms/step - accuracy: 0.5040 - loss: 0.7096 - val_accuracy: 0.5625 - val_loss: 0.6876\n","Epoch 4/10\n","\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5312 - loss: 0.6969 - val_accuracy: 0.5000 - val_loss: 0.6813\n","Epoch 5/10\n","\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 415ms/step - accuracy: 0.5099 - loss: 0.6919 - val_accuracy: 0.4219 - val_loss: 0.7234\n","Epoch 6/10\n","\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4688 - loss: 0.7063 - val_accuracy: 0.8000 - val_loss: 0.5750\n","Epoch 7/10\n","\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 429ms/step - accuracy: 0.5601 - loss: 0.6787 - val_accuracy: 0.6094 - val_loss: 0.6484\n","Epoch 8/10\n","\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5000 - loss: 0.7269 - val_accuracy: 0.4000 - val_loss: 0.7912\n","Epoch 9/10\n","\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 409ms/step - accuracy: 0.5342 - loss: 0.7036 - val_accuracy: 0.4375 - val_loss: 0.6856\n","Epoch 10/10\n","\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4375 - loss: 0.6834 - val_accuracy: 0.6000 - val_loss: 0.6441\n","Finished training for class: Bird\n","Training for class: Pottedplant\n","Number of positive samples for Pottedplant: 244\n","Number of negative samples before balancing: 6663\n","Number of negative samples after balancing: 244\n","Found 390 validated image filenames belonging to 2 classes.\n","Found 98 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45\u001b[0m 10s/step - accuracy: 0.8333 - loss: 0.3367"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577613.377587      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","W0000 00:00:1711577615.609624      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578ms/step - accuracy: 0.5682 - loss: 0.8881"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577620.763554      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 689ms/step - accuracy: 0.5625 - loss: 0.8825 - val_accuracy: 0.5000 - val_loss: 0.6920\n","Epoch 2/10\n","\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 381ms/step - accuracy: 0.5000 - loss: 0.6956"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5000 - loss: 0.6956 - val_accuracy: 0.5000 - val_loss: 0.6957\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577621.887505      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 403ms/step - accuracy: 0.4945 - loss: 0.6944 - val_accuracy: 0.5938 - val_loss: 0.6911\n","Epoch 4/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3438 - loss: 0.6967 - val_accuracy: 0.5000 - val_loss: 0.6909\n","Epoch 5/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 427ms/step - accuracy: 0.4988 - loss: 0.6939 - val_accuracy: 0.6042 - val_loss: 0.6784\n","Epoch 6/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4062 - loss: 0.7127 - val_accuracy: 0.0000e+00 - val_loss: 0.7633\n","Epoch 7/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 408ms/step - accuracy: 0.5173 - loss: 0.6948 - val_accuracy: 0.4271 - val_loss: 0.6931\n","Epoch 8/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5000 - loss: 0.6929 - val_accuracy: 0.5000 - val_loss: 0.6943\n","Epoch 9/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 415ms/step - accuracy: 0.5165 - loss: 0.6927 - val_accuracy: 0.4167 - val_loss: 0.6970\n","Epoch 10/10\n","\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4688 - loss: 0.6952 - val_accuracy: 0.0000e+00 - val_loss: 0.7202\n","Finished training for class: Pottedplant\n","Training for class: Tvmonitor\n","Number of positive samples for Tvmonitor: 272\n","Number of negative samples before balancing: 6635\n","Number of negative samples after balancing: 272\n","Found 435 validated image filenames belonging to 2 classes.\n","Found 109 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711577663.858320      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m 1/13\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45\u001b[0m 9s/step - accuracy: 0.4211 - loss: 0.8814"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577666.343377      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574ms/step - accuracy: 0.4882 - loss: 0.9203"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577671.987297      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 677ms/step - accuracy: 0.4911 - loss: 0.9112 - val_accuracy: 0.4792 - val_loss: 0.6926\n","Epoch 2/10\n","\u001b[1m 1/13\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 387ms/step - accuracy: 0.5625 - loss: 0.6835"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.5625 - loss: 0.6835 - val_accuracy: 0.3077 - val_loss: 0.7250\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577673.122950      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 423ms/step - accuracy: 0.5578 - loss: 0.6878 - val_accuracy: 0.5208 - val_loss: 0.6744\n","Epoch 4/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4688 - loss: 0.6846 - val_accuracy: 0.5385 - val_loss: 0.6848\n","Epoch 5/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 423ms/step - accuracy: 0.5619 - loss: 0.6766 - val_accuracy: 0.6979 - val_loss: 0.5646\n","Epoch 6/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6250 - loss: 0.6193 - val_accuracy: 0.6923 - val_loss: 0.4993\n","Epoch 7/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 423ms/step - accuracy: 0.6066 - loss: 0.6634 - val_accuracy: 0.7708 - val_loss: 0.6023\n","Epoch 8/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6875 - loss: 0.6462 - val_accuracy: 0.6923 - val_loss: 0.6405\n","Epoch 9/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 422ms/step - accuracy: 0.5990 - loss: 0.6598 - val_accuracy: 0.7188 - val_loss: 0.5609\n","Epoch 10/10\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7188 - loss: 0.5386 - val_accuracy: 0.3846 - val_loss: 0.8109\n","Finished training for class: Tvmonitor\n","Training for class: Dog\n","Number of positive samples for Dog: 410\n","Number of negative samples before balancing: 6497\n","Number of negative samples after balancing: 410\n","Found 656 validated image filenames belonging to 2 classes.\n","Found 164 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711577717.297795      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m11/20\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 392ms/step - accuracy: 0.5363 - loss: 0.7981"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577723.740516      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step - accuracy: 0.5314 - loss: 0.7771"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577728.053799      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 575ms/step - accuracy: 0.5316 - loss: 0.7751 - val_accuracy: 0.5562 - val_loss: 0.6905\n","Epoch 2/10\n","\u001b[1m 1/20\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 418ms/step - accuracy: 0.6250 - loss: 0.6691"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6250 - loss: 0.6691 - val_accuracy: 0.7500 - val_loss: 0.6205\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577729.467110      87 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 439ms/step - accuracy: 0.5998 - loss: 0.6719 - val_accuracy: 0.6000 - val_loss: 0.6522\n","Epoch 4/10\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6875 - loss: 0.5908 - val_accuracy: 0.0000e+00 - val_loss: 0.9574\n","Epoch 5/10\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 435ms/step - accuracy: 0.6444 - loss: 0.6347 - val_accuracy: 0.5063 - val_loss: 0.7308\n","Epoch 6/10\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6562 - loss: 0.6017 - val_accuracy: 0.5000 - val_loss: 0.8136\n","Epoch 7/10\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 444ms/step - accuracy: 0.6170 - loss: 0.6410 - val_accuracy: 0.5625 - val_loss: 0.6744\n","Epoch 8/10\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6250 - loss: 0.6445 - val_accuracy: 0.5000 - val_loss: 0.6575\n","Epoch 9/10\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 422ms/step - accuracy: 0.6550 - loss: 0.6124 - val_accuracy: 0.6187 - val_loss: 0.8008\n","Epoch 10/10\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5938 - loss: 0.8790 - val_accuracy: 0.5000 - val_loss: 0.9334\n","Finished training for class: Dog\n","Training for class: Chair\n","Number of positive samples for Chair: 380\n","Number of negative samples before balancing: 6527\n","Number of negative samples after balancing: 380\n","Found 608 validated image filenames belonging to 2 classes.\n","Found 152 validated image filenames belonging to 2 classes.\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","W0000 00:00:1711577786.321569      89 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - accuracy: 0.4942 - loss: 0.7824"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577794.721327      88 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 469ms/step - accuracy: 0.4929 - loss: 0.7804 - val_accuracy: 0.5625 - val_loss: 0.6872\n","Epoch 2/10\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.3333 - val_loss: 0.7176\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["W0000 00:00:1711577795.576387      86 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 424ms/step - accuracy: 0.4903 - loss: 0.6950 - val_accuracy: 0.4922 - val_loss: 0.6951\n","Epoch 4/10\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.4167 - val_loss: 0.7041\n","Epoch 5/10\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 430ms/step - accuracy: 0.4951 - loss: 0.6964 - val_accuracy: 0.4922 - val_loss: 0.6912\n","Epoch 6/10\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.4583 - val_loss: 0.6957\n","Epoch 7/10\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 442ms/step - accuracy: 0.5761 - loss: 0.6842 - val_accuracy: 0.5000 - val_loss: 0.7119\n","Epoch 8/10\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.3750 - val_loss: 0.8830\n","Epoch 9/10\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 430ms/step - accuracy: 0.6247 - loss: 0.6403 - val_accuracy: 0.5938 - val_loss: 0.6521\n","Epoch 10/10\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.4167 - val_loss: 0.6973\n","Finished training for class: Chair\n"]}],"source":["# Loop through each class and train a binary classification model\n","for class_name in class_names:\n","    print(f\"Training for class: {class_name}\")\n","\n","    # Retrieve the list of image paths for the positive class\n","    positive_images = train_data_lists[class_name]\n","    if not positive_images:\n","        print(f\"No images found for class {class_name}. Skipping this class.\")\n","        continue\n","    positive_labels = [1] * len(positive_images)\n","\n","    # Build a list of image paths for the negative class (all other classes)\n","    negative_images = []\n","    for other_class_name, image_paths in train_data_lists.items():\n","        if other_class_name != class_name:\n","            negative_images.extend(image_paths)\n","\n","    print(f\"Number of positive samples for {class_name}: {len(positive_images)}\")\n","    print(f\"Number of negative samples before balancing: {len(negative_images)}\")\n","\n","\n","    random.shuffle(negative_images)  # Shuffle the negative images\n","    negative_images = negative_images[:len(positive_images)]  # Balance the positive and negative datasets\n","    negative_labels = [0] * len(negative_images)\n","    print(f\"Number of negative samples after balancing: {len(negative_images)}\")\n","\n","    # Combine and shuffle the positive and negative samples\n","    combined_images = positive_images + negative_images\n","    combined_labels = positive_labels + negative_labels\n","    combined_list = list(zip(combined_images, combined_labels))\n","    random.shuffle(combined_list)\n","    combined_images, combined_labels = zip(*combined_list)\n","\n","    # Split the data into training and validation sets\n","    X_train, X_val, y_train, y_val = train_test_split(combined_images, combined_labels, test_size=0.2, random_state=42)\n","\n","    # Create DataFrames for the training and validation sets\n","    train_df = pd.DataFrame({\n","    'filename': X_train,\n","    'label': [str(label) for label in y_train]  # Convert labels to strings\n","})\n","    val_df = pd.DataFrame({\n","    'filename': X_val,\n","    'label': [str(label) for label in y_val]  # Convert labels to strings\n","})\n","\n","    # Create data generators for training and validation\n","    train_generator = train_datagen.flow_from_dataframe(\n","        train_df,\n","        x_col='filename',\n","        y_col='label',\n","        target_size=(224, 224),\n","        batch_size=32,\n","        class_mode='binary'\n","    )\n","\n","    val_datagen = ImageDataGenerator(rescale=1./255)\n","    val_generator = val_datagen.flow_from_dataframe(\n","        val_df,\n","        x_col='filename',\n","        y_col='label',\n","        target_size=(224, 224),\n","        batch_size=32,\n","        class_mode='binary'\n","    )\n","\n","    #Build the binary classification model\n","    model = build_binary_classification_model()\n","\n","    # Train the model on the data\n","    history = model.fit(\n","        train_generator,\n","        steps_per_epoch=len(X_train) // 32,\n","        validation_data=val_generator,\n","        validation_steps=len(X_val) // 32,\n","        epochs=10\n","    )\n","\n","    # Save the trained model\n","    model_save_path = os.path.join('models', f\"{class_name}_binary_model.h5\")\n","    os.makedirs('models3', exist_ok=True)\n","    model.save(model_save_path)\n","\n","    print(f\"Finished training for class: {class_name}\")"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T22:19:10.967069Z","iopub.status.busy":"2024-03-27T22:19:10.966699Z","iopub.status.idle":"2024-03-27T22:19:10.975238Z","shell.execute_reply":"2024-03-27T22:19:10.974294Z","shell.execute_reply.started":"2024-03-27T22:19:10.967038Z"},"trusted":true},"outputs":[],"source":["import os\n","import shutil\n","\n","# Define the path to the train directory\n","train_dir = \"/content/test\"\n","\n","# Iterate over each subfolder in the train directory\n","for class_name in os.listdir(train_dir):\n","    class_dir = os.path.join(train_dir, class_name)\n","    \n","    # Check if the item in the directory is a subfolder\n","    if os.path.isdir(class_dir):\n","        # Define the path to the subsubfolder\n","        subsubfolder_dir = os.path.join(class_dir, class_name)\n","        \n","        # Check if the subsubfolder exists\n","        if os.path.exists(subsubfolder_dir):\n","            # Iterate over each file in the subsubfolder\n","            for file_name in os.listdir(subsubfolder_dir):\n","                file_path = os.path.join(subsubfolder_dir, file_name)\n","                \n","                # Move the file to the parent subfolder\n","                if os.path.isfile(file_path):\n","                    shutil.move(file_path, class_dir)\n","            \n","            # Remove the empty subsubfolder\n","            os.rmdir(subsubfolder_dir)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","from sklearn.metrics import classification_report, confusion_matrix, average_precision_score\n","import matplotlib.pyplot as plt\n","from PIL import Image, ImageDraw, ImageFont\n","\n","model_dir = '/content/models'\n","test_data_dir = '/content/test'\n","\n","# Initialize ImageDataGenerator for preprocessing\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Store average precision scores for mAP calculation\n","ap_scores = []\n","\n","# Loop through each model file in the models directory\n","for model_file in sorted(os.listdir(model_dir)):\n","    if model_file.endswith(\".h5\"):\n","        print(f\"\\nLoading model {model_file}...\")\n","        model_path = os.path.join(model_dir, model_file)\n","        model = load_model(model_path)\n","        class_name = model_file.replace(\"_binary_model.h5\", \"\")\n","        print(f\"Model for class '{class_name}' loaded successfully.\")\n","\n","        # Create DataFrame for test data with labels as strings\n","        images = []\n","        labels = []\n","        for folder in os.listdir(test_data_dir):\n","            folder_path = os.path.join(test_data_dir, folder)\n","            for image_file in os.listdir(folder_path):\n","                images.append(os.path.join(folder, image_file))\n","                labels.append(str(int(folder == class_name)))  # Convert boolean to int to string\n","\n","        test_df = pd.DataFrame({\n","            'filename': images,\n","            'label': labels  # Labels are now strings\n","        })\n","\n","        # Prepare test generator\n","        test_generator = test_datagen.flow_from_dataframe(\n","            dataframe=test_df,\n","            directory=test_data_dir,\n","            x_col='filename',\n","            y_col='label',\n","            target_size=(224, 224),\n","            batch_size=32,\n","            class_mode='binary',\n","            shuffle=False)\n","\n","        # Predict and evaluate\n","        predictions = model.predict(test_generator, steps=int(np.ceil(len(test_df)/32)))\n","\n","        predicted_labels = (predictions > 0.5).astype(int)\n","        ap_score = average_precision_score(test_generator.classes, predictions)\n","        ap_scores.append(ap_score)\n","        #print(f\"AP score for class '{class_name}': {ap_score:.3f}\")\n","\n","\n","\n"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T22:21:53.050274Z","iopub.status.busy":"2024-03-27T22:21:53.049925Z","iopub.status.idle":"2024-03-27T22:21:53.055804Z","shell.execute_reply":"2024-03-27T22:21:53.054847Z","shell.execute_reply.started":"2024-03-27T22:21:53.050249Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Mean Average Precision (mAP) across all classes: 0.163\n"]}],"source":["# Calculate mean Average Precision (mAP)\n","mAP = np.mean(ap_scores)\n","print(f\"\\nMean Average Precision (mAP) across all classes: {mAP:.3f}\")"]},{"cell_type":"markdown","metadata":{},"source":["# A comparison of mAP changes as samples size increase"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-03-27T22:22:02.836020Z","iopub.status.busy":"2024-03-27T22:22:02.835661Z","iopub.status.idle":"2024-03-27T22:22:03.041459Z","shell.execute_reply":"2024-03-27T22:22:03.040562Z","shell.execute_reply.started":"2024-03-27T22:22:02.835991Z"},"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["sample_sizes = [100, 200, 500]   #Samples\n","mAP_values = [0.147, 0.152, 0.163]  #  mAP values\n","\n","# Plot the graph\n","plt.plot(sample_sizes, mAP_values, marker='o', linestyle='-')\n","plt.title('mAP vs Sample Size')\n","plt.xlabel('Sample Size')\n","plt.ylabel('mAP')\n","plt.grid(True)\n","plt.xticks(sample_sizes)  \n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4668815,"sourceId":7941038,"sourceType":"datasetVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
