{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## In this notebook, we try to see how class imbalance affects the accuracy of our classifier. We generate random samples for each class and fill out the deficit between the number of samples of each class and then see how our binary classifier performs with and without class imbalance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyfTBdH7dbSa"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import numpy as np\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGbLUxJGYeOZ",
        "outputId": "b600f9d0-4cc4-4aad-a74a-3badb41ea0a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHooR2lUY3NJ"
      },
      "outputs": [],
      "source": [
        "path= '/content/drive/MyDrive/VOCtrainval_14-Jul-2008.tar'\n",
        "\n",
        "\n",
        "import tarfile\n",
        "with tarfile.open(path, 'r') as tar:\n",
        "    tar.extractall()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRc6VqUIcUri"
      },
      "source": [
        "# Preparing the dataset for the training\n",
        "\n",
        "## Splitting data into train and test folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "di5mQV0Ha77o"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "folder_path = \"/content/VOCdevkit/VOC2008/JPEGImages\"\n",
        "def extract_positive_images(directory, file_name):\n",
        "    positive_images = []\n",
        "    variations = [\n",
        "        file_name,\n",
        "        file_name.replace(\"_train\", \"_trainval\"),\n",
        "        file_name.replace(\"_train\", \"_val\")\n",
        "    ]\n",
        "\n",
        "    for variation in variations:\n",
        "        file_path = os.path.join(directory, variation)\n",
        "        with open(file_path, \"r\") as file:\n",
        "            lines = file.readlines()\n",
        "\n",
        "        for line in lines:\n",
        "            if line.strip().endswith(\" 1\"):\n",
        "                image_name = line.split()[0] + \".jpg\"\n",
        "                if image_name not in positive_images:\n",
        "                    positive_images.append(image_name)\n",
        "\n",
        "    return positive_images\n",
        "\n",
        "\n",
        "data_directory = \"/content/VOCdevkit/VOC2008/ImageSets/Main\"\n",
        "folder_path = \"/content/VOCdevkit/VOC2008/JPEGImages\"\n",
        "\n",
        "aeroplane_images = extract_positive_images(data_directory, \"aeroplane_train.txt\")\n",
        "bicycle_images = extract_positive_images(data_directory, \"bicycle_train.txt\")\n",
        "bird_images = extract_positive_images(data_directory, \"bird_train.txt\")\n",
        "boat_images = extract_positive_images(data_directory, \"boat_train.txt\")\n",
        "bottle_images = extract_positive_images(data_directory, \"bottle_train.txt\")\n",
        "bus_images = extract_positive_images(data_directory, \"bus_train.txt\")\n",
        "car_images = extract_positive_images(data_directory, \"car_train.txt\")\n",
        "cat_images = extract_positive_images(data_directory, \"cat_train.txt\")\n",
        "chair_images = extract_positive_images(data_directory, \"chair_train.txt\")\n",
        "cow_images = extract_positive_images(data_directory, \"cow_train.txt\")\n",
        "diningtable_images = extract_positive_images(data_directory, \"diningtable_train.txt\")\n",
        "dog_images = extract_positive_images(data_directory, \"dog_train.txt\")\n",
        "horse_images = extract_positive_images(data_directory, \"horse_train.txt\")\n",
        "motorbike_images = extract_positive_images(data_directory, \"motorbike_train.txt\")\n",
        "person_images = extract_positive_images(data_directory, \"person_train.txt\")\n",
        "pottedplant_images = extract_positive_images(data_directory, \"pottedplant_train.txt\")\n",
        "sheep_images = extract_positive_images(data_directory, \"sheep_train.txt\")\n",
        "sofa_images = extract_positive_images(data_directory, \"sofa_train.txt\")\n",
        "train_images = extract_positive_images(data_directory, \"train_train.txt\")\n",
        "tvmonitor_images = extract_positive_images(data_directory, \"tvmonitor_train.txt\")\n",
        "\n",
        "jpg_files = []\n",
        "\n",
        "for file in os.listdir(folder_path):\n",
        "    if file.endswith(\".jpg\"):\n",
        "        jpg_files.append(file)\n",
        "\n",
        "\n",
        "class_data_lists = {\n",
        "    \"Aeroplane\": aeroplane_images,\n",
        "    \"Bicycle\": bicycle_images,\n",
        "    \"Bird\": bird_images,\n",
        "    \"Boat\": boat_images,\n",
        "    \"Bottle\": bottle_images,\n",
        "    \"Bus\": bus_images,\n",
        "    \"Car\": car_images,\n",
        "    \"Cat\": cat_images,\n",
        "    \"Chair\": chair_images,\n",
        "    \"Cow\": cow_images,\n",
        "    \"Diningtable\": diningtable_images,\n",
        "    \"Dog\": dog_images,\n",
        "    \"Horse\": horse_images,\n",
        "    \"Motorbike\": motorbike_images,\n",
        "    \"Person\": person_images,\n",
        "    \"Pottedplant\": pottedplant_images,\n",
        "    \"Sheep\": sheep_images,\n",
        "    \"Sofa\": sofa_images,\n",
        "    \"Train\": train_images,\n",
        "    \"Tvmonitor\": tvmonitor_images\n",
        "}\n",
        "\n",
        "\n",
        "train_data_lists = {class_name: [] for class_name in class_data_lists}\n",
        "test_data_lists = {class_name: [] for class_name in class_data_lists}\n",
        "\n",
        "\n",
        "for class_name, data_list in class_data_lists.items():\n",
        "    train_images, test_images = train_test_split(data_list, test_size=0.2, random_state=42)\n",
        "    train_data_lists[class_name] = train_images\n",
        "    test_data_lists[class_name] = test_images\n",
        "\n",
        "\n",
        "for class_name, train_images in train_data_lists.items():\n",
        "    for file in train_images:\n",
        "        try:\n",
        "            src_path = os.path.join(folder_path, file)\n",
        "            dest_dir = os.path.join(\"/content/train\", class_name)\n",
        "            dest_path = os.path.join(dest_dir, file)\n",
        "            os.makedirs(dest_dir, exist_ok=True)\n",
        "            shutil.copyfile(src_path, dest_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Error copying {file} to {dest_dir}: {e}\")\n",
        "\n",
        "\n",
        "for class_name, test_images in test_data_lists.items():\n",
        "    for file in test_images:\n",
        "        try:\n",
        "            src_path = os.path.join(folder_path, file)\n",
        "            dest_dir = os.path.join(\"/content/test\", class_name)\n",
        "            dest_path = os.path.join(dest_dir, file)\n",
        "            os.makedirs(dest_dir, exist_ok=True)\n",
        "            shutil.copyfile(src_path, dest_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Error copying {file} to {dest_dir}: {e}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bg4dUGgQb59v",
        "outputId": "4947bb48-ebbe-4e96-9661-d3ee5cfa5413"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Bus',\n",
              " 'Tvmonitor',\n",
              " 'Bottle',\n",
              " 'Dog',\n",
              " 'Cow',\n",
              " 'Motorbike',\n",
              " 'Sheep',\n",
              " 'Car',\n",
              " 'Diningtable',\n",
              " 'Horse',\n",
              " 'Pottedplant',\n",
              " 'Aeroplane',\n",
              " 'Person',\n",
              " 'Boat',\n",
              " 'Chair',\n",
              " 'Train',\n",
              " 'Bird',\n",
              " 'Bicycle',\n",
              " 'Cat',\n",
              " 'Sofa']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_folder_path = \"/content/train\"\n",
        "class_names = [d for d in os.listdir(train_folder_path) if os.path.isdir(os.path.join(train_folder_path, d))]\n",
        "class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIREL6uxcDHo",
        "outputId": "9bc33313-b801-4d8e-f8bb-67b57d8fe52e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created subfolder for class 'Bus' in '/content/train/Bus'\n",
            "Created subfolder for class 'Tvmonitor' in '/content/train/Tvmonitor'\n",
            "Created subfolder for class 'Bottle' in '/content/train/Bottle'\n",
            "Created subfolder for class 'Dog' in '/content/train/Dog'\n",
            "Created subfolder for class 'Cow' in '/content/train/Cow'\n",
            "Created subfolder for class 'Motorbike' in '/content/train/Motorbike'\n",
            "Created subfolder for class 'Sheep' in '/content/train/Sheep'\n",
            "Created subfolder for class 'Car' in '/content/train/Car'\n",
            "Created subfolder for class 'Diningtable' in '/content/train/Diningtable'\n",
            "Created subfolder for class 'Horse' in '/content/train/Horse'\n",
            "Created subfolder for class 'Pottedplant' in '/content/train/Pottedplant'\n",
            "Created subfolder for class 'Aeroplane' in '/content/train/Aeroplane'\n",
            "Created subfolder for class 'Person' in '/content/train/Person'\n",
            "Created subfolder for class 'Boat' in '/content/train/Boat'\n",
            "Created subfolder for class 'Chair' in '/content/train/Chair'\n",
            "Created subfolder for class 'Train' in '/content/train/Train'\n",
            "Created subfolder for class 'Bird' in '/content/train/Bird'\n",
            "Created subfolder for class 'Bicycle' in '/content/train/Bicycle'\n",
            "Created subfolder for class 'Cat' in '/content/train/Cat'\n",
            "Created subfolder for class 'Sofa' in '/content/train/Sofa'\n"
          ]
        }
      ],
      "source": [
        "def create_class_subfolders(parent_folder):\n",
        "    # Iterate through each class subfolder\n",
        "    for class_folder in os.listdir(parent_folder):\n",
        "        class_folder_path = os.path.join(parent_folder, class_folder)\n",
        "        if os.path.isdir(class_folder_path):\n",
        "            # Create a new subfolder with the same class name\n",
        "            new_subfolder_path = os.path.join(class_folder_path, class_folder)\n",
        "            os.makedirs(new_subfolder_path, exist_ok=True)\n",
        "\n",
        "            # Copy all images from the class folder to the new subfolder\n",
        "            for file_name in os.listdir(class_folder_path):\n",
        "                file_path = os.path.join(class_folder_path, file_name)\n",
        "                if os.path.isfile(file_path):\n",
        "                    shutil.move(file_path, new_subfolder_path)\n",
        "\n",
        "            print(f\"Created subfolder for class '{class_folder}' in '{class_folder_path}'\")\n",
        "\n",
        "# Define the parent folder containing class subfolders\n",
        "parent_folder = \"/content/train\"\n",
        "\n",
        "# Call the function to create class subfolders and copy images\n",
        "create_class_subfolders(parent_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoZEBmgpcJTh",
        "outputId": "c215e692-e680-441d-ff13-b64ad4f0390d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created subfolder for class 'Bus' in '/content/test/Bus'\n",
            "Created subfolder for class 'Tvmonitor' in '/content/test/Tvmonitor'\n",
            "Created subfolder for class 'Bottle' in '/content/test/Bottle'\n",
            "Created subfolder for class 'Dog' in '/content/test/Dog'\n",
            "Created subfolder for class 'Cow' in '/content/test/Cow'\n",
            "Created subfolder for class 'Motorbike' in '/content/test/Motorbike'\n",
            "Created subfolder for class 'Sheep' in '/content/test/Sheep'\n",
            "Created subfolder for class 'Car' in '/content/test/Car'\n",
            "Created subfolder for class 'Diningtable' in '/content/test/Diningtable'\n",
            "Created subfolder for class 'Horse' in '/content/test/Horse'\n",
            "Created subfolder for class 'Pottedplant' in '/content/test/Pottedplant'\n",
            "Created subfolder for class 'Aeroplane' in '/content/test/Aeroplane'\n",
            "Created subfolder for class 'Person' in '/content/test/Person'\n",
            "Created subfolder for class 'Boat' in '/content/test/Boat'\n",
            "Created subfolder for class 'Chair' in '/content/test/Chair'\n",
            "Created subfolder for class 'Train' in '/content/test/Train'\n",
            "Created subfolder for class 'Bird' in '/content/test/Bird'\n",
            "Created subfolder for class 'Bicycle' in '/content/test/Bicycle'\n",
            "Created subfolder for class 'Cat' in '/content/test/Cat'\n",
            "Created subfolder for class 'Sofa' in '/content/test/Sofa'\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "#for Test data\n",
        "\n",
        "def create_class_subfolders(parent_folder):\n",
        "    # Iterate through each class subfolder\n",
        "    for class_folder in os.listdir(parent_folder):\n",
        "        class_folder_path = os.path.join(parent_folder, class_folder)\n",
        "        if os.path.isdir(class_folder_path):\n",
        "            # Create a new subfolder with the same class name\n",
        "            new_subfolder_path = os.path.join(class_folder_path, class_folder)\n",
        "            os.makedirs(new_subfolder_path, exist_ok=True)\n",
        "\n",
        "            # Copy all images from the class folder to the new subfolder\n",
        "            for file_name in os.listdir(class_folder_path):\n",
        "                file_path = os.path.join(class_folder_path, file_name)\n",
        "                if os.path.isfile(file_path):\n",
        "                    shutil.move(file_path, new_subfolder_path)\n",
        "\n",
        "            print(f\"Created subfolder for class '{class_folder}' in '{class_folder_path}'\")\n",
        "\n",
        "\n",
        "\n",
        "# Define the parent folder containing class subfolders\n",
        "parent_folder = \"/content/test\"\n",
        "\n",
        "# Call the function to create class subfolders and copy images\n",
        "create_class_subfolders(parent_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChZU3oQycRdB"
      },
      "source": [
        "## Building The VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sl5LjZ8ecNqX"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_DIM = 2\n",
        "BETA = 1.0  # Weight for KL divergence in VAE loss\n",
        "EPOCHS = 500  # Increase the number of epochs for better training\n",
        "BATCH_SIZE = 16\n",
        "FOLDER_PATH = '/content/models'  # Directory where trained models will be saved"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwUjlzZ3ct5Y"
      },
      "outputs": [],
      "source": [
        "# Define the Sampling layer\n",
        "class Sampling(layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.random.normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxhPo_Ycd24k"
      },
      "source": [
        "## VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMNdXg1gcuPk"
      },
      "outputs": [],
      "source": [
        "# Define the VAE model\n",
        "class VAE(keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.total_loss_tracker, self.reconstruction_loss_tracker, self.kl_loss_tracker]\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var, z = self.encoder(inputs)\n",
        "        reconstruction = self.decoder(z)\n",
        "        return reconstruction\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            reconstruction = self.decoder(z)\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                tf.reduce_sum(\n",
        "                    keras.losses.binary_crossentropy(data, reconstruction),\n",
        "                    axis=(1, 2),\n",
        "                )\n",
        "            )\n",
        "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqReqFijeDTs"
      },
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7ZZUpOweCnI",
        "outputId": "88b8a11b-91bb-4b5b-f8d8-046cad7e9b52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, 28, 28, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 14, 14, 256)          7168      ['input_3[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 7, 7, 512)            1180160   ['conv2d_4[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 4, 4, 1024)           4719616   ['conv2d_5[0][0]']            \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)         (None, 16384)                0         ['conv2d_6[0][0]']            \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 512)                  8389120   ['flatten_1[0][0]']           \n",
            "                                                                                                  \n",
            " z_mean (Dense)              (None, 2)                    1026      ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            " z_log_var (Dense)           (None, 2)                    1026      ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            " sampling_1 (Sampling)       (None, 2)                    0         ['z_mean[0][0]',              \n",
            "                                                                     'z_log_var[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 14298116 (54.54 MB)\n",
            "Trainable params: 14298116 (54.54 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Define the encoder\n",
        "encoder_input = keras.Input(shape=(28, 28, 3))\n",
        "x = layers.Conv2D(256, 3, strides=2, activation=\"relu\", padding=\"same\")(encoder_input)\n",
        "x = layers.Conv2D(512, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "x = layers.Conv2D(1024, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(512, activation=\"relu\")(x)\n",
        "z_mean = layers.Dense(EMBEDDING_DIM, name=\"z_mean\")(x)\n",
        "z_log_var = layers.Dense(EMBEDDING_DIM, name=\"z_log_var\")(x)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "\n",
        "encoder = keras.Model(encoder_input, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "encoder.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-OYiZRaeH1F"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3-DMRoseGsV",
        "outputId": "211f519b-5d19-48f8-b5ca-d785cdd280e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 2)]               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 50176)             150528    \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 7, 7, 1024)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2D  (None, 7, 7, 512)         4719104   \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_4 (Conv2D  (None, 14, 14, 256)       1179904   \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_5 (Conv2D  (None, 28, 28, 128)       295040    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 28, 28, 3)         3459      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6348035 (24.22 MB)\n",
            "Trainable params: 6348035 (24.22 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Define the decoder\n",
        "decoder_input = keras.Input(shape=(EMBEDDING_DIM,))\n",
        "x = layers.Dense(7 * 7 * 1024, activation=\"relu\")(decoder_input)\n",
        "x = layers.Reshape((7, 7, 1024))(x)\n",
        "x = layers.Conv2DTranspose(512, 3, strides=1, activation=\"relu\", padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(256, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(128, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "decoder_output = layers.Conv2D(3, 3, strides=1, activation=\"sigmoid\", padding=\"same\")(x)\n",
        "\n",
        "decoder = keras.Model(decoder_input, decoder_output, name=\"decoder\")\n",
        "decoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qk-Ui5UjeJe9"
      },
      "outputs": [],
      "source": [
        "encoder = keras.Model(encoder)\n",
        "decoder = keras.Model(decoder)\n",
        "vae = VAE(encoder, decoder)\n",
        "vae.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AoNMvxKxe88y"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras import (\n",
        "    layers,\n",
        "    models,\n",
        "    datasets,\n",
        "    callbacks,\n",
        "    losses,\n",
        "    optimizers,\n",
        "    metrics,\n",
        ")\n",
        "IMAGE_SIZE = 28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVJIAlegeUhO",
        "outputId": "0b24228c-62f0-40c9-d681-fbf114e170a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 480.7077 - reconstruction_loss: 471.1973 - kl_loss: 6.2756\n",
            "Epoch 219/300\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 474.3251 - reconstruction_loss: 470.5490 - kl_loss: 6.3631\n",
            "Epoch 220/300\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 478.1544 - reconstruction_loss: 471.8739 - kl_loss: 6.2237\n",
            "Epoch 221/300\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 477.2090 - reconstruction_loss: 471.3303 - kl_loss: 6.2812\n",
            "Epoch 222/300\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 481.1284 - reconstruction_loss: 470.8113 - kl_loss: 6.4744\n",
            "Epoch 223/300\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 471.7235 - reconstruction_loss: 470.3216 - kl_loss: 6.4007\n",
            "Epoch 224/300\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 484.3993 - reconstruction_loss: 470.2520 - kl_loss: 6.1755\n",
            "Epoch 225/300\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 473.0898 - reconstruction_loss: 470.9858 - kl_loss: 6.0342\n",
            "Epoch 226/300\n",
            "12/12 [==============================] - 1s 82ms/step - loss: 471.8721 - reconstruction_loss: 470.4300 - kl_loss: 6.2289\n",
            "Epoch 227/300\n",
            "12/12 [==============================] - 1s 83ms/step - loss: 473.0455 - reconstruction_loss: 470.7588 - kl_loss: 6.2481\n",
            "Epoch 228/300\n",
            "12/12 [==============================] - 1s 86ms/step - loss: 477.7291 - reconstruction_loss: 470.3714 - kl_loss: 6.0083\n",
            "Epoch 229/300\n",
            "12/12 [==============================] - 1s 82ms/step - loss: 473.4242 - reconstruction_loss: 470.6915 - kl_loss: 6.1120\n",
            "Epoch 230/300\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 480.9332 - reconstruction_loss: 469.7893 - kl_loss: 6.3794\n",
            "Epoch 231/300\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 477.1443 - reconstruction_loss: 470.3290 - kl_loss: 6.3535\n",
            "Epoch 232/300\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 483.6196 - reconstruction_loss: 470.2298 - kl_loss: 6.4140\n",
            "Epoch 233/300\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 477.8483 - reconstruction_loss: 469.2589 - kl_loss: 6.4638\n",
            "Epoch 234/300\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 468.8804 - reconstruction_loss: 470.3302 - kl_loss: 6.1884\n",
            "Epoch 235/300\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 469.5471 - reconstruction_loss: 470.0754 - kl_loss: 6.1740\n",
            "Epoch 236/300\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 478.7864 - reconstruction_loss: 469.4825 - kl_loss: 6.1830\n",
            "Epoch 237/300\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 475.8118 - reconstruction_loss: 469.3729 - kl_loss: 6.3090\n",
            "Epoch 238/300\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 478.9149 - reconstruction_loss: 470.2466 - kl_loss: 6.3112\n",
            "Epoch 239/300\n",
            "12/12 [==============================] - 1s 79ms/step - loss: 476.7561 - reconstruction_loss: 469.6439 - kl_loss: 6.1485\n",
            "Epoch 240/300\n",
            "12/12 [==============================] - 1s 94ms/step - loss: 471.9014 - reconstruction_loss: 470.2210 - kl_loss: 6.0677\n",
            "Epoch 241/300\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 481.1268 - reconstruction_loss: 470.8122 - kl_loss: 6.1065\n",
            "Epoch 242/300\n",
            "12/12 [==============================] - 1s 74ms/step - loss: 477.3799 - reconstruction_loss: 471.4276 - kl_loss: 6.3935\n",
            "Epoch 243/300\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 474.3443 - reconstruction_loss: 470.3695 - kl_loss: 6.5592\n",
            "Epoch 244/300\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 478.0406 - reconstruction_loss: 470.0461 - kl_loss: 6.3744\n",
            "Epoch 245/300\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 477.9424 - reconstruction_loss: 470.1399 - kl_loss: 6.1992\n",
            "Epoch 246/300\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 475.6146 - reconstruction_loss: 469.3536 - kl_loss: 6.5372\n",
            "Epoch 247/300\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 475.1677 - reconstruction_loss: 468.8153 - kl_loss: 6.6435\n",
            "Epoch 248/300\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 471.0742 - reconstruction_loss: 468.7746 - kl_loss: 6.2604\n",
            "Epoch 249/300\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 472.8423 - reconstruction_loss: 469.7122 - kl_loss: 6.1138\n",
            "Epoch 250/300\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 475.9171 - reconstruction_loss: 469.2273 - kl_loss: 6.4409\n",
            "Epoch 251/300\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 476.8879 - reconstruction_loss: 469.9955 - kl_loss: 6.3816\n",
            "Epoch 252/300\n",
            "12/12 [==============================] - 1s 80ms/step - loss: 477.4814 - reconstruction_loss: 469.6086 - kl_loss: 6.3459\n",
            "Epoch 253/300\n",
            "12/12 [==============================] - 1s 80ms/step - loss: 481.7371 - reconstruction_loss: 469.6940 - kl_loss: 6.3630\n",
            "Epoch 254/300\n",
            "12/12 [==============================] - 1s 90ms/step - loss: 473.8782 - reconstruction_loss: 469.4821 - kl_loss: 6.4107\n",
            "Epoch 255/300\n",
            "12/12 [==============================] - 1s 89ms/step - loss: 467.7058 - reconstruction_loss: 468.4665 - kl_loss: 6.3416\n",
            "Epoch 256/300\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 477.8723 - reconstruction_loss: 469.6419 - kl_loss: 6.4223\n",
            "Epoch 257/300\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 473.3022 - reconstruction_loss: 469.0274 - kl_loss: 6.5548\n",
            "Epoch 258/300\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 473.6646 - reconstruction_loss: 469.3617 - kl_loss: 6.3894\n",
            "Epoch 259/300\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 478.8289 - reconstruction_loss: 469.1656 - kl_loss: 6.2078\n",
            "Epoch 260/300\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 470.9593 - reconstruction_loss: 469.3367 - kl_loss: 6.2472\n",
            "Epoch 261/300\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 475.7055 - reconstruction_loss: 469.1109 - kl_loss: 6.5110\n",
            "Epoch 262/300\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 468.6787 - reconstruction_loss: 468.7276 - kl_loss: 6.4497\n",
            "Epoch 263/300\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 472.5850 - reconstruction_loss: 467.7145 - kl_loss: 6.2734\n",
            "Epoch 264/300\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 478.4668 - reconstruction_loss: 468.3637 - kl_loss: 6.4115\n",
            "Epoch 265/300\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 479.5630 - reconstruction_loss: 468.4973 - kl_loss: 6.4173\n",
            "Epoch 266/300\n",
            "12/12 [==============================] - 1s 87ms/step - loss: 475.3071 - reconstruction_loss: 468.8390 - kl_loss: 6.3539\n",
            "Epoch 267/300\n",
            "12/12 [==============================] - 1s 80ms/step - loss: 475.8677 - reconstruction_loss: 468.7707 - kl_loss: 6.4515\n",
            "Epoch 268/300\n",
            "12/12 [==============================] - 1s 89ms/step - loss: 472.4142 - reconstruction_loss: 468.3814 - kl_loss: 6.3481\n",
            "Epoch 269/300\n",
            "12/12 [==============================] - 1s 86ms/step - loss: 478.3531 - reconstruction_loss: 469.2178 - kl_loss: 6.2239\n",
            "Epoch 270/300\n",
            "12/12 [==============================] - 1s 77ms/step - loss: 473.4465 - reconstruction_loss: 468.1686 - kl_loss: 6.2917\n",
            "Epoch 271/300\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 476.8014 - reconstruction_loss: 468.2079 - kl_loss: 6.3517\n",
            "Epoch 272/300\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 474.7429 - reconstruction_loss: 469.0441 - kl_loss: 6.3406\n",
            "Epoch 273/300\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 477.8928 - reconstruction_loss: 469.0061 - kl_loss: 6.4175\n",
            "Epoch 274/300\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 472.5067 - reconstruction_loss: 468.0004 - kl_loss: 6.4353\n",
            "Epoch 275/300\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 477.3062 - reconstruction_loss: 468.1982 - kl_loss: 6.2898\n",
            "Epoch 276/300\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 473.4367 - reconstruction_loss: 467.5628 - kl_loss: 6.2325\n",
            "Epoch 277/300\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 470.0804 - reconstruction_loss: 468.4951 - kl_loss: 6.3469\n",
            "Epoch 278/300\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 480.4769 - reconstruction_loss: 468.7558 - kl_loss: 6.3645\n",
            "Epoch 279/300\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 471.5679 - reconstruction_loss: 468.3696 - kl_loss: 6.3594\n",
            "Epoch 280/300\n",
            "12/12 [==============================] - 1s 78ms/step - loss: 480.5043 - reconstruction_loss: 468.6850 - kl_loss: 6.3718\n",
            "Epoch 281/300\n",
            "12/12 [==============================] - 1s 86ms/step - loss: 475.8237 - reconstruction_loss: 468.3692 - kl_loss: 6.2702\n",
            "Epoch 282/300\n",
            "12/12 [==============================] - 1s 89ms/step - loss: 475.0429 - reconstruction_loss: 469.3978 - kl_loss: 6.2733\n",
            "Epoch 283/300\n",
            "12/12 [==============================] - 1s 93ms/step - loss: 478.0251 - reconstruction_loss: 469.0631 - kl_loss: 6.4055\n",
            "Epoch 284/300\n",
            "12/12 [==============================] - 1s 74ms/step - loss: 469.3615 - reconstruction_loss: 468.1760 - kl_loss: 6.4640\n",
            "Epoch 285/300\n",
            "12/12 [==============================] - 1s 67ms/step - loss: 474.7478 - reconstruction_loss: 467.1866 - kl_loss: 6.3178\n",
            "Epoch 286/300\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 475.8026 - reconstruction_loss: 468.3914 - kl_loss: 6.2883\n",
            "Epoch 287/300\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 477.8464 - reconstruction_loss: 468.6667 - kl_loss: 6.4702\n",
            "Epoch 288/300\n",
            "12/12 [==============================] - 1s 74ms/step - loss: 474.9385 - reconstruction_loss: 468.7525 - kl_loss: 6.4654\n",
            "Epoch 289/300\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 476.5206 - reconstruction_loss: 468.5730 - kl_loss: 6.4176\n",
            "Epoch 290/300\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 474.0644 - reconstruction_loss: 468.6872 - kl_loss: 6.3633\n",
            "Epoch 291/300\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 472.9374 - reconstruction_loss: 468.1425 - kl_loss: 6.2870\n",
            "Epoch 292/300\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 471.5277 - reconstruction_loss: 469.0279 - kl_loss: 6.4744\n",
            "Epoch 293/300\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 477.3620 - reconstruction_loss: 468.3883 - kl_loss: 6.3838\n",
            "Epoch 294/300\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 470.7681 - reconstruction_loss: 468.7836 - kl_loss: 6.4106\n",
            "Epoch 295/300\n",
            "12/12 [==============================] - 1s 88ms/step - loss: 477.8913 - reconstruction_loss: 467.7667 - kl_loss: 6.4027\n",
            "Epoch 296/300\n",
            "12/12 [==============================] - 1s 87ms/step - loss: 472.8656 - reconstruction_loss: 468.4011 - kl_loss: 6.2442\n",
            "Epoch 297/300\n",
            "12/12 [==============================] - 1s 95ms/step - loss: 478.2390 - reconstruction_loss: 468.8150 - kl_loss: 6.2794\n",
            "Epoch 298/300\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 475.9637 - reconstruction_loss: 468.6780 - kl_loss: 6.3942\n",
            "Epoch 299/300\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 474.2882 - reconstruction_loss: 468.2137 - kl_loss: 6.5118\n",
            "Epoch 300/300\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 478.7393 - reconstruction_loss: 467.6775 - kl_loss: 6.3824\n",
            "Found 48 images belonging to 1 classes.\n",
            "16/16 [==============================] - 0s 7ms/step\n",
            "Training VAE for class: Person\n",
            "Found 1601 images belonging to 1 classes.\n",
            "Epoch 1/300\n",
            "101/101 [==============================] - 12s 93ms/step - loss: 512.0846 - reconstruction_loss: 500.5608 - kl_loss: 4.8631\n",
            "Epoch 2/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 499.6807 - reconstruction_loss: 493.0051 - kl_loss: 4.8818\n",
            "Epoch 3/300\n",
            "101/101 [==============================] - 9s 85ms/step - loss: 495.7041 - reconstruction_loss: 491.7554 - kl_loss: 4.8348\n",
            "Epoch 4/300\n",
            "101/101 [==============================] - 8s 80ms/step - loss: 494.1267 - reconstruction_loss: 490.9573 - kl_loss: 4.8697\n",
            "Epoch 5/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 492.9018 - reconstruction_loss: 490.1887 - kl_loss: 4.7697\n",
            "Epoch 6/300\n",
            "101/101 [==============================] - 9s 85ms/step - loss: 495.0786 - reconstruction_loss: 489.8215 - kl_loss: 4.7493\n",
            "Epoch 7/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 493.2351 - reconstruction_loss: 488.5897 - kl_loss: 4.8346\n",
            "Epoch 8/300\n",
            "101/101 [==============================] - 7s 73ms/step - loss: 492.9718 - reconstruction_loss: 488.6562 - kl_loss: 4.7523\n",
            "Epoch 9/300\n",
            "101/101 [==============================] - 9s 86ms/step - loss: 493.3756 - reconstruction_loss: 488.9370 - kl_loss: 4.7104\n",
            "Epoch 10/300\n",
            "101/101 [==============================] - 7s 71ms/step - loss: 492.8806 - reconstruction_loss: 488.5465 - kl_loss: 4.7582\n",
            "Epoch 11/300\n",
            "101/101 [==============================] - 7s 71ms/step - loss: 491.2731 - reconstruction_loss: 488.8329 - kl_loss: 4.7306\n",
            "Epoch 12/300\n",
            "101/101 [==============================] - 9s 86ms/step - loss: 494.4992 - reconstruction_loss: 488.7947 - kl_loss: 4.6642\n",
            "Epoch 13/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 491.8964 - reconstruction_loss: 486.8022 - kl_loss: 4.6749\n",
            "Epoch 14/300\n",
            "101/101 [==============================] - 9s 87ms/step - loss: 492.3843 - reconstruction_loss: 488.2075 - kl_loss: 4.6519\n",
            "Epoch 15/300\n",
            "101/101 [==============================] - 7s 73ms/step - loss: 492.3362 - reconstruction_loss: 487.7829 - kl_loss: 4.6267\n",
            "Epoch 16/300\n",
            "101/101 [==============================] - 9s 84ms/step - loss: 492.2344 - reconstruction_loss: 487.2729 - kl_loss: 4.5884\n",
            "Epoch 17/300\n",
            "101/101 [==============================] - 8s 81ms/step - loss: 490.3507 - reconstruction_loss: 486.0661 - kl_loss: 4.5953\n",
            "Epoch 18/300\n",
            "101/101 [==============================] - 7s 70ms/step - loss: 490.8690 - reconstruction_loss: 487.6971 - kl_loss: 4.5625\n",
            "Epoch 19/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 494.0433 - reconstruction_loss: 487.1962 - kl_loss: 4.5120\n",
            "Epoch 20/300\n",
            "101/101 [==============================] - 9s 87ms/step - loss: 491.6797 - reconstruction_loss: 487.5923 - kl_loss: 4.5953\n",
            "Epoch 21/300\n",
            "101/101 [==============================] - 8s 79ms/step - loss: 493.8632 - reconstruction_loss: 487.5603 - kl_loss: 4.5420\n",
            "Epoch 22/300\n",
            "101/101 [==============================] - 8s 80ms/step - loss: 489.6988 - reconstruction_loss: 487.3152 - kl_loss: 4.4808\n",
            "Epoch 23/300\n",
            "101/101 [==============================] - 9s 86ms/step - loss: 491.3319 - reconstruction_loss: 486.6932 - kl_loss: 4.5890\n",
            "Epoch 24/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 492.5610 - reconstruction_loss: 487.1643 - kl_loss: 4.5237\n",
            "Epoch 25/300\n",
            "101/101 [==============================] - 9s 87ms/step - loss: 491.1592 - reconstruction_loss: 486.6829 - kl_loss: 4.5121\n",
            "Epoch 26/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 487.9264 - reconstruction_loss: 486.1280 - kl_loss: 4.5415\n",
            "Epoch 27/300\n",
            "101/101 [==============================] - 7s 71ms/step - loss: 489.3241 - reconstruction_loss: 486.8065 - kl_loss: 4.5002\n",
            "Epoch 28/300\n",
            "101/101 [==============================] - 8s 83ms/step - loss: 488.1149 - reconstruction_loss: 486.4779 - kl_loss: 4.5250\n",
            "Epoch 29/300\n",
            "101/101 [==============================] - 8s 76ms/step - loss: 490.1809 - reconstruction_loss: 486.9555 - kl_loss: 4.4529\n",
            "Epoch 30/300\n",
            "101/101 [==============================] - 7s 71ms/step - loss: 490.5648 - reconstruction_loss: 486.7627 - kl_loss: 4.4850\n",
            "Epoch 31/300\n",
            "101/101 [==============================] - 8s 75ms/step - loss: 487.2919 - reconstruction_loss: 486.4460 - kl_loss: 4.5268\n",
            "Epoch 32/300\n",
            "101/101 [==============================] - 9s 89ms/step - loss: 490.5941 - reconstruction_loss: 485.5412 - kl_loss: 4.5104\n",
            "Epoch 33/300\n",
            "101/101 [==============================] - 8s 75ms/step - loss: 490.2090 - reconstruction_loss: 486.2159 - kl_loss: 4.4830\n",
            "Epoch 34/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 492.7984 - reconstruction_loss: 486.5244 - kl_loss: 4.4296\n",
            "Epoch 35/300\n",
            "101/101 [==============================] - 8s 77ms/step - loss: 489.9025 - reconstruction_loss: 486.0013 - kl_loss: 4.4877\n",
            "Epoch 36/300\n",
            "101/101 [==============================] - 9s 87ms/step - loss: 494.9477 - reconstruction_loss: 485.7468 - kl_loss: 4.5048\n",
            "Epoch 37/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 487.3110 - reconstruction_loss: 484.8143 - kl_loss: 4.4368\n",
            "Epoch 38/300\n",
            "101/101 [==============================] - 9s 89ms/step - loss: 489.2563 - reconstruction_loss: 486.0641 - kl_loss: 4.5092\n",
            "Epoch 39/300\n",
            "101/101 [==============================] - 8s 75ms/step - loss: 486.6197 - reconstruction_loss: 483.7882 - kl_loss: 4.6380\n",
            "Epoch 40/300\n",
            "101/101 [==============================] - 8s 83ms/step - loss: 493.1444 - reconstruction_loss: 485.2679 - kl_loss: 4.5046\n",
            "Epoch 41/300\n",
            "101/101 [==============================] - 8s 77ms/step - loss: 488.9753 - reconstruction_loss: 485.8001 - kl_loss: 4.5698\n",
            "Epoch 42/300\n",
            "101/101 [==============================] - 8s 80ms/step - loss: 488.3364 - reconstruction_loss: 484.9813 - kl_loss: 4.5322\n",
            "Epoch 43/300\n",
            "101/101 [==============================] - 8s 78ms/step - loss: 488.4079 - reconstruction_loss: 485.7124 - kl_loss: 4.5286\n",
            "Epoch 44/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 489.9148 - reconstruction_loss: 485.2205 - kl_loss: 4.5246\n",
            "Epoch 45/300\n",
            "101/101 [==============================] - 9s 93ms/step - loss: 487.7164 - reconstruction_loss: 485.1737 - kl_loss: 4.5307\n",
            "Epoch 46/300\n",
            "101/101 [==============================] - 9s 90ms/step - loss: 487.9893 - reconstruction_loss: 484.6531 - kl_loss: 4.6308\n",
            "Epoch 47/300\n",
            "101/101 [==============================] - 7s 73ms/step - loss: 489.9536 - reconstruction_loss: 484.9452 - kl_loss: 4.5772\n",
            "Epoch 48/300\n",
            "101/101 [==============================] - 9s 87ms/step - loss: 489.0120 - reconstruction_loss: 484.1477 - kl_loss: 4.6478\n",
            "Epoch 49/300\n",
            "101/101 [==============================] - 8s 79ms/step - loss: 491.0396 - reconstruction_loss: 484.9450 - kl_loss: 4.5618\n",
            "Epoch 50/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 487.7018 - reconstruction_loss: 484.4875 - kl_loss: 4.5954\n",
            "Epoch 51/300\n",
            "101/101 [==============================] - 8s 74ms/step - loss: 486.1969 - reconstruction_loss: 483.8625 - kl_loss: 4.6107\n",
            "Epoch 52/300\n",
            "101/101 [==============================] - 9s 85ms/step - loss: 487.5081 - reconstruction_loss: 484.1448 - kl_loss: 4.6101\n",
            "Epoch 53/300\n",
            "101/101 [==============================] - 7s 73ms/step - loss: 487.9365 - reconstruction_loss: 484.1448 - kl_loss: 4.6789\n",
            "Epoch 54/300\n",
            "101/101 [==============================] - 9s 92ms/step - loss: 492.0592 - reconstruction_loss: 483.4888 - kl_loss: 4.6645\n",
            "Epoch 55/300\n",
            "101/101 [==============================] - 8s 79ms/step - loss: 487.5464 - reconstruction_loss: 483.9445 - kl_loss: 4.6454\n",
            "Epoch 56/300\n",
            "101/101 [==============================] - 8s 81ms/step - loss: 490.3117 - reconstruction_loss: 483.9525 - kl_loss: 4.7316\n",
            "Epoch 57/300\n",
            "101/101 [==============================] - 8s 79ms/step - loss: 489.3676 - reconstruction_loss: 483.7608 - kl_loss: 4.6992\n",
            "Epoch 58/300\n",
            "101/101 [==============================] - 8s 80ms/step - loss: 488.6021 - reconstruction_loss: 483.6901 - kl_loss: 4.7322\n",
            "Epoch 59/300\n",
            "101/101 [==============================] - 8s 79ms/step - loss: 486.9077 - reconstruction_loss: 481.5022 - kl_loss: 4.7823\n",
            "Epoch 60/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 486.9113 - reconstruction_loss: 483.5485 - kl_loss: 4.7770\n",
            "Epoch 61/300\n",
            "101/101 [==============================] - 9s 86ms/step - loss: 487.3615 - reconstruction_loss: 483.6044 - kl_loss: 4.7460\n",
            "Epoch 62/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 488.9644 - reconstruction_loss: 483.0334 - kl_loss: 4.7697\n",
            "Epoch 63/300\n",
            "101/101 [==============================] - 7s 73ms/step - loss: 486.6580 - reconstruction_loss: 482.5332 - kl_loss: 4.7865\n",
            "Epoch 64/300\n",
            "101/101 [==============================] - 9s 86ms/step - loss: 487.3326 - reconstruction_loss: 482.8581 - kl_loss: 4.8327\n",
            "Epoch 65/300\n",
            "101/101 [==============================] - 8s 74ms/step - loss: 487.2509 - reconstruction_loss: 483.4438 - kl_loss: 4.8062\n",
            "Epoch 66/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 493.5214 - reconstruction_loss: 484.3707 - kl_loss: 4.7893\n",
            "Epoch 67/300\n",
            "101/101 [==============================] - 9s 87ms/step - loss: 487.9850 - reconstruction_loss: 483.1386 - kl_loss: 4.7665\n",
            "Epoch 68/300\n",
            "101/101 [==============================] - 7s 73ms/step - loss: 486.5147 - reconstruction_loss: 482.9058 - kl_loss: 4.8735\n",
            "Epoch 69/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 489.9012 - reconstruction_loss: 482.7361 - kl_loss: 4.8743\n",
            "Epoch 70/300\n",
            "101/101 [==============================] - 8s 78ms/step - loss: 486.5214 - reconstruction_loss: 480.1298 - kl_loss: 4.9370\n",
            "Epoch 71/300\n",
            "101/101 [==============================] - 9s 85ms/step - loss: 486.5422 - reconstruction_loss: 482.5045 - kl_loss: 4.8953\n",
            "Epoch 72/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 488.5065 - reconstruction_loss: 482.2205 - kl_loss: 4.9059\n",
            "Epoch 73/300\n",
            "101/101 [==============================] - 9s 85ms/step - loss: 485.2419 - reconstruction_loss: 481.2436 - kl_loss: 4.8682\n",
            "Epoch 74/300\n",
            "101/101 [==============================] - 9s 86ms/step - loss: 486.4508 - reconstruction_loss: 481.7275 - kl_loss: 4.9209\n",
            "Epoch 75/300\n",
            "101/101 [==============================] - 7s 73ms/step - loss: 486.1854 - reconstruction_loss: 481.8334 - kl_loss: 4.8651\n",
            "Epoch 76/300\n",
            "101/101 [==============================] - 8s 83ms/step - loss: 485.1773 - reconstruction_loss: 482.2397 - kl_loss: 4.9966\n",
            "Epoch 77/300\n",
            "101/101 [==============================] - 8s 76ms/step - loss: 487.5478 - reconstruction_loss: 482.0498 - kl_loss: 4.9690\n",
            "Epoch 78/300\n",
            "101/101 [==============================] - 9s 84ms/step - loss: 487.6110 - reconstruction_loss: 481.2882 - kl_loss: 4.9954\n",
            "Epoch 79/300\n",
            "101/101 [==============================] - 9s 84ms/step - loss: 484.4495 - reconstruction_loss: 480.1434 - kl_loss: 4.9381\n",
            "Epoch 80/300\n",
            "101/101 [==============================] - 8s 75ms/step - loss: 485.8571 - reconstruction_loss: 481.7764 - kl_loss: 4.9589\n",
            "Epoch 81/300\n",
            "101/101 [==============================] - 9s 88ms/step - loss: 483.9833 - reconstruction_loss: 481.6885 - kl_loss: 4.9815\n",
            "Epoch 82/300\n",
            "101/101 [==============================] - 7s 74ms/step - loss: 488.2665 - reconstruction_loss: 481.2041 - kl_loss: 5.0223\n",
            "Epoch 83/300\n",
            "101/101 [==============================] - 9s 88ms/step - loss: 486.7244 - reconstruction_loss: 479.3764 - kl_loss: 5.0600\n",
            "Epoch 84/300\n",
            "101/101 [==============================] - 9s 88ms/step - loss: 486.7458 - reconstruction_loss: 481.8516 - kl_loss: 5.0412\n",
            "Epoch 85/300\n",
            "101/101 [==============================] - 8s 77ms/step - loss: 485.8884 - reconstruction_loss: 481.4263 - kl_loss: 5.0186\n",
            "Epoch 86/300\n",
            "101/101 [==============================] - 9s 86ms/step - loss: 485.0399 - reconstruction_loss: 481.2639 - kl_loss: 5.0242\n",
            "Epoch 87/300\n",
            "101/101 [==============================] - 7s 71ms/step - loss: 485.3085 - reconstruction_loss: 480.3011 - kl_loss: 5.0372\n",
            "Epoch 88/300\n",
            "101/101 [==============================] - 9s 87ms/step - loss: 486.7878 - reconstruction_loss: 482.1649 - kl_loss: 5.0653\n",
            "Epoch 89/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 483.6307 - reconstruction_loss: 481.2903 - kl_loss: 5.1100\n",
            "Epoch 90/300\n",
            "101/101 [==============================] - 9s 86ms/step - loss: 484.3128 - reconstruction_loss: 480.4440 - kl_loss: 5.0903\n",
            "Epoch 91/300\n",
            "101/101 [==============================] - 8s 79ms/step - loss: 484.4336 - reconstruction_loss: 481.3839 - kl_loss: 5.0926\n",
            "Epoch 92/300\n",
            "101/101 [==============================] - 7s 74ms/step - loss: 485.9267 - reconstruction_loss: 480.7788 - kl_loss: 5.1075\n",
            "Epoch 93/300\n",
            "101/101 [==============================] - 7s 73ms/step - loss: 485.8235 - reconstruction_loss: 480.4673 - kl_loss: 5.0963\n",
            "Epoch 94/300\n",
            "101/101 [==============================] - 9s 88ms/step - loss: 485.4394 - reconstruction_loss: 480.8799 - kl_loss: 5.0573\n",
            "Epoch 95/300\n",
            "101/101 [==============================] - 7s 71ms/step - loss: 487.8851 - reconstruction_loss: 480.8609 - kl_loss: 5.1511\n",
            "Epoch 96/300\n",
            "101/101 [==============================] - 9s 87ms/step - loss: 486.5393 - reconstruction_loss: 480.7687 - kl_loss: 5.1478\n",
            "Epoch 97/300\n",
            "101/101 [==============================] - 7s 71ms/step - loss: 486.1930 - reconstruction_loss: 480.6015 - kl_loss: 5.1410\n",
            "Epoch 98/300\n",
            "101/101 [==============================] - 7s 73ms/step - loss: 483.8810 - reconstruction_loss: 480.4602 - kl_loss: 5.0836\n",
            "Epoch 99/300\n",
            "101/101 [==============================] - 9s 85ms/step - loss: 488.2563 - reconstruction_loss: 480.8918 - kl_loss: 5.1433\n",
            "Epoch 100/300\n",
            "101/101 [==============================] - 7s 70ms/step - loss: 485.3019 - reconstruction_loss: 480.5825 - kl_loss: 5.1555\n",
            "Epoch 101/300\n",
            "101/101 [==============================] - 9s 87ms/step - loss: 486.1539 - reconstruction_loss: 480.1966 - kl_loss: 5.1727\n",
            "Epoch 102/300\n",
            "101/101 [==============================] - 7s 71ms/step - loss: 486.6835 - reconstruction_loss: 480.0402 - kl_loss: 5.1939\n",
            "Epoch 103/300\n",
            "101/101 [==============================] - 9s 86ms/step - loss: 483.4140 - reconstruction_loss: 479.6651 - kl_loss: 5.2312\n",
            "Epoch 104/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 486.4354 - reconstruction_loss: 480.2697 - kl_loss: 5.1764\n",
            "Epoch 105/300\n",
            "101/101 [==============================] - 7s 73ms/step - loss: 486.9220 - reconstruction_loss: 480.2949 - kl_loss: 5.2138\n",
            "Epoch 106/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 483.9920 - reconstruction_loss: 478.9249 - kl_loss: 5.2301\n",
            "Epoch 107/300\n",
            "101/101 [==============================] - 8s 84ms/step - loss: 484.7822 - reconstruction_loss: 479.2984 - kl_loss: 5.1966\n",
            "Epoch 108/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 485.0374 - reconstruction_loss: 479.5106 - kl_loss: 5.2465\n",
            "Epoch 109/300\n",
            "101/101 [==============================] - 7s 70ms/step - loss: 485.2534 - reconstruction_loss: 480.1392 - kl_loss: 5.1338\n",
            "Epoch 110/300\n",
            "101/101 [==============================] - 9s 85ms/step - loss: 487.4363 - reconstruction_loss: 479.3325 - kl_loss: 5.2072\n",
            "Epoch 111/300\n",
            "101/101 [==============================] - 8s 79ms/step - loss: 483.6342 - reconstruction_loss: 479.8534 - kl_loss: 5.2603\n",
            "Epoch 112/300\n",
            "101/101 [==============================] - 8s 81ms/step - loss: 484.7012 - reconstruction_loss: 479.5977 - kl_loss: 5.2866\n",
            "Epoch 113/300\n",
            "101/101 [==============================] - 8s 83ms/step - loss: 485.4293 - reconstruction_loss: 480.1815 - kl_loss: 5.2231\n",
            "Epoch 114/300\n",
            "101/101 [==============================] - 8s 76ms/step - loss: 485.9136 - reconstruction_loss: 479.5735 - kl_loss: 5.2921\n",
            "Epoch 115/300\n",
            "101/101 [==============================] - 9s 85ms/step - loss: 483.4978 - reconstruction_loss: 479.8575 - kl_loss: 5.1836\n",
            "Epoch 116/300\n",
            "101/101 [==============================] - 7s 71ms/step - loss: 484.6275 - reconstruction_loss: 479.6756 - kl_loss: 5.2276\n",
            "Epoch 117/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 487.7887 - reconstruction_loss: 479.6033 - kl_loss: 5.3030\n",
            "Epoch 118/300\n",
            "101/101 [==============================] - 9s 85ms/step - loss: 482.9818 - reconstruction_loss: 478.3809 - kl_loss: 5.3221\n",
            "Epoch 119/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 486.6684 - reconstruction_loss: 479.5385 - kl_loss: 5.3533\n",
            "Epoch 120/300\n",
            "101/101 [==============================] - 9s 86ms/step - loss: 479.9239 - reconstruction_loss: 479.0690 - kl_loss: 5.3711\n",
            "Epoch 121/300\n",
            "101/101 [==============================] - 7s 71ms/step - loss: 481.6101 - reconstruction_loss: 479.4313 - kl_loss: 5.3459\n",
            "Epoch 122/300\n",
            "101/101 [==============================] - 9s 87ms/step - loss: 484.1370 - reconstruction_loss: 479.5996 - kl_loss: 5.3167\n",
            "Epoch 123/300\n",
            "101/101 [==============================] - 8s 75ms/step - loss: 485.6625 - reconstruction_loss: 480.2950 - kl_loss: 5.2733\n",
            "Epoch 124/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 480.0350 - reconstruction_loss: 478.6196 - kl_loss: 5.2572\n",
            "Epoch 125/300\n",
            "101/101 [==============================] - 7s 73ms/step - loss: 485.2977 - reconstruction_loss: 479.2969 - kl_loss: 5.2955\n",
            "Epoch 126/300\n",
            "101/101 [==============================] - 9s 87ms/step - loss: 484.7531 - reconstruction_loss: 478.2625 - kl_loss: 5.3027\n",
            "Epoch 127/300\n",
            "101/101 [==============================] - 8s 75ms/step - loss: 484.4511 - reconstruction_loss: 477.4888 - kl_loss: 5.3660\n",
            "Epoch 128/300\n",
            "101/101 [==============================] - 8s 83ms/step - loss: 480.4895 - reconstruction_loss: 476.6671 - kl_loss: 5.4370\n",
            "Epoch 129/300\n",
            "101/101 [==============================] - 8s 75ms/step - loss: 483.7763 - reconstruction_loss: 479.0948 - kl_loss: 5.3055\n",
            "Epoch 130/300\n",
            "101/101 [==============================] - 8s 82ms/step - loss: 482.3964 - reconstruction_loss: 479.1917 - kl_loss: 5.2748\n",
            "Epoch 131/300\n",
            "101/101 [==============================] - 8s 83ms/step - loss: 483.4007 - reconstruction_loss: 477.5655 - kl_loss: 5.4330\n",
            "Epoch 132/300\n",
            "101/101 [==============================] - 7s 73ms/step - loss: 481.6760 - reconstruction_loss: 479.2314 - kl_loss: 5.3888\n",
            "Epoch 133/300\n",
            "101/101 [==============================] - 7s 73ms/step - loss: 481.2512 - reconstruction_loss: 478.5447 - kl_loss: 5.3695\n",
            "Epoch 134/300\n",
            "101/101 [==============================] - 9s 84ms/step - loss: 482.9598 - reconstruction_loss: 478.8974 - kl_loss: 5.4495\n",
            "Epoch 135/300\n",
            "101/101 [==============================] - 7s 73ms/step - loss: 484.4685 - reconstruction_loss: 478.4118 - kl_loss: 5.4918\n",
            "Epoch 136/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 483.7147 - reconstruction_loss: 478.8718 - kl_loss: 5.4962\n",
            "Epoch 137/300\n",
            "101/101 [==============================] - 9s 86ms/step - loss: 483.8869 - reconstruction_loss: 478.2208 - kl_loss: 5.4480\n",
            "Epoch 138/300\n",
            "101/101 [==============================] - 7s 73ms/step - loss: 482.7995 - reconstruction_loss: 478.2858 - kl_loss: 5.3818\n",
            "Epoch 139/300\n",
            "101/101 [==============================] - 7s 73ms/step - loss: 480.2262 - reconstruction_loss: 477.3922 - kl_loss: 5.4612\n",
            "Epoch 140/300\n",
            "101/101 [==============================] - 8s 81ms/step - loss: 482.3378 - reconstruction_loss: 478.4993 - kl_loss: 5.4021\n",
            "Epoch 141/300\n",
            "101/101 [==============================] - 8s 81ms/step - loss: 483.2627 - reconstruction_loss: 478.3190 - kl_loss: 5.3862\n",
            "Epoch 142/300\n",
            "101/101 [==============================] - 7s 74ms/step - loss: 483.2946 - reconstruction_loss: 478.7798 - kl_loss: 5.4714\n",
            "Epoch 143/300\n",
            "101/101 [==============================] - 8s 76ms/step - loss: 483.1816 - reconstruction_loss: 478.4550 - kl_loss: 5.4455\n",
            "Epoch 144/300\n",
            "101/101 [==============================] - 9s 88ms/step - loss: 482.5205 - reconstruction_loss: 478.4387 - kl_loss: 5.4565\n",
            "Epoch 145/300\n",
            "101/101 [==============================] - 8s 78ms/step - loss: 481.4171 - reconstruction_loss: 478.2692 - kl_loss: 5.4426\n",
            "Epoch 146/300\n",
            "101/101 [==============================] - 7s 73ms/step - loss: 481.4040 - reconstruction_loss: 478.2999 - kl_loss: 5.5508\n",
            "Epoch 147/300\n",
            "101/101 [==============================] - 9s 87ms/step - loss: 484.5143 - reconstruction_loss: 478.4384 - kl_loss: 5.4652\n",
            "Epoch 148/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 484.1418 - reconstruction_loss: 478.3576 - kl_loss: 5.4577\n",
            "Epoch 149/300\n",
            "101/101 [==============================] - 8s 75ms/step - loss: 485.2344 - reconstruction_loss: 478.6888 - kl_loss: 5.4862\n",
            "Epoch 150/300\n",
            "101/101 [==============================] - 9s 88ms/step - loss: 480.1622 - reconstruction_loss: 477.6759 - kl_loss: 5.3925\n",
            "Epoch 151/300\n",
            "101/101 [==============================] - 8s 75ms/step - loss: 484.4012 - reconstruction_loss: 478.3096 - kl_loss: 5.4995\n",
            "Epoch 152/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 481.0824 - reconstruction_loss: 476.1562 - kl_loss: 5.5218\n",
            "Epoch 153/300\n",
            "101/101 [==============================] - 8s 74ms/step - loss: 483.9542 - reconstruction_loss: 478.5763 - kl_loss: 5.5760\n",
            "Epoch 154/300\n",
            "101/101 [==============================] - 9s 88ms/step - loss: 481.3027 - reconstruction_loss: 477.7430 - kl_loss: 5.4321\n",
            "Epoch 155/300\n",
            "101/101 [==============================] - 8s 75ms/step - loss: 483.3084 - reconstruction_loss: 477.2609 - kl_loss: 5.5433\n",
            "Epoch 156/300\n",
            "101/101 [==============================] - 9s 84ms/step - loss: 482.8807 - reconstruction_loss: 477.9679 - kl_loss: 5.5601\n",
            "Epoch 157/300\n",
            "101/101 [==============================] - 8s 81ms/step - loss: 485.7924 - reconstruction_loss: 478.6076 - kl_loss: 5.4608\n",
            "Epoch 158/300\n",
            "101/101 [==============================] - 7s 71ms/step - loss: 481.7199 - reconstruction_loss: 477.6685 - kl_loss: 5.4983\n",
            "Epoch 159/300\n",
            "101/101 [==============================] - 8s 76ms/step - loss: 483.3796 - reconstruction_loss: 477.2338 - kl_loss: 5.5463\n",
            "Epoch 160/300\n",
            "101/101 [==============================] - 8s 83ms/step - loss: 484.1139 - reconstruction_loss: 477.9425 - kl_loss: 5.5952\n",
            "Epoch 161/300\n",
            "101/101 [==============================] - 8s 75ms/step - loss: 484.1845 - reconstruction_loss: 477.6781 - kl_loss: 5.5245\n",
            "Epoch 162/300\n",
            "101/101 [==============================] - 8s 83ms/step - loss: 482.6009 - reconstruction_loss: 477.8928 - kl_loss: 5.5222\n",
            "Epoch 163/300\n",
            "101/101 [==============================] - 8s 77ms/step - loss: 485.0237 - reconstruction_loss: 477.7294 - kl_loss: 5.5299\n",
            "Epoch 164/300\n",
            "101/101 [==============================] - 9s 85ms/step - loss: 484.0731 - reconstruction_loss: 477.5925 - kl_loss: 5.5396\n",
            "Epoch 165/300\n",
            "101/101 [==============================] - 8s 75ms/step - loss: 485.3260 - reconstruction_loss: 477.8294 - kl_loss: 5.5498\n",
            "Epoch 166/300\n",
            "101/101 [==============================] - 9s 84ms/step - loss: 479.4801 - reconstruction_loss: 476.1965 - kl_loss: 5.5894\n",
            "Epoch 167/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 479.5814 - reconstruction_loss: 476.7970 - kl_loss: 5.5849\n",
            "Epoch 168/300\n",
            "101/101 [==============================] - 9s 88ms/step - loss: 481.1706 - reconstruction_loss: 477.9058 - kl_loss: 5.5348\n",
            "Epoch 169/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 481.0425 - reconstruction_loss: 477.2751 - kl_loss: 5.5747\n",
            "Epoch 170/300\n",
            "101/101 [==============================] - 9s 86ms/step - loss: 481.5422 - reconstruction_loss: 475.2906 - kl_loss: 5.6114\n",
            "Epoch 171/300\n",
            "101/101 [==============================] - 8s 78ms/step - loss: 481.6084 - reconstruction_loss: 477.5207 - kl_loss: 5.6194\n",
            "Epoch 172/300\n",
            "101/101 [==============================] - 8s 81ms/step - loss: 482.7681 - reconstruction_loss: 477.4648 - kl_loss: 5.5544\n",
            "Epoch 173/300\n",
            "101/101 [==============================] - 8s 80ms/step - loss: 479.9612 - reconstruction_loss: 477.6040 - kl_loss: 5.6605\n",
            "Epoch 174/300\n",
            "101/101 [==============================] - 8s 79ms/step - loss: 482.2830 - reconstruction_loss: 477.6251 - kl_loss: 5.6344\n",
            "Epoch 175/300\n",
            "101/101 [==============================] - 8s 81ms/step - loss: 480.8249 - reconstruction_loss: 477.3968 - kl_loss: 5.7021\n",
            "Epoch 176/300\n",
            "101/101 [==============================] - 8s 78ms/step - loss: 484.5101 - reconstruction_loss: 477.6613 - kl_loss: 5.6085\n",
            "Epoch 177/300\n",
            "101/101 [==============================] - 9s 86ms/step - loss: 481.8640 - reconstruction_loss: 477.3211 - kl_loss: 5.6196\n",
            "Epoch 178/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 483.6465 - reconstruction_loss: 477.2002 - kl_loss: 5.6410\n",
            "Epoch 179/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 481.6506 - reconstruction_loss: 476.7764 - kl_loss: 5.6619\n",
            "Epoch 180/300\n",
            "101/101 [==============================] - 7s 73ms/step - loss: 481.2008 - reconstruction_loss: 476.7983 - kl_loss: 5.5953\n",
            "Epoch 181/300\n",
            "101/101 [==============================] - 9s 86ms/step - loss: 481.8469 - reconstruction_loss: 475.8793 - kl_loss: 5.5892\n",
            "Epoch 182/300\n",
            "101/101 [==============================] - 7s 71ms/step - loss: 482.2398 - reconstruction_loss: 477.6041 - kl_loss: 5.5806\n",
            "Epoch 183/300\n",
            "101/101 [==============================] - 9s 86ms/step - loss: 481.6065 - reconstruction_loss: 476.2809 - kl_loss: 5.6914\n",
            "Epoch 184/300\n",
            "101/101 [==============================] - 7s 70ms/step - loss: 481.4089 - reconstruction_loss: 476.9206 - kl_loss: 5.6414\n",
            "Epoch 185/300\n",
            "101/101 [==============================] - 8s 80ms/step - loss: 480.2600 - reconstruction_loss: 476.8676 - kl_loss: 5.6799\n",
            "Epoch 186/300\n",
            "101/101 [==============================] - 8s 78ms/step - loss: 479.0751 - reconstruction_loss: 476.4848 - kl_loss: 5.6833\n",
            "Epoch 187/300\n",
            "101/101 [==============================] - 8s 79ms/step - loss: 479.8956 - reconstruction_loss: 476.8277 - kl_loss: 5.6205\n",
            "Epoch 188/300\n",
            "101/101 [==============================] - 8s 81ms/step - loss: 480.9175 - reconstruction_loss: 476.6612 - kl_loss: 5.7188\n",
            "Epoch 189/300\n",
            "101/101 [==============================] - 8s 76ms/step - loss: 484.1993 - reconstruction_loss: 476.4459 - kl_loss: 5.7483\n",
            "Epoch 190/300\n",
            "101/101 [==============================] - 9s 86ms/step - loss: 481.6123 - reconstruction_loss: 475.9424 - kl_loss: 5.7831\n",
            "Epoch 191/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 480.6562 - reconstruction_loss: 477.2119 - kl_loss: 5.6673\n",
            "Epoch 192/300\n",
            "101/101 [==============================] - 7s 71ms/step - loss: 483.1649 - reconstruction_loss: 477.0700 - kl_loss: 5.7427\n",
            "Epoch 193/300\n",
            "101/101 [==============================] - 9s 85ms/step - loss: 484.2946 - reconstruction_loss: 477.1150 - kl_loss: 5.7302\n",
            "Epoch 194/300\n",
            "101/101 [==============================] - 7s 71ms/step - loss: 481.8796 - reconstruction_loss: 476.2813 - kl_loss: 5.7332\n",
            "Epoch 195/300\n",
            "101/101 [==============================] - 9s 84ms/step - loss: 483.4829 - reconstruction_loss: 476.3122 - kl_loss: 5.7494\n",
            "Epoch 196/300\n",
            "101/101 [==============================] - 8s 79ms/step - loss: 475.8379 - reconstruction_loss: 475.4973 - kl_loss: 5.7044\n",
            "Epoch 197/300\n",
            "101/101 [==============================] - 7s 73ms/step - loss: 481.5471 - reconstruction_loss: 476.4010 - kl_loss: 5.7452\n",
            "Epoch 198/300\n",
            "101/101 [==============================] - 9s 88ms/step - loss: 482.6703 - reconstruction_loss: 476.5739 - kl_loss: 5.7650\n",
            "Epoch 199/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 484.8878 - reconstruction_loss: 476.3187 - kl_loss: 5.7569\n",
            "Epoch 200/300\n",
            "101/101 [==============================] - 9s 86ms/step - loss: 476.4190 - reconstruction_loss: 473.2729 - kl_loss: 5.8267\n",
            "Epoch 201/300\n",
            "101/101 [==============================] - 7s 73ms/step - loss: 480.0551 - reconstruction_loss: 476.3642 - kl_loss: 5.7918\n",
            "Epoch 202/300\n",
            "101/101 [==============================] - 9s 86ms/step - loss: 481.9176 - reconstruction_loss: 475.1593 - kl_loss: 5.8264\n",
            "Epoch 203/300\n",
            "101/101 [==============================] - 8s 76ms/step - loss: 481.2938 - reconstruction_loss: 476.8081 - kl_loss: 5.7327\n",
            "Epoch 204/300\n",
            "101/101 [==============================] - 8s 83ms/step - loss: 481.9392 - reconstruction_loss: 475.9683 - kl_loss: 5.7580\n",
            "Epoch 205/300\n",
            "101/101 [==============================] - 8s 83ms/step - loss: 481.3701 - reconstruction_loss: 476.4479 - kl_loss: 5.8188\n",
            "Epoch 206/300\n",
            "101/101 [==============================] - 8s 76ms/step - loss: 480.8122 - reconstruction_loss: 476.1720 - kl_loss: 5.8064\n",
            "Epoch 207/300\n",
            "101/101 [==============================] - 8s 82ms/step - loss: 481.9857 - reconstruction_loss: 476.4101 - kl_loss: 5.8251\n",
            "Epoch 208/300\n",
            "101/101 [==============================] - 7s 70ms/step - loss: 480.5768 - reconstruction_loss: 476.1460 - kl_loss: 5.7907\n",
            "Epoch 209/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 482.4801 - reconstruction_loss: 475.8702 - kl_loss: 5.7958\n",
            "Epoch 210/300\n",
            "101/101 [==============================] - 9s 84ms/step - loss: 479.6836 - reconstruction_loss: 475.3000 - kl_loss: 5.8152\n",
            "Epoch 211/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 482.1394 - reconstruction_loss: 475.1343 - kl_loss: 5.8227\n",
            "Epoch 212/300\n",
            "101/101 [==============================] - 9s 86ms/step - loss: 481.8879 - reconstruction_loss: 475.7597 - kl_loss: 5.8541\n",
            "Epoch 213/300\n",
            "101/101 [==============================] - 8s 75ms/step - loss: 482.9570 - reconstruction_loss: 475.6982 - kl_loss: 5.7550\n",
            "Epoch 214/300\n",
            "101/101 [==============================] - 7s 71ms/step - loss: 478.8602 - reconstruction_loss: 476.2394 - kl_loss: 5.8320\n",
            "Epoch 215/300\n",
            "101/101 [==============================] - 9s 87ms/step - loss: 481.7660 - reconstruction_loss: 476.0580 - kl_loss: 5.8627\n",
            "Epoch 216/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 482.4265 - reconstruction_loss: 475.8593 - kl_loss: 5.8556\n",
            "Epoch 217/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 479.5764 - reconstruction_loss: 475.4724 - kl_loss: 5.8098\n",
            "Epoch 218/300\n",
            "101/101 [==============================] - 9s 87ms/step - loss: 482.4529 - reconstruction_loss: 475.8719 - kl_loss: 5.8267\n",
            "Epoch 219/300\n",
            "101/101 [==============================] - 7s 71ms/step - loss: 481.5380 - reconstruction_loss: 475.4870 - kl_loss: 5.8525\n",
            "Epoch 220/300\n",
            "101/101 [==============================] - 9s 86ms/step - loss: 482.7856 - reconstruction_loss: 475.9193 - kl_loss: 5.8144\n",
            "Epoch 221/300\n",
            "101/101 [==============================] - 7s 73ms/step - loss: 481.4970 - reconstruction_loss: 475.5249 - kl_loss: 5.7931\n",
            "Epoch 222/300\n",
            "101/101 [==============================] - 9s 85ms/step - loss: 482.7331 - reconstruction_loss: 476.3023 - kl_loss: 5.7961\n",
            "Epoch 223/300\n",
            "101/101 [==============================] - 7s 70ms/step - loss: 480.7384 - reconstruction_loss: 475.8268 - kl_loss: 5.8616\n",
            "Epoch 224/300\n",
            "101/101 [==============================] - 9s 85ms/step - loss: 482.3422 - reconstruction_loss: 474.9132 - kl_loss: 5.8539\n",
            "Epoch 225/300\n",
            "101/101 [==============================] - 8s 75ms/step - loss: 484.9498 - reconstruction_loss: 475.2350 - kl_loss: 5.9050\n",
            "Epoch 226/300\n",
            "101/101 [==============================] - 7s 73ms/step - loss: 481.9070 - reconstruction_loss: 475.3821 - kl_loss: 5.8286\n",
            "Epoch 227/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 481.2352 - reconstruction_loss: 475.2985 - kl_loss: 5.8555\n",
            "Epoch 228/300\n",
            "101/101 [==============================] - 9s 85ms/step - loss: 479.8585 - reconstruction_loss: 474.8720 - kl_loss: 5.8221\n",
            "Epoch 229/300\n",
            "101/101 [==============================] - 7s 73ms/step - loss: 481.6496 - reconstruction_loss: 474.6830 - kl_loss: 5.8971\n",
            "Epoch 230/300\n",
            "101/101 [==============================] - 7s 71ms/step - loss: 478.5962 - reconstruction_loss: 475.0923 - kl_loss: 5.8561\n",
            "Epoch 231/300\n",
            "101/101 [==============================] - 7s 73ms/step - loss: 482.3594 - reconstruction_loss: 475.6901 - kl_loss: 5.8918\n",
            "Epoch 232/300\n",
            "101/101 [==============================] - 9s 86ms/step - loss: 478.5613 - reconstruction_loss: 474.2483 - kl_loss: 5.9739\n",
            "Epoch 233/300\n",
            "101/101 [==============================] - 7s 71ms/step - loss: 481.3310 - reconstruction_loss: 475.6403 - kl_loss: 5.8473\n",
            "Epoch 234/300\n",
            "101/101 [==============================] - 9s 84ms/step - loss: 481.0336 - reconstruction_loss: 475.1117 - kl_loss: 5.8410\n",
            "Epoch 235/300\n",
            "101/101 [==============================] - 7s 71ms/step - loss: 481.0889 - reconstruction_loss: 474.9093 - kl_loss: 5.8907\n",
            "Epoch 236/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 479.9847 - reconstruction_loss: 474.9203 - kl_loss: 5.9202\n",
            "Epoch 237/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 478.4846 - reconstruction_loss: 475.4669 - kl_loss: 5.8925\n",
            "Epoch 238/300\n",
            "101/101 [==============================] - 8s 83ms/step - loss: 482.2640 - reconstruction_loss: 474.8562 - kl_loss: 5.9602\n",
            "Epoch 239/300\n",
            "101/101 [==============================] - 8s 74ms/step - loss: 484.2662 - reconstruction_loss: 475.3083 - kl_loss: 5.9673\n",
            "Epoch 240/300\n",
            "101/101 [==============================] - 9s 86ms/step - loss: 481.1779 - reconstruction_loss: 475.2733 - kl_loss: 5.9011\n",
            "Epoch 241/300\n",
            "101/101 [==============================] - 8s 75ms/step - loss: 476.8817 - reconstruction_loss: 475.1759 - kl_loss: 5.9944\n",
            "Epoch 242/300\n",
            "101/101 [==============================] - 7s 70ms/step - loss: 480.2855 - reconstruction_loss: 475.2911 - kl_loss: 5.9422\n",
            "Epoch 243/300\n",
            "101/101 [==============================] - 9s 87ms/step - loss: 479.0723 - reconstruction_loss: 474.7316 - kl_loss: 5.9004\n",
            "Epoch 244/300\n",
            "101/101 [==============================] - 7s 71ms/step - loss: 477.7705 - reconstruction_loss: 473.2855 - kl_loss: 5.9631\n",
            "Epoch 245/300\n",
            "101/101 [==============================] - 7s 71ms/step - loss: 481.2392 - reconstruction_loss: 474.5603 - kl_loss: 5.8966\n",
            "Epoch 246/300\n",
            "101/101 [==============================] - 7s 73ms/step - loss: 480.6497 - reconstruction_loss: 475.0605 - kl_loss: 5.9757\n",
            "Epoch 247/300\n",
            "101/101 [==============================] - 8s 82ms/step - loss: 481.2889 - reconstruction_loss: 474.7274 - kl_loss: 6.0231\n",
            "Epoch 248/300\n",
            "101/101 [==============================] - 8s 75ms/step - loss: 481.6699 - reconstruction_loss: 475.4246 - kl_loss: 5.9542\n",
            "Epoch 249/300\n",
            "101/101 [==============================] - 9s 84ms/step - loss: 480.3814 - reconstruction_loss: 474.9332 - kl_loss: 5.9626\n",
            "Epoch 250/300\n",
            "101/101 [==============================] - 7s 71ms/step - loss: 479.7389 - reconstruction_loss: 474.5322 - kl_loss: 5.9629\n",
            "Epoch 251/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 480.5834 - reconstruction_loss: 474.8104 - kl_loss: 5.9456\n",
            "Epoch 252/300\n",
            "101/101 [==============================] - 9s 85ms/step - loss: 479.9987 - reconstruction_loss: 474.4514 - kl_loss: 6.0225\n",
            "Epoch 253/300\n",
            "101/101 [==============================] - 8s 78ms/step - loss: 482.8010 - reconstruction_loss: 474.8040 - kl_loss: 6.0177\n",
            "Epoch 254/300\n",
            "101/101 [==============================] - 7s 71ms/step - loss: 482.1439 - reconstruction_loss: 475.2226 - kl_loss: 6.0365\n",
            "Epoch 255/300\n",
            "101/101 [==============================] - 9s 85ms/step - loss: 480.7944 - reconstruction_loss: 474.4607 - kl_loss: 6.0116\n",
            "Epoch 256/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 481.3331 - reconstruction_loss: 475.0635 - kl_loss: 5.9413\n",
            "Epoch 257/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 479.5368 - reconstruction_loss: 474.1823 - kl_loss: 5.9898\n",
            "Epoch 258/300\n",
            "101/101 [==============================] - 9s 86ms/step - loss: 482.9160 - reconstruction_loss: 474.6405 - kl_loss: 5.9797\n",
            "Epoch 259/300\n",
            "101/101 [==============================] - 7s 73ms/step - loss: 480.2199 - reconstruction_loss: 474.7789 - kl_loss: 6.0054\n",
            "Epoch 260/300\n",
            "101/101 [==============================] - 9s 87ms/step - loss: 481.9835 - reconstruction_loss: 474.4244 - kl_loss: 5.9663\n",
            "Epoch 261/300\n",
            "101/101 [==============================] - 7s 71ms/step - loss: 481.0999 - reconstruction_loss: 474.1075 - kl_loss: 5.9873\n",
            "Epoch 262/300\n",
            "101/101 [==============================] - 7s 71ms/step - loss: 482.7160 - reconstruction_loss: 474.5686 - kl_loss: 6.0081\n",
            "Epoch 263/300\n",
            "101/101 [==============================] - 9s 86ms/step - loss: 480.3741 - reconstruction_loss: 474.4862 - kl_loss: 6.0162\n",
            "Epoch 264/300\n",
            "101/101 [==============================] - 7s 70ms/step - loss: 478.0109 - reconstruction_loss: 474.5882 - kl_loss: 6.0473\n",
            "Epoch 265/300\n",
            "101/101 [==============================] - 7s 71ms/step - loss: 479.7949 - reconstruction_loss: 474.2908 - kl_loss: 6.0171\n",
            "Epoch 266/300\n",
            "101/101 [==============================] - 8s 79ms/step - loss: 474.7597 - reconstruction_loss: 473.2660 - kl_loss: 6.0612\n",
            "Epoch 267/300\n",
            "101/101 [==============================] - 9s 86ms/step - loss: 481.5561 - reconstruction_loss: 473.0826 - kl_loss: 6.0618\n",
            "Epoch 268/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 477.5179 - reconstruction_loss: 474.5667 - kl_loss: 6.1109\n",
            "Epoch 269/300\n",
            "101/101 [==============================] - 9s 87ms/step - loss: 481.3217 - reconstruction_loss: 474.4198 - kl_loss: 6.0726\n",
            "Epoch 270/300\n",
            "101/101 [==============================] - 8s 75ms/step - loss: 478.8868 - reconstruction_loss: 473.4714 - kl_loss: 6.0510\n",
            "Epoch 271/300\n",
            "101/101 [==============================] - 8s 81ms/step - loss: 478.6797 - reconstruction_loss: 474.3772 - kl_loss: 6.0327\n",
            "Epoch 272/300\n",
            "101/101 [==============================] - 8s 77ms/step - loss: 478.6791 - reconstruction_loss: 473.8813 - kl_loss: 6.0533\n",
            "Epoch 273/300\n",
            "101/101 [==============================] - 8s 81ms/step - loss: 477.8627 - reconstruction_loss: 474.6769 - kl_loss: 6.0185\n",
            "Epoch 274/300\n",
            "101/101 [==============================] - 9s 85ms/step - loss: 479.0785 - reconstruction_loss: 474.7296 - kl_loss: 5.9698\n",
            "Epoch 275/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 480.9682 - reconstruction_loss: 474.2056 - kl_loss: 5.9633\n",
            "Epoch 276/300\n",
            "101/101 [==============================] - 9s 85ms/step - loss: 483.5873 - reconstruction_loss: 474.4078 - kl_loss: 6.0555\n",
            "Epoch 277/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 479.3277 - reconstruction_loss: 474.2403 - kl_loss: 6.0741\n",
            "Epoch 278/300\n",
            "101/101 [==============================] - 7s 71ms/step - loss: 479.2236 - reconstruction_loss: 474.1307 - kl_loss: 6.0057\n",
            "Epoch 279/300\n",
            "101/101 [==============================] - 9s 87ms/step - loss: 478.8239 - reconstruction_loss: 473.3687 - kl_loss: 6.0295\n",
            "Epoch 280/300\n",
            "101/101 [==============================] - 7s 74ms/step - loss: 481.3030 - reconstruction_loss: 474.1214 - kl_loss: 6.0852\n",
            "Epoch 281/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 478.4891 - reconstruction_loss: 473.6501 - kl_loss: 6.0930\n",
            "Epoch 282/300\n",
            "101/101 [==============================] - 8s 75ms/step - loss: 481.9631 - reconstruction_loss: 473.5814 - kl_loss: 6.1171\n",
            "Epoch 283/300\n",
            "101/101 [==============================] - 8s 84ms/step - loss: 478.5020 - reconstruction_loss: 473.4799 - kl_loss: 6.0713\n",
            "Epoch 284/300\n",
            "101/101 [==============================] - 7s 73ms/step - loss: 479.4066 - reconstruction_loss: 473.7450 - kl_loss: 6.0144\n",
            "Epoch 285/300\n",
            "101/101 [==============================] - 9s 87ms/step - loss: 479.6243 - reconstruction_loss: 474.4279 - kl_loss: 6.0664\n",
            "Epoch 286/300\n",
            "101/101 [==============================] - 7s 71ms/step - loss: 479.7234 - reconstruction_loss: 473.4949 - kl_loss: 6.1135\n",
            "Epoch 287/300\n",
            "101/101 [==============================] - 9s 84ms/step - loss: 480.6749 - reconstruction_loss: 473.1182 - kl_loss: 6.0746\n",
            "Epoch 288/300\n",
            "101/101 [==============================] - 7s 73ms/step - loss: 476.8302 - reconstruction_loss: 472.6747 - kl_loss: 6.1289\n",
            "Epoch 289/300\n",
            "101/101 [==============================] - 9s 89ms/step - loss: 482.5844 - reconstruction_loss: 474.1976 - kl_loss: 6.1790\n",
            "Epoch 290/300\n",
            "101/101 [==============================] - 8s 80ms/step - loss: 478.0184 - reconstruction_loss: 473.6977 - kl_loss: 6.0597\n",
            "Epoch 291/300\n",
            "101/101 [==============================] - 7s 73ms/step - loss: 477.2336 - reconstruction_loss: 473.2870 - kl_loss: 6.1379\n",
            "Epoch 292/300\n",
            "101/101 [==============================] - 9s 89ms/step - loss: 480.4427 - reconstruction_loss: 474.1004 - kl_loss: 6.1203\n",
            "Epoch 293/300\n",
            "101/101 [==============================] - 8s 74ms/step - loss: 480.4471 - reconstruction_loss: 473.6755 - kl_loss: 6.1691\n",
            "Epoch 294/300\n",
            "101/101 [==============================] - 9s 88ms/step - loss: 479.0801 - reconstruction_loss: 473.8473 - kl_loss: 6.1399\n",
            "Epoch 295/300\n",
            "101/101 [==============================] - 8s 78ms/step - loss: 478.9794 - reconstruction_loss: 473.1823 - kl_loss: 6.1140\n",
            "Epoch 296/300\n",
            "101/101 [==============================] - 7s 71ms/step - loss: 479.7652 - reconstruction_loss: 473.1298 - kl_loss: 6.1346\n",
            "Epoch 297/300\n",
            "101/101 [==============================] - 9s 86ms/step - loss: 478.9017 - reconstruction_loss: 472.6627 - kl_loss: 6.1863\n",
            "Epoch 298/300\n",
            "101/101 [==============================] - 7s 72ms/step - loss: 480.8054 - reconstruction_loss: 473.5457 - kl_loss: 6.1929\n",
            "Epoch 299/300\n",
            "101/101 [==============================] - 7s 73ms/step - loss: 478.5727 - reconstruction_loss: 473.3669 - kl_loss: 6.1806\n",
            "Epoch 300/300\n",
            "101/101 [==============================] - 9s 87ms/step - loss: 480.8085 - reconstruction_loss: 472.2813 - kl_loss: 6.1802\n",
            "Found 401 images belonging to 1 classes.\n",
            "16/16 [==============================] - 0s 10ms/step\n",
            "Training VAE for class: Boat\n",
            "Found 165 images belonging to 1 classes.\n",
            "Epoch 1/300\n",
            "11/11 [==============================] - 5s 168ms/step - loss: 516.7129 - reconstruction_loss: 509.2577 - kl_loss: 5.5509\n",
            "Epoch 2/300\n",
            "11/11 [==============================] - 1s 81ms/step - loss: 508.8045 - reconstruction_loss: 500.6937 - kl_loss: 5.0286\n",
            "Epoch 3/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 502.2053 - reconstruction_loss: 495.6887 - kl_loss: 4.9391\n",
            "Epoch 4/300\n",
            "11/11 [==============================] - 1s 68ms/step - loss: 498.3458 - reconstruction_loss: 492.6519 - kl_loss: 4.6101\n",
            "Epoch 5/300\n",
            "11/11 [==============================] - 1s 68ms/step - loss: 494.7310 - reconstruction_loss: 490.7975 - kl_loss: 4.7684\n",
            "Epoch 6/300\n",
            "11/11 [==============================] - 1s 68ms/step - loss: 491.9194 - reconstruction_loss: 486.8770 - kl_loss: 4.9190\n",
            "Epoch 7/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 498.6271 - reconstruction_loss: 489.8109 - kl_loss: 4.9168\n",
            "Epoch 8/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 493.1605 - reconstruction_loss: 487.5549 - kl_loss: 5.0658\n",
            "Epoch 9/300\n",
            "11/11 [==============================] - 1s 70ms/step - loss: 487.2643 - reconstruction_loss: 483.7388 - kl_loss: 5.1112\n",
            "Epoch 10/300\n",
            "11/11 [==============================] - 1s 70ms/step - loss: 480.5153 - reconstruction_loss: 482.8818 - kl_loss: 5.1921\n",
            "Epoch 11/300\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 489.2633 - reconstruction_loss: 483.9096 - kl_loss: 5.2074\n",
            "Epoch 12/300\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 483.4715 - reconstruction_loss: 481.8256 - kl_loss: 5.1925\n",
            "Epoch 13/300\n",
            "11/11 [==============================] - 1s 97ms/step - loss: 492.7131 - reconstruction_loss: 484.9762 - kl_loss: 5.2178\n",
            "Epoch 14/300\n",
            "11/11 [==============================] - 1s 87ms/step - loss: 490.5823 - reconstruction_loss: 484.9179 - kl_loss: 5.2864\n",
            "Epoch 15/300\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 482.6013 - reconstruction_loss: 479.7775 - kl_loss: 5.4298\n",
            "Epoch 16/300\n",
            "11/11 [==============================] - 1s 68ms/step - loss: 488.4088 - reconstruction_loss: 485.1754 - kl_loss: 5.2716\n",
            "Epoch 17/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 486.8432 - reconstruction_loss: 483.3077 - kl_loss: 5.4960\n",
            "Epoch 18/300\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 493.4286 - reconstruction_loss: 483.5225 - kl_loss: 5.5726\n",
            "Epoch 19/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 486.4070 - reconstruction_loss: 479.9045 - kl_loss: 5.5739\n",
            "Epoch 20/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 484.6178 - reconstruction_loss: 479.8986 - kl_loss: 5.5030\n",
            "Epoch 21/300\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 483.4329 - reconstruction_loss: 479.7094 - kl_loss: 5.5741\n",
            "Epoch 22/300\n",
            "11/11 [==============================] - 1s 64ms/step - loss: 481.9272 - reconstruction_loss: 478.5938 - kl_loss: 5.6547\n",
            "Epoch 23/300\n",
            "11/11 [==============================] - 1s 62ms/step - loss: 490.7298 - reconstruction_loss: 481.1347 - kl_loss: 5.5974\n",
            "Epoch 24/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 480.5302 - reconstruction_loss: 474.4135 - kl_loss: 5.6971\n",
            "Epoch 25/300\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 480.3377 - reconstruction_loss: 480.4124 - kl_loss: 5.5232\n",
            "Epoch 26/300\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 489.5048 - reconstruction_loss: 479.6320 - kl_loss: 5.6249\n",
            "Epoch 27/300\n",
            "11/11 [==============================] - 1s 81ms/step - loss: 483.7334 - reconstruction_loss: 478.0681 - kl_loss: 5.7281\n",
            "Epoch 28/300\n",
            "11/11 [==============================] - 1s 68ms/step - loss: 488.0273 - reconstruction_loss: 479.9988 - kl_loss: 5.7223\n",
            "Epoch 29/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 489.3800 - reconstruction_loss: 477.0372 - kl_loss: 5.8406\n",
            "Epoch 30/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 487.5893 - reconstruction_loss: 479.0467 - kl_loss: 5.8364\n",
            "Epoch 31/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 483.1886 - reconstruction_loss: 477.8298 - kl_loss: 5.8181\n",
            "Epoch 32/300\n",
            "11/11 [==============================] - 1s 68ms/step - loss: 477.6528 - reconstruction_loss: 476.3350 - kl_loss: 5.6981\n",
            "Epoch 33/300\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 475.5660 - reconstruction_loss: 478.1463 - kl_loss: 5.7967\n",
            "Epoch 34/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 478.1543 - reconstruction_loss: 477.1534 - kl_loss: 5.9502\n",
            "Epoch 35/300\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 478.4517 - reconstruction_loss: 476.8564 - kl_loss: 5.8247\n",
            "Epoch 36/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 478.7995 - reconstruction_loss: 474.8794 - kl_loss: 5.7678\n",
            "Epoch 37/300\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 483.5256 - reconstruction_loss: 474.3462 - kl_loss: 5.8846\n",
            "Epoch 38/300\n",
            "11/11 [==============================] - 1s 97ms/step - loss: 475.0130 - reconstruction_loss: 473.8816 - kl_loss: 5.9385\n",
            "Epoch 39/300\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 481.3974 - reconstruction_loss: 476.7093 - kl_loss: 5.8127\n",
            "Epoch 40/300\n",
            "11/11 [==============================] - 1s 79ms/step - loss: 477.3191 - reconstruction_loss: 473.2255 - kl_loss: 5.7938\n",
            "Epoch 41/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 482.3159 - reconstruction_loss: 476.3061 - kl_loss: 5.8652\n",
            "Epoch 42/300\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 472.4210 - reconstruction_loss: 469.6972 - kl_loss: 6.0398\n",
            "Epoch 43/300\n",
            "11/11 [==============================] - 1s 70ms/step - loss: 458.3106 - reconstruction_loss: 468.6566 - kl_loss: 6.1371\n",
            "Epoch 44/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 483.0532 - reconstruction_loss: 475.6584 - kl_loss: 6.0015\n",
            "Epoch 45/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 486.1585 - reconstruction_loss: 476.4593 - kl_loss: 6.0130\n",
            "Epoch 46/300\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 476.3449 - reconstruction_loss: 471.3706 - kl_loss: 6.0292\n",
            "Epoch 47/300\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 475.5063 - reconstruction_loss: 470.5745 - kl_loss: 6.0768\n",
            "Epoch 48/300\n",
            "11/11 [==============================] - 1s 70ms/step - loss: 481.7755 - reconstruction_loss: 471.8106 - kl_loss: 6.0279\n",
            "Epoch 49/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 483.7950 - reconstruction_loss: 474.6402 - kl_loss: 5.9682\n",
            "Epoch 50/300\n",
            "11/11 [==============================] - 1s 70ms/step - loss: 480.0612 - reconstruction_loss: 470.9060 - kl_loss: 6.0406\n",
            "Epoch 51/300\n",
            "11/11 [==============================] - 1s 87ms/step - loss: 475.5859 - reconstruction_loss: 473.8690 - kl_loss: 5.9449\n",
            "Epoch 52/300\n",
            "11/11 [==============================] - 1s 100ms/step - loss: 478.0062 - reconstruction_loss: 472.1336 - kl_loss: 6.1417\n",
            "Epoch 53/300\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 478.6926 - reconstruction_loss: 472.2148 - kl_loss: 6.1034\n",
            "Epoch 54/300\n",
            "11/11 [==============================] - 1s 78ms/step - loss: 477.7154 - reconstruction_loss: 472.0984 - kl_loss: 6.0508\n",
            "Epoch 55/300\n",
            "11/11 [==============================] - 1s 72ms/step - loss: 481.5732 - reconstruction_loss: 473.8276 - kl_loss: 5.9457\n",
            "Epoch 56/300\n",
            "11/11 [==============================] - 1s 68ms/step - loss: 480.1316 - reconstruction_loss: 471.0299 - kl_loss: 6.1181\n",
            "Epoch 57/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 474.2474 - reconstruction_loss: 472.7707 - kl_loss: 6.0783\n",
            "Epoch 58/300\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 476.3420 - reconstruction_loss: 470.6346 - kl_loss: 6.2461\n",
            "Epoch 59/300\n",
            "11/11 [==============================] - 1s 72ms/step - loss: 476.8016 - reconstruction_loss: 470.9526 - kl_loss: 6.2044\n",
            "Epoch 60/300\n",
            "11/11 [==============================] - 1s 70ms/step - loss: 474.3366 - reconstruction_loss: 469.6022 - kl_loss: 6.1507\n",
            "Epoch 61/300\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 478.4034 - reconstruction_loss: 474.5476 - kl_loss: 6.0729\n",
            "Epoch 62/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 481.9109 - reconstruction_loss: 472.1042 - kl_loss: 5.9896\n",
            "Epoch 63/300\n",
            "11/11 [==============================] - 1s 72ms/step - loss: 478.7905 - reconstruction_loss: 471.5622 - kl_loss: 6.1454\n",
            "Epoch 64/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 475.1259 - reconstruction_loss: 470.7989 - kl_loss: 6.0192\n",
            "Epoch 65/300\n",
            "11/11 [==============================] - 1s 82ms/step - loss: 471.2699 - reconstruction_loss: 469.3473 - kl_loss: 6.3102\n",
            "Epoch 66/300\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 483.8997 - reconstruction_loss: 475.5906 - kl_loss: 6.1785\n",
            "Epoch 67/300\n",
            "11/11 [==============================] - 1s 101ms/step - loss: 477.5604 - reconstruction_loss: 472.7816 - kl_loss: 6.4480\n",
            "Epoch 68/300\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 483.4619 - reconstruction_loss: 470.8914 - kl_loss: 6.4201\n",
            "Epoch 69/300\n",
            "11/11 [==============================] - 1s 84ms/step - loss: 484.0861 - reconstruction_loss: 473.0284 - kl_loss: 6.3786\n",
            "Epoch 70/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 484.9403 - reconstruction_loss: 473.1563 - kl_loss: 6.1686\n",
            "Epoch 71/300\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 477.8652 - reconstruction_loss: 470.7717 - kl_loss: 6.0611\n",
            "Epoch 72/300\n",
            "11/11 [==============================] - 1s 68ms/step - loss: 471.7827 - reconstruction_loss: 469.8828 - kl_loss: 6.1054\n",
            "Epoch 73/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 469.0909 - reconstruction_loss: 471.8182 - kl_loss: 6.1799\n",
            "Epoch 74/300\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 479.7663 - reconstruction_loss: 471.9584 - kl_loss: 6.2811\n",
            "Epoch 75/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 470.9225 - reconstruction_loss: 470.3177 - kl_loss: 6.3894\n",
            "Epoch 76/300\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 469.4167 - reconstruction_loss: 471.7079 - kl_loss: 6.3349\n",
            "Epoch 77/300\n",
            "11/11 [==============================] - 1s 64ms/step - loss: 476.3943 - reconstruction_loss: 468.1710 - kl_loss: 6.3220\n",
            "Epoch 78/300\n",
            "11/11 [==============================] - 1s 68ms/step - loss: 479.8914 - reconstruction_loss: 469.4419 - kl_loss: 6.2442\n",
            "Epoch 79/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 466.7062 - reconstruction_loss: 466.6328 - kl_loss: 6.2398\n",
            "Epoch 80/300\n",
            "11/11 [==============================] - 1s 81ms/step - loss: 492.0433 - reconstruction_loss: 472.6469 - kl_loss: 6.0684\n",
            "Epoch 81/300\n",
            "11/11 [==============================] - 1s 87ms/step - loss: 468.6105 - reconstruction_loss: 465.9052 - kl_loss: 6.2938\n",
            "Epoch 82/300\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 476.5031 - reconstruction_loss: 469.3974 - kl_loss: 6.2115\n",
            "Epoch 83/300\n",
            "11/11 [==============================] - 1s 103ms/step - loss: 460.3524 - reconstruction_loss: 466.7612 - kl_loss: 6.1871\n",
            "Epoch 84/300\n",
            "11/11 [==============================] - 1s 71ms/step - loss: 474.7767 - reconstruction_loss: 469.9301 - kl_loss: 6.2148\n",
            "Epoch 85/300\n",
            "11/11 [==============================] - 1s 71ms/step - loss: 473.0162 - reconstruction_loss: 469.1807 - kl_loss: 6.4467\n",
            "Epoch 86/300\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 477.2307 - reconstruction_loss: 469.0125 - kl_loss: 6.3843\n",
            "Epoch 87/300\n",
            "11/11 [==============================] - 1s 69ms/step - loss: 476.0301 - reconstruction_loss: 464.2290 - kl_loss: 6.5299\n",
            "Epoch 88/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 478.2353 - reconstruction_loss: 468.4393 - kl_loss: 6.4484\n",
            "Epoch 89/300\n",
            "11/11 [==============================] - 1s 69ms/step - loss: 474.1484 - reconstruction_loss: 467.0523 - kl_loss: 6.3643\n",
            "Epoch 90/300\n",
            "11/11 [==============================] - 1s 71ms/step - loss: 474.5026 - reconstruction_loss: 467.9423 - kl_loss: 6.2118\n",
            "Epoch 91/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 467.5581 - reconstruction_loss: 465.8753 - kl_loss: 6.2723\n",
            "Epoch 92/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 468.3520 - reconstruction_loss: 468.3087 - kl_loss: 6.4114\n",
            "Epoch 93/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 472.1560 - reconstruction_loss: 469.5574 - kl_loss: 6.3041\n",
            "Epoch 94/300\n",
            "11/11 [==============================] - 1s 84ms/step - loss: 472.7293 - reconstruction_loss: 466.3723 - kl_loss: 6.3336\n",
            "Epoch 95/300\n",
            "11/11 [==============================] - 1s 105ms/step - loss: 467.5292 - reconstruction_loss: 468.3106 - kl_loss: 6.3467\n",
            "Epoch 96/300\n",
            "11/11 [==============================] - 1s 107ms/step - loss: 477.6341 - reconstruction_loss: 468.8790 - kl_loss: 6.4333\n",
            "Epoch 97/300\n",
            "11/11 [==============================] - 1s 100ms/step - loss: 481.0457 - reconstruction_loss: 468.4443 - kl_loss: 6.3622\n",
            "Epoch 98/300\n",
            "11/11 [==============================] - 1s 74ms/step - loss: 470.5155 - reconstruction_loss: 466.3799 - kl_loss: 6.4375\n",
            "Epoch 99/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 473.1779 - reconstruction_loss: 465.1425 - kl_loss: 6.3020\n",
            "Epoch 100/300\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 470.2085 - reconstruction_loss: 467.3893 - kl_loss: 6.2170\n",
            "Epoch 101/300\n",
            "11/11 [==============================] - 1s 68ms/step - loss: 471.4257 - reconstruction_loss: 466.5678 - kl_loss: 6.2991\n",
            "Epoch 102/300\n",
            "11/11 [==============================] - 1s 64ms/step - loss: 473.8337 - reconstruction_loss: 465.0812 - kl_loss: 6.4659\n",
            "Epoch 103/300\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 466.2188 - reconstruction_loss: 462.3659 - kl_loss: 6.4082\n",
            "Epoch 104/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 474.5314 - reconstruction_loss: 467.5370 - kl_loss: 6.3700\n",
            "Epoch 105/300\n",
            "11/11 [==============================] - 1s 71ms/step - loss: 473.5769 - reconstruction_loss: 464.2081 - kl_loss: 6.4496\n",
            "Epoch 106/300\n",
            "11/11 [==============================] - 1s 70ms/step - loss: 469.3791 - reconstruction_loss: 465.4745 - kl_loss: 6.4226\n",
            "Epoch 107/300\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 470.6309 - reconstruction_loss: 465.6512 - kl_loss: 6.4043\n",
            "Epoch 108/300\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 473.4871 - reconstruction_loss: 465.9078 - kl_loss: 6.5518\n",
            "Epoch 109/300\n",
            "11/11 [==============================] - 1s 86ms/step - loss: 470.4382 - reconstruction_loss: 466.8260 - kl_loss: 6.4003\n",
            "Epoch 110/300\n",
            "11/11 [==============================] - 1s 85ms/step - loss: 476.1247 - reconstruction_loss: 467.0572 - kl_loss: 6.3338\n",
            "Epoch 111/300\n",
            "11/11 [==============================] - 1s 103ms/step - loss: 478.8778 - reconstruction_loss: 467.1347 - kl_loss: 6.5390\n",
            "Epoch 112/300\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 473.2157 - reconstruction_loss: 465.2987 - kl_loss: 6.5483\n",
            "Epoch 113/300\n",
            "11/11 [==============================] - 1s 68ms/step - loss: 470.4909 - reconstruction_loss: 463.8991 - kl_loss: 6.3763\n",
            "Epoch 114/300\n",
            "11/11 [==============================] - 1s 64ms/step - loss: 474.1772 - reconstruction_loss: 462.3332 - kl_loss: 6.3838\n",
            "Epoch 115/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 470.6758 - reconstruction_loss: 464.5868 - kl_loss: 6.3905\n",
            "Epoch 116/300\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 471.6421 - reconstruction_loss: 464.1099 - kl_loss: 6.5921\n",
            "Epoch 117/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 471.5503 - reconstruction_loss: 464.1164 - kl_loss: 6.5999\n",
            "Epoch 118/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 471.4998 - reconstruction_loss: 466.4106 - kl_loss: 6.4623\n",
            "Epoch 119/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 471.9219 - reconstruction_loss: 464.1529 - kl_loss: 6.5444\n",
            "Epoch 120/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 466.1728 - reconstruction_loss: 464.6558 - kl_loss: 6.5339\n",
            "Epoch 121/300\n",
            "11/11 [==============================] - 1s 70ms/step - loss: 474.0599 - reconstruction_loss: 467.6439 - kl_loss: 6.3816\n",
            "Epoch 122/300\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 461.2522 - reconstruction_loss: 462.4167 - kl_loss: 6.5806\n",
            "Epoch 123/300\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 467.6439 - reconstruction_loss: 462.1733 - kl_loss: 6.6055\n",
            "Epoch 124/300\n",
            "11/11 [==============================] - 1s 100ms/step - loss: 461.0808 - reconstruction_loss: 458.5476 - kl_loss: 6.7447\n",
            "Epoch 125/300\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 467.5337 - reconstruction_loss: 464.4292 - kl_loss: 6.5551\n",
            "Epoch 126/300\n",
            "11/11 [==============================] - 1s 70ms/step - loss: 476.0664 - reconstruction_loss: 465.3375 - kl_loss: 6.4631\n",
            "Epoch 127/300\n",
            "11/11 [==============================] - 1s 71ms/step - loss: 471.7639 - reconstruction_loss: 461.8900 - kl_loss: 6.5213\n",
            "Epoch 128/300\n",
            "11/11 [==============================] - 1s 68ms/step - loss: 472.8144 - reconstruction_loss: 460.4134 - kl_loss: 6.6078\n",
            "Epoch 129/300\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 468.9966 - reconstruction_loss: 463.4306 - kl_loss: 6.5929\n",
            "Epoch 130/300\n",
            "11/11 [==============================] - 1s 70ms/step - loss: 464.6961 - reconstruction_loss: 462.1251 - kl_loss: 6.6097\n",
            "Epoch 131/300\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 463.6099 - reconstruction_loss: 462.0496 - kl_loss: 6.6034\n",
            "Epoch 132/300\n",
            "11/11 [==============================] - 1s 69ms/step - loss: 471.1354 - reconstruction_loss: 466.7651 - kl_loss: 6.5127\n",
            "Epoch 133/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 466.5330 - reconstruction_loss: 464.0544 - kl_loss: 6.5658\n",
            "Epoch 134/300\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 470.0066 - reconstruction_loss: 461.7929 - kl_loss: 6.6976\n",
            "Epoch 135/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 471.8252 - reconstruction_loss: 461.6424 - kl_loss: 6.6561\n",
            "Epoch 136/300\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 467.6341 - reconstruction_loss: 463.0670 - kl_loss: 6.6377\n",
            "Epoch 137/300\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 463.4009 - reconstruction_loss: 464.0688 - kl_loss: 6.6435\n",
            "Epoch 138/300\n",
            "11/11 [==============================] - 1s 82ms/step - loss: 464.4720 - reconstruction_loss: 462.1980 - kl_loss: 6.6965\n",
            "Epoch 139/300\n",
            "11/11 [==============================] - 1s 87ms/step - loss: 470.4931 - reconstruction_loss: 464.0668 - kl_loss: 6.7175\n",
            "Epoch 140/300\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 475.2620 - reconstruction_loss: 466.0418 - kl_loss: 6.4398\n",
            "Epoch 141/300\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 470.1989 - reconstruction_loss: 463.3477 - kl_loss: 6.4907\n",
            "Epoch 142/300\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 469.3183 - reconstruction_loss: 464.4506 - kl_loss: 6.5411\n",
            "Epoch 143/300\n",
            "11/11 [==============================] - 1s 69ms/step - loss: 472.2740 - reconstruction_loss: 462.2269 - kl_loss: 6.7836\n",
            "Epoch 144/300\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 468.0046 - reconstruction_loss: 464.3670 - kl_loss: 6.6827\n",
            "Epoch 145/300\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 467.0448 - reconstruction_loss: 461.6862 - kl_loss: 6.6233\n",
            "Epoch 146/300\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 464.9124 - reconstruction_loss: 461.4638 - kl_loss: 6.5642\n",
            "Epoch 147/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 471.1780 - reconstruction_loss: 465.2006 - kl_loss: 6.5945\n",
            "Epoch 148/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 472.9541 - reconstruction_loss: 463.4418 - kl_loss: 6.5462\n",
            "Epoch 149/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 464.3666 - reconstruction_loss: 461.7665 - kl_loss: 6.6386\n",
            "Epoch 150/300\n",
            "11/11 [==============================] - 1s 68ms/step - loss: 465.0893 - reconstruction_loss: 464.1822 - kl_loss: 6.5943\n",
            "Epoch 151/300\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 471.4743 - reconstruction_loss: 465.0422 - kl_loss: 6.6468\n",
            "Epoch 152/300\n",
            "11/11 [==============================] - 1s 69ms/step - loss: 469.0462 - reconstruction_loss: 464.2579 - kl_loss: 6.6069\n",
            "Epoch 153/300\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 468.0590 - reconstruction_loss: 464.2098 - kl_loss: 6.4647\n",
            "Epoch 154/300\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 460.9874 - reconstruction_loss: 463.5671 - kl_loss: 6.5375\n",
            "Epoch 155/300\n",
            "11/11 [==============================] - 1s 89ms/step - loss: 464.8108 - reconstruction_loss: 464.2583 - kl_loss: 6.5937\n",
            "Epoch 156/300\n",
            "11/11 [==============================] - 1s 74ms/step - loss: 469.7893 - reconstruction_loss: 464.6508 - kl_loss: 6.5291\n",
            "Epoch 157/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 462.9629 - reconstruction_loss: 462.6561 - kl_loss: 6.6608\n",
            "Epoch 158/300\n",
            "11/11 [==============================] - 1s 68ms/step - loss: 464.0155 - reconstruction_loss: 463.5492 - kl_loss: 6.6811\n",
            "Epoch 159/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 471.7857 - reconstruction_loss: 460.7733 - kl_loss: 6.7917\n",
            "Epoch 160/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 465.1735 - reconstruction_loss: 460.8037 - kl_loss: 6.6536\n",
            "Epoch 161/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 464.9458 - reconstruction_loss: 461.6423 - kl_loss: 6.5401\n",
            "Epoch 162/300\n",
            "11/11 [==============================] - 1s 69ms/step - loss: 470.4555 - reconstruction_loss: 464.2383 - kl_loss: 6.5868\n",
            "Epoch 163/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 477.5068 - reconstruction_loss: 464.7373 - kl_loss: 6.7378\n",
            "Epoch 164/300\n",
            "11/11 [==============================] - 1s 64ms/step - loss: 471.6602 - reconstruction_loss: 462.8998 - kl_loss: 6.8958\n",
            "Epoch 165/300\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 472.3004 - reconstruction_loss: 465.1338 - kl_loss: 6.7752\n",
            "Epoch 166/300\n",
            "11/11 [==============================] - 1s 84ms/step - loss: 464.3678 - reconstruction_loss: 462.8857 - kl_loss: 6.7960\n",
            "Epoch 167/300\n",
            "11/11 [==============================] - 1s 86ms/step - loss: 467.4653 - reconstruction_loss: 461.4003 - kl_loss: 6.7406\n",
            "Epoch 168/300\n",
            "11/11 [==============================] - 1s 82ms/step - loss: 469.1192 - reconstruction_loss: 464.6713 - kl_loss: 6.8017\n",
            "Epoch 169/300\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 467.7175 - reconstruction_loss: 463.7236 - kl_loss: 6.8225\n",
            "Epoch 170/300\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 472.4996 - reconstruction_loss: 463.5212 - kl_loss: 6.6698\n",
            "Epoch 171/300\n",
            "11/11 [==============================] - 1s 68ms/step - loss: 466.7832 - reconstruction_loss: 461.2787 - kl_loss: 6.6614\n",
            "Epoch 172/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 470.2752 - reconstruction_loss: 463.3498 - kl_loss: 6.8279\n",
            "Epoch 173/300\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 477.0258 - reconstruction_loss: 467.2053 - kl_loss: 6.6767\n",
            "Epoch 174/300\n",
            "11/11 [==============================] - 1s 69ms/step - loss: 471.7111 - reconstruction_loss: 465.8151 - kl_loss: 6.6101\n",
            "Epoch 175/300\n",
            "11/11 [==============================] - 1s 68ms/step - loss: 468.5952 - reconstruction_loss: 464.6566 - kl_loss: 6.6254\n",
            "Epoch 176/300\n",
            "11/11 [==============================] - 1s 68ms/step - loss: 463.1959 - reconstruction_loss: 461.2772 - kl_loss: 6.7901\n",
            "Epoch 177/300\n",
            "11/11 [==============================] - 1s 68ms/step - loss: 469.8446 - reconstruction_loss: 460.5845 - kl_loss: 6.7549\n",
            "Epoch 178/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 470.0849 - reconstruction_loss: 461.2640 - kl_loss: 6.8507\n",
            "Epoch 179/300\n",
            "11/11 [==============================] - 1s 73ms/step - loss: 471.5007 - reconstruction_loss: 462.1117 - kl_loss: 6.8602\n",
            "Epoch 180/300\n",
            "11/11 [==============================] - 1s 75ms/step - loss: 465.4583 - reconstruction_loss: 461.4727 - kl_loss: 6.7858\n",
            "Epoch 181/300\n",
            "11/11 [==============================] - 1s 84ms/step - loss: 461.2432 - reconstruction_loss: 463.2869 - kl_loss: 6.6714\n",
            "Epoch 182/300\n",
            "11/11 [==============================] - 1s 87ms/step - loss: 465.9678 - reconstruction_loss: 462.5071 - kl_loss: 6.6819\n",
            "Epoch 183/300\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 459.9620 - reconstruction_loss: 460.5516 - kl_loss: 6.9276\n",
            "Epoch 184/300\n",
            "11/11 [==============================] - 1s 81ms/step - loss: 476.4002 - reconstruction_loss: 460.6096 - kl_loss: 7.0138\n",
            "Epoch 185/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 468.2444 - reconstruction_loss: 461.6866 - kl_loss: 6.8161\n",
            "Epoch 186/300\n",
            "11/11 [==============================] - 1s 69ms/step - loss: 470.3342 - reconstruction_loss: 460.5516 - kl_loss: 6.8474\n",
            "Epoch 187/300\n",
            "11/11 [==============================] - 1s 69ms/step - loss: 465.0391 - reconstruction_loss: 459.3492 - kl_loss: 6.7740\n",
            "Epoch 188/300\n",
            "11/11 [==============================] - 1s 68ms/step - loss: 467.4931 - reconstruction_loss: 460.3177 - kl_loss: 6.7147\n",
            "Epoch 189/300\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 471.2911 - reconstruction_loss: 461.0072 - kl_loss: 6.7091\n",
            "Epoch 190/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 468.9107 - reconstruction_loss: 461.6666 - kl_loss: 6.6134\n",
            "Epoch 191/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 469.0152 - reconstruction_loss: 459.0375 - kl_loss: 6.6762\n",
            "Epoch 192/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 465.5897 - reconstruction_loss: 460.4349 - kl_loss: 6.6682\n",
            "Epoch 193/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 464.2300 - reconstruction_loss: 457.8667 - kl_loss: 6.7532\n",
            "Epoch 194/300\n",
            "11/11 [==============================] - 1s 86ms/step - loss: 469.2046 - reconstruction_loss: 460.0740 - kl_loss: 6.6623\n",
            "Epoch 195/300\n",
            "11/11 [==============================] - 1s 84ms/step - loss: 471.9526 - reconstruction_loss: 459.6658 - kl_loss: 6.7206\n",
            "Epoch 196/300\n",
            "11/11 [==============================] - 1s 88ms/step - loss: 461.9866 - reconstruction_loss: 458.3021 - kl_loss: 6.7206\n",
            "Epoch 197/300\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 466.0985 - reconstruction_loss: 460.8510 - kl_loss: 6.8138\n",
            "Epoch 198/300\n",
            "11/11 [==============================] - 1s 87ms/step - loss: 468.1389 - reconstruction_loss: 458.4927 - kl_loss: 6.8228\n",
            "Epoch 199/300\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 470.9872 - reconstruction_loss: 461.3564 - kl_loss: 6.7785\n",
            "Epoch 200/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 471.5836 - reconstruction_loss: 460.0286 - kl_loss: 6.8754\n",
            "Epoch 201/300\n",
            "11/11 [==============================] - 1s 68ms/step - loss: 467.9262 - reconstruction_loss: 461.5328 - kl_loss: 6.9691\n",
            "Epoch 202/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 468.3233 - reconstruction_loss: 459.7461 - kl_loss: 6.7918\n",
            "Epoch 203/300\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 471.0064 - reconstruction_loss: 461.2653 - kl_loss: 6.7689\n",
            "Epoch 204/300\n",
            "11/11 [==============================] - 1s 64ms/step - loss: 467.0680 - reconstruction_loss: 458.9106 - kl_loss: 6.8001\n",
            "Epoch 205/300\n",
            "11/11 [==============================] - 1s 68ms/step - loss: 467.7769 - reconstruction_loss: 458.3281 - kl_loss: 6.9509\n",
            "Epoch 206/300\n",
            "11/11 [==============================] - 1s 73ms/step - loss: 445.5682 - reconstruction_loss: 454.6330 - kl_loss: 6.9393\n",
            "Epoch 207/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 458.9423 - reconstruction_loss: 459.2829 - kl_loss: 6.8490\n",
            "Epoch 208/300\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 464.9908 - reconstruction_loss: 460.5151 - kl_loss: 6.7820\n",
            "Epoch 209/300\n",
            "11/11 [==============================] - 1s 85ms/step - loss: 470.6265 - reconstruction_loss: 460.4852 - kl_loss: 6.7774\n",
            "Epoch 210/300\n",
            "11/11 [==============================] - 1s 96ms/step - loss: 457.1994 - reconstruction_loss: 457.1461 - kl_loss: 6.8055\n",
            "Epoch 211/300\n",
            "11/11 [==============================] - 1s 99ms/step - loss: 465.1863 - reconstruction_loss: 459.2592 - kl_loss: 6.8371\n",
            "Epoch 212/300\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 460.4121 - reconstruction_loss: 459.7166 - kl_loss: 6.9247\n",
            "Epoch 213/300\n",
            "11/11 [==============================] - 1s 70ms/step - loss: 457.7971 - reconstruction_loss: 459.6102 - kl_loss: 6.8270\n",
            "Epoch 214/300\n",
            "11/11 [==============================] - 1s 68ms/step - loss: 464.8767 - reconstruction_loss: 458.5695 - kl_loss: 6.7365\n",
            "Epoch 215/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 468.5451 - reconstruction_loss: 460.9042 - kl_loss: 6.7869\n",
            "Epoch 216/300\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 466.1298 - reconstruction_loss: 459.5432 - kl_loss: 6.9306\n",
            "Epoch 217/300\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 470.3186 - reconstruction_loss: 460.0179 - kl_loss: 6.9167\n",
            "Epoch 218/300\n",
            "11/11 [==============================] - 1s 73ms/step - loss: 462.5994 - reconstruction_loss: 461.0003 - kl_loss: 6.9167\n",
            "Epoch 219/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 470.0792 - reconstruction_loss: 460.0701 - kl_loss: 6.7823\n",
            "Epoch 220/300\n",
            "11/11 [==============================] - 1s 64ms/step - loss: 461.9300 - reconstruction_loss: 458.4390 - kl_loss: 6.8080\n",
            "Epoch 221/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 462.9766 - reconstruction_loss: 460.4496 - kl_loss: 6.7146\n",
            "Epoch 222/300\n",
            "11/11 [==============================] - 1s 76ms/step - loss: 471.2339 - reconstruction_loss: 461.8610 - kl_loss: 6.6685\n",
            "Epoch 223/300\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 465.1436 - reconstruction_loss: 458.0370 - kl_loss: 6.8494\n",
            "Epoch 224/300\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 470.9413 - reconstruction_loss: 459.1847 - kl_loss: 6.8300\n",
            "Epoch 225/300\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 459.2724 - reconstruction_loss: 457.9981 - kl_loss: 6.8792\n",
            "Epoch 226/300\n",
            "11/11 [==============================] - 1s 95ms/step - loss: 458.5236 - reconstruction_loss: 457.4154 - kl_loss: 6.9392\n",
            "Epoch 227/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 467.7558 - reconstruction_loss: 458.6652 - kl_loss: 6.8334\n",
            "Epoch 228/300\n",
            "11/11 [==============================] - 1s 64ms/step - loss: 464.6254 - reconstruction_loss: 457.9195 - kl_loss: 6.8839\n",
            "Epoch 229/300\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 457.4938 - reconstruction_loss: 458.0186 - kl_loss: 6.8116\n",
            "Epoch 230/300\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 469.1649 - reconstruction_loss: 456.6373 - kl_loss: 6.8565\n",
            "Epoch 231/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 471.5122 - reconstruction_loss: 460.9194 - kl_loss: 6.7846\n",
            "Epoch 232/300\n",
            "11/11 [==============================] - 1s 64ms/step - loss: 456.4743 - reconstruction_loss: 459.6044 - kl_loss: 6.8125\n",
            "Epoch 233/300\n",
            "11/11 [==============================] - 1s 62ms/step - loss: 464.7806 - reconstruction_loss: 458.3291 - kl_loss: 6.8532\n",
            "Epoch 234/300\n",
            "11/11 [==============================] - 1s 64ms/step - loss: 470.2416 - reconstruction_loss: 457.6471 - kl_loss: 7.0096\n",
            "Epoch 235/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 460.4731 - reconstruction_loss: 455.1544 - kl_loss: 7.0758\n",
            "Epoch 236/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 467.5436 - reconstruction_loss: 459.8667 - kl_loss: 6.9887\n",
            "Epoch 237/300\n",
            "11/11 [==============================] - 1s 85ms/step - loss: 471.9047 - reconstruction_loss: 459.9548 - kl_loss: 6.9954\n",
            "Epoch 238/300\n",
            "11/11 [==============================] - 1s 86ms/step - loss: 464.6497 - reconstruction_loss: 460.5495 - kl_loss: 6.8539\n",
            "Epoch 239/300\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 473.4426 - reconstruction_loss: 461.2171 - kl_loss: 6.8512\n",
            "Epoch 240/300\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 464.8494 - reconstruction_loss: 458.8037 - kl_loss: 6.9347\n",
            "Epoch 241/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 470.5298 - reconstruction_loss: 458.9966 - kl_loss: 6.7859\n",
            "Epoch 242/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 463.0434 - reconstruction_loss: 461.0485 - kl_loss: 6.7012\n",
            "Epoch 243/300\n",
            "11/11 [==============================] - 1s 68ms/step - loss: 454.6525 - reconstruction_loss: 460.0790 - kl_loss: 6.8845\n",
            "Epoch 244/300\n",
            "11/11 [==============================] - 1s 71ms/step - loss: 466.2437 - reconstruction_loss: 458.4082 - kl_loss: 7.0309\n",
            "Epoch 245/300\n",
            "11/11 [==============================] - 1s 68ms/step - loss: 472.7009 - reconstruction_loss: 458.2545 - kl_loss: 7.0055\n",
            "Epoch 246/300\n",
            "11/11 [==============================] - 1s 69ms/step - loss: 465.4742 - reconstruction_loss: 459.5473 - kl_loss: 6.7777\n",
            "Epoch 247/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 462.3784 - reconstruction_loss: 456.7579 - kl_loss: 6.8040\n",
            "Epoch 248/300\n",
            "11/11 [==============================] - 1s 69ms/step - loss: 470.7574 - reconstruction_loss: 460.0019 - kl_loss: 6.9365\n",
            "Epoch 249/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 461.1450 - reconstruction_loss: 458.0424 - kl_loss: 6.9561\n",
            "Epoch 250/300\n",
            "11/11 [==============================] - 1s 68ms/step - loss: 460.2813 - reconstruction_loss: 458.1351 - kl_loss: 6.8629\n",
            "Epoch 251/300\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 461.1022 - reconstruction_loss: 456.8905 - kl_loss: 6.8890\n",
            "Epoch 252/300\n",
            "11/11 [==============================] - 1s 94ms/step - loss: 467.7542 - reconstruction_loss: 460.1645 - kl_loss: 6.9639\n",
            "Epoch 253/300\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 468.4093 - reconstruction_loss: 456.9620 - kl_loss: 6.9904\n",
            "Epoch 254/300\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 463.4842 - reconstruction_loss: 454.1846 - kl_loss: 6.9268\n",
            "Epoch 255/300\n",
            "11/11 [==============================] - 1s 64ms/step - loss: 465.3117 - reconstruction_loss: 456.3330 - kl_loss: 6.8836\n",
            "Epoch 256/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 453.3381 - reconstruction_loss: 452.0954 - kl_loss: 6.9470\n",
            "Epoch 257/300\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 455.0469 - reconstruction_loss: 455.7603 - kl_loss: 6.9680\n",
            "Epoch 258/300\n",
            "11/11 [==============================] - 1s 64ms/step - loss: 465.5612 - reconstruction_loss: 458.1310 - kl_loss: 7.1009\n",
            "Epoch 259/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 472.3935 - reconstruction_loss: 463.2054 - kl_loss: 7.0409\n",
            "Epoch 260/300\n",
            "11/11 [==============================] - 1s 73ms/step - loss: 468.2705 - reconstruction_loss: 459.1694 - kl_loss: 6.9554\n",
            "Epoch 261/300\n",
            "11/11 [==============================] - 1s 69ms/step - loss: 462.5517 - reconstruction_loss: 461.0689 - kl_loss: 6.8258\n",
            "Epoch 262/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 466.1913 - reconstruction_loss: 459.7483 - kl_loss: 6.8540\n",
            "Epoch 263/300\n",
            "11/11 [==============================] - 1s 68ms/step - loss: 472.3873 - reconstruction_loss: 459.6809 - kl_loss: 6.9339\n",
            "Epoch 264/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 465.1377 - reconstruction_loss: 455.6632 - kl_loss: 6.9663\n",
            "Epoch 265/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 460.6718 - reconstruction_loss: 458.0663 - kl_loss: 6.9150\n",
            "Epoch 266/300\n",
            "11/11 [==============================] - 1s 68ms/step - loss: 465.8754 - reconstruction_loss: 459.7727 - kl_loss: 6.9859\n",
            "Epoch 267/300\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 463.2123 - reconstruction_loss: 454.7082 - kl_loss: 6.8788\n",
            "Epoch 268/300\n",
            "11/11 [==============================] - 1s 85ms/step - loss: 463.5504 - reconstruction_loss: 455.2151 - kl_loss: 6.9107\n",
            "Epoch 269/300\n",
            "11/11 [==============================] - 1s 93ms/step - loss: 462.1672 - reconstruction_loss: 455.1975 - kl_loss: 6.8324\n",
            "Epoch 270/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 464.8810 - reconstruction_loss: 455.7637 - kl_loss: 6.8393\n",
            "Epoch 271/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 466.3001 - reconstruction_loss: 456.7560 - kl_loss: 6.8370\n",
            "Epoch 272/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 467.0987 - reconstruction_loss: 457.0323 - kl_loss: 6.7430\n",
            "Epoch 273/300\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 462.4138 - reconstruction_loss: 456.6969 - kl_loss: 6.8408\n",
            "Epoch 274/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 466.0894 - reconstruction_loss: 455.6895 - kl_loss: 6.8466\n",
            "Epoch 275/300\n",
            "11/11 [==============================] - 1s 72ms/step - loss: 466.8248 - reconstruction_loss: 457.6755 - kl_loss: 6.8356\n",
            "Epoch 276/300\n",
            "11/11 [==============================] - 1s 71ms/step - loss: 465.0590 - reconstruction_loss: 455.7901 - kl_loss: 6.9147\n",
            "Epoch 277/300\n",
            "11/11 [==============================] - 1s 69ms/step - loss: 467.0172 - reconstruction_loss: 458.6093 - kl_loss: 7.0121\n",
            "Epoch 278/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 468.1437 - reconstruction_loss: 456.1461 - kl_loss: 6.9869\n",
            "Epoch 279/300\n",
            "11/11 [==============================] - 1s 91ms/step - loss: 470.4106 - reconstruction_loss: 457.1885 - kl_loss: 7.0215\n",
            "Epoch 280/300\n",
            "11/11 [==============================] - 1s 90ms/step - loss: 460.8386 - reconstruction_loss: 459.6237 - kl_loss: 6.9010\n",
            "Epoch 281/300\n",
            "11/11 [==============================] - 1s 97ms/step - loss: 470.3517 - reconstruction_loss: 457.8309 - kl_loss: 7.0429\n",
            "Epoch 282/300\n",
            "11/11 [==============================] - 1s 97ms/step - loss: 458.8891 - reconstruction_loss: 455.3145 - kl_loss: 7.1096\n",
            "Epoch 283/300\n",
            "11/11 [==============================] - 1s 84ms/step - loss: 468.3787 - reconstruction_loss: 458.2614 - kl_loss: 7.0068\n",
            "Epoch 284/300\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 455.3780 - reconstruction_loss: 454.7088 - kl_loss: 7.0238\n",
            "Epoch 285/300\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 464.0599 - reconstruction_loss: 457.4492 - kl_loss: 6.9298\n",
            "Epoch 286/300\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 463.2470 - reconstruction_loss: 456.1821 - kl_loss: 6.9363\n",
            "Epoch 287/300\n",
            "11/11 [==============================] - 1s 68ms/step - loss: 465.9612 - reconstruction_loss: 453.3624 - kl_loss: 7.0033\n",
            "Epoch 288/300\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 463.1105 - reconstruction_loss: 456.2593 - kl_loss: 6.8873\n",
            "Epoch 289/300\n",
            "11/11 [==============================] - 1s 73ms/step - loss: 468.3431 - reconstruction_loss: 457.7103 - kl_loss: 6.8746\n",
            "Epoch 290/300\n",
            "11/11 [==============================] - 1s 68ms/step - loss: 459.9001 - reconstruction_loss: 456.6118 - kl_loss: 6.9712\n",
            "Epoch 291/300\n",
            "11/11 [==============================] - 1s 64ms/step - loss: 462.3333 - reconstruction_loss: 455.9443 - kl_loss: 6.9415\n",
            "Epoch 292/300\n",
            "11/11 [==============================] - 1s 72ms/step - loss: 468.6375 - reconstruction_loss: 456.8335 - kl_loss: 7.0245\n",
            "Epoch 293/300\n",
            "11/11 [==============================] - 1s 92ms/step - loss: 469.4746 - reconstruction_loss: 457.5541 - kl_loss: 6.9549\n",
            "Epoch 294/300\n",
            "11/11 [==============================] - 1s 87ms/step - loss: 465.5349 - reconstruction_loss: 456.2246 - kl_loss: 7.0084\n",
            "Epoch 295/300\n",
            "11/11 [==============================] - 1s 85ms/step - loss: 460.6708 - reconstruction_loss: 453.5406 - kl_loss: 7.0372\n",
            "Epoch 296/300\n",
            "11/11 [==============================] - 1s 102ms/step - loss: 455.3781 - reconstruction_loss: 453.3123 - kl_loss: 7.0302\n",
            "Epoch 297/300\n",
            "11/11 [==============================] - 1s 80ms/step - loss: 466.7381 - reconstruction_loss: 456.4197 - kl_loss: 6.9878\n",
            "Epoch 298/300\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 464.1090 - reconstruction_loss: 455.1079 - kl_loss: 7.0623\n",
            "Epoch 299/300\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 465.2932 - reconstruction_loss: 455.6316 - kl_loss: 6.9726\n",
            "Epoch 300/300\n",
            "11/11 [==============================] - 1s 74ms/step - loss: 464.5698 - reconstruction_loss: 455.9860 - kl_loss: 7.0511\n",
            "Found 42 images belonging to 1 classes.\n",
            "16/16 [==============================] - 0s 7ms/step\n",
            "Training VAE for class: Chair\n",
            "Found 280 images belonging to 1 classes.\n",
            "Epoch 1/300\n",
            "18/18 [==============================] - 6s 141ms/step - loss: 532.7088 - reconstruction_loss: 524.3528 - kl_loss: 6.0926\n",
            "Epoch 2/300\n",
            "18/18 [==============================] - 2s 91ms/step - loss: 511.2656 - reconstruction_loss: 506.9355 - kl_loss: 5.3035\n",
            "Epoch 3/300\n",
            "18/18 [==============================] - 2s 94ms/step - loss: 503.1684 - reconstruction_loss: 499.9171 - kl_loss: 5.1794\n",
            "Epoch 4/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 498.4019 - reconstruction_loss: 496.4641 - kl_loss: 5.1172\n",
            "Epoch 5/300\n",
            "18/18 [==============================] - 1s 72ms/step - loss: 500.1274 - reconstruction_loss: 494.4568 - kl_loss: 5.2674\n",
            "Epoch 6/300\n",
            "18/18 [==============================] - 1s 71ms/step - loss: 498.5735 - reconstruction_loss: 491.2464 - kl_loss: 5.3827\n",
            "Epoch 7/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 494.2457 - reconstruction_loss: 491.0297 - kl_loss: 5.4585\n",
            "Epoch 8/300\n",
            "18/18 [==============================] - 1s 73ms/step - loss: 493.8975 - reconstruction_loss: 490.2015 - kl_loss: 5.4741\n",
            "Epoch 9/300\n",
            "18/18 [==============================] - 2s 93ms/step - loss: 495.8119 - reconstruction_loss: 489.4058 - kl_loss: 5.5183\n",
            "Epoch 10/300\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 499.5601 - reconstruction_loss: 488.5279 - kl_loss: 5.4929\n",
            "Epoch 11/300\n",
            "18/18 [==============================] - 1s 71ms/step - loss: 492.2923 - reconstruction_loss: 485.6303 - kl_loss: 5.5321\n",
            "Epoch 12/300\n",
            "18/18 [==============================] - 1s 71ms/step - loss: 492.9767 - reconstruction_loss: 485.8872 - kl_loss: 5.4822\n",
            "Epoch 13/300\n",
            "18/18 [==============================] - 1s 71ms/step - loss: 489.3572 - reconstruction_loss: 485.6697 - kl_loss: 5.6041\n",
            "Epoch 14/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 489.2985 - reconstruction_loss: 485.0048 - kl_loss: 5.7999\n",
            "Epoch 15/300\n",
            "18/18 [==============================] - 2s 95ms/step - loss: 496.0053 - reconstruction_loss: 485.1392 - kl_loss: 5.6426\n",
            "Epoch 16/300\n",
            "18/18 [==============================] - 2s 102ms/step - loss: 484.1111 - reconstruction_loss: 485.0105 - kl_loss: 5.5769\n",
            "Epoch 17/300\n",
            "18/18 [==============================] - 1s 72ms/step - loss: 487.8219 - reconstruction_loss: 484.1334 - kl_loss: 5.7125\n",
            "Epoch 18/300\n",
            "18/18 [==============================] - 1s 73ms/step - loss: 484.6226 - reconstruction_loss: 483.1691 - kl_loss: 5.9122\n",
            "Epoch 19/300\n",
            "18/18 [==============================] - 1s 71ms/step - loss: 486.3092 - reconstruction_loss: 482.8484 - kl_loss: 5.8757\n",
            "Epoch 20/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 487.3282 - reconstruction_loss: 480.9333 - kl_loss: 5.8325\n",
            "Epoch 21/300\n",
            "18/18 [==============================] - 1s 79ms/step - loss: 491.5989 - reconstruction_loss: 481.4257 - kl_loss: 5.6412\n",
            "Epoch 22/300\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 487.8435 - reconstruction_loss: 482.0277 - kl_loss: 5.8817\n",
            "Epoch 23/300\n",
            "18/18 [==============================] - 2s 91ms/step - loss: 484.8601 - reconstruction_loss: 481.4074 - kl_loss: 6.0755\n",
            "Epoch 24/300\n",
            "18/18 [==============================] - 1s 73ms/step - loss: 483.2243 - reconstruction_loss: 480.7093 - kl_loss: 5.9274\n",
            "Epoch 25/300\n",
            "18/18 [==============================] - 1s 77ms/step - loss: 484.0919 - reconstruction_loss: 479.7628 - kl_loss: 5.9275\n",
            "Epoch 26/300\n",
            "18/18 [==============================] - 1s 71ms/step - loss: 482.7647 - reconstruction_loss: 481.1043 - kl_loss: 5.9418\n",
            "Epoch 27/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 481.8615 - reconstruction_loss: 478.8622 - kl_loss: 5.9307\n",
            "Epoch 28/300\n",
            "18/18 [==============================] - 1s 73ms/step - loss: 488.2580 - reconstruction_loss: 480.1807 - kl_loss: 5.8619\n",
            "Epoch 29/300\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 486.5532 - reconstruction_loss: 479.5806 - kl_loss: 5.9357\n",
            "Epoch 30/300\n",
            "18/18 [==============================] - 1s 79ms/step - loss: 483.0636 - reconstruction_loss: 479.3098 - kl_loss: 6.0643\n",
            "Epoch 31/300\n",
            "18/18 [==============================] - 2s 96ms/step - loss: 482.4308 - reconstruction_loss: 478.7900 - kl_loss: 6.0806\n",
            "Epoch 32/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 488.5221 - reconstruction_loss: 477.4605 - kl_loss: 6.0792\n",
            "Epoch 33/300\n",
            "18/18 [==============================] - 1s 72ms/step - loss: 485.0189 - reconstruction_loss: 477.8771 - kl_loss: 6.0645\n",
            "Epoch 34/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 484.9394 - reconstruction_loss: 478.0032 - kl_loss: 6.0630\n",
            "Epoch 35/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 488.6744 - reconstruction_loss: 480.6968 - kl_loss: 6.0199\n",
            "Epoch 36/300\n",
            "18/18 [==============================] - 1s 71ms/step - loss: 483.5739 - reconstruction_loss: 478.1177 - kl_loss: 6.1747\n",
            "Epoch 37/300\n",
            "18/18 [==============================] - 1s 73ms/step - loss: 472.0722 - reconstruction_loss: 476.0461 - kl_loss: 6.1837\n",
            "Epoch 38/300\n",
            "18/18 [==============================] - 2s 85ms/step - loss: 481.1358 - reconstruction_loss: 476.2906 - kl_loss: 6.1158\n",
            "Epoch 39/300\n",
            "18/18 [==============================] - 2s 98ms/step - loss: 484.5921 - reconstruction_loss: 476.9890 - kl_loss: 6.1834\n",
            "Epoch 40/300\n",
            "18/18 [==============================] - 1s 71ms/step - loss: 477.8731 - reconstruction_loss: 476.8093 - kl_loss: 6.1735\n",
            "Epoch 41/300\n",
            "18/18 [==============================] - 1s 66ms/step - loss: 481.1468 - reconstruction_loss: 477.0815 - kl_loss: 6.2037\n",
            "Epoch 42/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 480.3000 - reconstruction_loss: 475.2076 - kl_loss: 6.1766\n",
            "Epoch 43/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 487.6985 - reconstruction_loss: 477.3729 - kl_loss: 6.2200\n",
            "Epoch 44/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 484.4342 - reconstruction_loss: 477.3770 - kl_loss: 6.1495\n",
            "Epoch 45/300\n",
            "18/18 [==============================] - 2s 90ms/step - loss: 480.4446 - reconstruction_loss: 476.1274 - kl_loss: 6.1601\n",
            "Epoch 46/300\n",
            "18/18 [==============================] - 2s 92ms/step - loss: 484.7502 - reconstruction_loss: 476.1412 - kl_loss: 6.2150\n",
            "Epoch 47/300\n",
            "18/18 [==============================] - 1s 71ms/step - loss: 477.9014 - reconstruction_loss: 475.7762 - kl_loss: 6.1977\n",
            "Epoch 48/300\n",
            "18/18 [==============================] - 1s 66ms/step - loss: 484.1451 - reconstruction_loss: 475.5402 - kl_loss: 6.3182\n",
            "Epoch 49/300\n",
            "18/18 [==============================] - 1s 67ms/step - loss: 479.5446 - reconstruction_loss: 474.4911 - kl_loss: 6.3021\n",
            "Epoch 50/300\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 475.8707 - reconstruction_loss: 473.6648 - kl_loss: 6.1797\n",
            "Epoch 51/300\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 478.7339 - reconstruction_loss: 474.0951 - kl_loss: 6.2722\n",
            "Epoch 52/300\n",
            "18/18 [==============================] - 2s 83ms/step - loss: 480.3781 - reconstruction_loss: 473.7974 - kl_loss: 6.3728\n",
            "Epoch 53/300\n",
            "18/18 [==============================] - 2s 91ms/step - loss: 479.3436 - reconstruction_loss: 473.9782 - kl_loss: 6.3982\n",
            "Epoch 54/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 480.3855 - reconstruction_loss: 474.9031 - kl_loss: 6.2971\n",
            "Epoch 55/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 482.8152 - reconstruction_loss: 473.8127 - kl_loss: 6.3779\n",
            "Epoch 56/300\n",
            "18/18 [==============================] - 1s 67ms/step - loss: 486.3838 - reconstruction_loss: 474.2328 - kl_loss: 6.3227\n",
            "Epoch 57/300\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 478.7291 - reconstruction_loss: 473.7164 - kl_loss: 6.3530\n",
            "Epoch 58/300\n",
            "18/18 [==============================] - 1s 72ms/step - loss: 480.5008 - reconstruction_loss: 472.6888 - kl_loss: 6.3232\n",
            "Epoch 59/300\n",
            "18/18 [==============================] - 2s 91ms/step - loss: 479.7596 - reconstruction_loss: 475.1768 - kl_loss: 6.4083\n",
            "Epoch 60/300\n",
            "18/18 [==============================] - 2s 93ms/step - loss: 481.7418 - reconstruction_loss: 474.2375 - kl_loss: 6.5289\n",
            "Epoch 61/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 481.5141 - reconstruction_loss: 473.6065 - kl_loss: 6.2936\n",
            "Epoch 62/300\n",
            "18/18 [==============================] - 1s 71ms/step - loss: 471.9163 - reconstruction_loss: 471.9147 - kl_loss: 6.4696\n",
            "Epoch 63/300\n",
            "18/18 [==============================] - 1s 71ms/step - loss: 471.7887 - reconstruction_loss: 472.4619 - kl_loss: 6.5259\n",
            "Epoch 64/300\n",
            "18/18 [==============================] - 1s 67ms/step - loss: 480.1100 - reconstruction_loss: 473.3345 - kl_loss: 6.5457\n",
            "Epoch 65/300\n",
            "18/18 [==============================] - 1s 71ms/step - loss: 480.8570 - reconstruction_loss: 472.4215 - kl_loss: 6.3947\n",
            "Epoch 66/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 477.6579 - reconstruction_loss: 472.3332 - kl_loss: 6.4429\n",
            "Epoch 67/300\n",
            "18/18 [==============================] - 2s 92ms/step - loss: 478.4157 - reconstruction_loss: 472.1249 - kl_loss: 6.5184\n",
            "Epoch 68/300\n",
            "18/18 [==============================] - 1s 76ms/step - loss: 469.3138 - reconstruction_loss: 470.8784 - kl_loss: 6.5782\n",
            "Epoch 69/300\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 480.1635 - reconstruction_loss: 472.1906 - kl_loss: 6.4175\n",
            "Epoch 70/300\n",
            "18/18 [==============================] - 1s 71ms/step - loss: 479.9412 - reconstruction_loss: 472.1288 - kl_loss: 6.3963\n",
            "Epoch 71/300\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 479.3660 - reconstruction_loss: 472.3392 - kl_loss: 6.4678\n",
            "Epoch 72/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 476.1471 - reconstruction_loss: 472.6863 - kl_loss: 6.5045\n",
            "Epoch 73/300\n",
            "18/18 [==============================] - 1s 80ms/step - loss: 476.7051 - reconstruction_loss: 472.3507 - kl_loss: 6.5608\n",
            "Epoch 74/300\n",
            "18/18 [==============================] - 2s 98ms/step - loss: 480.1580 - reconstruction_loss: 472.0342 - kl_loss: 6.6172\n",
            "Epoch 75/300\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 473.7291 - reconstruction_loss: 470.1527 - kl_loss: 6.5946\n",
            "Epoch 76/300\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 475.6108 - reconstruction_loss: 470.6033 - kl_loss: 6.4921\n",
            "Epoch 77/300\n",
            "18/18 [==============================] - 1s 66ms/step - loss: 476.8354 - reconstruction_loss: 470.9590 - kl_loss: 6.5770\n",
            "Epoch 78/300\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 478.6241 - reconstruction_loss: 471.2099 - kl_loss: 6.5695\n",
            "Epoch 79/300\n",
            "18/18 [==============================] - 1s 67ms/step - loss: 478.3100 - reconstruction_loss: 471.6383 - kl_loss: 6.6060\n",
            "Epoch 80/300\n",
            "18/18 [==============================] - 1s 66ms/step - loss: 479.7219 - reconstruction_loss: 471.2541 - kl_loss: 6.5970\n",
            "Epoch 81/300\n",
            "18/18 [==============================] - 1s 73ms/step - loss: 480.5680 - reconstruction_loss: 471.5024 - kl_loss: 6.5886\n",
            "Epoch 82/300\n",
            "18/18 [==============================] - 2s 97ms/step - loss: 482.9090 - reconstruction_loss: 472.0376 - kl_loss: 6.6603\n",
            "Epoch 83/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 479.7300 - reconstruction_loss: 472.6670 - kl_loss: 6.5671\n",
            "Epoch 84/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 480.8662 - reconstruction_loss: 471.3166 - kl_loss: 6.5301\n",
            "Epoch 85/300\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 474.2234 - reconstruction_loss: 470.8875 - kl_loss: 6.5895\n",
            "Epoch 86/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 482.3017 - reconstruction_loss: 469.7381 - kl_loss: 6.6759\n",
            "Epoch 87/300\n",
            "18/18 [==============================] - 1s 71ms/step - loss: 471.1439 - reconstruction_loss: 468.5701 - kl_loss: 6.6811\n",
            "Epoch 88/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 476.0203 - reconstruction_loss: 468.5005 - kl_loss: 6.6750\n",
            "Epoch 89/300\n",
            "18/18 [==============================] - 1s 74ms/step - loss: 480.0788 - reconstruction_loss: 469.4817 - kl_loss: 6.7628\n",
            "Epoch 90/300\n",
            "18/18 [==============================] - 2s 96ms/step - loss: 479.0640 - reconstruction_loss: 468.4948 - kl_loss: 6.7957\n",
            "Epoch 91/300\n",
            "18/18 [==============================] - 1s 74ms/step - loss: 477.0269 - reconstruction_loss: 469.9437 - kl_loss: 6.5947\n",
            "Epoch 92/300\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 477.1025 - reconstruction_loss: 469.4403 - kl_loss: 6.5556\n",
            "Epoch 93/300\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 473.6203 - reconstruction_loss: 469.4803 - kl_loss: 6.6388\n",
            "Epoch 94/300\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 472.5385 - reconstruction_loss: 467.9418 - kl_loss: 6.7346\n",
            "Epoch 95/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 476.9782 - reconstruction_loss: 469.6193 - kl_loss: 6.7422\n",
            "Epoch 96/300\n",
            "18/18 [==============================] - 2s 100ms/step - loss: 475.9163 - reconstruction_loss: 468.8860 - kl_loss: 6.7578\n",
            "Epoch 97/300\n",
            "18/18 [==============================] - 2s 95ms/step - loss: 475.6599 - reconstruction_loss: 469.3031 - kl_loss: 6.6967\n",
            "Epoch 98/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 469.1891 - reconstruction_loss: 469.1650 - kl_loss: 6.7124\n",
            "Epoch 99/300\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 472.8521 - reconstruction_loss: 468.6623 - kl_loss: 6.6859\n",
            "Epoch 100/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 478.6755 - reconstruction_loss: 467.8031 - kl_loss: 6.6530\n",
            "Epoch 101/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 473.0990 - reconstruction_loss: 467.5445 - kl_loss: 6.6679\n",
            "Epoch 102/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 474.2936 - reconstruction_loss: 468.0405 - kl_loss: 6.7688\n",
            "Epoch 103/300\n",
            "18/18 [==============================] - 1s 71ms/step - loss: 485.1751 - reconstruction_loss: 468.2773 - kl_loss: 6.9324\n",
            "Epoch 104/300\n",
            "18/18 [==============================] - 2s 101ms/step - loss: 476.6247 - reconstruction_loss: 468.4220 - kl_loss: 6.7974\n",
            "Epoch 105/300\n",
            "18/18 [==============================] - 1s 77ms/step - loss: 473.6212 - reconstruction_loss: 467.8800 - kl_loss: 6.8284\n",
            "Epoch 106/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 469.2678 - reconstruction_loss: 467.6433 - kl_loss: 6.8207\n",
            "Epoch 107/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 475.1421 - reconstruction_loss: 468.2349 - kl_loss: 6.7801\n",
            "Epoch 108/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 474.0619 - reconstruction_loss: 466.7930 - kl_loss: 6.8301\n",
            "Epoch 109/300\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 472.1994 - reconstruction_loss: 467.5419 - kl_loss: 6.7793\n",
            "Epoch 110/300\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 470.0919 - reconstruction_loss: 466.4598 - kl_loss: 6.8353\n",
            "Epoch 111/300\n",
            "18/18 [==============================] - 2s 96ms/step - loss: 480.2475 - reconstruction_loss: 465.6727 - kl_loss: 6.8440\n",
            "Epoch 112/300\n",
            "18/18 [==============================] - 1s 72ms/step - loss: 475.7048 - reconstruction_loss: 467.8893 - kl_loss: 6.7477\n",
            "Epoch 113/300\n",
            "18/18 [==============================] - 1s 74ms/step - loss: 475.2350 - reconstruction_loss: 466.7054 - kl_loss: 6.7529\n",
            "Epoch 114/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 483.8345 - reconstruction_loss: 468.0842 - kl_loss: 6.7086\n",
            "Epoch 115/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 477.3459 - reconstruction_loss: 466.6147 - kl_loss: 6.8811\n",
            "Epoch 116/300\n",
            "18/18 [==============================] - 1s 73ms/step - loss: 470.4240 - reconstruction_loss: 468.5965 - kl_loss: 6.7663\n",
            "Epoch 117/300\n",
            "18/18 [==============================] - 1s 72ms/step - loss: 473.5416 - reconstruction_loss: 466.3177 - kl_loss: 6.8838\n",
            "Epoch 118/300\n",
            "18/18 [==============================] - 2s 94ms/step - loss: 472.3791 - reconstruction_loss: 467.0004 - kl_loss: 6.8419\n",
            "Epoch 119/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 476.1171 - reconstruction_loss: 466.9886 - kl_loss: 6.9611\n",
            "Epoch 120/300\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 474.3046 - reconstruction_loss: 467.1509 - kl_loss: 6.9418\n",
            "Epoch 121/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 477.6836 - reconstruction_loss: 468.4727 - kl_loss: 6.8538\n",
            "Epoch 122/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 469.8255 - reconstruction_loss: 466.1136 - kl_loss: 6.9536\n",
            "Epoch 123/300\n",
            "18/18 [==============================] - 1s 72ms/step - loss: 473.8652 - reconstruction_loss: 465.5481 - kl_loss: 6.8621\n",
            "Epoch 124/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 473.2917 - reconstruction_loss: 466.6660 - kl_loss: 6.7740\n",
            "Epoch 125/300\n",
            "18/18 [==============================] - 1s 72ms/step - loss: 469.7864 - reconstruction_loss: 467.2907 - kl_loss: 6.8983\n",
            "Epoch 126/300\n",
            "18/18 [==============================] - 2s 102ms/step - loss: 477.9728 - reconstruction_loss: 466.7086 - kl_loss: 6.9954\n",
            "Epoch 127/300\n",
            "18/18 [==============================] - 2s 94ms/step - loss: 478.1425 - reconstruction_loss: 466.9224 - kl_loss: 6.9247\n",
            "Epoch 128/300\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 472.8541 - reconstruction_loss: 466.1643 - kl_loss: 6.7812\n",
            "Epoch 129/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 474.3747 - reconstruction_loss: 466.2397 - kl_loss: 6.8748\n",
            "Epoch 130/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 472.1096 - reconstruction_loss: 464.8014 - kl_loss: 7.0147\n",
            "Epoch 131/300\n",
            "18/18 [==============================] - 1s 71ms/step - loss: 469.2168 - reconstruction_loss: 465.1859 - kl_loss: 6.9578\n",
            "Epoch 132/300\n",
            "18/18 [==============================] - 1s 73ms/step - loss: 471.3580 - reconstruction_loss: 465.2540 - kl_loss: 6.9772\n",
            "Epoch 133/300\n",
            "18/18 [==============================] - 2s 91ms/step - loss: 472.6807 - reconstruction_loss: 467.2736 - kl_loss: 6.9181\n",
            "Epoch 134/300\n",
            "18/18 [==============================] - 1s 82ms/step - loss: 473.4146 - reconstruction_loss: 467.2303 - kl_loss: 6.9930\n",
            "Epoch 135/300\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 475.0581 - reconstruction_loss: 467.4049 - kl_loss: 7.0085\n",
            "Epoch 136/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 471.3895 - reconstruction_loss: 465.4067 - kl_loss: 6.9276\n",
            "Epoch 137/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 475.0744 - reconstruction_loss: 465.5140 - kl_loss: 6.8828\n",
            "Epoch 138/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 472.0518 - reconstruction_loss: 465.4941 - kl_loss: 7.0917\n",
            "Epoch 139/300\n",
            "18/18 [==============================] - 2s 90ms/step - loss: 472.7765 - reconstruction_loss: 466.2860 - kl_loss: 7.0124\n",
            "Epoch 140/300\n",
            "18/18 [==============================] - 2s 96ms/step - loss: 475.9254 - reconstruction_loss: 465.4186 - kl_loss: 6.8377\n",
            "Epoch 141/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 472.3741 - reconstruction_loss: 465.0877 - kl_loss: 6.8515\n",
            "Epoch 142/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 471.8686 - reconstruction_loss: 464.5873 - kl_loss: 7.0311\n",
            "Epoch 143/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 471.0095 - reconstruction_loss: 465.4147 - kl_loss: 7.0515\n",
            "Epoch 144/300\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 466.9865 - reconstruction_loss: 465.0600 - kl_loss: 7.0583\n",
            "Epoch 145/300\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 474.8006 - reconstruction_loss: 464.2338 - kl_loss: 7.0561\n",
            "Epoch 146/300\n",
            "18/18 [==============================] - 2s 101ms/step - loss: 472.8016 - reconstruction_loss: 465.4164 - kl_loss: 6.9412\n",
            "Epoch 147/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 470.8752 - reconstruction_loss: 466.5871 - kl_loss: 6.9895\n",
            "Epoch 148/300\n",
            "18/18 [==============================] - 1s 71ms/step - loss: 474.4674 - reconstruction_loss: 464.9123 - kl_loss: 7.0006\n",
            "Epoch 149/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 468.6543 - reconstruction_loss: 464.7144 - kl_loss: 7.0394\n",
            "Epoch 150/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 475.5431 - reconstruction_loss: 464.7201 - kl_loss: 6.9899\n",
            "Epoch 151/300\n",
            "18/18 [==============================] - 2s 90ms/step - loss: 470.6113 - reconstruction_loss: 464.4183 - kl_loss: 7.0836\n",
            "Epoch 152/300\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 472.4359 - reconstruction_loss: 464.9688 - kl_loss: 6.9047\n",
            "Epoch 153/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 475.0308 - reconstruction_loss: 465.9664 - kl_loss: 6.8082\n",
            "Epoch 154/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 472.0480 - reconstruction_loss: 465.7119 - kl_loss: 6.9823\n",
            "Epoch 155/300\n",
            "18/18 [==============================] - 1s 67ms/step - loss: 472.4095 - reconstruction_loss: 466.0338 - kl_loss: 6.9861\n",
            "Epoch 156/300\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 469.1717 - reconstruction_loss: 465.1450 - kl_loss: 7.0780\n",
            "Epoch 157/300\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 471.1431 - reconstruction_loss: 464.9183 - kl_loss: 7.0669\n",
            "Epoch 158/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 468.5896 - reconstruction_loss: 463.9460 - kl_loss: 7.0302\n",
            "Epoch 159/300\n",
            "18/18 [==============================] - 2s 93ms/step - loss: 466.0145 - reconstruction_loss: 462.9969 - kl_loss: 6.9200\n",
            "Epoch 160/300\n",
            "18/18 [==============================] - 1s 81ms/step - loss: 467.0324 - reconstruction_loss: 462.6884 - kl_loss: 6.9854\n",
            "Epoch 161/300\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 468.0669 - reconstruction_loss: 463.4131 - kl_loss: 7.0012\n",
            "Epoch 162/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 467.2232 - reconstruction_loss: 462.9512 - kl_loss: 7.0622\n",
            "Epoch 163/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 466.8142 - reconstruction_loss: 463.4923 - kl_loss: 7.0236\n",
            "Epoch 164/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 472.6529 - reconstruction_loss: 463.2294 - kl_loss: 6.9600\n",
            "Epoch 165/300\n",
            "18/18 [==============================] - 1s 77ms/step - loss: 472.7798 - reconstruction_loss: 462.9833 - kl_loss: 7.0653\n",
            "Epoch 166/300\n",
            "18/18 [==============================] - 2s 90ms/step - loss: 473.3369 - reconstruction_loss: 462.1493 - kl_loss: 7.0793\n",
            "Epoch 167/300\n",
            "18/18 [==============================] - 1s 72ms/step - loss: 469.2211 - reconstruction_loss: 462.2443 - kl_loss: 7.0513\n",
            "Epoch 168/300\n",
            "18/18 [==============================] - 1s 71ms/step - loss: 472.9294 - reconstruction_loss: 463.9570 - kl_loss: 7.0392\n",
            "Epoch 169/300\n",
            "18/18 [==============================] - 1s 71ms/step - loss: 468.1612 - reconstruction_loss: 463.8089 - kl_loss: 7.0491\n",
            "Epoch 170/300\n",
            "18/18 [==============================] - 1s 72ms/step - loss: 466.9286 - reconstruction_loss: 463.1832 - kl_loss: 7.1566\n",
            "Epoch 171/300\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 466.7229 - reconstruction_loss: 463.1154 - kl_loss: 7.0311\n",
            "Epoch 172/300\n",
            "18/18 [==============================] - 2s 90ms/step - loss: 472.5146 - reconstruction_loss: 463.8232 - kl_loss: 7.0482\n",
            "Epoch 173/300\n",
            "18/18 [==============================] - 1s 72ms/step - loss: 472.2131 - reconstruction_loss: 463.9203 - kl_loss: 7.1708\n",
            "Epoch 174/300\n",
            "18/18 [==============================] - 1s 67ms/step - loss: 474.9868 - reconstruction_loss: 462.7866 - kl_loss: 7.2526\n",
            "Epoch 175/300\n",
            "18/18 [==============================] - 1s 67ms/step - loss: 465.3606 - reconstruction_loss: 462.1339 - kl_loss: 7.2528\n",
            "Epoch 176/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 466.4510 - reconstruction_loss: 461.9874 - kl_loss: 7.1999\n",
            "Epoch 177/300\n",
            "18/18 [==============================] - 1s 72ms/step - loss: 466.5966 - reconstruction_loss: 461.5292 - kl_loss: 7.1018\n",
            "Epoch 178/300\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 463.6142 - reconstruction_loss: 462.3409 - kl_loss: 7.0916\n",
            "Epoch 179/300\n",
            "18/18 [==============================] - 1s 73ms/step - loss: 473.4272 - reconstruction_loss: 462.2101 - kl_loss: 7.2059\n",
            "Epoch 180/300\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 470.5882 - reconstruction_loss: 462.3783 - kl_loss: 7.2065\n",
            "Epoch 181/300\n",
            "18/18 [==============================] - 2s 96ms/step - loss: 475.1955 - reconstruction_loss: 462.1234 - kl_loss: 7.2237\n",
            "Epoch 182/300\n",
            "18/18 [==============================] - 2s 98ms/step - loss: 471.1948 - reconstruction_loss: 462.5741 - kl_loss: 7.1643\n",
            "Epoch 183/300\n",
            "18/18 [==============================] - 1s 71ms/step - loss: 470.5336 - reconstruction_loss: 462.5889 - kl_loss: 7.1346\n",
            "Epoch 184/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 460.3010 - reconstruction_loss: 460.5966 - kl_loss: 7.1189\n",
            "Epoch 185/300\n",
            "18/18 [==============================] - 1s 73ms/step - loss: 468.3566 - reconstruction_loss: 461.4984 - kl_loss: 7.0966\n",
            "Epoch 186/300\n",
            "18/18 [==============================] - 1s 67ms/step - loss: 461.9343 - reconstruction_loss: 460.8615 - kl_loss: 7.2808\n",
            "Epoch 187/300\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 458.0111 - reconstruction_loss: 461.3987 - kl_loss: 7.1931\n",
            "Epoch 188/300\n",
            "18/18 [==============================] - 2s 92ms/step - loss: 464.7770 - reconstruction_loss: 462.9228 - kl_loss: 7.1410\n",
            "Epoch 189/300\n",
            "18/18 [==============================] - 1s 73ms/step - loss: 470.5266 - reconstruction_loss: 462.7569 - kl_loss: 7.1897\n",
            "Epoch 190/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 468.2571 - reconstruction_loss: 462.9167 - kl_loss: 7.1117\n",
            "Epoch 191/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 466.4987 - reconstruction_loss: 462.3762 - kl_loss: 7.2040\n",
            "Epoch 192/300\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 469.7815 - reconstruction_loss: 461.1588 - kl_loss: 7.1860\n",
            "Epoch 193/300\n",
            "18/18 [==============================] - 1s 77ms/step - loss: 469.4751 - reconstruction_loss: 461.2729 - kl_loss: 7.1290\n",
            "Epoch 194/300\n",
            "18/18 [==============================] - 2s 94ms/step - loss: 465.5457 - reconstruction_loss: 461.3846 - kl_loss: 7.0869\n",
            "Epoch 195/300\n",
            "18/18 [==============================] - 2s 84ms/step - loss: 467.8901 - reconstruction_loss: 460.3506 - kl_loss: 7.2939\n",
            "Epoch 196/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 465.9023 - reconstruction_loss: 459.7293 - kl_loss: 7.1978\n",
            "Epoch 197/300\n",
            "18/18 [==============================] - 1s 67ms/step - loss: 464.7348 - reconstruction_loss: 462.4815 - kl_loss: 7.2426\n",
            "Epoch 198/300\n",
            "18/18 [==============================] - 1s 71ms/step - loss: 471.7577 - reconstruction_loss: 460.5944 - kl_loss: 7.4369\n",
            "Epoch 199/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 469.7713 - reconstruction_loss: 461.0265 - kl_loss: 7.2842\n",
            "Epoch 200/300\n",
            "18/18 [==============================] - 1s 78ms/step - loss: 460.5501 - reconstruction_loss: 460.7122 - kl_loss: 7.2373\n",
            "Epoch 201/300\n",
            "18/18 [==============================] - 2s 91ms/step - loss: 465.7574 - reconstruction_loss: 461.7912 - kl_loss: 7.2788\n",
            "Epoch 202/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 470.3345 - reconstruction_loss: 459.9355 - kl_loss: 7.3645\n",
            "Epoch 203/300\n",
            "18/18 [==============================] - 1s 75ms/step - loss: 473.0192 - reconstruction_loss: 461.9572 - kl_loss: 7.2314\n",
            "Epoch 204/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 473.3888 - reconstruction_loss: 461.8881 - kl_loss: 7.1353\n",
            "Epoch 205/300\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 466.0454 - reconstruction_loss: 460.9376 - kl_loss: 7.1733\n",
            "Epoch 206/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 462.2626 - reconstruction_loss: 461.3015 - kl_loss: 7.2286\n",
            "Epoch 207/300\n",
            "18/18 [==============================] - 2s 95ms/step - loss: 467.4014 - reconstruction_loss: 461.3957 - kl_loss: 7.2939\n",
            "Epoch 208/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 460.5775 - reconstruction_loss: 460.2322 - kl_loss: 7.2269\n",
            "Epoch 209/300\n",
            "18/18 [==============================] - 1s 71ms/step - loss: 463.7902 - reconstruction_loss: 460.8063 - kl_loss: 7.1769\n",
            "Epoch 210/300\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 466.4615 - reconstruction_loss: 461.2843 - kl_loss: 7.2049\n",
            "Epoch 211/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 470.2452 - reconstruction_loss: 461.9099 - kl_loss: 7.3138\n",
            "Epoch 212/300\n",
            "18/18 [==============================] - 2s 94ms/step - loss: 460.2560 - reconstruction_loss: 461.1284 - kl_loss: 7.1533\n",
            "Epoch 213/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 467.7217 - reconstruction_loss: 461.0449 - kl_loss: 7.1352\n",
            "Epoch 214/300\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 470.7598 - reconstruction_loss: 460.9755 - kl_loss: 7.1316\n",
            "Epoch 215/300\n",
            "18/18 [==============================] - 1s 71ms/step - loss: 465.9635 - reconstruction_loss: 461.2570 - kl_loss: 7.2609\n",
            "Epoch 216/300\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 471.2314 - reconstruction_loss: 461.5111 - kl_loss: 7.2155\n",
            "Epoch 217/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 474.6084 - reconstruction_loss: 462.0122 - kl_loss: 7.2123\n",
            "Epoch 218/300\n",
            "18/18 [==============================] - 2s 94ms/step - loss: 468.3432 - reconstruction_loss: 462.6906 - kl_loss: 7.2632\n",
            "Epoch 219/300\n",
            "18/18 [==============================] - 2s 95ms/step - loss: 464.7002 - reconstruction_loss: 461.3941 - kl_loss: 7.2441\n",
            "Epoch 220/300\n",
            "18/18 [==============================] - 2s 90ms/step - loss: 466.1737 - reconstruction_loss: 460.0154 - kl_loss: 7.2030\n",
            "Epoch 221/300\n",
            "18/18 [==============================] - 1s 72ms/step - loss: 465.6421 - reconstruction_loss: 460.0573 - kl_loss: 7.2804\n",
            "Epoch 222/300\n",
            "18/18 [==============================] - 1s 71ms/step - loss: 470.5559 - reconstruction_loss: 460.0958 - kl_loss: 7.3162\n",
            "Epoch 223/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 466.4412 - reconstruction_loss: 460.5829 - kl_loss: 7.2366\n",
            "Epoch 224/300\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 472.9553 - reconstruction_loss: 460.2931 - kl_loss: 7.3247\n",
            "Epoch 225/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 465.6526 - reconstruction_loss: 459.5377 - kl_loss: 7.2669\n",
            "Epoch 226/300\n",
            "18/18 [==============================] - 1s 72ms/step - loss: 470.6250 - reconstruction_loss: 460.4044 - kl_loss: 7.3626\n",
            "Epoch 227/300\n",
            "18/18 [==============================] - 2s 82ms/step - loss: 471.6273 - reconstruction_loss: 459.6996 - kl_loss: 7.2332\n",
            "Epoch 228/300\n",
            "18/18 [==============================] - 2s 100ms/step - loss: 465.8835 - reconstruction_loss: 459.7307 - kl_loss: 7.2143\n",
            "Epoch 229/300\n",
            "18/18 [==============================] - 2s 85ms/step - loss: 458.0512 - reconstruction_loss: 458.6857 - kl_loss: 7.3704\n",
            "Epoch 230/300\n",
            "18/18 [==============================] - 1s 67ms/step - loss: 469.3495 - reconstruction_loss: 460.4723 - kl_loss: 7.2101\n",
            "Epoch 231/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 470.2380 - reconstruction_loss: 458.5846 - kl_loss: 7.2936\n",
            "Epoch 232/300\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 466.9830 - reconstruction_loss: 458.9716 - kl_loss: 7.2935\n",
            "Epoch 233/300\n",
            "18/18 [==============================] - 1s 72ms/step - loss: 461.2998 - reconstruction_loss: 459.6982 - kl_loss: 7.2846\n",
            "Epoch 234/300\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 468.9990 - reconstruction_loss: 459.8882 - kl_loss: 7.4067\n",
            "Epoch 235/300\n",
            "18/18 [==============================] - 2s 94ms/step - loss: 465.0138 - reconstruction_loss: 459.2277 - kl_loss: 7.3971\n",
            "Epoch 236/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 464.0657 - reconstruction_loss: 459.7162 - kl_loss: 7.3210\n",
            "Epoch 237/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 469.9741 - reconstruction_loss: 458.8046 - kl_loss: 7.1840\n",
            "Epoch 238/300\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 466.6879 - reconstruction_loss: 459.5525 - kl_loss: 7.2858\n",
            "Epoch 239/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 466.8307 - reconstruction_loss: 460.4155 - kl_loss: 7.3242\n",
            "Epoch 240/300\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 466.6358 - reconstruction_loss: 459.1997 - kl_loss: 7.2957\n",
            "Epoch 241/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 462.2552 - reconstruction_loss: 459.5746 - kl_loss: 7.2885\n",
            "Epoch 242/300\n",
            "18/18 [==============================] - 1s 80ms/step - loss: 465.9958 - reconstruction_loss: 459.1524 - kl_loss: 7.2758\n",
            "Epoch 243/300\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 464.9369 - reconstruction_loss: 458.3268 - kl_loss: 7.2471\n",
            "Epoch 244/300\n",
            "18/18 [==============================] - 2s 94ms/step - loss: 461.8281 - reconstruction_loss: 458.8973 - kl_loss: 7.3211\n",
            "Epoch 245/300\n",
            "18/18 [==============================] - 2s 95ms/step - loss: 467.5222 - reconstruction_loss: 458.5916 - kl_loss: 7.3122\n",
            "Epoch 246/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 466.5441 - reconstruction_loss: 459.2318 - kl_loss: 7.4331\n",
            "Epoch 247/300\n",
            "18/18 [==============================] - 1s 71ms/step - loss: 462.1957 - reconstruction_loss: 458.0290 - kl_loss: 7.3729\n",
            "Epoch 248/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 470.8114 - reconstruction_loss: 459.0388 - kl_loss: 7.4492\n",
            "Epoch 249/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 467.2532 - reconstruction_loss: 459.2868 - kl_loss: 7.4998\n",
            "Epoch 250/300\n",
            "18/18 [==============================] - 2s 84ms/step - loss: 466.8691 - reconstruction_loss: 457.8835 - kl_loss: 7.3899\n",
            "Epoch 251/300\n",
            "18/18 [==============================] - 2s 101ms/step - loss: 463.9988 - reconstruction_loss: 457.2726 - kl_loss: 7.4352\n",
            "Epoch 252/300\n",
            "18/18 [==============================] - 2s 84ms/step - loss: 465.7720 - reconstruction_loss: 458.4671 - kl_loss: 7.3007\n",
            "Epoch 253/300\n",
            "18/18 [==============================] - 1s 67ms/step - loss: 466.4332 - reconstruction_loss: 457.3882 - kl_loss: 7.3560\n",
            "Epoch 254/300\n",
            "18/18 [==============================] - 1s 67ms/step - loss: 469.2598 - reconstruction_loss: 458.2879 - kl_loss: 7.3596\n",
            "Epoch 255/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 467.4899 - reconstruction_loss: 458.4119 - kl_loss: 7.3702\n",
            "Epoch 256/300\n",
            "18/18 [==============================] - 1s 67ms/step - loss: 471.3613 - reconstruction_loss: 458.1628 - kl_loss: 7.3073\n",
            "Epoch 257/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 469.8862 - reconstruction_loss: 459.5079 - kl_loss: 7.3166\n",
            "Epoch 258/300\n",
            "18/18 [==============================] - 1s 72ms/step - loss: 465.5518 - reconstruction_loss: 459.4744 - kl_loss: 7.3923\n",
            "Epoch 259/300\n",
            "18/18 [==============================] - 2s 83ms/step - loss: 465.4035 - reconstruction_loss: 459.0533 - kl_loss: 7.3844\n",
            "Epoch 260/300\n",
            "18/18 [==============================] - 2s 90ms/step - loss: 459.5026 - reconstruction_loss: 458.2736 - kl_loss: 7.3166\n",
            "Epoch 261/300\n",
            "18/18 [==============================] - 1s 79ms/step - loss: 463.0414 - reconstruction_loss: 458.9020 - kl_loss: 7.2883\n",
            "Epoch 262/300\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 466.5850 - reconstruction_loss: 459.1636 - kl_loss: 7.3163\n",
            "Epoch 263/300\n",
            "18/18 [==============================] - 1s 68ms/step - loss: 468.1288 - reconstruction_loss: 459.6286 - kl_loss: 7.5159\n",
            "Epoch 264/300\n",
            "18/18 [==============================] - 1s 71ms/step - loss: 465.1053 - reconstruction_loss: 459.2507 - kl_loss: 7.5420\n",
            "Epoch 265/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 469.7924 - reconstruction_loss: 458.4104 - kl_loss: 7.2952\n",
            "Epoch 266/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 459.3981 - reconstruction_loss: 458.8092 - kl_loss: 7.4524\n",
            "Epoch 267/300\n",
            "18/18 [==============================] - 2s 95ms/step - loss: 465.6654 - reconstruction_loss: 458.2644 - kl_loss: 7.4219\n",
            "Epoch 268/300\n",
            "18/18 [==============================] - 1s 81ms/step - loss: 466.1591 - reconstruction_loss: 459.2192 - kl_loss: 7.4017\n",
            "Epoch 269/300\n",
            "18/18 [==============================] - 1s 71ms/step - loss: 469.5420 - reconstruction_loss: 457.1266 - kl_loss: 7.4264\n",
            "Epoch 270/300\n",
            "18/18 [==============================] - 1s 73ms/step - loss: 467.1964 - reconstruction_loss: 458.1613 - kl_loss: 7.3612\n",
            "Epoch 271/300\n",
            "18/18 [==============================] - 1s 75ms/step - loss: 462.3487 - reconstruction_loss: 456.5929 - kl_loss: 7.4643\n",
            "Epoch 272/300\n",
            "18/18 [==============================] - 2s 94ms/step - loss: 466.2627 - reconstruction_loss: 456.5827 - kl_loss: 7.4412\n",
            "Epoch 273/300\n",
            "18/18 [==============================] - 2s 96ms/step - loss: 462.2574 - reconstruction_loss: 458.3575 - kl_loss: 7.5038\n",
            "Epoch 274/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 463.6440 - reconstruction_loss: 457.4812 - kl_loss: 7.4871\n",
            "Epoch 275/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 460.5946 - reconstruction_loss: 457.7365 - kl_loss: 7.4172\n",
            "Epoch 276/300\n",
            "18/18 [==============================] - 1s 73ms/step - loss: 463.0688 - reconstruction_loss: 458.9054 - kl_loss: 7.3964\n",
            "Epoch 277/300\n",
            "18/18 [==============================] - 1s 72ms/step - loss: 461.7537 - reconstruction_loss: 458.0130 - kl_loss: 7.4272\n",
            "Epoch 278/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 466.2733 - reconstruction_loss: 457.6906 - kl_loss: 7.3938\n",
            "Epoch 279/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 467.1808 - reconstruction_loss: 458.5589 - kl_loss: 7.4591\n",
            "Epoch 280/300\n",
            "18/18 [==============================] - 2s 93ms/step - loss: 464.7895 - reconstruction_loss: 458.1359 - kl_loss: 7.5307\n",
            "Epoch 281/300\n",
            "18/18 [==============================] - 2s 95ms/step - loss: 462.2208 - reconstruction_loss: 456.8301 - kl_loss: 7.5523\n",
            "Epoch 282/300\n",
            "18/18 [==============================] - 1s 76ms/step - loss: 463.9500 - reconstruction_loss: 457.7334 - kl_loss: 7.3352\n",
            "Epoch 283/300\n",
            "18/18 [==============================] - 1s 69ms/step - loss: 467.6299 - reconstruction_loss: 457.8705 - kl_loss: 7.3996\n",
            "Epoch 284/300\n",
            "18/18 [==============================] - 1s 76ms/step - loss: 466.0184 - reconstruction_loss: 458.1400 - kl_loss: 7.3698\n",
            "Epoch 285/300\n",
            "18/18 [==============================] - 1s 74ms/step - loss: 460.1463 - reconstruction_loss: 457.1052 - kl_loss: 7.3599\n",
            "Epoch 286/300\n",
            "18/18 [==============================] - 1s 75ms/step - loss: 459.0949 - reconstruction_loss: 456.8325 - kl_loss: 7.3293\n",
            "Epoch 287/300\n",
            "18/18 [==============================] - 2s 96ms/step - loss: 460.3877 - reconstruction_loss: 456.9047 - kl_loss: 7.4230\n",
            "Epoch 288/300\n",
            "18/18 [==============================] - 1s 73ms/step - loss: 464.2345 - reconstruction_loss: 457.3341 - kl_loss: 7.5589\n",
            "Epoch 289/300\n",
            "18/18 [==============================] - 1s 67ms/step - loss: 462.0653 - reconstruction_loss: 457.0845 - kl_loss: 7.3974\n",
            "Epoch 290/300\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 462.7120 - reconstruction_loss: 457.1273 - kl_loss: 7.2813\n",
            "Epoch 291/300\n",
            "18/18 [==============================] - 1s 71ms/step - loss: 462.3169 - reconstruction_loss: 456.5389 - kl_loss: 7.3873\n",
            "Epoch 292/300\n",
            "18/18 [==============================] - 1s 75ms/step - loss: 458.7361 - reconstruction_loss: 456.1873 - kl_loss: 7.4497\n",
            "Epoch 293/300\n",
            "18/18 [==============================] - 2s 84ms/step - loss: 463.4135 - reconstruction_loss: 457.3585 - kl_loss: 7.4373\n",
            "Epoch 294/300\n",
            "18/18 [==============================] - 2s 95ms/step - loss: 464.0895 - reconstruction_loss: 456.3283 - kl_loss: 7.6285\n",
            "Epoch 295/300\n",
            "18/18 [==============================] - 1s 76ms/step - loss: 463.6036 - reconstruction_loss: 456.8629 - kl_loss: 7.4102\n",
            "Epoch 296/300\n",
            "18/18 [==============================] - 1s 72ms/step - loss: 461.8194 - reconstruction_loss: 456.7970 - kl_loss: 7.4780\n",
            "Epoch 297/300\n",
            "18/18 [==============================] - 1s 74ms/step - loss: 461.1004 - reconstruction_loss: 457.3917 - kl_loss: 7.5204\n",
            "Epoch 298/300\n",
            "18/18 [==============================] - 1s 74ms/step - loss: 462.3834 - reconstruction_loss: 455.8558 - kl_loss: 7.4806\n",
            "Epoch 299/300\n",
            "18/18 [==============================] - 1s 71ms/step - loss: 464.2025 - reconstruction_loss: 458.9364 - kl_loss: 7.6120\n",
            "Epoch 300/300\n",
            "18/18 [==============================] - 2s 85ms/step - loss: 464.2420 - reconstruction_loss: 457.8438 - kl_loss: 7.4979\n",
            "Found 71 images belonging to 1 classes.\n",
            "16/16 [==============================] - 0s 8ms/step\n",
            "Training VAE for class: Train\n",
            "Found 120 images belonging to 1 classes.\n",
            "Epoch 1/300\n",
            "8/8 [==============================] - 4s 65ms/step - loss: 534.2472 - reconstruction_loss: 524.7760 - kl_loss: 7.1262\n",
            "Epoch 2/300\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 506.6302 - reconstruction_loss: 497.5784 - kl_loss: 6.5210\n",
            "Epoch 3/300\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 493.3534 - reconstruction_loss: 488.8350 - kl_loss: 6.1368\n",
            "Epoch 4/300\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 494.1383 - reconstruction_loss: 484.5806 - kl_loss: 5.9079\n",
            "Epoch 5/300\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 482.0759 - reconstruction_loss: 477.8006 - kl_loss: 5.9204\n",
            "Epoch 6/300\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 483.0396 - reconstruction_loss: 477.2863 - kl_loss: 5.9107\n",
            "Epoch 7/300\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 473.4370 - reconstruction_loss: 471.7460 - kl_loss: 6.1184\n",
            "Epoch 8/300\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 472.3238 - reconstruction_loss: 466.0275 - kl_loss: 6.2326\n",
            "Epoch 9/300\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 474.3623 - reconstruction_loss: 466.8378 - kl_loss: 6.2484\n",
            "Epoch 10/300\n",
            "8/8 [==============================] - 1s 74ms/step - loss: 476.4259 - reconstruction_loss: 465.4091 - kl_loss: 6.3232\n",
            "Epoch 11/300\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 471.7515 - reconstruction_loss: 462.6537 - kl_loss: 6.5111\n",
            "Epoch 12/300\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 465.9900 - reconstruction_loss: 459.7945 - kl_loss: 6.6678\n",
            "Epoch 13/300\n",
            "8/8 [==============================] - 1s 93ms/step - loss: 464.5463 - reconstruction_loss: 461.5612 - kl_loss: 6.7017\n",
            "Epoch 14/300\n",
            "8/8 [==============================] - 1s 96ms/step - loss: 468.3168 - reconstruction_loss: 457.6300 - kl_loss: 6.8249\n",
            "Epoch 15/300\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 461.8455 - reconstruction_loss: 455.1733 - kl_loss: 6.7651\n",
            "Epoch 16/300\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 461.7066 - reconstruction_loss: 456.5449 - kl_loss: 6.7086\n",
            "Epoch 17/300\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 461.3690 - reconstruction_loss: 455.5611 - kl_loss: 6.7648\n",
            "Epoch 18/300\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 468.7715 - reconstruction_loss: 457.1192 - kl_loss: 6.8316\n",
            "Epoch 19/300\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 462.8080 - reconstruction_loss: 454.8233 - kl_loss: 6.9220\n",
            "Epoch 20/300\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 451.1616 - reconstruction_loss: 453.7934 - kl_loss: 6.9586\n",
            "Epoch 21/300\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 457.2746 - reconstruction_loss: 452.9766 - kl_loss: 6.9928\n",
            "Epoch 22/300\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 461.5703 - reconstruction_loss: 452.8262 - kl_loss: 6.9906\n",
            "Epoch 23/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 459.8148 - reconstruction_loss: 452.6682 - kl_loss: 6.9698\n",
            "Epoch 24/300\n",
            "8/8 [==============================] - 1s 73ms/step - loss: 452.8672 - reconstruction_loss: 451.3199 - kl_loss: 6.9437\n",
            "Epoch 25/300\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 455.8838 - reconstruction_loss: 447.2093 - kl_loss: 6.9597\n",
            "Epoch 26/300\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 461.3450 - reconstruction_loss: 449.8275 - kl_loss: 6.8997\n",
            "Epoch 27/300\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 456.4842 - reconstruction_loss: 448.7249 - kl_loss: 6.9219\n",
            "Epoch 28/300\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 461.6480 - reconstruction_loss: 451.5941 - kl_loss: 7.0122\n",
            "Epoch 29/300\n",
            "8/8 [==============================] - 1s 101ms/step - loss: 441.2906 - reconstruction_loss: 445.4607 - kl_loss: 7.1221\n",
            "Epoch 30/300\n",
            "8/8 [==============================] - 1s 105ms/step - loss: 457.3828 - reconstruction_loss: 450.0422 - kl_loss: 7.0586\n",
            "Epoch 31/300\n",
            "8/8 [==============================] - 1s 94ms/step - loss: 455.0313 - reconstruction_loss: 448.3239 - kl_loss: 7.1223\n",
            "Epoch 32/300\n",
            "8/8 [==============================] - 1s 101ms/step - loss: 456.8743 - reconstruction_loss: 447.8247 - kl_loss: 6.9856\n",
            "Epoch 33/300\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 448.8694 - reconstruction_loss: 446.6364 - kl_loss: 7.0138\n",
            "Epoch 34/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 452.2189 - reconstruction_loss: 445.0191 - kl_loss: 7.1189\n",
            "Epoch 35/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 449.7970 - reconstruction_loss: 444.8059 - kl_loss: 7.1018\n",
            "Epoch 36/300\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 451.5441 - reconstruction_loss: 448.0932 - kl_loss: 7.1043\n",
            "Epoch 37/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 449.1127 - reconstruction_loss: 441.7657 - kl_loss: 7.1616\n",
            "Epoch 38/300\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 449.5561 - reconstruction_loss: 444.1894 - kl_loss: 7.1153\n",
            "Epoch 39/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 451.3506 - reconstruction_loss: 443.9851 - kl_loss: 7.1565\n",
            "Epoch 40/300\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 448.3732 - reconstruction_loss: 444.5991 - kl_loss: 7.1668\n",
            "Epoch 41/300\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 446.3148 - reconstruction_loss: 444.4093 - kl_loss: 7.1333\n",
            "Epoch 42/300\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 448.9665 - reconstruction_loss: 444.4409 - kl_loss: 7.1916\n",
            "Epoch 43/300\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 448.1438 - reconstruction_loss: 442.4553 - kl_loss: 7.1737\n",
            "Epoch 44/300\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 448.8880 - reconstruction_loss: 442.6716 - kl_loss: 7.1260\n",
            "Epoch 45/300\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 450.8298 - reconstruction_loss: 442.1122 - kl_loss: 7.1937\n",
            "Epoch 46/300\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 451.6899 - reconstruction_loss: 442.6995 - kl_loss: 7.2362\n",
            "Epoch 47/300\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 440.4233 - reconstruction_loss: 443.5208 - kl_loss: 7.2033\n",
            "Epoch 48/300\n",
            "8/8 [==============================] - 1s 94ms/step - loss: 444.9523 - reconstruction_loss: 438.6202 - kl_loss: 7.2682\n",
            "Epoch 49/300\n",
            "8/8 [==============================] - 1s 112ms/step - loss: 454.0925 - reconstruction_loss: 441.7905 - kl_loss: 7.1975\n",
            "Epoch 50/300\n",
            "8/8 [==============================] - 1s 101ms/step - loss: 452.9444 - reconstruction_loss: 438.7765 - kl_loss: 7.2998\n",
            "Epoch 51/300\n",
            "8/8 [==============================] - 1s 73ms/step - loss: 452.7171 - reconstruction_loss: 438.4832 - kl_loss: 7.2910\n",
            "Epoch 52/300\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 447.4143 - reconstruction_loss: 438.6603 - kl_loss: 7.2161\n",
            "Epoch 53/300\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 436.2280 - reconstruction_loss: 437.7070 - kl_loss: 7.2144\n",
            "Epoch 54/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 447.8045 - reconstruction_loss: 438.2599 - kl_loss: 7.2024\n",
            "Epoch 55/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 454.1164 - reconstruction_loss: 440.5931 - kl_loss: 7.2744\n",
            "Epoch 56/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 440.9933 - reconstruction_loss: 438.7315 - kl_loss: 7.3561\n",
            "Epoch 57/300\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 449.7189 - reconstruction_loss: 439.2259 - kl_loss: 7.2874\n",
            "Epoch 58/300\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 446.7839 - reconstruction_loss: 438.7710 - kl_loss: 7.3380\n",
            "Epoch 59/300\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 447.4303 - reconstruction_loss: 438.6345 - kl_loss: 7.3632\n",
            "Epoch 60/300\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 442.7279 - reconstruction_loss: 437.9998 - kl_loss: 7.3933\n",
            "Epoch 61/300\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 454.0979 - reconstruction_loss: 439.7220 - kl_loss: 7.4426\n",
            "Epoch 62/300\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 439.6094 - reconstruction_loss: 437.1935 - kl_loss: 7.5274\n",
            "Epoch 63/300\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 444.1489 - reconstruction_loss: 438.5191 - kl_loss: 7.4858\n",
            "Epoch 64/300\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 440.2185 - reconstruction_loss: 437.0455 - kl_loss: 7.4524\n",
            "Epoch 65/300\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 439.8694 - reconstruction_loss: 438.9247 - kl_loss: 7.4205\n",
            "Epoch 66/300\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 438.3982 - reconstruction_loss: 435.9226 - kl_loss: 7.4074\n",
            "Epoch 67/300\n",
            "8/8 [==============================] - 1s 94ms/step - loss: 440.9132 - reconstruction_loss: 435.8295 - kl_loss: 7.3577\n",
            "Epoch 68/300\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 446.5840 - reconstruction_loss: 437.2799 - kl_loss: 7.4277\n",
            "Epoch 69/300\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 446.5649 - reconstruction_loss: 437.8414 - kl_loss: 7.4212\n",
            "Epoch 70/300\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 443.7869 - reconstruction_loss: 437.6647 - kl_loss: 7.5339\n",
            "Epoch 71/300\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 439.1759 - reconstruction_loss: 438.4475 - kl_loss: 7.5168\n",
            "Epoch 72/300\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 440.0013 - reconstruction_loss: 436.4590 - kl_loss: 7.5599\n",
            "Epoch 73/300\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 451.5117 - reconstruction_loss: 436.7715 - kl_loss: 7.4939\n",
            "Epoch 74/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 442.4100 - reconstruction_loss: 433.1239 - kl_loss: 7.5503\n",
            "Epoch 75/300\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 443.9821 - reconstruction_loss: 437.4070 - kl_loss: 7.4623\n",
            "Epoch 76/300\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 449.1959 - reconstruction_loss: 435.4695 - kl_loss: 7.5141\n",
            "Epoch 77/300\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 443.4307 - reconstruction_loss: 436.2585 - kl_loss: 7.5171\n",
            "Epoch 78/300\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 438.3765 - reconstruction_loss: 432.9893 - kl_loss: 7.5613\n",
            "Epoch 79/300\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 440.4947 - reconstruction_loss: 435.6102 - kl_loss: 7.5739\n",
            "Epoch 80/300\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 441.0086 - reconstruction_loss: 439.0645 - kl_loss: 7.4674\n",
            "Epoch 81/300\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 438.0442 - reconstruction_loss: 433.2917 - kl_loss: 7.5413\n",
            "Epoch 82/300\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 434.0590 - reconstruction_loss: 435.0251 - kl_loss: 7.5455\n",
            "Epoch 83/300\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 440.9552 - reconstruction_loss: 433.6620 - kl_loss: 7.5507\n",
            "Epoch 84/300\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 445.3527 - reconstruction_loss: 433.5463 - kl_loss: 7.5182\n",
            "Epoch 85/300\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 442.6950 - reconstruction_loss: 433.4730 - kl_loss: 7.4079\n",
            "Epoch 86/300\n",
            "8/8 [==============================] - 1s 101ms/step - loss: 440.7398 - reconstruction_loss: 432.0472 - kl_loss: 7.4581\n",
            "Epoch 87/300\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 443.2496 - reconstruction_loss: 434.8667 - kl_loss: 7.3548\n",
            "Epoch 88/300\n",
            "8/8 [==============================] - 1s 91ms/step - loss: 439.1009 - reconstruction_loss: 432.1382 - kl_loss: 7.4614\n",
            "Epoch 89/300\n",
            "8/8 [==============================] - 1s 108ms/step - loss: 440.9877 - reconstruction_loss: 433.1842 - kl_loss: 7.5158\n",
            "Epoch 90/300\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 435.3473 - reconstruction_loss: 431.9276 - kl_loss: 7.4616\n",
            "Epoch 91/300\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 449.0719 - reconstruction_loss: 435.7459 - kl_loss: 7.4313\n",
            "Epoch 92/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 435.6115 - reconstruction_loss: 433.7284 - kl_loss: 7.4672\n",
            "Epoch 93/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 434.6180 - reconstruction_loss: 430.5283 - kl_loss: 7.4705\n",
            "Epoch 94/300\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 442.8345 - reconstruction_loss: 431.0461 - kl_loss: 7.4889\n",
            "Epoch 95/300\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 440.9987 - reconstruction_loss: 430.7990 - kl_loss: 7.4220\n",
            "Epoch 96/300\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 434.6150 - reconstruction_loss: 430.8006 - kl_loss: 7.3794\n",
            "Epoch 97/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 440.2206 - reconstruction_loss: 432.6743 - kl_loss: 7.3608\n",
            "Epoch 98/300\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 434.2824 - reconstruction_loss: 432.1348 - kl_loss: 7.3907\n",
            "Epoch 99/300\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 443.5711 - reconstruction_loss: 434.2520 - kl_loss: 7.4691\n",
            "Epoch 100/300\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 440.2237 - reconstruction_loss: 435.7061 - kl_loss: 7.5020\n",
            "Epoch 101/300\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 445.1117 - reconstruction_loss: 435.7822 - kl_loss: 7.5637\n",
            "Epoch 102/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 431.7016 - reconstruction_loss: 432.1240 - kl_loss: 7.5375\n",
            "Epoch 103/300\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 442.6246 - reconstruction_loss: 432.6974 - kl_loss: 7.5227\n",
            "Epoch 104/300\n",
            "8/8 [==============================] - 1s 93ms/step - loss: 446.6137 - reconstruction_loss: 431.7540 - kl_loss: 7.5246\n",
            "Epoch 105/300\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 437.7799 - reconstruction_loss: 430.8206 - kl_loss: 7.4295\n",
            "Epoch 106/300\n",
            "8/8 [==============================] - 1s 95ms/step - loss: 430.1808 - reconstruction_loss: 427.1689 - kl_loss: 7.5247\n",
            "Epoch 107/300\n",
            "8/8 [==============================] - 1s 92ms/step - loss: 437.5816 - reconstruction_loss: 430.2289 - kl_loss: 7.4745\n",
            "Epoch 108/300\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 439.8498 - reconstruction_loss: 428.9438 - kl_loss: 7.4584\n",
            "Epoch 109/300\n",
            "8/8 [==============================] - 1s 74ms/step - loss: 439.9777 - reconstruction_loss: 429.0393 - kl_loss: 7.4275\n",
            "Epoch 110/300\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 429.3454 - reconstruction_loss: 427.8018 - kl_loss: 7.4225\n",
            "Epoch 111/300\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 430.3834 - reconstruction_loss: 428.4344 - kl_loss: 7.4444\n",
            "Epoch 112/300\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 437.0033 - reconstruction_loss: 432.3543 - kl_loss: 7.4519\n",
            "Epoch 113/300\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 443.6089 - reconstruction_loss: 428.4780 - kl_loss: 7.4805\n",
            "Epoch 114/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 442.5940 - reconstruction_loss: 431.4193 - kl_loss: 7.4245\n",
            "Epoch 115/300\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 436.0714 - reconstruction_loss: 432.4656 - kl_loss: 7.5250\n",
            "Epoch 116/300\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 438.3134 - reconstruction_loss: 430.3366 - kl_loss: 7.4915\n",
            "Epoch 117/300\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 437.6984 - reconstruction_loss: 430.7173 - kl_loss: 7.4350\n",
            "Epoch 118/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 439.8684 - reconstruction_loss: 429.9411 - kl_loss: 7.4626\n",
            "Epoch 119/300\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 438.4173 - reconstruction_loss: 430.1114 - kl_loss: 7.4832\n",
            "Epoch 120/300\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 433.5120 - reconstruction_loss: 429.4556 - kl_loss: 7.5436\n",
            "Epoch 121/300\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 442.1302 - reconstruction_loss: 429.6600 - kl_loss: 7.4438\n",
            "Epoch 122/300\n",
            "8/8 [==============================] - 1s 73ms/step - loss: 433.2705 - reconstruction_loss: 429.2912 - kl_loss: 7.4838\n",
            "Epoch 123/300\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 435.9243 - reconstruction_loss: 426.6379 - kl_loss: 7.4918\n",
            "Epoch 124/300\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 435.4303 - reconstruction_loss: 427.5066 - kl_loss: 7.4773\n",
            "Epoch 125/300\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 437.8790 - reconstruction_loss: 426.6680 - kl_loss: 7.5336\n",
            "Epoch 126/300\n",
            "8/8 [==============================] - 1s 100ms/step - loss: 437.9725 - reconstruction_loss: 430.6385 - kl_loss: 7.4429\n",
            "Epoch 127/300\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 442.8184 - reconstruction_loss: 426.4374 - kl_loss: 7.5321\n",
            "Epoch 128/300\n",
            "8/8 [==============================] - 1s 73ms/step - loss: 434.0092 - reconstruction_loss: 427.2837 - kl_loss: 7.5072\n",
            "Epoch 129/300\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 437.9683 - reconstruction_loss: 429.2590 - kl_loss: 7.5427\n",
            "Epoch 130/300\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 426.1207 - reconstruction_loss: 425.1407 - kl_loss: 7.6293\n",
            "Epoch 131/300\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 433.8770 - reconstruction_loss: 426.1037 - kl_loss: 7.5923\n",
            "Epoch 132/300\n",
            "8/8 [==============================] - 1s 73ms/step - loss: 432.7018 - reconstruction_loss: 429.4258 - kl_loss: 7.5539\n",
            "Epoch 133/300\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 440.4078 - reconstruction_loss: 428.6823 - kl_loss: 7.6996\n",
            "Epoch 134/300\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 441.7838 - reconstruction_loss: 427.1454 - kl_loss: 7.6130\n",
            "Epoch 135/300\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 435.0312 - reconstruction_loss: 428.5584 - kl_loss: 7.4628\n",
            "Epoch 136/300\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 431.5172 - reconstruction_loss: 427.2361 - kl_loss: 7.4604\n",
            "Epoch 137/300\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 440.7627 - reconstruction_loss: 424.3320 - kl_loss: 7.5886\n",
            "Epoch 138/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 429.3177 - reconstruction_loss: 429.2974 - kl_loss: 7.5939\n",
            "Epoch 139/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 435.9560 - reconstruction_loss: 425.0787 - kl_loss: 7.6552\n",
            "Epoch 140/300\n",
            "8/8 [==============================] - 1s 74ms/step - loss: 431.7746 - reconstruction_loss: 428.2335 - kl_loss: 7.5532\n",
            "Epoch 141/300\n",
            "8/8 [==============================] - 1s 92ms/step - loss: 443.7920 - reconstruction_loss: 430.0159 - kl_loss: 7.6098\n",
            "Epoch 142/300\n",
            "8/8 [==============================] - 1s 91ms/step - loss: 432.2845 - reconstruction_loss: 425.5901 - kl_loss: 7.5846\n",
            "Epoch 143/300\n",
            "8/8 [==============================] - 1s 93ms/step - loss: 431.3863 - reconstruction_loss: 425.9834 - kl_loss: 7.6045\n",
            "Epoch 144/300\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 436.9498 - reconstruction_loss: 427.2898 - kl_loss: 7.5749\n",
            "Epoch 145/300\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 435.7400 - reconstruction_loss: 426.8215 - kl_loss: 7.5890\n",
            "Epoch 146/300\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 430.8559 - reconstruction_loss: 423.9344 - kl_loss: 7.5949\n",
            "Epoch 147/300\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 431.9407 - reconstruction_loss: 425.3109 - kl_loss: 7.5796\n",
            "Epoch 148/300\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 436.9470 - reconstruction_loss: 427.5997 - kl_loss: 7.6514\n",
            "Epoch 149/300\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 432.0377 - reconstruction_loss: 424.8109 - kl_loss: 7.7255\n",
            "Epoch 150/300\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 433.7524 - reconstruction_loss: 423.6977 - kl_loss: 7.7018\n",
            "Epoch 151/300\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 432.2666 - reconstruction_loss: 425.7598 - kl_loss: 7.5893\n",
            "Epoch 152/300\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 436.1654 - reconstruction_loss: 427.8427 - kl_loss: 7.4834\n",
            "Epoch 153/300\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 426.2242 - reconstruction_loss: 425.8241 - kl_loss: 7.5145\n",
            "Epoch 154/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 438.5538 - reconstruction_loss: 427.6840 - kl_loss: 7.5061\n",
            "Epoch 155/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 439.6852 - reconstruction_loss: 427.9200 - kl_loss: 7.4638\n",
            "Epoch 156/300\n",
            "8/8 [==============================] - 1s 74ms/step - loss: 444.7483 - reconstruction_loss: 427.3524 - kl_loss: 7.5367\n",
            "Epoch 157/300\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 429.2445 - reconstruction_loss: 422.2513 - kl_loss: 7.5772\n",
            "Epoch 158/300\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 439.2749 - reconstruction_loss: 425.0229 - kl_loss: 7.5171\n",
            "Epoch 159/300\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 429.2298 - reconstruction_loss: 426.1678 - kl_loss: 7.4001\n",
            "Epoch 160/300\n",
            "8/8 [==============================] - 1s 103ms/step - loss: 434.4247 - reconstruction_loss: 424.4862 - kl_loss: 7.4718\n",
            "Epoch 161/300\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 431.3089 - reconstruction_loss: 422.6418 - kl_loss: 7.5637\n",
            "Epoch 162/300\n",
            "8/8 [==============================] - 1s 104ms/step - loss: 436.5004 - reconstruction_loss: 424.7643 - kl_loss: 7.6023\n",
            "Epoch 163/300\n",
            "8/8 [==============================] - 1s 92ms/step - loss: 427.1698 - reconstruction_loss: 424.8596 - kl_loss: 7.5759\n",
            "Epoch 164/300\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 428.6976 - reconstruction_loss: 424.2363 - kl_loss: 7.6367\n",
            "Epoch 165/300\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 433.3865 - reconstruction_loss: 422.5097 - kl_loss: 7.6474\n",
            "Epoch 166/300\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 436.0932 - reconstruction_loss: 421.2779 - kl_loss: 7.6565\n",
            "Epoch 167/300\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 431.0736 - reconstruction_loss: 425.6409 - kl_loss: 7.5788\n",
            "Epoch 168/300\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 433.6489 - reconstruction_loss: 422.4145 - kl_loss: 7.6187\n",
            "Epoch 169/300\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 434.1642 - reconstruction_loss: 424.1524 - kl_loss: 7.6006\n",
            "Epoch 170/300\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 424.6229 - reconstruction_loss: 422.1790 - kl_loss: 7.6683\n",
            "Epoch 171/300\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 427.9145 - reconstruction_loss: 425.1796 - kl_loss: 7.6361\n",
            "Epoch 172/300\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 437.0179 - reconstruction_loss: 426.6499 - kl_loss: 7.6069\n",
            "Epoch 173/300\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 428.0565 - reconstruction_loss: 425.2678 - kl_loss: 7.5555\n",
            "Epoch 174/300\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 431.7934 - reconstruction_loss: 425.6097 - kl_loss: 7.4724\n",
            "Epoch 175/300\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 420.7049 - reconstruction_loss: 422.0664 - kl_loss: 7.5241\n",
            "Epoch 176/300\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 430.5264 - reconstruction_loss: 424.2582 - kl_loss: 7.5605\n",
            "Epoch 177/300\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 436.8125 - reconstruction_loss: 421.4187 - kl_loss: 7.6387\n",
            "Epoch 178/300\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 433.3208 - reconstruction_loss: 422.9482 - kl_loss: 7.5318\n",
            "Epoch 179/300\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 427.9704 - reconstruction_loss: 422.7067 - kl_loss: 7.5201\n",
            "Epoch 180/300\n",
            "8/8 [==============================] - 1s 107ms/step - loss: 422.8716 - reconstruction_loss: 423.6920 - kl_loss: 7.4794\n",
            "Epoch 181/300\n",
            "8/8 [==============================] - 1s 88ms/step - loss: 436.0312 - reconstruction_loss: 424.4072 - kl_loss: 7.5034\n",
            "Epoch 182/300\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 423.8568 - reconstruction_loss: 422.8658 - kl_loss: 7.6405\n",
            "Epoch 183/300\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 435.7983 - reconstruction_loss: 421.9637 - kl_loss: 7.6941\n",
            "Epoch 184/300\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 429.9213 - reconstruction_loss: 423.3184 - kl_loss: 7.7126\n",
            "Epoch 185/300\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 433.6081 - reconstruction_loss: 423.0203 - kl_loss: 7.6698\n",
            "Epoch 186/300\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 430.1148 - reconstruction_loss: 423.8476 - kl_loss: 7.5870\n",
            "Epoch 187/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 427.7396 - reconstruction_loss: 420.5795 - kl_loss: 7.6346\n",
            "Epoch 188/300\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 431.4818 - reconstruction_loss: 423.5906 - kl_loss: 7.6043\n",
            "Epoch 189/300\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 431.7905 - reconstruction_loss: 424.4158 - kl_loss: 7.6214\n",
            "Epoch 190/300\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 438.5275 - reconstruction_loss: 424.5002 - kl_loss: 7.5733\n",
            "Epoch 191/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 431.0610 - reconstruction_loss: 422.7865 - kl_loss: 7.5604\n",
            "Epoch 192/300\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 433.3085 - reconstruction_loss: 423.7534 - kl_loss: 7.5730\n",
            "Epoch 193/300\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 431.2732 - reconstruction_loss: 423.5459 - kl_loss: 7.5333\n",
            "Epoch 194/300\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 433.3964 - reconstruction_loss: 421.9684 - kl_loss: 7.5864\n",
            "Epoch 195/300\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 438.1518 - reconstruction_loss: 422.5517 - kl_loss: 7.5916\n",
            "Epoch 196/300\n",
            "8/8 [==============================] - 1s 81ms/step - loss: 422.1902 - reconstruction_loss: 420.0114 - kl_loss: 7.6255\n",
            "Epoch 197/300\n",
            "8/8 [==============================] - 1s 94ms/step - loss: 422.0007 - reconstruction_loss: 420.9720 - kl_loss: 7.7081\n",
            "Epoch 198/300\n",
            "8/8 [==============================] - 1s 95ms/step - loss: 425.2056 - reconstruction_loss: 421.4130 - kl_loss: 7.6360\n",
            "Epoch 199/300\n",
            "8/8 [==============================] - 1s 95ms/step - loss: 434.1205 - reconstruction_loss: 421.7307 - kl_loss: 7.6518\n",
            "Epoch 200/300\n",
            "8/8 [==============================] - 1s 91ms/step - loss: 421.9422 - reconstruction_loss: 422.1233 - kl_loss: 7.6501\n",
            "Epoch 201/300\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 424.9201 - reconstruction_loss: 420.3149 - kl_loss: 7.6642\n",
            "Epoch 202/300\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 432.5679 - reconstruction_loss: 421.6833 - kl_loss: 7.6198\n",
            "Epoch 203/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 433.4610 - reconstruction_loss: 421.2960 - kl_loss: 7.5876\n",
            "Epoch 204/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 436.9081 - reconstruction_loss: 424.6614 - kl_loss: 7.5991\n",
            "Epoch 205/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 430.2653 - reconstruction_loss: 419.7122 - kl_loss: 7.6485\n",
            "Epoch 206/300\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 426.7297 - reconstruction_loss: 422.4446 - kl_loss: 7.6429\n",
            "Epoch 207/300\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 421.6811 - reconstruction_loss: 419.1570 - kl_loss: 7.6924\n",
            "Epoch 208/300\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 426.7711 - reconstruction_loss: 423.8554 - kl_loss: 7.6990\n",
            "Epoch 209/300\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 429.1225 - reconstruction_loss: 422.8050 - kl_loss: 7.7310\n",
            "Epoch 210/300\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 426.9366 - reconstruction_loss: 420.6850 - kl_loss: 7.7704\n",
            "Epoch 211/300\n",
            "8/8 [==============================] - 1s 74ms/step - loss: 427.6484 - reconstruction_loss: 422.6961 - kl_loss: 7.7981\n",
            "Epoch 212/300\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 426.7298 - reconstruction_loss: 420.9917 - kl_loss: 7.7971\n",
            "Epoch 213/300\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 425.1985 - reconstruction_loss: 422.7046 - kl_loss: 7.8153\n",
            "Epoch 214/300\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 426.2902 - reconstruction_loss: 424.0782 - kl_loss: 7.8021\n",
            "Epoch 215/300\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 435.8155 - reconstruction_loss: 428.0663 - kl_loss: 7.8571\n",
            "Epoch 216/300\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 437.7825 - reconstruction_loss: 429.2519 - kl_loss: 7.9152\n",
            "Epoch 217/300\n",
            "8/8 [==============================] - 1s 99ms/step - loss: 429.9280 - reconstruction_loss: 427.9316 - kl_loss: 7.8620\n",
            "Epoch 218/300\n",
            "8/8 [==============================] - 1s 103ms/step - loss: 435.6785 - reconstruction_loss: 424.1109 - kl_loss: 7.8443\n",
            "Epoch 219/300\n",
            "8/8 [==============================] - 1s 93ms/step - loss: 435.3928 - reconstruction_loss: 424.4530 - kl_loss: 7.7186\n",
            "Epoch 220/300\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 429.6623 - reconstruction_loss: 422.8138 - kl_loss: 7.6733\n",
            "Epoch 221/300\n",
            "8/8 [==============================] - 1s 94ms/step - loss: 433.1108 - reconstruction_loss: 422.0799 - kl_loss: 7.6319\n",
            "Epoch 222/300\n",
            "8/8 [==============================] - 1s 73ms/step - loss: 430.2641 - reconstruction_loss: 421.9327 - kl_loss: 7.6328\n",
            "Epoch 223/300\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 424.1763 - reconstruction_loss: 424.3101 - kl_loss: 7.5858\n",
            "Epoch 224/300\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 433.1214 - reconstruction_loss: 422.5868 - kl_loss: 7.6166\n",
            "Epoch 225/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 433.5344 - reconstruction_loss: 421.3377 - kl_loss: 7.7163\n",
            "Epoch 226/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 434.1233 - reconstruction_loss: 419.4561 - kl_loss: 7.8124\n",
            "Epoch 227/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 423.5053 - reconstruction_loss: 420.8155 - kl_loss: 7.7660\n",
            "Epoch 228/300\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 431.8089 - reconstruction_loss: 420.6911 - kl_loss: 7.7016\n",
            "Epoch 229/300\n",
            "8/8 [==============================] - 1s 73ms/step - loss: 434.0184 - reconstruction_loss: 419.8072 - kl_loss: 7.7639\n",
            "Epoch 230/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 425.6422 - reconstruction_loss: 421.2901 - kl_loss: 7.6722\n",
            "Epoch 231/300\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 421.2599 - reconstruction_loss: 418.9185 - kl_loss: 7.6556\n",
            "Epoch 232/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 431.3178 - reconstruction_loss: 420.7976 - kl_loss: 7.5598\n",
            "Epoch 233/300\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 420.9669 - reconstruction_loss: 421.8142 - kl_loss: 7.5445\n",
            "Epoch 234/300\n",
            "8/8 [==============================] - 1s 74ms/step - loss: 429.7045 - reconstruction_loss: 419.8485 - kl_loss: 7.7232\n",
            "Epoch 235/300\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 424.3838 - reconstruction_loss: 420.8686 - kl_loss: 7.7334\n",
            "Epoch 236/300\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 428.9547 - reconstruction_loss: 421.2466 - kl_loss: 7.7407\n",
            "Epoch 237/300\n",
            "8/8 [==============================] - 1s 94ms/step - loss: 427.1219 - reconstruction_loss: 419.5477 - kl_loss: 7.6866\n",
            "Epoch 238/300\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 422.0494 - reconstruction_loss: 421.2769 - kl_loss: 7.6447\n",
            "Epoch 239/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 431.7358 - reconstruction_loss: 420.0992 - kl_loss: 7.6443\n",
            "Epoch 240/300\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 430.8638 - reconstruction_loss: 419.4996 - kl_loss: 7.7051\n",
            "Epoch 241/300\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 426.1792 - reconstruction_loss: 419.8429 - kl_loss: 7.7121\n",
            "Epoch 242/300\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 425.7745 - reconstruction_loss: 421.4124 - kl_loss: 7.6925\n",
            "Epoch 243/300\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 430.0601 - reconstruction_loss: 420.4488 - kl_loss: 7.7941\n",
            "Epoch 244/300\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 425.0492 - reconstruction_loss: 417.5826 - kl_loss: 7.9385\n",
            "Epoch 245/300\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 435.6968 - reconstruction_loss: 421.5397 - kl_loss: 7.8023\n",
            "Epoch 246/300\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 425.9344 - reconstruction_loss: 420.5618 - kl_loss: 7.6974\n",
            "Epoch 247/300\n",
            "8/8 [==============================] - 1s 64ms/step - loss: 428.9792 - reconstruction_loss: 421.0340 - kl_loss: 7.7352\n",
            "Epoch 248/300\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 423.7729 - reconstruction_loss: 418.0913 - kl_loss: 7.7363\n",
            "Epoch 249/300\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 424.7612 - reconstruction_loss: 419.1699 - kl_loss: 7.6959\n",
            "Epoch 250/300\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 419.8246 - reconstruction_loss: 420.1860 - kl_loss: 7.6559\n",
            "Epoch 251/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 436.2308 - reconstruction_loss: 417.9261 - kl_loss: 7.6880\n",
            "Epoch 252/300\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 424.7999 - reconstruction_loss: 414.0876 - kl_loss: 7.7178\n",
            "Epoch 253/300\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 415.3805 - reconstruction_loss: 417.3922 - kl_loss: 7.6312\n",
            "Epoch 254/300\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 430.3363 - reconstruction_loss: 419.2919 - kl_loss: 7.5543\n",
            "Epoch 255/300\n",
            "8/8 [==============================] - 1s 95ms/step - loss: 426.8048 - reconstruction_loss: 420.9974 - kl_loss: 7.5031\n",
            "Epoch 256/300\n",
            "8/8 [==============================] - 1s 92ms/step - loss: 423.6137 - reconstruction_loss: 419.0228 - kl_loss: 7.5661\n",
            "Epoch 257/300\n",
            "8/8 [==============================] - 1s 99ms/step - loss: 430.5886 - reconstruction_loss: 419.6132 - kl_loss: 7.5912\n",
            "Epoch 258/300\n",
            "8/8 [==============================] - 1s 110ms/step - loss: 429.0642 - reconstruction_loss: 420.2465 - kl_loss: 7.5365\n",
            "Epoch 259/300\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 422.8095 - reconstruction_loss: 421.0839 - kl_loss: 7.6406\n",
            "Epoch 260/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 427.6776 - reconstruction_loss: 418.4230 - kl_loss: 7.6831\n",
            "Epoch 261/300\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 424.0796 - reconstruction_loss: 419.5389 - kl_loss: 7.6427\n",
            "Epoch 262/300\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 422.4648 - reconstruction_loss: 418.7902 - kl_loss: 7.7049\n",
            "Epoch 263/300\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 423.7791 - reconstruction_loss: 421.6205 - kl_loss: 7.6976\n",
            "Epoch 264/300\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 431.0957 - reconstruction_loss: 417.3412 - kl_loss: 7.7275\n",
            "Epoch 265/300\n",
            "8/8 [==============================] - 1s 74ms/step - loss: 416.6891 - reconstruction_loss: 417.0780 - kl_loss: 7.6791\n",
            "Epoch 266/300\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 427.8506 - reconstruction_loss: 418.1057 - kl_loss: 7.5584\n",
            "Epoch 267/300\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 426.9180 - reconstruction_loss: 417.9591 - kl_loss: 7.4614\n",
            "Epoch 268/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 428.9874 - reconstruction_loss: 421.5789 - kl_loss: 7.4607\n",
            "Epoch 269/300\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 424.4055 - reconstruction_loss: 421.1020 - kl_loss: 7.6389\n",
            "Epoch 270/300\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 424.8442 - reconstruction_loss: 418.2592 - kl_loss: 7.7998\n",
            "Epoch 271/300\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 426.0589 - reconstruction_loss: 419.4030 - kl_loss: 7.8108\n",
            "Epoch 272/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 423.8824 - reconstruction_loss: 417.7061 - kl_loss: 7.7635\n",
            "Epoch 273/300\n",
            "8/8 [==============================] - 1s 73ms/step - loss: 428.2481 - reconstruction_loss: 419.7628 - kl_loss: 7.7184\n",
            "Epoch 274/300\n",
            "8/8 [==============================] - 1s 71ms/step - loss: 421.8470 - reconstruction_loss: 418.5810 - kl_loss: 7.7432\n",
            "Epoch 275/300\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 422.9240 - reconstruction_loss: 418.8535 - kl_loss: 7.6993\n",
            "Epoch 276/300\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 433.5260 - reconstruction_loss: 419.2761 - kl_loss: 7.6708\n",
            "Epoch 277/300\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 426.9349 - reconstruction_loss: 419.0860 - kl_loss: 7.6700\n",
            "Epoch 278/300\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 420.4592 - reconstruction_loss: 416.5672 - kl_loss: 7.6591\n",
            "Epoch 279/300\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 422.6266 - reconstruction_loss: 417.2404 - kl_loss: 7.6783\n",
            "Epoch 280/300\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 433.2213 - reconstruction_loss: 420.5450 - kl_loss: 7.6342\n",
            "Epoch 281/300\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 427.6390 - reconstruction_loss: 418.3831 - kl_loss: 7.6048\n",
            "Epoch 282/300\n",
            "8/8 [==============================] - 1s 69ms/step - loss: 420.9593 - reconstruction_loss: 416.7670 - kl_loss: 7.6145\n",
            "Epoch 283/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 431.9716 - reconstruction_loss: 417.1449 - kl_loss: 7.6200\n",
            "Epoch 284/300\n",
            "8/8 [==============================] - 1s 78ms/step - loss: 425.9004 - reconstruction_loss: 417.7240 - kl_loss: 7.5921\n",
            "Epoch 285/300\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 424.2860 - reconstruction_loss: 417.7408 - kl_loss: 7.7131\n",
            "Epoch 286/300\n",
            "8/8 [==============================] - 1s 73ms/step - loss: 424.9025 - reconstruction_loss: 416.8587 - kl_loss: 7.7902\n",
            "Epoch 287/300\n",
            "8/8 [==============================] - 1s 74ms/step - loss: 426.8585 - reconstruction_loss: 417.9577 - kl_loss: 7.6677\n",
            "Epoch 288/300\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 427.3492 - reconstruction_loss: 417.9023 - kl_loss: 7.6466\n",
            "Epoch 289/300\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 426.4706 - reconstruction_loss: 417.7291 - kl_loss: 7.6927\n",
            "Epoch 290/300\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 423.7520 - reconstruction_loss: 418.0710 - kl_loss: 7.7701\n",
            "Epoch 291/300\n",
            "8/8 [==============================] - 1s 68ms/step - loss: 429.6608 - reconstruction_loss: 417.3113 - kl_loss: 7.8887\n",
            "Epoch 292/300\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 424.9874 - reconstruction_loss: 419.7124 - kl_loss: 7.8401\n",
            "Epoch 293/300\n",
            "8/8 [==============================] - 1s 95ms/step - loss: 420.3263 - reconstruction_loss: 418.6586 - kl_loss: 7.9186\n",
            "Epoch 294/300\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 421.8285 - reconstruction_loss: 419.8789 - kl_loss: 7.8147\n",
            "Epoch 295/300\n",
            "8/8 [==============================] - 1s 101ms/step - loss: 416.0711 - reconstruction_loss: 418.3344 - kl_loss: 7.7720\n",
            "Epoch 296/300\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 422.9441 - reconstruction_loss: 419.9368 - kl_loss: 7.6398\n",
            "Epoch 297/300\n",
            "8/8 [==============================] - 1s 75ms/step - loss: 414.1750 - reconstruction_loss: 415.6278 - kl_loss: 7.5949\n",
            "Epoch 298/300\n",
            "8/8 [==============================] - 1s 73ms/step - loss: 420.6155 - reconstruction_loss: 418.2106 - kl_loss: 7.5812\n",
            "Epoch 299/300\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 418.8328 - reconstruction_loss: 417.8931 - kl_loss: 7.5883\n",
            "Epoch 300/300\n",
            "8/8 [==============================] - 1s 72ms/step - loss: 425.1675 - reconstruction_loss: 418.2919 - kl_loss: 7.5896\n",
            "Found 31 images belonging to 1 classes.\n",
            "16/16 [==============================] - 0s 7ms/step\n",
            "Training VAE for class: Bird\n",
            "Found 244 images belonging to 1 classes.\n",
            "Epoch 1/300\n",
            "16/16 [==============================] - 4s 69ms/step - loss: 570.5985 - reconstruction_loss: 554.8922 - kl_loss: 6.6182\n",
            "Epoch 2/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 537.4093 - reconstruction_loss: 528.9641 - kl_loss: 5.7118\n",
            "Epoch 3/300\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 529.3692 - reconstruction_loss: 521.3381 - kl_loss: 5.1386\n",
            "Epoch 4/300\n",
            "16/16 [==============================] - 2s 91ms/step - loss: 528.1096 - reconstruction_loss: 518.4685 - kl_loss: 5.2451\n",
            "Epoch 5/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 520.6735 - reconstruction_loss: 515.1512 - kl_loss: 5.3860\n",
            "Epoch 6/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 519.7303 - reconstruction_loss: 513.4803 - kl_loss: 5.4608\n",
            "Epoch 7/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 509.3429 - reconstruction_loss: 508.5626 - kl_loss: 5.4842\n",
            "Epoch 8/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 517.0133 - reconstruction_loss: 511.1466 - kl_loss: 5.5691\n",
            "Epoch 9/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 516.1471 - reconstruction_loss: 510.9345 - kl_loss: 5.5278\n",
            "Epoch 10/300\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 513.6872 - reconstruction_loss: 508.6347 - kl_loss: 5.4274\n",
            "Epoch 11/300\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 513.4331 - reconstruction_loss: 509.9477 - kl_loss: 5.4198\n",
            "Epoch 12/300\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 509.9386 - reconstruction_loss: 508.5473 - kl_loss: 5.4437\n",
            "Epoch 13/300\n",
            "16/16 [==============================] - 2s 97ms/step - loss: 514.9988 - reconstruction_loss: 506.0873 - kl_loss: 5.5709\n",
            "Epoch 14/300\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 512.1822 - reconstruction_loss: 507.5798 - kl_loss: 5.5870\n",
            "Epoch 15/300\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 513.0623 - reconstruction_loss: 506.9705 - kl_loss: 5.5028\n",
            "Epoch 16/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 509.5000 - reconstruction_loss: 507.8659 - kl_loss: 5.5108\n",
            "Epoch 17/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 510.2929 - reconstruction_loss: 506.4896 - kl_loss: 5.5065\n",
            "Epoch 18/300\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 516.4885 - reconstruction_loss: 506.2502 - kl_loss: 5.5596\n",
            "Epoch 19/300\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 505.9501 - reconstruction_loss: 503.9940 - kl_loss: 5.6806\n",
            "Epoch 20/300\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 506.0981 - reconstruction_loss: 503.2655 - kl_loss: 5.7005\n",
            "Epoch 21/300\n",
            "16/16 [==============================] - 2s 100ms/step - loss: 508.7997 - reconstruction_loss: 505.2262 - kl_loss: 5.6201\n",
            "Epoch 22/300\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 509.9040 - reconstruction_loss: 504.6115 - kl_loss: 5.5368\n",
            "Epoch 23/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 512.3622 - reconstruction_loss: 503.8962 - kl_loss: 5.4948\n",
            "Epoch 24/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 510.8654 - reconstruction_loss: 503.9488 - kl_loss: 5.6712\n",
            "Epoch 25/300\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 501.8874 - reconstruction_loss: 502.2807 - kl_loss: 5.6171\n",
            "Epoch 26/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 504.3199 - reconstruction_loss: 502.9372 - kl_loss: 5.6842\n",
            "Epoch 27/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 512.4380 - reconstruction_loss: 504.2347 - kl_loss: 5.7323\n",
            "Epoch 28/300\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 514.0705 - reconstruction_loss: 504.4509 - kl_loss: 5.7154\n",
            "Epoch 29/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 507.9244 - reconstruction_loss: 503.4737 - kl_loss: 5.7239\n",
            "Epoch 30/300\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 507.2100 - reconstruction_loss: 503.7317 - kl_loss: 5.6683\n",
            "Epoch 31/300\n",
            "16/16 [==============================] - 2s 99ms/step - loss: 505.3927 - reconstruction_loss: 503.3474 - kl_loss: 5.6975\n",
            "Epoch 32/300\n",
            "16/16 [==============================] - 2s 95ms/step - loss: 506.2689 - reconstruction_loss: 500.9272 - kl_loss: 5.6014\n",
            "Epoch 33/300\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 510.4954 - reconstruction_loss: 503.5891 - kl_loss: 5.5670\n",
            "Epoch 34/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 505.6346 - reconstruction_loss: 500.4663 - kl_loss: 5.7106\n",
            "Epoch 35/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 505.0346 - reconstruction_loss: 502.6024 - kl_loss: 5.6111\n",
            "Epoch 36/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 505.7240 - reconstruction_loss: 502.8730 - kl_loss: 5.5908\n",
            "Epoch 37/300\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 507.3476 - reconstruction_loss: 500.7764 - kl_loss: 5.5388\n",
            "Epoch 38/300\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 507.3555 - reconstruction_loss: 500.8917 - kl_loss: 5.6908\n",
            "Epoch 39/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 508.5132 - reconstruction_loss: 501.5393 - kl_loss: 5.7724\n",
            "Epoch 40/300\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 503.9915 - reconstruction_loss: 500.7002 - kl_loss: 5.7655\n",
            "Epoch 41/300\n",
            "16/16 [==============================] - 2s 93ms/step - loss: 507.3949 - reconstruction_loss: 500.2755 - kl_loss: 5.6554\n",
            "Epoch 42/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 501.0694 - reconstruction_loss: 498.7539 - kl_loss: 5.8439\n",
            "Epoch 43/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 508.2258 - reconstruction_loss: 501.6898 - kl_loss: 5.7379\n",
            "Epoch 44/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 511.5646 - reconstruction_loss: 501.3462 - kl_loss: 5.6864\n",
            "Epoch 45/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 506.7773 - reconstruction_loss: 499.3144 - kl_loss: 5.7426\n",
            "Epoch 46/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 507.7807 - reconstruction_loss: 500.9096 - kl_loss: 5.7718\n",
            "Epoch 47/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 500.4011 - reconstruction_loss: 499.6401 - kl_loss: 5.8866\n",
            "Epoch 48/300\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 508.5550 - reconstruction_loss: 499.4485 - kl_loss: 5.7352\n",
            "Epoch 49/300\n",
            "16/16 [==============================] - 2s 97ms/step - loss: 501.9004 - reconstruction_loss: 499.5851 - kl_loss: 5.6589\n",
            "Epoch 50/300\n",
            "16/16 [==============================] - 2s 92ms/step - loss: 505.2111 - reconstruction_loss: 498.1377 - kl_loss: 5.7630\n",
            "Epoch 51/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 506.8382 - reconstruction_loss: 499.0510 - kl_loss: 5.8292\n",
            "Epoch 52/300\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 504.8777 - reconstruction_loss: 500.6596 - kl_loss: 5.8364\n",
            "Epoch 53/300\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 503.1636 - reconstruction_loss: 499.0912 - kl_loss: 5.8297\n",
            "Epoch 54/300\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 505.5416 - reconstruction_loss: 499.6049 - kl_loss: 5.7597\n",
            "Epoch 55/300\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 501.7353 - reconstruction_loss: 499.3521 - kl_loss: 5.7489\n",
            "Epoch 56/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 501.1198 - reconstruction_loss: 499.0276 - kl_loss: 5.7947\n",
            "Epoch 57/300\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 498.0713 - reconstruction_loss: 499.5450 - kl_loss: 5.8875\n",
            "Epoch 58/300\n",
            "16/16 [==============================] - 2s 91ms/step - loss: 501.2406 - reconstruction_loss: 495.4623 - kl_loss: 5.8675\n",
            "Epoch 59/300\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 501.0035 - reconstruction_loss: 498.1715 - kl_loss: 5.7687\n",
            "Epoch 60/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 504.0191 - reconstruction_loss: 497.9052 - kl_loss: 5.7932\n",
            "Epoch 61/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 506.5226 - reconstruction_loss: 499.7926 - kl_loss: 5.9168\n",
            "Epoch 62/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 500.9404 - reconstruction_loss: 498.3810 - kl_loss: 5.9964\n",
            "Epoch 63/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 503.2465 - reconstruction_loss: 496.8860 - kl_loss: 5.8656\n",
            "Epoch 64/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 501.2188 - reconstruction_loss: 497.1292 - kl_loss: 5.8036\n",
            "Epoch 65/300\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 503.8702 - reconstruction_loss: 498.1213 - kl_loss: 5.8049\n",
            "Epoch 66/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 501.1795 - reconstruction_loss: 498.4193 - kl_loss: 5.8799\n",
            "Epoch 67/300\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 506.0939 - reconstruction_loss: 498.7880 - kl_loss: 5.7442\n",
            "Epoch 68/300\n",
            "16/16 [==============================] - 2s 100ms/step - loss: 501.9707 - reconstruction_loss: 495.4406 - kl_loss: 5.8068\n",
            "Epoch 69/300\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 505.9645 - reconstruction_loss: 498.1111 - kl_loss: 5.8450\n",
            "Epoch 70/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 500.7848 - reconstruction_loss: 499.4611 - kl_loss: 5.8017\n",
            "Epoch 71/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 496.5001 - reconstruction_loss: 493.4996 - kl_loss: 5.8416\n",
            "Epoch 72/300\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 506.8931 - reconstruction_loss: 498.1682 - kl_loss: 5.8700\n",
            "Epoch 73/300\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 502.1035 - reconstruction_loss: 497.8563 - kl_loss: 5.7916\n",
            "Epoch 74/300\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 502.9353 - reconstruction_loss: 496.7866 - kl_loss: 5.7500\n",
            "Epoch 75/300\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 505.6540 - reconstruction_loss: 499.3892 - kl_loss: 5.8937\n",
            "Epoch 76/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 505.9303 - reconstruction_loss: 498.5981 - kl_loss: 5.9691\n",
            "Epoch 77/300\n",
            "16/16 [==============================] - 2s 102ms/step - loss: 507.2429 - reconstruction_loss: 496.6442 - kl_loss: 5.9573\n",
            "Epoch 78/300\n",
            "16/16 [==============================] - 2s 94ms/step - loss: 501.5922 - reconstruction_loss: 496.4307 - kl_loss: 5.8648\n",
            "Epoch 79/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 494.8079 - reconstruction_loss: 495.5441 - kl_loss: 5.9451\n",
            "Epoch 80/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 499.1443 - reconstruction_loss: 495.8745 - kl_loss: 5.9086\n",
            "Epoch 81/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 504.4272 - reconstruction_loss: 497.3090 - kl_loss: 5.8389\n",
            "Epoch 82/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 502.4939 - reconstruction_loss: 496.7561 - kl_loss: 5.8239\n",
            "Epoch 83/300\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 502.6012 - reconstruction_loss: 497.7844 - kl_loss: 5.8070\n",
            "Epoch 84/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 506.8052 - reconstruction_loss: 497.1538 - kl_loss: 5.9239\n",
            "Epoch 85/300\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 504.6472 - reconstruction_loss: 497.3948 - kl_loss: 5.9226\n",
            "Epoch 86/300\n",
            "16/16 [==============================] - 2s 94ms/step - loss: 497.6249 - reconstruction_loss: 495.2230 - kl_loss: 6.0292\n",
            "Epoch 87/300\n",
            "16/16 [==============================] - 2s 106ms/step - loss: 500.1502 - reconstruction_loss: 494.8006 - kl_loss: 6.0872\n",
            "Epoch 88/300\n",
            "16/16 [==============================] - 2s 99ms/step - loss: 500.8542 - reconstruction_loss: 496.3336 - kl_loss: 5.9026\n",
            "Epoch 89/300\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 502.6870 - reconstruction_loss: 498.1638 - kl_loss: 5.8021\n",
            "Epoch 90/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 500.6040 - reconstruction_loss: 494.6090 - kl_loss: 5.9285\n",
            "Epoch 91/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 505.8658 - reconstruction_loss: 496.3804 - kl_loss: 5.8685\n",
            "Epoch 92/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 502.3690 - reconstruction_loss: 497.8274 - kl_loss: 5.8553\n",
            "Epoch 93/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 503.7431 - reconstruction_loss: 496.7627 - kl_loss: 5.8228\n",
            "Epoch 94/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 500.0208 - reconstruction_loss: 495.7550 - kl_loss: 5.9119\n",
            "Epoch 95/300\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 503.5010 - reconstruction_loss: 493.8038 - kl_loss: 5.9102\n",
            "Epoch 96/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 501.4436 - reconstruction_loss: 495.5417 - kl_loss: 5.9213\n",
            "Epoch 97/300\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 508.1014 - reconstruction_loss: 492.1407 - kl_loss: 5.9661\n",
            "Epoch 98/300\n",
            "16/16 [==============================] - 2s 102ms/step - loss: 504.7553 - reconstruction_loss: 495.3050 - kl_loss: 5.9677\n",
            "Epoch 99/300\n",
            "16/16 [==============================] - 2s 101ms/step - loss: 497.3966 - reconstruction_loss: 495.0626 - kl_loss: 5.9117\n",
            "Epoch 100/300\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 504.5987 - reconstruction_loss: 494.5300 - kl_loss: 6.0329\n",
            "Epoch 101/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 495.8638 - reconstruction_loss: 496.5637 - kl_loss: 5.8638\n",
            "Epoch 102/300\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 508.4164 - reconstruction_loss: 496.9529 - kl_loss: 5.8344\n",
            "Epoch 103/300\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 501.3143 - reconstruction_loss: 496.4877 - kl_loss: 5.9605\n",
            "Epoch 104/300\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 500.5737 - reconstruction_loss: 495.6284 - kl_loss: 5.9260\n",
            "Epoch 105/300\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 497.6231 - reconstruction_loss: 491.6099 - kl_loss: 6.0039\n",
            "Epoch 106/300\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 500.7091 - reconstruction_loss: 494.3133 - kl_loss: 6.0243\n",
            "Epoch 107/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 503.7493 - reconstruction_loss: 495.6035 - kl_loss: 6.0644\n",
            "Epoch 108/300\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 500.7686 - reconstruction_loss: 496.3817 - kl_loss: 5.8962\n",
            "Epoch 109/300\n",
            "16/16 [==============================] - 2s 95ms/step - loss: 504.4696 - reconstruction_loss: 496.3740 - kl_loss: 5.8329\n",
            "Epoch 110/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 495.4501 - reconstruction_loss: 492.7123 - kl_loss: 5.9405\n",
            "Epoch 111/300\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 498.4065 - reconstruction_loss: 495.0603 - kl_loss: 6.0856\n",
            "Epoch 112/300\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 499.5158 - reconstruction_loss: 495.1851 - kl_loss: 5.9758\n",
            "Epoch 113/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 502.7872 - reconstruction_loss: 496.2453 - kl_loss: 5.8382\n",
            "Epoch 114/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 496.8480 - reconstruction_loss: 494.2606 - kl_loss: 5.9473\n",
            "Epoch 115/300\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 496.4237 - reconstruction_loss: 492.5029 - kl_loss: 5.9087\n",
            "Epoch 116/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 500.4384 - reconstruction_loss: 493.2716 - kl_loss: 5.8554\n",
            "Epoch 117/300\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 503.2857 - reconstruction_loss: 493.9987 - kl_loss: 6.0296\n",
            "Epoch 118/300\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 501.6018 - reconstruction_loss: 492.7358 - kl_loss: 5.9552\n",
            "Epoch 119/300\n",
            "16/16 [==============================] - 2s 100ms/step - loss: 495.5143 - reconstruction_loss: 492.1384 - kl_loss: 6.0506\n",
            "Epoch 120/300\n",
            "16/16 [==============================] - 2s 105ms/step - loss: 499.8133 - reconstruction_loss: 493.4124 - kl_loss: 6.0355\n",
            "Epoch 121/300\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 499.4105 - reconstruction_loss: 494.4072 - kl_loss: 5.8738\n",
            "Epoch 122/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 498.6000 - reconstruction_loss: 494.4339 - kl_loss: 5.9195\n",
            "Epoch 123/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 495.3518 - reconstruction_loss: 494.7558 - kl_loss: 6.0946\n",
            "Epoch 124/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 495.9555 - reconstruction_loss: 487.9779 - kl_loss: 6.1896\n",
            "Epoch 125/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 490.6145 - reconstruction_loss: 493.3623 - kl_loss: 5.9582\n",
            "Epoch 126/300\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 497.2394 - reconstruction_loss: 495.4858 - kl_loss: 5.9518\n",
            "Epoch 127/300\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 507.0696 - reconstruction_loss: 494.9804 - kl_loss: 6.0201\n",
            "Epoch 128/300\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 501.3343 - reconstruction_loss: 492.0104 - kl_loss: 6.0573\n",
            "Epoch 129/300\n",
            "16/16 [==============================] - 2s 94ms/step - loss: 500.5048 - reconstruction_loss: 494.2838 - kl_loss: 6.0025\n",
            "Epoch 130/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 496.2024 - reconstruction_loss: 491.2714 - kl_loss: 6.0783\n",
            "Epoch 131/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 502.3468 - reconstruction_loss: 494.9355 - kl_loss: 5.8378\n",
            "Epoch 132/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 498.0745 - reconstruction_loss: 492.2348 - kl_loss: 5.9306\n",
            "Epoch 133/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 498.8942 - reconstruction_loss: 494.9398 - kl_loss: 6.0625\n",
            "Epoch 134/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 490.9117 - reconstruction_loss: 490.8968 - kl_loss: 6.1085\n",
            "Epoch 135/300\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 501.1286 - reconstruction_loss: 495.1595 - kl_loss: 6.0657\n",
            "Epoch 136/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 495.4311 - reconstruction_loss: 491.6010 - kl_loss: 6.0408\n",
            "Epoch 137/300\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 505.6155 - reconstruction_loss: 490.6367 - kl_loss: 6.1079\n",
            "Epoch 138/300\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 499.3098 - reconstruction_loss: 491.9265 - kl_loss: 6.0993\n",
            "Epoch 139/300\n",
            "16/16 [==============================] - 2s 105ms/step - loss: 501.5064 - reconstruction_loss: 494.2995 - kl_loss: 6.1920\n",
            "Epoch 140/300\n",
            "16/16 [==============================] - 2s 89ms/step - loss: 499.5455 - reconstruction_loss: 495.0737 - kl_loss: 6.0887\n",
            "Epoch 141/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 496.3111 - reconstruction_loss: 492.8135 - kl_loss: 6.0250\n",
            "Epoch 142/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 498.1067 - reconstruction_loss: 492.2405 - kl_loss: 6.0517\n",
            "Epoch 143/300\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 498.7397 - reconstruction_loss: 493.7582 - kl_loss: 5.9386\n",
            "Epoch 144/300\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 503.5736 - reconstruction_loss: 493.7774 - kl_loss: 6.0984\n",
            "Epoch 145/300\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 496.3298 - reconstruction_loss: 495.1123 - kl_loss: 6.0229\n",
            "Epoch 146/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 496.2840 - reconstruction_loss: 494.1640 - kl_loss: 6.0592\n",
            "Epoch 147/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 492.7387 - reconstruction_loss: 491.6513 - kl_loss: 6.0650\n",
            "Epoch 148/300\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 507.0021 - reconstruction_loss: 494.3951 - kl_loss: 5.9474\n",
            "Epoch 149/300\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 497.9634 - reconstruction_loss: 491.5591 - kl_loss: 5.9484\n",
            "Epoch 150/300\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 503.8580 - reconstruction_loss: 489.4352 - kl_loss: 6.1003\n",
            "Epoch 151/300\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 494.4638 - reconstruction_loss: 492.0939 - kl_loss: 6.0288\n",
            "Epoch 152/300\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 501.2015 - reconstruction_loss: 492.4064 - kl_loss: 6.0916\n",
            "Epoch 153/300\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 501.1926 - reconstruction_loss: 492.6864 - kl_loss: 6.0545\n",
            "Epoch 154/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 502.9340 - reconstruction_loss: 493.7928 - kl_loss: 6.0054\n",
            "Epoch 155/300\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 501.3233 - reconstruction_loss: 494.6435 - kl_loss: 5.9857\n",
            "Epoch 156/300\n",
            "16/16 [==============================] - 2s 105ms/step - loss: 495.8802 - reconstruction_loss: 488.2382 - kl_loss: 6.2092\n",
            "Epoch 157/300\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 500.5796 - reconstruction_loss: 491.7540 - kl_loss: 6.0581\n",
            "Epoch 158/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 500.1361 - reconstruction_loss: 492.7140 - kl_loss: 6.0086\n",
            "Epoch 159/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 500.4564 - reconstruction_loss: 493.3337 - kl_loss: 6.1682\n",
            "Epoch 160/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 500.7440 - reconstruction_loss: 490.6279 - kl_loss: 6.1455\n",
            "Epoch 161/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 493.0455 - reconstruction_loss: 491.7671 - kl_loss: 6.1585\n",
            "Epoch 162/300\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 498.9226 - reconstruction_loss: 492.9806 - kl_loss: 6.0409\n",
            "Epoch 163/300\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 503.3725 - reconstruction_loss: 493.6619 - kl_loss: 5.9706\n",
            "Epoch 164/300\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 500.7700 - reconstruction_loss: 490.3058 - kl_loss: 6.0538\n",
            "Epoch 165/300\n",
            "16/16 [==============================] - 2s 101ms/step - loss: 494.0735 - reconstruction_loss: 492.4412 - kl_loss: 6.2091\n",
            "Epoch 166/300\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 493.0921 - reconstruction_loss: 493.3029 - kl_loss: 6.0377\n",
            "Epoch 167/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 500.6946 - reconstruction_loss: 492.2647 - kl_loss: 5.9382\n",
            "Epoch 168/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 495.7525 - reconstruction_loss: 489.3232 - kl_loss: 6.1661\n",
            "Epoch 169/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 495.4165 - reconstruction_loss: 493.4235 - kl_loss: 5.9319\n",
            "Epoch 170/300\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 494.8151 - reconstruction_loss: 490.2327 - kl_loss: 5.9882\n",
            "Epoch 171/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 492.1027 - reconstruction_loss: 493.2241 - kl_loss: 5.9733\n",
            "Epoch 172/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 498.0882 - reconstruction_loss: 490.7471 - kl_loss: 6.0001\n",
            "Epoch 173/300\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 494.1195 - reconstruction_loss: 491.1159 - kl_loss: 6.1449\n",
            "Epoch 174/300\n",
            "16/16 [==============================] - 2s 91ms/step - loss: 503.7598 - reconstruction_loss: 491.9861 - kl_loss: 6.1472\n",
            "Epoch 175/300\n",
            "16/16 [==============================] - 2s 96ms/step - loss: 503.4063 - reconstruction_loss: 492.5613 - kl_loss: 6.0843\n",
            "Epoch 176/300\n",
            "16/16 [==============================] - 2s 95ms/step - loss: 504.2837 - reconstruction_loss: 492.3041 - kl_loss: 6.0453\n",
            "Epoch 177/300\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 499.4678 - reconstruction_loss: 492.3835 - kl_loss: 6.0515\n",
            "Epoch 178/300\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 505.1101 - reconstruction_loss: 493.2340 - kl_loss: 5.9897\n",
            "Epoch 179/300\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 502.8963 - reconstruction_loss: 491.9904 - kl_loss: 6.2075\n",
            "Epoch 180/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 496.4136 - reconstruction_loss: 491.2509 - kl_loss: 6.1532\n",
            "Epoch 181/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 502.4497 - reconstruction_loss: 492.5696 - kl_loss: 5.9569\n",
            "Epoch 182/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 492.7415 - reconstruction_loss: 490.3277 - kl_loss: 6.0554\n",
            "Epoch 183/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 500.3650 - reconstruction_loss: 491.7168 - kl_loss: 6.1344\n",
            "Epoch 184/300\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 502.0189 - reconstruction_loss: 493.2852 - kl_loss: 6.1156\n",
            "Epoch 185/300\n",
            "16/16 [==============================] - 2s 101ms/step - loss: 490.3205 - reconstruction_loss: 490.1953 - kl_loss: 6.1628\n",
            "Epoch 186/300\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 500.5338 - reconstruction_loss: 487.1869 - kl_loss: 6.0433\n",
            "Epoch 187/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 500.8063 - reconstruction_loss: 492.1842 - kl_loss: 5.9782\n",
            "Epoch 188/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 500.4363 - reconstruction_loss: 492.1468 - kl_loss: 6.1107\n",
            "Epoch 189/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 499.2936 - reconstruction_loss: 491.4284 - kl_loss: 6.1246\n",
            "Epoch 190/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 491.4402 - reconstruction_loss: 491.9438 - kl_loss: 6.0723\n",
            "Epoch 191/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 496.9775 - reconstruction_loss: 492.0958 - kl_loss: 6.1346\n",
            "Epoch 192/300\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 493.9039 - reconstruction_loss: 489.4925 - kl_loss: 6.1743\n",
            "Epoch 193/300\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 500.4351 - reconstruction_loss: 486.6736 - kl_loss: 6.1222\n",
            "Epoch 194/300\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 496.1207 - reconstruction_loss: 490.0966 - kl_loss: 6.0282\n",
            "Epoch 195/300\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 497.8494 - reconstruction_loss: 491.9569 - kl_loss: 6.2058\n",
            "Epoch 196/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 495.8013 - reconstruction_loss: 490.7617 - kl_loss: 6.1766\n",
            "Epoch 197/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 504.4058 - reconstruction_loss: 492.7798 - kl_loss: 6.0886\n",
            "Epoch 198/300\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 495.6454 - reconstruction_loss: 490.6591 - kl_loss: 6.1598\n",
            "Epoch 199/300\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 493.2551 - reconstruction_loss: 490.0921 - kl_loss: 6.1390\n",
            "Epoch 200/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 495.0790 - reconstruction_loss: 489.7673 - kl_loss: 6.0099\n",
            "Epoch 201/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 494.9828 - reconstruction_loss: 488.7048 - kl_loss: 6.1343\n",
            "Epoch 202/300\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 499.7029 - reconstruction_loss: 491.5501 - kl_loss: 6.2489\n",
            "Epoch 203/300\n",
            "16/16 [==============================] - 2s 93ms/step - loss: 498.4693 - reconstruction_loss: 491.0865 - kl_loss: 6.2314\n",
            "Epoch 204/300\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 490.2031 - reconstruction_loss: 490.6143 - kl_loss: 6.2508\n",
            "Epoch 205/300\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 495.8600 - reconstruction_loss: 490.9570 - kl_loss: 6.2458\n",
            "Epoch 206/300\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 498.4613 - reconstruction_loss: 491.9303 - kl_loss: 6.1296\n",
            "Epoch 207/300\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 501.1462 - reconstruction_loss: 490.8201 - kl_loss: 6.1922\n",
            "Epoch 208/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 491.2286 - reconstruction_loss: 488.7491 - kl_loss: 6.2660\n",
            "Epoch 209/300\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 503.1304 - reconstruction_loss: 492.4364 - kl_loss: 6.1617\n",
            "Epoch 210/300\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 489.4161 - reconstruction_loss: 488.3021 - kl_loss: 6.2145\n",
            "Epoch 211/300\n",
            "16/16 [==============================] - 2s 95ms/step - loss: 501.6363 - reconstruction_loss: 490.7051 - kl_loss: 6.3084\n",
            "Epoch 212/300\n",
            "16/16 [==============================] - 2s 96ms/step - loss: 491.6331 - reconstruction_loss: 490.2067 - kl_loss: 6.1811\n",
            "Epoch 213/300\n",
            "16/16 [==============================] - 2s 103ms/step - loss: 501.4436 - reconstruction_loss: 489.2186 - kl_loss: 6.2486\n",
            "Epoch 214/300\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 491.1962 - reconstruction_loss: 488.7405 - kl_loss: 6.2006\n",
            "Epoch 215/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 494.2550 - reconstruction_loss: 490.7067 - kl_loss: 6.1462\n",
            "Epoch 216/300\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 501.6455 - reconstruction_loss: 491.4886 - kl_loss: 6.1244\n",
            "Epoch 217/300\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 503.4732 - reconstruction_loss: 491.9338 - kl_loss: 6.1551\n",
            "Epoch 218/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 494.8888 - reconstruction_loss: 490.0269 - kl_loss: 6.2482\n",
            "Epoch 219/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 487.4245 - reconstruction_loss: 487.6142 - kl_loss: 6.2744\n",
            "Epoch 220/300\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 501.3154 - reconstruction_loss: 490.7201 - kl_loss: 6.2553\n",
            "Epoch 221/300\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 493.2274 - reconstruction_loss: 488.1418 - kl_loss: 6.1623\n",
            "Epoch 222/300\n",
            "16/16 [==============================] - 2s 89ms/step - loss: 493.7737 - reconstruction_loss: 490.3974 - kl_loss: 6.1501\n",
            "Epoch 223/300\n",
            "16/16 [==============================] - 2s 101ms/step - loss: 498.5644 - reconstruction_loss: 487.4814 - kl_loss: 6.1596\n",
            "Epoch 224/300\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 495.6462 - reconstruction_loss: 488.8320 - kl_loss: 6.1770\n",
            "Epoch 225/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 499.4461 - reconstruction_loss: 490.9716 - kl_loss: 6.2498\n",
            "Epoch 226/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 496.0434 - reconstruction_loss: 488.0844 - kl_loss: 6.2758\n",
            "Epoch 227/300\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 493.3865 - reconstruction_loss: 490.4144 - kl_loss: 5.9923\n",
            "Epoch 228/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 490.5059 - reconstruction_loss: 490.7852 - kl_loss: 6.0717\n",
            "Epoch 229/300\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 491.0836 - reconstruction_loss: 490.4340 - kl_loss: 6.1222\n",
            "Epoch 230/300\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 493.6249 - reconstruction_loss: 490.1542 - kl_loss: 6.1378\n",
            "Epoch 231/300\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 491.5237 - reconstruction_loss: 487.8725 - kl_loss: 6.1818\n",
            "Epoch 232/300\n",
            "16/16 [==============================] - 2s 97ms/step - loss: 493.6049 - reconstruction_loss: 490.7929 - kl_loss: 6.2401\n",
            "Epoch 233/300\n",
            "16/16 [==============================] - 1s 87ms/step - loss: 496.8549 - reconstruction_loss: 490.0114 - kl_loss: 6.1854\n",
            "Epoch 234/300\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 500.2019 - reconstruction_loss: 489.1349 - kl_loss: 6.2005\n",
            "Epoch 235/300\n",
            "16/16 [==============================] - 1s 67ms/step - loss: 501.0135 - reconstruction_loss: 491.4907 - kl_loss: 6.0368\n",
            "Epoch 236/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 493.0751 - reconstruction_loss: 489.4109 - kl_loss: 6.2747\n",
            "Epoch 237/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 494.9609 - reconstruction_loss: 490.4919 - kl_loss: 6.0940\n",
            "Epoch 238/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 495.8559 - reconstruction_loss: 488.8927 - kl_loss: 6.1334\n",
            "Epoch 239/300\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 497.9326 - reconstruction_loss: 490.5342 - kl_loss: 6.1735\n",
            "Epoch 240/300\n",
            "16/16 [==============================] - 1s 77ms/step - loss: 493.2432 - reconstruction_loss: 486.8226 - kl_loss: 6.3041\n",
            "Epoch 241/300\n",
            "16/16 [==============================] - 2s 96ms/step - loss: 491.5589 - reconstruction_loss: 487.7642 - kl_loss: 6.2104\n",
            "Epoch 242/300\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 496.1019 - reconstruction_loss: 491.1022 - kl_loss: 6.1358\n",
            "Epoch 243/300\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 496.4542 - reconstruction_loss: 489.0154 - kl_loss: 6.2305\n",
            "Epoch 244/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 493.5845 - reconstruction_loss: 487.4030 - kl_loss: 6.2476\n",
            "Epoch 245/300\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 501.1656 - reconstruction_loss: 490.8767 - kl_loss: 6.1837\n",
            "Epoch 246/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 497.7940 - reconstruction_loss: 488.9923 - kl_loss: 6.2786\n",
            "Epoch 247/300\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 498.5478 - reconstruction_loss: 490.7158 - kl_loss: 6.1905\n",
            "Epoch 248/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 487.2503 - reconstruction_loss: 486.8291 - kl_loss: 6.3443\n",
            "Epoch 249/300\n",
            "16/16 [==============================] - 1s 68ms/step - loss: 495.7229 - reconstruction_loss: 488.7008 - kl_loss: 6.2588\n",
            "Epoch 250/300\n",
            "16/16 [==============================] - 1s 68ms/step - loss: 496.7093 - reconstruction_loss: 490.6438 - kl_loss: 6.1019\n",
            "Epoch 251/300\n",
            "16/16 [==============================] - 2s 98ms/step - loss: 494.7492 - reconstruction_loss: 488.6912 - kl_loss: 6.0772\n",
            "Epoch 252/300\n",
            "16/16 [==============================] - 2s 97ms/step - loss: 495.0932 - reconstruction_loss: 489.3346 - kl_loss: 6.1037\n",
            "Epoch 253/300\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 496.7557 - reconstruction_loss: 488.7627 - kl_loss: 6.1292\n",
            "Epoch 254/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 498.0482 - reconstruction_loss: 489.5465 - kl_loss: 6.1170\n",
            "Epoch 255/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 495.1267 - reconstruction_loss: 489.0154 - kl_loss: 6.1083\n",
            "Epoch 256/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 493.2088 - reconstruction_loss: 489.0406 - kl_loss: 6.1257\n",
            "Epoch 257/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 493.4344 - reconstruction_loss: 488.4449 - kl_loss: 6.2117\n",
            "Epoch 258/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 493.5144 - reconstruction_loss: 488.1057 - kl_loss: 6.0620\n",
            "Epoch 259/300\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 491.0338 - reconstruction_loss: 489.0838 - kl_loss: 6.2868\n",
            "Epoch 260/300\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 497.0843 - reconstruction_loss: 490.2509 - kl_loss: 6.3121\n",
            "Epoch 261/300\n",
            "16/16 [==============================] - 2s 94ms/step - loss: 496.4875 - reconstruction_loss: 488.3785 - kl_loss: 6.2337\n",
            "Epoch 262/300\n",
            "16/16 [==============================] - 1s 86ms/step - loss: 490.9705 - reconstruction_loss: 489.5085 - kl_loss: 6.1086\n",
            "Epoch 263/300\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 484.3637 - reconstruction_loss: 485.2662 - kl_loss: 6.1830\n",
            "Epoch 264/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 499.2768 - reconstruction_loss: 491.2085 - kl_loss: 6.1991\n",
            "Epoch 265/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 485.4464 - reconstruction_loss: 485.0849 - kl_loss: 6.3117\n",
            "Epoch 266/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 491.8235 - reconstruction_loss: 486.1364 - kl_loss: 6.2820\n",
            "Epoch 267/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 496.9460 - reconstruction_loss: 488.1192 - kl_loss: 6.2775\n",
            "Epoch 268/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 496.0103 - reconstruction_loss: 489.1583 - kl_loss: 6.2496\n",
            "Epoch 269/300\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 489.5577 - reconstruction_loss: 486.4908 - kl_loss: 6.3622\n",
            "Epoch 270/300\n",
            "16/16 [==============================] - 2s 91ms/step - loss: 492.6380 - reconstruction_loss: 488.2114 - kl_loss: 6.1846\n",
            "Epoch 271/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 496.8211 - reconstruction_loss: 488.4752 - kl_loss: 6.1768\n",
            "Epoch 272/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 495.8718 - reconstruction_loss: 487.0999 - kl_loss: 6.1952\n",
            "Epoch 273/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 489.1885 - reconstruction_loss: 484.8724 - kl_loss: 6.2423\n",
            "Epoch 274/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 496.3555 - reconstruction_loss: 488.0500 - kl_loss: 6.2478\n",
            "Epoch 275/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 501.1566 - reconstruction_loss: 488.8427 - kl_loss: 6.2207\n",
            "Epoch 276/300\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 497.7516 - reconstruction_loss: 487.4922 - kl_loss: 6.2012\n",
            "Epoch 277/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 498.4863 - reconstruction_loss: 489.5121 - kl_loss: 6.2102\n",
            "Epoch 278/300\n",
            "16/16 [==============================] - 2s 97ms/step - loss: 495.6116 - reconstruction_loss: 486.0216 - kl_loss: 6.3215\n",
            "Epoch 279/300\n",
            "16/16 [==============================] - 2s 95ms/step - loss: 495.0060 - reconstruction_loss: 489.9243 - kl_loss: 6.1625\n",
            "Epoch 280/300\n",
            "16/16 [==============================] - 2s 101ms/step - loss: 493.8051 - reconstruction_loss: 488.3376 - kl_loss: 6.1172\n",
            "Epoch 281/300\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 493.4093 - reconstruction_loss: 486.6940 - kl_loss: 6.1154\n",
            "Epoch 282/300\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 501.1806 - reconstruction_loss: 490.4018 - kl_loss: 6.3022\n",
            "Epoch 283/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 489.3566 - reconstruction_loss: 488.4947 - kl_loss: 6.2574\n",
            "Epoch 284/300\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 493.8998 - reconstruction_loss: 489.6885 - kl_loss: 6.1734\n",
            "Epoch 285/300\n",
            "16/16 [==============================] - 1s 72ms/step - loss: 497.3662 - reconstruction_loss: 488.3584 - kl_loss: 6.1726\n",
            "Epoch 286/300\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 493.7694 - reconstruction_loss: 489.8264 - kl_loss: 6.0595\n",
            "Epoch 287/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 493.1272 - reconstruction_loss: 489.1566 - kl_loss: 6.1692\n",
            "Epoch 288/300\n",
            "16/16 [==============================] - 1s 85ms/step - loss: 495.6648 - reconstruction_loss: 489.8724 - kl_loss: 6.0713\n",
            "Epoch 289/300\n",
            "16/16 [==============================] - 2s 91ms/step - loss: 496.5846 - reconstruction_loss: 488.6451 - kl_loss: 6.2451\n",
            "Epoch 290/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 496.2873 - reconstruction_loss: 488.8746 - kl_loss: 6.2777\n",
            "Epoch 291/300\n",
            "16/16 [==============================] - 1s 75ms/step - loss: 474.2824 - reconstruction_loss: 482.5593 - kl_loss: 6.2997\n",
            "Epoch 292/300\n",
            "16/16 [==============================] - 1s 73ms/step - loss: 491.4265 - reconstruction_loss: 488.3492 - kl_loss: 6.2051\n",
            "Epoch 293/300\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 495.8916 - reconstruction_loss: 489.5910 - kl_loss: 6.1848\n",
            "Epoch 294/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 496.7724 - reconstruction_loss: 485.1107 - kl_loss: 6.1999\n",
            "Epoch 295/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 495.7496 - reconstruction_loss: 486.6801 - kl_loss: 6.2055\n",
            "Epoch 296/300\n",
            "16/16 [==============================] - 1s 70ms/step - loss: 494.0119 - reconstruction_loss: 489.4120 - kl_loss: 6.3644\n",
            "Epoch 297/300\n",
            "16/16 [==============================] - 1s 74ms/step - loss: 492.6023 - reconstruction_loss: 488.4388 - kl_loss: 6.1542\n",
            "Epoch 298/300\n",
            "16/16 [==============================] - 2s 93ms/step - loss: 479.4804 - reconstruction_loss: 489.7106 - kl_loss: 6.2510\n",
            "Epoch 299/300\n",
            "16/16 [==============================] - 2s 97ms/step - loss: 497.7541 - reconstruction_loss: 487.3805 - kl_loss: 6.3224\n",
            "Epoch 300/300\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 490.0394 - reconstruction_loss: 487.8087 - kl_loss: 6.2710\n",
            "Found 61 images belonging to 1 classes.\n",
            "16/16 [==============================] - 0s 7ms/step\n",
            "Training VAE for class: Bicycle\n",
            "Found 153 images belonging to 1 classes.\n",
            "Epoch 1/300\n",
            "10/10 [==============================] - 5s 223ms/step - loss: 540.6645 - reconstruction_loss: 533.1431 - kl_loss: 6.5446\n",
            "Epoch 2/300\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 525.1528 - reconstruction_loss: 515.2450 - kl_loss: 5.7337\n",
            "Epoch 3/300\n",
            "10/10 [==============================] - 1s 96ms/step - loss: 514.8802 - reconstruction_loss: 507.2176 - kl_loss: 5.4942\n",
            "Epoch 4/300\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 507.7692 - reconstruction_loss: 502.5823 - kl_loss: 5.4810\n",
            "Epoch 5/300\n",
            "10/10 [==============================] - 1s 96ms/step - loss: 505.2147 - reconstruction_loss: 500.1769 - kl_loss: 5.5863\n",
            "Epoch 6/300\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 501.6040 - reconstruction_loss: 497.9317 - kl_loss: 5.7182\n",
            "Epoch 7/300\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 500.6208 - reconstruction_loss: 496.0443 - kl_loss: 5.6819\n",
            "Epoch 8/300\n",
            "10/10 [==============================] - 1s 80ms/step - loss: 498.5901 - reconstruction_loss: 494.4881 - kl_loss: 5.7126\n",
            "Epoch 9/300\n",
            "10/10 [==============================] - 1s 80ms/step - loss: 502.7551 - reconstruction_loss: 494.8187 - kl_loss: 5.6586\n",
            "Epoch 10/300\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 498.8811 - reconstruction_loss: 492.6852 - kl_loss: 5.7968\n",
            "Epoch 11/300\n",
            "10/10 [==============================] - 1s 78ms/step - loss: 498.3746 - reconstruction_loss: 492.1555 - kl_loss: 5.8619\n",
            "Epoch 12/300\n",
            "10/10 [==============================] - 1s 70ms/step - loss: 496.1572 - reconstruction_loss: 491.4791 - kl_loss: 5.9191\n",
            "Epoch 13/300\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 495.6635 - reconstruction_loss: 489.5004 - kl_loss: 5.9041\n",
            "Epoch 14/300\n",
            "10/10 [==============================] - 1s 77ms/step - loss: 489.8733 - reconstruction_loss: 489.5929 - kl_loss: 5.8598\n",
            "Epoch 15/300\n",
            "10/10 [==============================] - 1s 74ms/step - loss: 494.2391 - reconstruction_loss: 489.6566 - kl_loss: 5.9582\n",
            "Epoch 16/300\n",
            "10/10 [==============================] - 1s 78ms/step - loss: 488.5145 - reconstruction_loss: 488.2350 - kl_loss: 5.9665\n",
            "Epoch 17/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 491.6768 - reconstruction_loss: 487.7296 - kl_loss: 6.0073\n",
            "Epoch 18/300\n",
            "10/10 [==============================] - 1s 75ms/step - loss: 493.2378 - reconstruction_loss: 488.7484 - kl_loss: 5.9176\n",
            "Epoch 19/300\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 487.9842 - reconstruction_loss: 487.7399 - kl_loss: 6.0290\n",
            "Epoch 20/300\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 493.0068 - reconstruction_loss: 487.9491 - kl_loss: 5.9468\n",
            "Epoch 21/300\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 498.7350 - reconstruction_loss: 487.9846 - kl_loss: 6.1052\n",
            "Epoch 22/300\n",
            "10/10 [==============================] - 1s 100ms/step - loss: 490.9469 - reconstruction_loss: 487.5671 - kl_loss: 6.1801\n",
            "Epoch 23/300\n",
            "10/10 [==============================] - 1s 76ms/step - loss: 484.9615 - reconstruction_loss: 486.0549 - kl_loss: 6.1052\n",
            "Epoch 24/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 492.0199 - reconstruction_loss: 483.1631 - kl_loss: 6.1987\n",
            "Epoch 25/300\n",
            "10/10 [==============================] - 1s 75ms/step - loss: 489.4205 - reconstruction_loss: 484.5620 - kl_loss: 6.2048\n",
            "Epoch 26/300\n",
            "10/10 [==============================] - 1s 77ms/step - loss: 492.8291 - reconstruction_loss: 485.1047 - kl_loss: 6.1061\n",
            "Epoch 27/300\n",
            "10/10 [==============================] - 1s 75ms/step - loss: 493.8563 - reconstruction_loss: 484.9167 - kl_loss: 6.1278\n",
            "Epoch 28/300\n",
            "10/10 [==============================] - 1s 80ms/step - loss: 479.1005 - reconstruction_loss: 483.0156 - kl_loss: 6.2050\n",
            "Epoch 29/300\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 492.4594 - reconstruction_loss: 484.3034 - kl_loss: 6.2301\n",
            "Epoch 30/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 491.6201 - reconstruction_loss: 484.4814 - kl_loss: 6.2942\n",
            "Epoch 31/300\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 493.4168 - reconstruction_loss: 484.2079 - kl_loss: 6.1408\n",
            "Epoch 32/300\n",
            "10/10 [==============================] - 1s 83ms/step - loss: 494.1165 - reconstruction_loss: 483.8782 - kl_loss: 6.3308\n",
            "Epoch 33/300\n",
            "10/10 [==============================] - 1s 95ms/step - loss: 488.0066 - reconstruction_loss: 483.9218 - kl_loss: 6.1399\n",
            "Epoch 34/300\n",
            "10/10 [==============================] - 1s 93ms/step - loss: 490.1271 - reconstruction_loss: 483.9831 - kl_loss: 6.1058\n",
            "Epoch 35/300\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 486.6756 - reconstruction_loss: 482.2979 - kl_loss: 6.0934\n",
            "Epoch 36/300\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 483.8937 - reconstruction_loss: 482.0878 - kl_loss: 6.2090\n",
            "Epoch 37/300\n",
            "10/10 [==============================] - 1s 83ms/step - loss: 487.0198 - reconstruction_loss: 481.4730 - kl_loss: 6.1938\n",
            "Epoch 38/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 487.6437 - reconstruction_loss: 482.5771 - kl_loss: 6.1899\n",
            "Epoch 39/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 489.8900 - reconstruction_loss: 482.2569 - kl_loss: 6.2561\n",
            "Epoch 40/300\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 483.6766 - reconstruction_loss: 481.0696 - kl_loss: 6.2835\n",
            "Epoch 41/300\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 491.2151 - reconstruction_loss: 480.9157 - kl_loss: 6.4065\n",
            "Epoch 42/300\n",
            "10/10 [==============================] - 1s 76ms/step - loss: 484.1967 - reconstruction_loss: 481.2548 - kl_loss: 6.4057\n",
            "Epoch 43/300\n",
            "10/10 [==============================] - 1s 74ms/step - loss: 486.8235 - reconstruction_loss: 481.7021 - kl_loss: 6.4503\n",
            "Epoch 44/300\n",
            "10/10 [==============================] - 1s 74ms/step - loss: 485.4243 - reconstruction_loss: 480.4683 - kl_loss: 6.3461\n",
            "Epoch 45/300\n",
            "10/10 [==============================] - 1s 70ms/step - loss: 493.6506 - reconstruction_loss: 480.7300 - kl_loss: 6.3327\n",
            "Epoch 46/300\n",
            "10/10 [==============================] - 1s 82ms/step - loss: 486.6651 - reconstruction_loss: 480.5273 - kl_loss: 6.2571\n",
            "Epoch 47/300\n",
            "10/10 [==============================] - 1s 95ms/step - loss: 491.1948 - reconstruction_loss: 480.8735 - kl_loss: 6.3541\n",
            "Epoch 48/300\n",
            "10/10 [==============================] - 1s 94ms/step - loss: 477.2109 - reconstruction_loss: 479.7443 - kl_loss: 6.3472\n",
            "Epoch 49/300\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 488.1718 - reconstruction_loss: 478.9617 - kl_loss: 6.3542\n",
            "Epoch 50/300\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 489.6963 - reconstruction_loss: 479.1600 - kl_loss: 6.3917\n",
            "Epoch 51/300\n",
            "10/10 [==============================] - 1s 100ms/step - loss: 483.1885 - reconstruction_loss: 478.9801 - kl_loss: 6.4514\n",
            "Epoch 52/300\n",
            "10/10 [==============================] - 1s 81ms/step - loss: 484.5952 - reconstruction_loss: 479.5401 - kl_loss: 6.5335\n",
            "Epoch 53/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 488.8666 - reconstruction_loss: 480.9960 - kl_loss: 6.3883\n",
            "Epoch 54/300\n",
            "10/10 [==============================] - 1s 71ms/step - loss: 487.5735 - reconstruction_loss: 479.5871 - kl_loss: 6.3855\n",
            "Epoch 55/300\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 488.2156 - reconstruction_loss: 479.3405 - kl_loss: 6.4661\n",
            "Epoch 56/300\n",
            "10/10 [==============================] - 1s 75ms/step - loss: 483.4906 - reconstruction_loss: 477.8495 - kl_loss: 6.5897\n",
            "Epoch 57/300\n",
            "10/10 [==============================] - 1s 75ms/step - loss: 486.8062 - reconstruction_loss: 478.7143 - kl_loss: 6.6411\n",
            "Epoch 58/300\n",
            "10/10 [==============================] - 1s 76ms/step - loss: 486.5571 - reconstruction_loss: 477.9605 - kl_loss: 6.6502\n",
            "Epoch 59/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 490.2624 - reconstruction_loss: 478.6512 - kl_loss: 6.5351\n",
            "Epoch 60/300\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 482.7729 - reconstruction_loss: 477.5259 - kl_loss: 6.5511\n",
            "Epoch 61/300\n",
            "10/10 [==============================] - 1s 96ms/step - loss: 483.6200 - reconstruction_loss: 478.5968 - kl_loss: 6.5375\n",
            "Epoch 62/300\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 483.1116 - reconstruction_loss: 478.0587 - kl_loss: 6.5805\n",
            "Epoch 63/300\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 488.9682 - reconstruction_loss: 478.7682 - kl_loss: 6.5233\n",
            "Epoch 64/300\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 485.6153 - reconstruction_loss: 478.9318 - kl_loss: 6.6819\n",
            "Epoch 65/300\n",
            "10/10 [==============================] - 1s 74ms/step - loss: 483.7081 - reconstruction_loss: 478.9167 - kl_loss: 6.6133\n",
            "Epoch 66/300\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 487.0656 - reconstruction_loss: 478.4955 - kl_loss: 6.5035\n",
            "Epoch 67/300\n",
            "10/10 [==============================] - 1s 76ms/step - loss: 484.2057 - reconstruction_loss: 478.6318 - kl_loss: 6.4351\n",
            "Epoch 68/300\n",
            "10/10 [==============================] - 1s 74ms/step - loss: 485.8259 - reconstruction_loss: 478.9376 - kl_loss: 6.4859\n",
            "Epoch 69/300\n",
            "10/10 [==============================] - 1s 75ms/step - loss: 485.0152 - reconstruction_loss: 474.4866 - kl_loss: 6.6252\n",
            "Epoch 70/300\n",
            "10/10 [==============================] - 1s 79ms/step - loss: 474.3088 - reconstruction_loss: 475.3303 - kl_loss: 6.5287\n",
            "Epoch 71/300\n",
            "10/10 [==============================] - 1s 74ms/step - loss: 480.7243 - reconstruction_loss: 475.8620 - kl_loss: 6.5370\n",
            "Epoch 72/300\n",
            "10/10 [==============================] - 1s 74ms/step - loss: 480.2924 - reconstruction_loss: 478.3675 - kl_loss: 6.6175\n",
            "Epoch 73/300\n",
            "10/10 [==============================] - 1s 77ms/step - loss: 485.9927 - reconstruction_loss: 477.3008 - kl_loss: 6.4908\n",
            "Epoch 74/300\n",
            "10/10 [==============================] - 1s 94ms/step - loss: 483.3876 - reconstruction_loss: 477.5659 - kl_loss: 6.4533\n",
            "Epoch 75/300\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 482.7626 - reconstruction_loss: 476.7679 - kl_loss: 6.4651\n",
            "Epoch 76/300\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 481.8244 - reconstruction_loss: 475.8535 - kl_loss: 6.5723\n",
            "Epoch 77/300\n",
            "10/10 [==============================] - 1s 75ms/step - loss: 474.5322 - reconstruction_loss: 475.5034 - kl_loss: 6.6693\n",
            "Epoch 78/300\n",
            "10/10 [==============================] - 1s 71ms/step - loss: 476.7539 - reconstruction_loss: 476.0506 - kl_loss: 6.7390\n",
            "Epoch 79/300\n",
            "10/10 [==============================] - 1s 75ms/step - loss: 486.3080 - reconstruction_loss: 478.6308 - kl_loss: 6.6693\n",
            "Epoch 80/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 481.1218 - reconstruction_loss: 477.1323 - kl_loss: 6.6922\n",
            "Epoch 81/300\n",
            "10/10 [==============================] - 1s 75ms/step - loss: 489.5252 - reconstruction_loss: 477.8544 - kl_loss: 6.6006\n",
            "Epoch 82/300\n",
            "10/10 [==============================] - 1s 74ms/step - loss: 484.5703 - reconstruction_loss: 478.4207 - kl_loss: 6.3620\n",
            "Epoch 83/300\n",
            "10/10 [==============================] - 1s 74ms/step - loss: 487.3984 - reconstruction_loss: 477.8511 - kl_loss: 6.5537\n",
            "Epoch 84/300\n",
            "10/10 [==============================] - 1s 76ms/step - loss: 482.9200 - reconstruction_loss: 475.8593 - kl_loss: 6.6950\n",
            "Epoch 85/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 484.7589 - reconstruction_loss: 475.3722 - kl_loss: 6.6478\n",
            "Epoch 86/300\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 485.4425 - reconstruction_loss: 476.8555 - kl_loss: 6.5778\n",
            "Epoch 87/300\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 477.3008 - reconstruction_loss: 473.3167 - kl_loss: 6.5940\n",
            "Epoch 88/300\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 486.4440 - reconstruction_loss: 475.7332 - kl_loss: 6.5208\n",
            "Epoch 89/300\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 479.9627 - reconstruction_loss: 474.5963 - kl_loss: 6.4743\n",
            "Epoch 90/300\n",
            "10/10 [==============================] - 1s 77ms/step - loss: 491.5136 - reconstruction_loss: 475.7795 - kl_loss: 6.6099\n",
            "Epoch 91/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 478.8176 - reconstruction_loss: 474.2068 - kl_loss: 6.7094\n",
            "Epoch 92/300\n",
            "10/10 [==============================] - 1s 75ms/step - loss: 481.2011 - reconstruction_loss: 474.6482 - kl_loss: 6.6844\n",
            "Epoch 93/300\n",
            "10/10 [==============================] - 1s 75ms/step - loss: 471.4078 - reconstruction_loss: 473.1728 - kl_loss: 6.7188\n",
            "Epoch 94/300\n",
            "10/10 [==============================] - 1s 81ms/step - loss: 480.0397 - reconstruction_loss: 474.8205 - kl_loss: 6.6793\n",
            "Epoch 95/300\n",
            "10/10 [==============================] - 1s 71ms/step - loss: 477.1539 - reconstruction_loss: 474.6293 - kl_loss: 6.5815\n",
            "Epoch 96/300\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 480.8553 - reconstruction_loss: 474.0542 - kl_loss: 6.5379\n",
            "Epoch 97/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 480.8264 - reconstruction_loss: 474.3685 - kl_loss: 6.5576\n",
            "Epoch 98/300\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 482.7538 - reconstruction_loss: 475.3664 - kl_loss: 6.6873\n",
            "Epoch 99/300\n",
            "10/10 [==============================] - 1s 94ms/step - loss: 481.8836 - reconstruction_loss: 473.8641 - kl_loss: 6.7535\n",
            "Epoch 100/300\n",
            "10/10 [==============================] - 1s 95ms/step - loss: 480.4319 - reconstruction_loss: 474.7998 - kl_loss: 6.8658\n",
            "Epoch 101/300\n",
            "10/10 [==============================] - 1s 96ms/step - loss: 477.0656 - reconstruction_loss: 473.9850 - kl_loss: 6.7919\n",
            "Epoch 102/300\n",
            "10/10 [==============================] - 1s 88ms/step - loss: 477.6353 - reconstruction_loss: 473.9799 - kl_loss: 6.6387\n",
            "Epoch 103/300\n",
            "10/10 [==============================] - 1s 79ms/step - loss: 482.2505 - reconstruction_loss: 473.5585 - kl_loss: 6.6535\n",
            "Epoch 104/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 475.4093 - reconstruction_loss: 473.5207 - kl_loss: 6.7334\n",
            "Epoch 105/300\n",
            "10/10 [==============================] - 1s 79ms/step - loss: 481.1034 - reconstruction_loss: 471.6574 - kl_loss: 6.8911\n",
            "Epoch 106/300\n",
            "10/10 [==============================] - 1s 76ms/step - loss: 475.1068 - reconstruction_loss: 470.7560 - kl_loss: 6.8960\n",
            "Epoch 107/300\n",
            "10/10 [==============================] - 1s 76ms/step - loss: 476.0165 - reconstruction_loss: 472.8761 - kl_loss: 6.7558\n",
            "Epoch 108/300\n",
            "10/10 [==============================] - 1s 74ms/step - loss: 477.4190 - reconstruction_loss: 472.7007 - kl_loss: 6.6602\n",
            "Epoch 109/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 477.4619 - reconstruction_loss: 474.7313 - kl_loss: 6.6114\n",
            "Epoch 110/300\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 483.8381 - reconstruction_loss: 472.5763 - kl_loss: 6.7494\n",
            "Epoch 111/300\n",
            "10/10 [==============================] - 1s 70ms/step - loss: 476.5827 - reconstruction_loss: 472.7881 - kl_loss: 6.8579\n",
            "Epoch 112/300\n",
            "10/10 [==============================] - 1s 95ms/step - loss: 477.5651 - reconstruction_loss: 472.1888 - kl_loss: 6.8916\n",
            "Epoch 113/300\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 477.8889 - reconstruction_loss: 471.8987 - kl_loss: 6.8423\n",
            "Epoch 114/300\n",
            "10/10 [==============================] - 1s 110ms/step - loss: 483.2892 - reconstruction_loss: 472.5617 - kl_loss: 6.7456\n",
            "Epoch 115/300\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 476.9675 - reconstruction_loss: 473.5403 - kl_loss: 6.6711\n",
            "Epoch 116/300\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 478.5724 - reconstruction_loss: 472.9673 - kl_loss: 6.9077\n",
            "Epoch 117/300\n",
            "10/10 [==============================] - 1s 75ms/step - loss: 480.1600 - reconstruction_loss: 471.1640 - kl_loss: 6.9241\n",
            "Epoch 118/300\n",
            "10/10 [==============================] - 1s 76ms/step - loss: 476.0565 - reconstruction_loss: 472.2444 - kl_loss: 6.8114\n",
            "Epoch 119/300\n",
            "10/10 [==============================] - 1s 75ms/step - loss: 482.4736 - reconstruction_loss: 471.3464 - kl_loss: 6.8467\n",
            "Epoch 120/300\n",
            "10/10 [==============================] - 1s 76ms/step - loss: 480.7972 - reconstruction_loss: 470.4332 - kl_loss: 6.8043\n",
            "Epoch 121/300\n",
            "10/10 [==============================] - 1s 74ms/step - loss: 473.9615 - reconstruction_loss: 472.8052 - kl_loss: 6.7251\n",
            "Epoch 122/300\n",
            "10/10 [==============================] - 1s 79ms/step - loss: 475.6174 - reconstruction_loss: 470.8875 - kl_loss: 6.8038\n",
            "Epoch 123/300\n",
            "10/10 [==============================] - 1s 74ms/step - loss: 477.1890 - reconstruction_loss: 472.2206 - kl_loss: 6.8573\n",
            "Epoch 124/300\n",
            "10/10 [==============================] - 1s 77ms/step - loss: 480.0107 - reconstruction_loss: 473.0072 - kl_loss: 6.8754\n",
            "Epoch 125/300\n",
            "10/10 [==============================] - 1s 88ms/step - loss: 475.0808 - reconstruction_loss: 471.1898 - kl_loss: 6.9284\n",
            "Epoch 126/300\n",
            "10/10 [==============================] - 1s 100ms/step - loss: 468.9598 - reconstruction_loss: 471.3429 - kl_loss: 6.7728\n",
            "Epoch 127/300\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 481.6611 - reconstruction_loss: 471.4127 - kl_loss: 6.8161\n",
            "Epoch 128/300\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 471.7184 - reconstruction_loss: 470.3359 - kl_loss: 6.9168\n",
            "Epoch 129/300\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 481.4681 - reconstruction_loss: 471.5445 - kl_loss: 6.8914\n",
            "Epoch 130/300\n",
            "10/10 [==============================] - 1s 89ms/step - loss: 477.4496 - reconstruction_loss: 470.6570 - kl_loss: 6.8088\n",
            "Epoch 131/300\n",
            "10/10 [==============================] - 1s 76ms/step - loss: 468.4315 - reconstruction_loss: 471.6153 - kl_loss: 6.7238\n",
            "Epoch 132/300\n",
            "10/10 [==============================] - 1s 77ms/step - loss: 478.3317 - reconstruction_loss: 470.7243 - kl_loss: 6.8121\n",
            "Epoch 133/300\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 472.2282 - reconstruction_loss: 470.7554 - kl_loss: 6.7866\n",
            "Epoch 134/300\n",
            "10/10 [==============================] - 1s 74ms/step - loss: 478.5407 - reconstruction_loss: 471.0713 - kl_loss: 6.9115\n",
            "Epoch 135/300\n",
            "10/10 [==============================] - 1s 80ms/step - loss: 475.8142 - reconstruction_loss: 471.5229 - kl_loss: 6.9557\n",
            "Epoch 136/300\n",
            "10/10 [==============================] - 1s 78ms/step - loss: 480.5869 - reconstruction_loss: 471.8533 - kl_loss: 7.0091\n",
            "Epoch 137/300\n",
            "10/10 [==============================] - 1s 78ms/step - loss: 481.1534 - reconstruction_loss: 471.4761 - kl_loss: 6.9593\n",
            "Epoch 138/300\n",
            "10/10 [==============================] - 1s 74ms/step - loss: 474.3215 - reconstruction_loss: 470.8625 - kl_loss: 6.7939\n",
            "Epoch 139/300\n",
            "10/10 [==============================] - 1s 81ms/step - loss: 481.6716 - reconstruction_loss: 471.9497 - kl_loss: 6.7519\n",
            "Epoch 140/300\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 478.4773 - reconstruction_loss: 471.8446 - kl_loss: 6.8730\n",
            "Epoch 141/300\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 480.8415 - reconstruction_loss: 470.2257 - kl_loss: 6.9212\n",
            "Epoch 142/300\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 479.5357 - reconstruction_loss: 473.0143 - kl_loss: 6.7995\n",
            "Epoch 143/300\n",
            "10/10 [==============================] - 1s 77ms/step - loss: 475.3425 - reconstruction_loss: 469.7486 - kl_loss: 6.8696\n",
            "Epoch 144/300\n",
            "10/10 [==============================] - 1s 77ms/step - loss: 474.3889 - reconstruction_loss: 471.5806 - kl_loss: 6.8054\n",
            "Epoch 145/300\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 471.4269 - reconstruction_loss: 469.7102 - kl_loss: 6.8937\n",
            "Epoch 146/300\n",
            "10/10 [==============================] - 1s 75ms/step - loss: 474.6099 - reconstruction_loss: 471.0711 - kl_loss: 6.9212\n",
            "Epoch 147/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 474.0869 - reconstruction_loss: 469.4520 - kl_loss: 6.8986\n",
            "Epoch 148/300\n",
            "10/10 [==============================] - 1s 69ms/step - loss: 476.7720 - reconstruction_loss: 471.5960 - kl_loss: 6.7631\n",
            "Epoch 149/300\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 475.6236 - reconstruction_loss: 469.2397 - kl_loss: 6.8483\n",
            "Epoch 150/300\n",
            "10/10 [==============================] - 1s 74ms/step - loss: 476.3409 - reconstruction_loss: 471.5383 - kl_loss: 6.8357\n",
            "Epoch 151/300\n",
            "10/10 [==============================] - 1s 77ms/step - loss: 473.2035 - reconstruction_loss: 471.0709 - kl_loss: 6.9606\n",
            "Epoch 152/300\n",
            "10/10 [==============================] - 1s 76ms/step - loss: 485.3454 - reconstruction_loss: 472.0239 - kl_loss: 6.9614\n",
            "Epoch 153/300\n",
            "10/10 [==============================] - 1s 91ms/step - loss: 478.0533 - reconstruction_loss: 471.2552 - kl_loss: 6.9939\n",
            "Epoch 154/300\n",
            "10/10 [==============================] - 1s 94ms/step - loss: 479.9563 - reconstruction_loss: 469.3779 - kl_loss: 7.1006\n",
            "Epoch 155/300\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 481.3489 - reconstruction_loss: 468.9872 - kl_loss: 6.8821\n",
            "Epoch 156/300\n",
            "10/10 [==============================] - 1s 90ms/step - loss: 474.6147 - reconstruction_loss: 468.5181 - kl_loss: 6.8563\n",
            "Epoch 157/300\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 475.0142 - reconstruction_loss: 470.5248 - kl_loss: 6.8483\n",
            "Epoch 158/300\n",
            "10/10 [==============================] - 1s 80ms/step - loss: 478.5470 - reconstruction_loss: 470.4549 - kl_loss: 6.8501\n",
            "Epoch 159/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 473.3837 - reconstruction_loss: 469.0758 - kl_loss: 6.9731\n",
            "Epoch 160/300\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 480.8894 - reconstruction_loss: 469.2772 - kl_loss: 6.8528\n",
            "Epoch 161/300\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 474.9729 - reconstruction_loss: 470.5512 - kl_loss: 6.8095\n",
            "Epoch 162/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 476.6736 - reconstruction_loss: 468.6562 - kl_loss: 7.0111\n",
            "Epoch 163/300\n",
            "10/10 [==============================] - 1s 76ms/step - loss: 473.4359 - reconstruction_loss: 467.9476 - kl_loss: 7.0487\n",
            "Epoch 164/300\n",
            "10/10 [==============================] - 1s 76ms/step - loss: 470.7360 - reconstruction_loss: 468.5749 - kl_loss: 6.9895\n",
            "Epoch 165/300\n",
            "10/10 [==============================] - 1s 74ms/step - loss: 479.3884 - reconstruction_loss: 468.9409 - kl_loss: 6.9566\n",
            "Epoch 166/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 476.9731 - reconstruction_loss: 467.6341 - kl_loss: 6.9900\n",
            "Epoch 167/300\n",
            "10/10 [==============================] - 1s 71ms/step - loss: 472.3861 - reconstruction_loss: 468.1719 - kl_loss: 7.0707\n",
            "Epoch 168/300\n",
            "10/10 [==============================] - 1s 99ms/step - loss: 475.6004 - reconstruction_loss: 469.5982 - kl_loss: 7.0211\n",
            "Epoch 169/300\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 473.3079 - reconstruction_loss: 468.7913 - kl_loss: 6.9176\n",
            "Epoch 170/300\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 476.7491 - reconstruction_loss: 469.3237 - kl_loss: 6.8785\n",
            "Epoch 171/300\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 473.8322 - reconstruction_loss: 468.9132 - kl_loss: 6.9078\n",
            "Epoch 172/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 478.9205 - reconstruction_loss: 469.5184 - kl_loss: 6.9264\n",
            "Epoch 173/300\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 482.5471 - reconstruction_loss: 469.1949 - kl_loss: 6.9642\n",
            "Epoch 174/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 480.6046 - reconstruction_loss: 468.4859 - kl_loss: 6.9987\n",
            "Epoch 175/300\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 479.8126 - reconstruction_loss: 465.9373 - kl_loss: 6.9781\n",
            "Epoch 176/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 477.6482 - reconstruction_loss: 468.4865 - kl_loss: 6.9965\n",
            "Epoch 177/300\n",
            "10/10 [==============================] - 1s 75ms/step - loss: 472.9018 - reconstruction_loss: 468.3530 - kl_loss: 7.0539\n",
            "Epoch 178/300\n",
            "10/10 [==============================] - 1s 74ms/step - loss: 472.9475 - reconstruction_loss: 467.4986 - kl_loss: 7.0115\n",
            "Epoch 179/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 478.1850 - reconstruction_loss: 468.2853 - kl_loss: 6.9356\n",
            "Epoch 180/300\n",
            "10/10 [==============================] - 1s 71ms/step - loss: 474.8358 - reconstruction_loss: 467.8700 - kl_loss: 6.9753\n",
            "Epoch 181/300\n",
            "10/10 [==============================] - 1s 75ms/step - loss: 476.2271 - reconstruction_loss: 468.3082 - kl_loss: 7.0155\n",
            "Epoch 182/300\n",
            "10/10 [==============================] - 1s 91ms/step - loss: 477.0465 - reconstruction_loss: 466.3925 - kl_loss: 6.9652\n",
            "Epoch 183/300\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 470.0898 - reconstruction_loss: 467.4644 - kl_loss: 6.9462\n",
            "Epoch 184/300\n",
            "10/10 [==============================] - 1s 95ms/step - loss: 470.0917 - reconstruction_loss: 467.2914 - kl_loss: 6.9542\n",
            "Epoch 185/300\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 474.2986 - reconstruction_loss: 469.0718 - kl_loss: 7.0459\n",
            "Epoch 186/300\n",
            "10/10 [==============================] - 1s 96ms/step - loss: 479.6772 - reconstruction_loss: 468.3738 - kl_loss: 7.0995\n",
            "Epoch 187/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 467.7945 - reconstruction_loss: 467.1505 - kl_loss: 7.0359\n",
            "Epoch 188/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 474.6020 - reconstruction_loss: 466.5911 - kl_loss: 7.0286\n",
            "Epoch 189/300\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 471.8600 - reconstruction_loss: 467.1678 - kl_loss: 6.9662\n",
            "Epoch 190/300\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 477.3881 - reconstruction_loss: 465.3682 - kl_loss: 6.9870\n",
            "Epoch 191/300\n",
            "10/10 [==============================] - 1s 79ms/step - loss: 479.3439 - reconstruction_loss: 468.3327 - kl_loss: 7.0525\n",
            "Epoch 192/300\n",
            "10/10 [==============================] - 1s 75ms/step - loss: 469.7155 - reconstruction_loss: 465.8435 - kl_loss: 7.0933\n",
            "Epoch 193/300\n",
            "10/10 [==============================] - 1s 74ms/step - loss: 465.7152 - reconstruction_loss: 466.7609 - kl_loss: 6.9954\n",
            "Epoch 194/300\n",
            "10/10 [==============================] - 1s 75ms/step - loss: 465.1135 - reconstruction_loss: 466.6264 - kl_loss: 7.0680\n",
            "Epoch 195/300\n",
            "10/10 [==============================] - 1s 82ms/step - loss: 469.0835 - reconstruction_loss: 465.8364 - kl_loss: 7.0986\n",
            "Epoch 196/300\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 480.5963 - reconstruction_loss: 467.6214 - kl_loss: 7.0383\n",
            "Epoch 197/300\n",
            "10/10 [==============================] - 1s 110ms/step - loss: 471.8807 - reconstruction_loss: 467.2932 - kl_loss: 7.1756\n",
            "Epoch 198/300\n",
            "10/10 [==============================] - 1s 100ms/step - loss: 479.1524 - reconstruction_loss: 467.2284 - kl_loss: 7.0818\n",
            "Epoch 199/300\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 477.1981 - reconstruction_loss: 467.4109 - kl_loss: 6.9940\n",
            "Epoch 200/300\n",
            "10/10 [==============================] - 1s 96ms/step - loss: 471.3639 - reconstruction_loss: 465.9208 - kl_loss: 6.9446\n",
            "Epoch 201/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 477.0125 - reconstruction_loss: 467.1661 - kl_loss: 6.8769\n",
            "Epoch 202/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 466.6767 - reconstruction_loss: 466.8407 - kl_loss: 6.9894\n",
            "Epoch 203/300\n",
            "10/10 [==============================] - 1s 68ms/step - loss: 470.8093 - reconstruction_loss: 467.0241 - kl_loss: 7.0039\n",
            "Epoch 204/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 476.7252 - reconstruction_loss: 466.8428 - kl_loss: 6.9760\n",
            "Epoch 205/300\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 464.1148 - reconstruction_loss: 467.1405 - kl_loss: 6.9527\n",
            "Epoch 206/300\n",
            "10/10 [==============================] - 1s 70ms/step - loss: 470.4820 - reconstruction_loss: 467.6403 - kl_loss: 7.0851\n",
            "Epoch 207/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 483.1251 - reconstruction_loss: 468.7031 - kl_loss: 7.0778\n",
            "Epoch 208/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 471.5613 - reconstruction_loss: 467.6397 - kl_loss: 7.1764\n",
            "Epoch 209/300\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 466.6487 - reconstruction_loss: 466.6559 - kl_loss: 7.2523\n",
            "Epoch 210/300\n",
            "10/10 [==============================] - 1s 74ms/step - loss: 479.3908 - reconstruction_loss: 467.1768 - kl_loss: 7.1717\n",
            "Epoch 211/300\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 474.7861 - reconstruction_loss: 465.7242 - kl_loss: 7.1526\n",
            "Epoch 212/300\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 469.8066 - reconstruction_loss: 464.9324 - kl_loss: 7.0677\n",
            "Epoch 213/300\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 473.0803 - reconstruction_loss: 466.1064 - kl_loss: 6.9830\n",
            "Epoch 214/300\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 470.8099 - reconstruction_loss: 466.4135 - kl_loss: 6.9120\n",
            "Epoch 215/300\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 472.6304 - reconstruction_loss: 466.6075 - kl_loss: 7.0429\n",
            "Epoch 216/300\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 471.8151 - reconstruction_loss: 464.8840 - kl_loss: 7.1485\n",
            "Epoch 217/300\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 466.5196 - reconstruction_loss: 465.8129 - kl_loss: 7.1464\n",
            "Epoch 218/300\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 476.2638 - reconstruction_loss: 466.0903 - kl_loss: 7.1834\n",
            "Epoch 219/300\n",
            "10/10 [==============================] - 1s 78ms/step - loss: 470.2133 - reconstruction_loss: 465.6220 - kl_loss: 7.1499\n",
            "Epoch 220/300\n",
            "10/10 [==============================] - 1s 75ms/step - loss: 476.8764 - reconstruction_loss: 466.4302 - kl_loss: 7.0689\n",
            "Epoch 221/300\n",
            "10/10 [==============================] - 1s 74ms/step - loss: 473.3576 - reconstruction_loss: 467.2480 - kl_loss: 6.9530\n",
            "Epoch 222/300\n",
            "10/10 [==============================] - 1s 74ms/step - loss: 466.6814 - reconstruction_loss: 464.2917 - kl_loss: 6.9823\n",
            "Epoch 223/300\n",
            "10/10 [==============================] - 1s 70ms/step - loss: 474.5384 - reconstruction_loss: 465.8368 - kl_loss: 6.9279\n",
            "Epoch 224/300\n",
            "10/10 [==============================] - 1s 89ms/step - loss: 478.3221 - reconstruction_loss: 466.0487 - kl_loss: 6.9272\n",
            "Epoch 225/300\n",
            "10/10 [==============================] - 1s 100ms/step - loss: 472.7302 - reconstruction_loss: 466.9973 - kl_loss: 6.9788\n",
            "Epoch 226/300\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 471.6352 - reconstruction_loss: 465.5413 - kl_loss: 7.0222\n",
            "Epoch 227/300\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 470.2169 - reconstruction_loss: 468.2662 - kl_loss: 7.1499\n",
            "Epoch 228/300\n",
            "10/10 [==============================] - 1s 74ms/step - loss: 477.5099 - reconstruction_loss: 466.9121 - kl_loss: 7.1872\n",
            "Epoch 229/300\n",
            "10/10 [==============================] - 1s 71ms/step - loss: 474.9363 - reconstruction_loss: 467.6686 - kl_loss: 7.1836\n",
            "Epoch 230/300\n",
            "10/10 [==============================] - 1s 78ms/step - loss: 478.9919 - reconstruction_loss: 467.3388 - kl_loss: 7.0426\n",
            "Epoch 231/300\n",
            "10/10 [==============================] - 1s 75ms/step - loss: 470.2902 - reconstruction_loss: 464.9455 - kl_loss: 7.0706\n",
            "Epoch 232/300\n",
            "10/10 [==============================] - 1s 70ms/step - loss: 477.0510 - reconstruction_loss: 468.5531 - kl_loss: 7.0721\n",
            "Epoch 233/300\n",
            "10/10 [==============================] - 1s 75ms/step - loss: 469.5026 - reconstruction_loss: 466.5688 - kl_loss: 7.1162\n",
            "Epoch 234/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 472.0430 - reconstruction_loss: 466.3888 - kl_loss: 7.0910\n",
            "Epoch 235/300\n",
            "10/10 [==============================] - 1s 71ms/step - loss: 468.1423 - reconstruction_loss: 464.7356 - kl_loss: 7.0859\n",
            "Epoch 236/300\n",
            "10/10 [==============================] - 1s 68ms/step - loss: 472.5876 - reconstruction_loss: 467.4019 - kl_loss: 7.0777\n",
            "Epoch 237/300\n",
            "10/10 [==============================] - 1s 71ms/step - loss: 468.1484 - reconstruction_loss: 466.6782 - kl_loss: 6.9361\n",
            "Epoch 238/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 474.0254 - reconstruction_loss: 465.4385 - kl_loss: 6.9552\n",
            "Epoch 239/300\n",
            "10/10 [==============================] - 1s 89ms/step - loss: 476.1718 - reconstruction_loss: 466.5123 - kl_loss: 7.0022\n",
            "Epoch 240/300\n",
            "10/10 [==============================] - 1s 100ms/step - loss: 471.7658 - reconstruction_loss: 464.5176 - kl_loss: 7.0961\n",
            "Epoch 241/300\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 472.7324 - reconstruction_loss: 465.2383 - kl_loss: 7.0994\n",
            "Epoch 242/300\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 473.0160 - reconstruction_loss: 466.5092 - kl_loss: 7.0340\n",
            "Epoch 243/300\n",
            "10/10 [==============================] - 1s 75ms/step - loss: 467.4097 - reconstruction_loss: 464.6229 - kl_loss: 7.0216\n",
            "Epoch 244/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 470.4230 - reconstruction_loss: 464.2354 - kl_loss: 7.1003\n",
            "Epoch 245/300\n",
            "10/10 [==============================] - 1s 75ms/step - loss: 463.3345 - reconstruction_loss: 466.5475 - kl_loss: 7.1207\n",
            "Epoch 246/300\n",
            "10/10 [==============================] - 1s 77ms/step - loss: 473.2113 - reconstruction_loss: 464.1284 - kl_loss: 7.1871\n",
            "Epoch 247/300\n",
            "10/10 [==============================] - 1s 77ms/step - loss: 471.8551 - reconstruction_loss: 464.7155 - kl_loss: 7.1768\n",
            "Epoch 248/300\n",
            "10/10 [==============================] - 1s 76ms/step - loss: 471.1426 - reconstruction_loss: 465.9643 - kl_loss: 7.0398\n",
            "Epoch 249/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 471.3611 - reconstruction_loss: 465.3239 - kl_loss: 7.0089\n",
            "Epoch 250/300\n",
            "10/10 [==============================] - 1s 76ms/step - loss: 471.2973 - reconstruction_loss: 465.9940 - kl_loss: 7.0948\n",
            "Epoch 251/300\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 473.0214 - reconstruction_loss: 465.5324 - kl_loss: 7.1051\n",
            "Epoch 252/300\n",
            "10/10 [==============================] - 1s 75ms/step - loss: 470.8592 - reconstruction_loss: 466.4826 - kl_loss: 7.0836\n",
            "Epoch 253/300\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 472.9963 - reconstruction_loss: 466.0199 - kl_loss: 7.1624\n",
            "Epoch 254/300\n",
            "10/10 [==============================] - 1s 96ms/step - loss: 469.1397 - reconstruction_loss: 465.0626 - kl_loss: 7.1180\n",
            "Epoch 255/300\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 472.1728 - reconstruction_loss: 463.5844 - kl_loss: 7.0893\n",
            "Epoch 256/300\n",
            "10/10 [==============================] - 1s 93ms/step - loss: 474.9077 - reconstruction_loss: 465.0696 - kl_loss: 7.1013\n",
            "Epoch 257/300\n",
            "10/10 [==============================] - 1s 80ms/step - loss: 472.6625 - reconstruction_loss: 464.4152 - kl_loss: 7.1334\n",
            "Epoch 258/300\n",
            "10/10 [==============================] - 1s 75ms/step - loss: 470.5902 - reconstruction_loss: 463.6562 - kl_loss: 7.1865\n",
            "Epoch 259/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 463.4245 - reconstruction_loss: 463.6707 - kl_loss: 7.0852\n",
            "Epoch 260/300\n",
            "10/10 [==============================] - 1s 75ms/step - loss: 467.2092 - reconstruction_loss: 465.1124 - kl_loss: 7.1266\n",
            "Epoch 261/300\n",
            "10/10 [==============================] - 1s 76ms/step - loss: 473.2560 - reconstruction_loss: 465.5710 - kl_loss: 7.1966\n",
            "Epoch 262/300\n",
            "10/10 [==============================] - 1s 75ms/step - loss: 477.2900 - reconstruction_loss: 464.7111 - kl_loss: 7.1825\n",
            "Epoch 263/300\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 472.5265 - reconstruction_loss: 465.1108 - kl_loss: 7.1483\n",
            "Epoch 264/300\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 469.6621 - reconstruction_loss: 466.6411 - kl_loss: 7.1294\n",
            "Epoch 265/300\n",
            "10/10 [==============================] - 1s 89ms/step - loss: 473.7387 - reconstruction_loss: 463.9905 - kl_loss: 7.1235\n",
            "Epoch 266/300\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 473.4113 - reconstruction_loss: 463.6383 - kl_loss: 7.2314\n",
            "Epoch 267/300\n",
            "10/10 [==============================] - 1s 97ms/step - loss: 472.3851 - reconstruction_loss: 463.1331 - kl_loss: 7.2898\n",
            "Epoch 268/300\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 475.0849 - reconstruction_loss: 464.1106 - kl_loss: 7.2136\n",
            "Epoch 269/300\n",
            "10/10 [==============================] - 1s 76ms/step - loss: 469.7762 - reconstruction_loss: 466.4307 - kl_loss: 7.1081\n",
            "Epoch 270/300\n",
            "10/10 [==============================] - 1s 76ms/step - loss: 470.6079 - reconstruction_loss: 462.1503 - kl_loss: 7.2345\n",
            "Epoch 271/300\n",
            "10/10 [==============================] - 1s 75ms/step - loss: 468.8011 - reconstruction_loss: 465.3740 - kl_loss: 7.2388\n",
            "Epoch 272/300\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 465.9339 - reconstruction_loss: 463.0324 - kl_loss: 7.2256\n",
            "Epoch 273/300\n",
            "10/10 [==============================] - 1s 71ms/step - loss: 464.2304 - reconstruction_loss: 463.1993 - kl_loss: 7.1099\n",
            "Epoch 274/300\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 466.3715 - reconstruction_loss: 464.4190 - kl_loss: 7.0415\n",
            "Epoch 275/300\n",
            "10/10 [==============================] - 1s 75ms/step - loss: 465.7478 - reconstruction_loss: 464.0424 - kl_loss: 7.0724\n",
            "Epoch 276/300\n",
            "10/10 [==============================] - 1s 69ms/step - loss: 477.3510 - reconstruction_loss: 465.8622 - kl_loss: 7.0200\n",
            "Epoch 277/300\n",
            "10/10 [==============================] - 1s 71ms/step - loss: 478.2979 - reconstruction_loss: 463.7095 - kl_loss: 7.1000\n",
            "Epoch 278/300\n",
            "10/10 [==============================] - 1s 90ms/step - loss: 468.8033 - reconstruction_loss: 463.5191 - kl_loss: 7.2725\n",
            "Epoch 279/300\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 474.6230 - reconstruction_loss: 464.6774 - kl_loss: 7.2414\n",
            "Epoch 280/300\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 471.6369 - reconstruction_loss: 464.2924 - kl_loss: 7.1802\n",
            "Epoch 281/300\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 467.3058 - reconstruction_loss: 463.1964 - kl_loss: 7.0686\n",
            "Epoch 282/300\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 472.0209 - reconstruction_loss: 464.2708 - kl_loss: 7.0299\n",
            "Epoch 283/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 473.7585 - reconstruction_loss: 464.1947 - kl_loss: 7.1252\n",
            "Epoch 284/300\n",
            "10/10 [==============================] - 1s 71ms/step - loss: 471.1632 - reconstruction_loss: 464.3537 - kl_loss: 7.1915\n",
            "Epoch 285/300\n",
            "10/10 [==============================] - 1s 71ms/step - loss: 473.1861 - reconstruction_loss: 464.7874 - kl_loss: 7.2532\n",
            "Epoch 286/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 469.6906 - reconstruction_loss: 463.4252 - kl_loss: 7.3559\n",
            "Epoch 287/300\n",
            "10/10 [==============================] - 1s 71ms/step - loss: 475.1367 - reconstruction_loss: 464.2824 - kl_loss: 7.3217\n",
            "Epoch 288/300\n",
            "10/10 [==============================] - 1s 75ms/step - loss: 468.1511 - reconstruction_loss: 464.1569 - kl_loss: 7.2252\n",
            "Epoch 289/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 466.3168 - reconstruction_loss: 464.1226 - kl_loss: 7.1600\n",
            "Epoch 290/300\n",
            "10/10 [==============================] - 1s 69ms/step - loss: 472.7815 - reconstruction_loss: 464.3063 - kl_loss: 7.1970\n",
            "Epoch 291/300\n",
            "10/10 [==============================] - 1s 81ms/step - loss: 472.5808 - reconstruction_loss: 464.2602 - kl_loss: 7.2481\n",
            "Epoch 292/300\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 474.1678 - reconstruction_loss: 464.0788 - kl_loss: 7.1518\n",
            "Epoch 293/300\n",
            "10/10 [==============================] - 1s 94ms/step - loss: 469.7191 - reconstruction_loss: 462.0207 - kl_loss: 7.1436\n",
            "Epoch 294/300\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 468.6815 - reconstruction_loss: 463.6063 - kl_loss: 7.2184\n",
            "Epoch 295/300\n",
            "10/10 [==============================] - 1s 84ms/step - loss: 469.3021 - reconstruction_loss: 462.7739 - kl_loss: 7.1752\n",
            "Epoch 296/300\n",
            "10/10 [==============================] - 1s 70ms/step - loss: 473.8693 - reconstruction_loss: 464.9011 - kl_loss: 7.2208\n",
            "Epoch 297/300\n",
            "10/10 [==============================] - 1s 72ms/step - loss: 469.2629 - reconstruction_loss: 464.6230 - kl_loss: 7.2482\n",
            "Epoch 298/300\n",
            "10/10 [==============================] - 1s 73ms/step - loss: 465.2980 - reconstruction_loss: 462.9493 - kl_loss: 7.1937\n",
            "Epoch 299/300\n",
            "10/10 [==============================] - 1s 74ms/step - loss: 469.5926 - reconstruction_loss: 463.6362 - kl_loss: 7.2237\n",
            "Epoch 300/300\n",
            "10/10 [==============================] - 1s 74ms/step - loss: 466.6013 - reconstruction_loss: 463.7534 - kl_loss: 7.1628\n",
            "Found 39 images belonging to 1 classes.\n",
            "16/16 [==============================] - 0s 7ms/step\n",
            "Training VAE for class: Cat\n",
            "Found 262 images belonging to 1 classes.\n",
            "Epoch 1/300\n",
            "17/17 [==============================] - 5s 84ms/step - loss: 540.9686 - reconstruction_loss: 530.3130 - kl_loss: 6.8923\n",
            "Epoch 2/300\n",
            "17/17 [==============================] - 2s 91ms/step - loss: 516.8048 - reconstruction_loss: 509.8848 - kl_loss: 5.9822\n",
            "Epoch 3/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 504.7832 - reconstruction_loss: 503.9413 - kl_loss: 5.3593\n",
            "Epoch 4/300\n",
            "17/17 [==============================] - 1s 73ms/step - loss: 507.2905 - reconstruction_loss: 501.6618 - kl_loss: 5.2944\n",
            "Epoch 5/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 503.6725 - reconstruction_loss: 498.0300 - kl_loss: 5.4032\n",
            "Epoch 6/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 500.6374 - reconstruction_loss: 496.5190 - kl_loss: 5.6637\n",
            "Epoch 7/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 497.5046 - reconstruction_loss: 492.8466 - kl_loss: 5.7429\n",
            "Epoch 8/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 501.9440 - reconstruction_loss: 493.8745 - kl_loss: 5.7872\n",
            "Epoch 9/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 497.8900 - reconstruction_loss: 490.5604 - kl_loss: 5.8693\n",
            "Epoch 10/300\n",
            "17/17 [==============================] - 1s 71ms/step - loss: 496.7332 - reconstruction_loss: 491.1368 - kl_loss: 5.8402\n",
            "Epoch 11/300\n",
            "17/17 [==============================] - 2s 86ms/step - loss: 497.6662 - reconstruction_loss: 490.9117 - kl_loss: 5.9600\n",
            "Epoch 12/300\n",
            "17/17 [==============================] - 2s 100ms/step - loss: 489.2788 - reconstruction_loss: 491.2729 - kl_loss: 5.8663\n",
            "Epoch 13/300\n",
            "17/17 [==============================] - 2s 98ms/step - loss: 488.6906 - reconstruction_loss: 490.6263 - kl_loss: 5.9736\n",
            "Epoch 14/300\n",
            "17/17 [==============================] - 1s 76ms/step - loss: 496.6805 - reconstruction_loss: 487.9195 - kl_loss: 6.0020\n",
            "Epoch 15/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 489.8924 - reconstruction_loss: 487.1595 - kl_loss: 6.0180\n",
            "Epoch 16/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 490.9322 - reconstruction_loss: 486.5847 - kl_loss: 5.9823\n",
            "Epoch 17/300\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 496.7698 - reconstruction_loss: 487.7923 - kl_loss: 5.9875\n",
            "Epoch 18/300\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 492.8953 - reconstruction_loss: 484.3174 - kl_loss: 6.1134\n",
            "Epoch 19/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 490.7701 - reconstruction_loss: 485.3230 - kl_loss: 6.1109\n",
            "Epoch 20/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 496.4559 - reconstruction_loss: 486.4342 - kl_loss: 6.0294\n",
            "Epoch 21/300\n",
            "17/17 [==============================] - 1s 85ms/step - loss: 493.9816 - reconstruction_loss: 484.1947 - kl_loss: 6.1746\n",
            "Epoch 22/300\n",
            "17/17 [==============================] - 2s 86ms/step - loss: 487.6672 - reconstruction_loss: 484.6964 - kl_loss: 6.2088\n",
            "Epoch 23/300\n",
            "17/17 [==============================] - 1s 71ms/step - loss: 482.9393 - reconstruction_loss: 483.7193 - kl_loss: 6.2978\n",
            "Epoch 24/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 490.0530 - reconstruction_loss: 483.7232 - kl_loss: 6.1925\n",
            "Epoch 25/300\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 492.1131 - reconstruction_loss: 482.7384 - kl_loss: 6.0897\n",
            "Epoch 26/300\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 486.5630 - reconstruction_loss: 480.5191 - kl_loss: 6.1400\n",
            "Epoch 27/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 494.3283 - reconstruction_loss: 480.4040 - kl_loss: 6.1766\n",
            "Epoch 28/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 491.4709 - reconstruction_loss: 481.9660 - kl_loss: 6.1418\n",
            "Epoch 29/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 490.5481 - reconstruction_loss: 481.5109 - kl_loss: 6.1696\n",
            "Epoch 30/300\n",
            "17/17 [==============================] - 1s 79ms/step - loss: 490.7281 - reconstruction_loss: 482.4211 - kl_loss: 6.1353\n",
            "Epoch 31/300\n",
            "17/17 [==============================] - 2s 91ms/step - loss: 489.9225 - reconstruction_loss: 481.2022 - kl_loss: 6.3287\n",
            "Epoch 32/300\n",
            "17/17 [==============================] - 2s 93ms/step - loss: 488.0311 - reconstruction_loss: 481.1880 - kl_loss: 6.3550\n",
            "Epoch 33/300\n",
            "17/17 [==============================] - 2s 96ms/step - loss: 485.4479 - reconstruction_loss: 481.7597 - kl_loss: 6.4283\n",
            "Epoch 34/300\n",
            "17/17 [==============================] - 1s 73ms/step - loss: 482.7519 - reconstruction_loss: 479.3226 - kl_loss: 6.4066\n",
            "Epoch 35/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 480.2656 - reconstruction_loss: 478.8029 - kl_loss: 6.3773\n",
            "Epoch 36/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 487.7111 - reconstruction_loss: 479.5542 - kl_loss: 6.4048\n",
            "Epoch 37/300\n",
            "17/17 [==============================] - 1s 71ms/step - loss: 486.5619 - reconstruction_loss: 479.7542 - kl_loss: 6.5182\n",
            "Epoch 38/300\n",
            "17/17 [==============================] - 1s 71ms/step - loss: 484.1756 - reconstruction_loss: 479.0230 - kl_loss: 6.3583\n",
            "Epoch 39/300\n",
            "17/17 [==============================] - 1s 71ms/step - loss: 483.3776 - reconstruction_loss: 480.4915 - kl_loss: 6.3645\n",
            "Epoch 40/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 482.2638 - reconstruction_loss: 479.0024 - kl_loss: 6.3909\n",
            "Epoch 41/300\n",
            "17/17 [==============================] - 1s 87ms/step - loss: 483.6324 - reconstruction_loss: 479.7633 - kl_loss: 6.4498\n",
            "Epoch 42/300\n",
            "17/17 [==============================] - 2s 100ms/step - loss: 486.5179 - reconstruction_loss: 478.6137 - kl_loss: 6.5452\n",
            "Epoch 43/300\n",
            "17/17 [==============================] - 2s 94ms/step - loss: 484.0988 - reconstruction_loss: 478.0458 - kl_loss: 6.4728\n",
            "Epoch 44/300\n",
            "17/17 [==============================] - 1s 71ms/step - loss: 484.2602 - reconstruction_loss: 477.8529 - kl_loss: 6.4894\n",
            "Epoch 45/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 482.8651 - reconstruction_loss: 478.6333 - kl_loss: 6.3583\n",
            "Epoch 46/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 487.0140 - reconstruction_loss: 477.8059 - kl_loss: 6.5407\n",
            "Epoch 47/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 481.2970 - reconstruction_loss: 477.3625 - kl_loss: 6.4875\n",
            "Epoch 48/300\n",
            "17/17 [==============================] - 1s 71ms/step - loss: 487.1259 - reconstruction_loss: 476.8367 - kl_loss: 6.5654\n",
            "Epoch 49/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 481.7590 - reconstruction_loss: 477.0869 - kl_loss: 6.6124\n",
            "Epoch 50/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 484.3662 - reconstruction_loss: 478.1183 - kl_loss: 6.4290\n",
            "Epoch 51/300\n",
            "17/17 [==============================] - 1s 80ms/step - loss: 483.1786 - reconstruction_loss: 477.6368 - kl_loss: 6.6106\n",
            "Epoch 52/300\n",
            "17/17 [==============================] - 2s 89ms/step - loss: 486.1187 - reconstruction_loss: 476.6640 - kl_loss: 6.4839\n",
            "Epoch 53/300\n",
            "17/17 [==============================] - 1s 84ms/step - loss: 479.3334 - reconstruction_loss: 477.5901 - kl_loss: 6.6207\n",
            "Epoch 54/300\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 479.5394 - reconstruction_loss: 476.7179 - kl_loss: 6.7020\n",
            "Epoch 55/300\n",
            "17/17 [==============================] - 1s 73ms/step - loss: 478.9123 - reconstruction_loss: 477.0861 - kl_loss: 6.5229\n",
            "Epoch 56/300\n",
            "17/17 [==============================] - 1s 72ms/step - loss: 478.6555 - reconstruction_loss: 475.7945 - kl_loss: 6.5406\n",
            "Epoch 57/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 481.3818 - reconstruction_loss: 476.5823 - kl_loss: 6.6173\n",
            "Epoch 58/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 479.1851 - reconstruction_loss: 474.8860 - kl_loss: 6.7549\n",
            "Epoch 59/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 483.4583 - reconstruction_loss: 476.2679 - kl_loss: 6.6907\n",
            "Epoch 60/300\n",
            "17/17 [==============================] - 1s 76ms/step - loss: 481.1412 - reconstruction_loss: 475.5120 - kl_loss: 6.5232\n",
            "Epoch 61/300\n",
            "17/17 [==============================] - 2s 95ms/step - loss: 480.7681 - reconstruction_loss: 474.9528 - kl_loss: 6.5782\n",
            "Epoch 62/300\n",
            "17/17 [==============================] - 1s 79ms/step - loss: 478.5419 - reconstruction_loss: 474.5993 - kl_loss: 6.8192\n",
            "Epoch 63/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 481.3305 - reconstruction_loss: 473.2948 - kl_loss: 6.8356\n",
            "Epoch 64/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 482.6530 - reconstruction_loss: 475.7283 - kl_loss: 6.5302\n",
            "Epoch 65/300\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 482.0870 - reconstruction_loss: 473.8595 - kl_loss: 6.4575\n",
            "Epoch 66/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 480.1815 - reconstruction_loss: 473.4019 - kl_loss: 6.6063\n",
            "Epoch 67/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 479.8454 - reconstruction_loss: 473.8813 - kl_loss: 6.6895\n",
            "Epoch 68/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 482.7282 - reconstruction_loss: 474.5383 - kl_loss: 6.5814\n",
            "Epoch 69/300\n",
            "17/17 [==============================] - 1s 74ms/step - loss: 479.9689 - reconstruction_loss: 475.2197 - kl_loss: 6.5980\n",
            "Epoch 70/300\n",
            "17/17 [==============================] - 2s 90ms/step - loss: 477.7309 - reconstruction_loss: 473.2821 - kl_loss: 6.5700\n",
            "Epoch 71/300\n",
            "17/17 [==============================] - 1s 73ms/step - loss: 477.3928 - reconstruction_loss: 473.3446 - kl_loss: 6.6481\n",
            "Epoch 72/300\n",
            "17/17 [==============================] - 1s 73ms/step - loss: 479.0409 - reconstruction_loss: 472.4951 - kl_loss: 6.7661\n",
            "Epoch 73/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 479.7206 - reconstruction_loss: 473.1197 - kl_loss: 6.7932\n",
            "Epoch 74/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 477.1580 - reconstruction_loss: 471.5225 - kl_loss: 6.7855\n",
            "Epoch 75/300\n",
            "17/17 [==============================] - 1s 72ms/step - loss: 478.0219 - reconstruction_loss: 472.2560 - kl_loss: 6.8049\n",
            "Epoch 76/300\n",
            "17/17 [==============================] - 1s 77ms/step - loss: 480.8637 - reconstruction_loss: 472.7197 - kl_loss: 6.8735\n",
            "Epoch 77/300\n",
            "17/17 [==============================] - 2s 100ms/step - loss: 481.8253 - reconstruction_loss: 472.4294 - kl_loss: 6.8291\n",
            "Epoch 78/300\n",
            "17/17 [==============================] - 2s 103ms/step - loss: 482.2293 - reconstruction_loss: 472.8369 - kl_loss: 6.7484\n",
            "Epoch 79/300\n",
            "17/17 [==============================] - 1s 87ms/step - loss: 474.5470 - reconstruction_loss: 471.4573 - kl_loss: 6.7566\n",
            "Epoch 80/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 476.0294 - reconstruction_loss: 471.6370 - kl_loss: 6.7349\n",
            "Epoch 81/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 481.8476 - reconstruction_loss: 471.3529 - kl_loss: 6.8266\n",
            "Epoch 82/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 475.0912 - reconstruction_loss: 469.9552 - kl_loss: 6.8153\n",
            "Epoch 83/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 472.8992 - reconstruction_loss: 470.0386 - kl_loss: 6.8677\n",
            "Epoch 84/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 478.1413 - reconstruction_loss: 468.3947 - kl_loss: 6.8935\n",
            "Epoch 85/300\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 480.3764 - reconstruction_loss: 470.7328 - kl_loss: 6.8508\n",
            "Epoch 86/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 478.1423 - reconstruction_loss: 470.2146 - kl_loss: 6.8550\n",
            "Epoch 87/300\n",
            "17/17 [==============================] - 2s 87ms/step - loss: 475.1652 - reconstruction_loss: 469.5047 - kl_loss: 6.9157\n",
            "Epoch 88/300\n",
            "17/17 [==============================] - 2s 96ms/step - loss: 474.6072 - reconstruction_loss: 469.3961 - kl_loss: 6.8602\n",
            "Epoch 89/300\n",
            "17/17 [==============================] - 2s 89ms/step - loss: 476.1659 - reconstruction_loss: 468.7903 - kl_loss: 6.7959\n",
            "Epoch 90/300\n",
            "17/17 [==============================] - 1s 72ms/step - loss: 479.4920 - reconstruction_loss: 471.4905 - kl_loss: 6.7745\n",
            "Epoch 91/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 481.9343 - reconstruction_loss: 471.3519 - kl_loss: 6.8444\n",
            "Epoch 92/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 474.7221 - reconstruction_loss: 470.8659 - kl_loss: 6.8946\n",
            "Epoch 93/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 474.6330 - reconstruction_loss: 471.7324 - kl_loss: 6.7584\n",
            "Epoch 94/300\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 475.7210 - reconstruction_loss: 472.0757 - kl_loss: 6.7899\n",
            "Epoch 95/300\n",
            "17/17 [==============================] - 1s 76ms/step - loss: 473.6347 - reconstruction_loss: 471.1766 - kl_loss: 6.9874\n",
            "Epoch 96/300\n",
            "17/17 [==============================] - 1s 83ms/step - loss: 478.3028 - reconstruction_loss: 470.1967 - kl_loss: 7.0123\n",
            "Epoch 97/300\n",
            "17/17 [==============================] - 2s 91ms/step - loss: 473.7825 - reconstruction_loss: 467.7426 - kl_loss: 6.9801\n",
            "Epoch 98/300\n",
            "17/17 [==============================] - 1s 77ms/step - loss: 477.9604 - reconstruction_loss: 469.4520 - kl_loss: 6.9682\n",
            "Epoch 99/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 475.4492 - reconstruction_loss: 468.0997 - kl_loss: 6.8813\n",
            "Epoch 100/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 481.1383 - reconstruction_loss: 468.7486 - kl_loss: 6.8682\n",
            "Epoch 101/300\n",
            "17/17 [==============================] - 1s 71ms/step - loss: 483.5976 - reconstruction_loss: 470.8250 - kl_loss: 6.9392\n",
            "Epoch 102/300\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 478.7226 - reconstruction_loss: 469.3109 - kl_loss: 7.0018\n",
            "Epoch 103/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 478.3176 - reconstruction_loss: 468.3286 - kl_loss: 6.8956\n",
            "Epoch 104/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 474.5645 - reconstruction_loss: 468.7165 - kl_loss: 6.8951\n",
            "Epoch 105/300\n",
            "17/17 [==============================] - 1s 84ms/step - loss: 472.2522 - reconstruction_loss: 468.1008 - kl_loss: 6.8898\n",
            "Epoch 106/300\n",
            "17/17 [==============================] - 2s 93ms/step - loss: 476.8598 - reconstruction_loss: 467.3411 - kl_loss: 6.9968\n",
            "Epoch 107/300\n",
            "17/17 [==============================] - 1s 72ms/step - loss: 479.6728 - reconstruction_loss: 471.2949 - kl_loss: 7.0288\n",
            "Epoch 108/300\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 469.9017 - reconstruction_loss: 469.3940 - kl_loss: 6.9989\n",
            "Epoch 109/300\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 476.3803 - reconstruction_loss: 470.0435 - kl_loss: 6.8542\n",
            "Epoch 110/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 468.5960 - reconstruction_loss: 466.5046 - kl_loss: 6.8823\n",
            "Epoch 111/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 473.8880 - reconstruction_loss: 467.2815 - kl_loss: 6.9637\n",
            "Epoch 112/300\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 474.1402 - reconstruction_loss: 468.6737 - kl_loss: 6.9352\n",
            "Epoch 113/300\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 479.7015 - reconstruction_loss: 469.2243 - kl_loss: 6.9981\n",
            "Epoch 114/300\n",
            "17/17 [==============================] - 1s 82ms/step - loss: 475.7604 - reconstruction_loss: 469.3857 - kl_loss: 6.9243\n",
            "Epoch 115/300\n",
            "17/17 [==============================] - 2s 91ms/step - loss: 471.6416 - reconstruction_loss: 467.1048 - kl_loss: 6.9507\n",
            "Epoch 116/300\n",
            "17/17 [==============================] - 1s 71ms/step - loss: 469.9991 - reconstruction_loss: 466.7711 - kl_loss: 7.0517\n",
            "Epoch 117/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 472.5729 - reconstruction_loss: 466.7144 - kl_loss: 7.1390\n",
            "Epoch 118/300\n",
            "17/17 [==============================] - 1s 71ms/step - loss: 468.6037 - reconstruction_loss: 466.5970 - kl_loss: 7.0959\n",
            "Epoch 119/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 475.0198 - reconstruction_loss: 468.0626 - kl_loss: 7.0043\n",
            "Epoch 120/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 477.0449 - reconstruction_loss: 466.4755 - kl_loss: 6.9343\n",
            "Epoch 121/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 473.6483 - reconstruction_loss: 468.4091 - kl_loss: 6.8188\n",
            "Epoch 122/300\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 471.5954 - reconstruction_loss: 465.6091 - kl_loss: 7.0756\n",
            "Epoch 123/300\n",
            "17/17 [==============================] - 2s 91ms/step - loss: 467.2447 - reconstruction_loss: 466.3555 - kl_loss: 7.1872\n",
            "Epoch 124/300\n",
            "17/17 [==============================] - 2s 101ms/step - loss: 476.9457 - reconstruction_loss: 467.4637 - kl_loss: 7.0163\n",
            "Epoch 125/300\n",
            "17/17 [==============================] - 2s 96ms/step - loss: 473.2937 - reconstruction_loss: 465.7981 - kl_loss: 7.1280\n",
            "Epoch 126/300\n",
            "17/17 [==============================] - 1s 73ms/step - loss: 469.0447 - reconstruction_loss: 466.7065 - kl_loss: 6.9893\n",
            "Epoch 127/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 473.4792 - reconstruction_loss: 467.8699 - kl_loss: 6.9731\n",
            "Epoch 128/300\n",
            "17/17 [==============================] - 1s 71ms/step - loss: 478.0740 - reconstruction_loss: 467.4171 - kl_loss: 7.0996\n",
            "Epoch 129/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 474.1014 - reconstruction_loss: 465.1216 - kl_loss: 7.1210\n",
            "Epoch 130/300\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 470.2220 - reconstruction_loss: 466.2877 - kl_loss: 7.0734\n",
            "Epoch 131/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 472.8229 - reconstruction_loss: 466.7805 - kl_loss: 7.1930\n",
            "Epoch 132/300\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 470.1369 - reconstruction_loss: 466.6797 - kl_loss: 7.2226\n",
            "Epoch 133/300\n",
            "17/17 [==============================] - 1s 66ms/step - loss: 480.5815 - reconstruction_loss: 466.4267 - kl_loss: 7.0610\n",
            "Epoch 134/300\n",
            "17/17 [==============================] - 1s 89ms/step - loss: 469.8413 - reconstruction_loss: 465.7890 - kl_loss: 7.0292\n",
            "Epoch 135/300\n",
            "17/17 [==============================] - 2s 104ms/step - loss: 477.2550 - reconstruction_loss: 466.8829 - kl_loss: 7.2119\n",
            "Epoch 136/300\n",
            "17/17 [==============================] - 2s 99ms/step - loss: 473.1130 - reconstruction_loss: 465.5993 - kl_loss: 7.1717\n",
            "Epoch 137/300\n",
            "17/17 [==============================] - 1s 73ms/step - loss: 480.3744 - reconstruction_loss: 465.3357 - kl_loss: 7.1940\n",
            "Epoch 138/300\n",
            "17/17 [==============================] - 1s 71ms/step - loss: 472.9370 - reconstruction_loss: 466.2321 - kl_loss: 7.1773\n",
            "Epoch 139/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 476.3507 - reconstruction_loss: 467.4914 - kl_loss: 6.9985\n",
            "Epoch 140/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 474.0674 - reconstruction_loss: 464.0468 - kl_loss: 6.9493\n",
            "Epoch 141/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 469.3251 - reconstruction_loss: 464.5219 - kl_loss: 7.0857\n",
            "Epoch 142/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 478.6677 - reconstruction_loss: 465.9765 - kl_loss: 7.0364\n",
            "Epoch 143/300\n",
            "17/17 [==============================] - 1s 80ms/step - loss: 468.2046 - reconstruction_loss: 466.0642 - kl_loss: 7.1774\n",
            "Epoch 144/300\n",
            "17/17 [==============================] - 2s 91ms/step - loss: 475.3303 - reconstruction_loss: 465.8496 - kl_loss: 7.2229\n",
            "Epoch 145/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 471.8746 - reconstruction_loss: 464.1230 - kl_loss: 7.1820\n",
            "Epoch 146/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 467.0159 - reconstruction_loss: 464.0284 - kl_loss: 7.2305\n",
            "Epoch 147/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 467.4166 - reconstruction_loss: 465.3318 - kl_loss: 7.1977\n",
            "Epoch 148/300\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 468.1069 - reconstruction_loss: 464.1640 - kl_loss: 7.0194\n",
            "Epoch 149/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 472.2041 - reconstruction_loss: 464.8627 - kl_loss: 7.0557\n",
            "Epoch 150/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 471.1657 - reconstruction_loss: 465.0813 - kl_loss: 7.1034\n",
            "Epoch 151/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 467.2417 - reconstruction_loss: 464.4268 - kl_loss: 7.2932\n",
            "Epoch 152/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 473.1750 - reconstruction_loss: 465.0017 - kl_loss: 7.3275\n",
            "Epoch 153/300\n",
            "17/17 [==============================] - 2s 92ms/step - loss: 477.2388 - reconstruction_loss: 465.3123 - kl_loss: 7.1388\n",
            "Epoch 154/300\n",
            "17/17 [==============================] - 2s 101ms/step - loss: 472.8364 - reconstruction_loss: 466.3016 - kl_loss: 7.0998\n",
            "Epoch 155/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 471.3479 - reconstruction_loss: 464.4619 - kl_loss: 7.2020\n",
            "Epoch 156/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 472.5483 - reconstruction_loss: 464.4611 - kl_loss: 7.2002\n",
            "Epoch 157/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 469.7654 - reconstruction_loss: 463.7415 - kl_loss: 7.0937\n",
            "Epoch 158/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 471.7137 - reconstruction_loss: 463.6500 - kl_loss: 7.2106\n",
            "Epoch 159/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 473.1707 - reconstruction_loss: 465.1409 - kl_loss: 7.2166\n",
            "Epoch 160/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 471.0132 - reconstruction_loss: 466.9253 - kl_loss: 7.0597\n",
            "Epoch 161/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 473.7524 - reconstruction_loss: 464.4317 - kl_loss: 7.1656\n",
            "Epoch 162/300\n",
            "17/17 [==============================] - 1s 71ms/step - loss: 470.3874 - reconstruction_loss: 465.0197 - kl_loss: 7.0632\n",
            "Epoch 163/300\n",
            "17/17 [==============================] - 2s 96ms/step - loss: 471.9556 - reconstruction_loss: 463.0413 - kl_loss: 7.2614\n",
            "Epoch 164/300\n",
            "17/17 [==============================] - 2s 90ms/step - loss: 470.4742 - reconstruction_loss: 464.2090 - kl_loss: 7.2275\n",
            "Epoch 165/300\n",
            "17/17 [==============================] - 1s 72ms/step - loss: 473.6590 - reconstruction_loss: 464.1591 - kl_loss: 7.2575\n",
            "Epoch 166/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 467.5265 - reconstruction_loss: 464.2916 - kl_loss: 7.1999\n",
            "Epoch 167/300\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 473.0966 - reconstruction_loss: 462.1958 - kl_loss: 7.2412\n",
            "Epoch 168/300\n",
            "17/17 [==============================] - 1s 66ms/step - loss: 473.9731 - reconstruction_loss: 464.2892 - kl_loss: 7.2171\n",
            "Epoch 169/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 466.5292 - reconstruction_loss: 462.0641 - kl_loss: 7.1957\n",
            "Epoch 170/300\n",
            "17/17 [==============================] - 1s 72ms/step - loss: 474.4946 - reconstruction_loss: 464.0852 - kl_loss: 7.1604\n",
            "Epoch 171/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 469.6782 - reconstruction_loss: 462.6608 - kl_loss: 7.2521\n",
            "Epoch 172/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 464.5408 - reconstruction_loss: 463.6786 - kl_loss: 7.2303\n",
            "Epoch 173/300\n",
            "17/17 [==============================] - 2s 94ms/step - loss: 472.9800 - reconstruction_loss: 461.9810 - kl_loss: 7.2838\n",
            "Epoch 174/300\n",
            "17/17 [==============================] - 2s 91ms/step - loss: 467.6529 - reconstruction_loss: 461.4201 - kl_loss: 7.1841\n",
            "Epoch 175/300\n",
            "17/17 [==============================] - 2s 97ms/step - loss: 464.3236 - reconstruction_loss: 462.9749 - kl_loss: 7.2845\n",
            "Epoch 176/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 473.6672 - reconstruction_loss: 462.1294 - kl_loss: 7.2802\n",
            "Epoch 177/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 474.2937 - reconstruction_loss: 464.4174 - kl_loss: 7.3163\n",
            "Epoch 178/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 469.0708 - reconstruction_loss: 464.1348 - kl_loss: 7.2718\n",
            "Epoch 179/300\n",
            "17/17 [==============================] - 1s 71ms/step - loss: 469.9962 - reconstruction_loss: 462.7932 - kl_loss: 7.1373\n",
            "Epoch 180/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 470.7873 - reconstruction_loss: 463.1014 - kl_loss: 6.9956\n",
            "Epoch 181/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 471.2116 - reconstruction_loss: 464.6824 - kl_loss: 7.1780\n",
            "Epoch 182/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 471.7611 - reconstruction_loss: 463.4681 - kl_loss: 7.2042\n",
            "Epoch 183/300\n",
            "17/17 [==============================] - 1s 76ms/step - loss: 476.6570 - reconstruction_loss: 464.6864 - kl_loss: 7.2550\n",
            "Epoch 184/300\n",
            "17/17 [==============================] - 2s 95ms/step - loss: 476.6145 - reconstruction_loss: 464.8153 - kl_loss: 7.2516\n",
            "Epoch 185/300\n",
            "17/17 [==============================] - 2s 95ms/step - loss: 471.7630 - reconstruction_loss: 463.6815 - kl_loss: 7.1105\n",
            "Epoch 186/300\n",
            "17/17 [==============================] - 2s 94ms/step - loss: 473.1067 - reconstruction_loss: 463.0959 - kl_loss: 7.0848\n",
            "Epoch 187/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 471.1312 - reconstruction_loss: 461.1022 - kl_loss: 7.2632\n",
            "Epoch 188/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 469.3567 - reconstruction_loss: 462.0897 - kl_loss: 7.2955\n",
            "Epoch 189/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 469.5730 - reconstruction_loss: 461.3645 - kl_loss: 7.1945\n",
            "Epoch 190/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 474.7989 - reconstruction_loss: 463.6314 - kl_loss: 7.1875\n",
            "Epoch 191/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 469.5018 - reconstruction_loss: 462.1399 - kl_loss: 7.3532\n",
            "Epoch 192/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 473.1235 - reconstruction_loss: 462.8911 - kl_loss: 7.3125\n",
            "Epoch 193/300\n",
            "17/17 [==============================] - 1s 72ms/step - loss: 472.3645 - reconstruction_loss: 462.1667 - kl_loss: 7.2567\n",
            "Epoch 194/300\n",
            "17/17 [==============================] - 2s 92ms/step - loss: 473.9984 - reconstruction_loss: 462.9249 - kl_loss: 7.1310\n",
            "Epoch 195/300\n",
            "17/17 [==============================] - 2s 96ms/step - loss: 471.6952 - reconstruction_loss: 461.1152 - kl_loss: 7.1874\n",
            "Epoch 196/300\n",
            "17/17 [==============================] - 2s 94ms/step - loss: 471.4723 - reconstruction_loss: 459.4048 - kl_loss: 7.3229\n",
            "Epoch 197/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 472.9343 - reconstruction_loss: 462.3136 - kl_loss: 7.2929\n",
            "Epoch 198/300\n",
            "17/17 [==============================] - 1s 71ms/step - loss: 464.5470 - reconstruction_loss: 461.3132 - kl_loss: 7.2688\n",
            "Epoch 199/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 465.2031 - reconstruction_loss: 461.2798 - kl_loss: 7.2378\n",
            "Epoch 200/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 465.0259 - reconstruction_loss: 460.3018 - kl_loss: 7.2203\n",
            "Epoch 201/300\n",
            "17/17 [==============================] - 1s 66ms/step - loss: 477.0652 - reconstruction_loss: 461.0691 - kl_loss: 7.3679\n",
            "Epoch 202/300\n",
            "17/17 [==============================] - 1s 66ms/step - loss: 469.4059 - reconstruction_loss: 460.7917 - kl_loss: 7.3144\n",
            "Epoch 203/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 468.5752 - reconstruction_loss: 461.3249 - kl_loss: 7.2682\n",
            "Epoch 204/300\n",
            "17/17 [==============================] - 1s 83ms/step - loss: 470.1777 - reconstruction_loss: 461.2031 - kl_loss: 7.3634\n",
            "Epoch 205/300\n",
            "17/17 [==============================] - 2s 90ms/step - loss: 468.8729 - reconstruction_loss: 461.8558 - kl_loss: 7.2736\n",
            "Epoch 206/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 468.0785 - reconstruction_loss: 462.1448 - kl_loss: 7.2563\n",
            "Epoch 207/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 474.9972 - reconstruction_loss: 461.3411 - kl_loss: 7.2995\n",
            "Epoch 208/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 465.2584 - reconstruction_loss: 459.8687 - kl_loss: 7.3612\n",
            "Epoch 209/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 468.3444 - reconstruction_loss: 459.1705 - kl_loss: 7.2112\n",
            "Epoch 210/300\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 467.7713 - reconstruction_loss: 461.2266 - kl_loss: 7.2505\n",
            "Epoch 211/300\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 464.7910 - reconstruction_loss: 460.6122 - kl_loss: 7.3551\n",
            "Epoch 212/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 468.6921 - reconstruction_loss: 460.1828 - kl_loss: 7.3719\n",
            "Epoch 213/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 472.4314 - reconstruction_loss: 459.6926 - kl_loss: 7.3064\n",
            "Epoch 214/300\n",
            "17/17 [==============================] - 2s 89ms/step - loss: 467.4261 - reconstruction_loss: 461.3718 - kl_loss: 7.1845\n",
            "Epoch 215/300\n",
            "17/17 [==============================] - 2s 92ms/step - loss: 463.7609 - reconstruction_loss: 459.8089 - kl_loss: 7.2700\n",
            "Epoch 216/300\n",
            "17/17 [==============================] - 1s 72ms/step - loss: 471.1548 - reconstruction_loss: 462.8210 - kl_loss: 7.3065\n",
            "Epoch 217/300\n",
            "17/17 [==============================] - 1s 86ms/step - loss: 468.3542 - reconstruction_loss: 461.0195 - kl_loss: 7.3306\n",
            "Epoch 218/300\n",
            "17/17 [==============================] - 2s 92ms/step - loss: 471.1459 - reconstruction_loss: 460.2875 - kl_loss: 7.3478\n",
            "Epoch 219/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 471.5135 - reconstruction_loss: 460.8096 - kl_loss: 7.4281\n",
            "Epoch 220/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 467.1321 - reconstruction_loss: 460.0826 - kl_loss: 7.4697\n",
            "Epoch 221/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 470.0300 - reconstruction_loss: 461.6427 - kl_loss: 7.3827\n",
            "Epoch 222/300\n",
            "17/17 [==============================] - 2s 93ms/step - loss: 465.2491 - reconstruction_loss: 461.4347 - kl_loss: 7.3496\n",
            "Epoch 223/300\n",
            "17/17 [==============================] - 1s 83ms/step - loss: 466.2883 - reconstruction_loss: 459.9670 - kl_loss: 7.5416\n",
            "Epoch 224/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 470.2503 - reconstruction_loss: 462.4677 - kl_loss: 7.3987\n",
            "Epoch 225/300\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 467.3086 - reconstruction_loss: 459.5309 - kl_loss: 7.2535\n",
            "Epoch 226/300\n",
            "17/17 [==============================] - 1s 71ms/step - loss: 470.3192 - reconstruction_loss: 459.9709 - kl_loss: 7.4178\n",
            "Epoch 227/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 468.0290 - reconstruction_loss: 460.1324 - kl_loss: 7.4203\n",
            "Epoch 228/300\n",
            "17/17 [==============================] - 1s 75ms/step - loss: 470.7966 - reconstruction_loss: 460.7704 - kl_loss: 7.1977\n",
            "Epoch 229/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 463.2731 - reconstruction_loss: 460.6118 - kl_loss: 7.3513\n",
            "Epoch 230/300\n",
            "17/17 [==============================] - 1s 71ms/step - loss: 465.8972 - reconstruction_loss: 460.2563 - kl_loss: 7.3700\n",
            "Epoch 231/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 467.5891 - reconstruction_loss: 460.0674 - kl_loss: 7.2978\n",
            "Epoch 232/300\n",
            "17/17 [==============================] - 2s 90ms/step - loss: 466.4341 - reconstruction_loss: 459.9233 - kl_loss: 7.4317\n",
            "Epoch 233/300\n",
            "17/17 [==============================] - 2s 86ms/step - loss: 469.7624 - reconstruction_loss: 460.0525 - kl_loss: 7.4158\n",
            "Epoch 234/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 467.2283 - reconstruction_loss: 460.7691 - kl_loss: 7.3887\n",
            "Epoch 235/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 471.0098 - reconstruction_loss: 463.7669 - kl_loss: 7.3677\n",
            "Epoch 236/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 473.3797 - reconstruction_loss: 461.9456 - kl_loss: 7.2262\n",
            "Epoch 237/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 469.1188 - reconstruction_loss: 461.2222 - kl_loss: 7.3830\n",
            "Epoch 238/300\n",
            "17/17 [==============================] - 1s 72ms/step - loss: 464.9315 - reconstruction_loss: 460.2691 - kl_loss: 7.4191\n",
            "Epoch 239/300\n",
            "17/17 [==============================] - 1s 77ms/step - loss: 465.3918 - reconstruction_loss: 459.0438 - kl_loss: 7.4367\n",
            "Epoch 240/300\n",
            "17/17 [==============================] - 2s 87ms/step - loss: 467.1982 - reconstruction_loss: 458.6447 - kl_loss: 7.3443\n",
            "Epoch 241/300\n",
            "17/17 [==============================] - 2s 87ms/step - loss: 466.3131 - reconstruction_loss: 459.6613 - kl_loss: 7.5356\n",
            "Epoch 242/300\n",
            "17/17 [==============================] - 2s 100ms/step - loss: 469.8631 - reconstruction_loss: 458.5445 - kl_loss: 7.3956\n",
            "Epoch 243/300\n",
            "17/17 [==============================] - 1s 80ms/step - loss: 470.0930 - reconstruction_loss: 459.1711 - kl_loss: 7.3642\n",
            "Epoch 244/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 469.3341 - reconstruction_loss: 459.3634 - kl_loss: 7.4566\n",
            "Epoch 245/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 462.3520 - reconstruction_loss: 458.9899 - kl_loss: 7.3978\n",
            "Epoch 246/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 467.9206 - reconstruction_loss: 458.1675 - kl_loss: 7.3979\n",
            "Epoch 247/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 470.5149 - reconstruction_loss: 459.3402 - kl_loss: 7.4242\n",
            "Epoch 248/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 470.3803 - reconstruction_loss: 459.0622 - kl_loss: 7.3686\n",
            "Epoch 249/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 461.5074 - reconstruction_loss: 458.4968 - kl_loss: 7.3428\n",
            "Epoch 250/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 464.2509 - reconstruction_loss: 458.3468 - kl_loss: 7.3553\n",
            "Epoch 251/300\n",
            "17/17 [==============================] - 1s 86ms/step - loss: 459.3084 - reconstruction_loss: 459.9641 - kl_loss: 7.4126\n",
            "Epoch 252/300\n",
            "17/17 [==============================] - 2s 90ms/step - loss: 468.5294 - reconstruction_loss: 459.2225 - kl_loss: 7.4050\n",
            "Epoch 253/300\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 464.6232 - reconstruction_loss: 458.7813 - kl_loss: 7.4781\n",
            "Epoch 254/300\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 463.1192 - reconstruction_loss: 459.9488 - kl_loss: 7.5769\n",
            "Epoch 255/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 461.8596 - reconstruction_loss: 458.1744 - kl_loss: 7.4858\n",
            "Epoch 256/300\n",
            "17/17 [==============================] - 1s 73ms/step - loss: 469.9969 - reconstruction_loss: 459.3964 - kl_loss: 7.3107\n",
            "Epoch 257/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 463.2970 - reconstruction_loss: 457.7837 - kl_loss: 7.4118\n",
            "Epoch 258/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 462.0463 - reconstruction_loss: 457.5025 - kl_loss: 7.5166\n",
            "Epoch 259/300\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 462.6359 - reconstruction_loss: 457.7491 - kl_loss: 7.3823\n",
            "Epoch 260/300\n",
            "17/17 [==============================] - 1s 71ms/step - loss: 466.5508 - reconstruction_loss: 458.4236 - kl_loss: 7.3412\n",
            "Epoch 261/300\n",
            "17/17 [==============================] - 1s 83ms/step - loss: 461.6607 - reconstruction_loss: 457.8054 - kl_loss: 7.4456\n",
            "Epoch 262/300\n",
            "17/17 [==============================] - 2s 89ms/step - loss: 466.6909 - reconstruction_loss: 455.9435 - kl_loss: 7.3714\n",
            "Epoch 263/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 460.7450 - reconstruction_loss: 455.7512 - kl_loss: 7.4817\n",
            "Epoch 264/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 464.3098 - reconstruction_loss: 459.2284 - kl_loss: 7.5150\n",
            "Epoch 265/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 462.2263 - reconstruction_loss: 458.8001 - kl_loss: 7.4376\n",
            "Epoch 266/300\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 460.9542 - reconstruction_loss: 458.3185 - kl_loss: 7.3467\n",
            "Epoch 267/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 461.0127 - reconstruction_loss: 457.3199 - kl_loss: 7.3564\n",
            "Epoch 268/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 469.4135 - reconstruction_loss: 459.1023 - kl_loss: 7.3929\n",
            "Epoch 269/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 466.8154 - reconstruction_loss: 458.5367 - kl_loss: 7.3883\n",
            "Epoch 270/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 460.4275 - reconstruction_loss: 457.9611 - kl_loss: 7.4374\n",
            "Epoch 271/300\n",
            "17/17 [==============================] - 2s 94ms/step - loss: 464.1708 - reconstruction_loss: 456.9752 - kl_loss: 7.4150\n",
            "Epoch 272/300\n",
            "17/17 [==============================] - 2s 92ms/step - loss: 465.6016 - reconstruction_loss: 457.5826 - kl_loss: 7.3307\n",
            "Epoch 273/300\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 466.8847 - reconstruction_loss: 458.8796 - kl_loss: 7.3692\n",
            "Epoch 274/300\n",
            "17/17 [==============================] - 1s 71ms/step - loss: 463.1166 - reconstruction_loss: 457.9951 - kl_loss: 7.4487\n",
            "Epoch 275/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 465.7667 - reconstruction_loss: 458.4200 - kl_loss: 7.5207\n",
            "Epoch 276/300\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 464.0799 - reconstruction_loss: 456.5952 - kl_loss: 7.4324\n",
            "Epoch 277/300\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 467.2137 - reconstruction_loss: 456.8614 - kl_loss: 7.4110\n",
            "Epoch 278/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 463.3809 - reconstruction_loss: 457.4031 - kl_loss: 7.5155\n",
            "Epoch 279/300\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 466.4720 - reconstruction_loss: 458.1632 - kl_loss: 7.5456\n",
            "Epoch 280/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 465.9961 - reconstruction_loss: 458.0942 - kl_loss: 7.3492\n",
            "Epoch 281/300\n",
            "17/17 [==============================] - 2s 99ms/step - loss: 465.4390 - reconstruction_loss: 458.4223 - kl_loss: 7.3101\n",
            "Epoch 282/300\n",
            "17/17 [==============================] - 2s 95ms/step - loss: 458.2580 - reconstruction_loss: 458.9461 - kl_loss: 7.3190\n",
            "Epoch 283/300\n",
            "17/17 [==============================] - 1s 73ms/step - loss: 467.9938 - reconstruction_loss: 459.0502 - kl_loss: 7.3697\n",
            "Epoch 284/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 463.5083 - reconstruction_loss: 458.8201 - kl_loss: 7.4153\n",
            "Epoch 285/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 464.2024 - reconstruction_loss: 457.0642 - kl_loss: 7.4167\n",
            "Epoch 286/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 471.4501 - reconstruction_loss: 460.2675 - kl_loss: 7.2650\n",
            "Epoch 287/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 470.2745 - reconstruction_loss: 457.6332 - kl_loss: 7.4761\n",
            "Epoch 288/300\n",
            "17/17 [==============================] - 1s 66ms/step - loss: 458.6409 - reconstruction_loss: 457.8647 - kl_loss: 7.3960\n",
            "Epoch 289/300\n",
            "17/17 [==============================] - 1s 71ms/step - loss: 465.0072 - reconstruction_loss: 455.9177 - kl_loss: 7.4803\n",
            "Epoch 290/300\n",
            "17/17 [==============================] - 1s 74ms/step - loss: 466.9404 - reconstruction_loss: 456.4211 - kl_loss: 7.4614\n",
            "Epoch 291/300\n",
            "17/17 [==============================] - 2s 89ms/step - loss: 472.1945 - reconstruction_loss: 458.1958 - kl_loss: 7.4931\n",
            "Epoch 292/300\n",
            "17/17 [==============================] - 1s 82ms/step - loss: 459.9455 - reconstruction_loss: 456.1841 - kl_loss: 7.4528\n",
            "Epoch 293/300\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 458.8455 - reconstruction_loss: 456.8601 - kl_loss: 7.3631\n",
            "Epoch 294/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 462.3705 - reconstruction_loss: 455.3038 - kl_loss: 7.4170\n",
            "Epoch 295/300\n",
            "17/17 [==============================] - 1s 70ms/step - loss: 471.2485 - reconstruction_loss: 457.5865 - kl_loss: 7.5143\n",
            "Epoch 296/300\n",
            "17/17 [==============================] - 1s 68ms/step - loss: 461.0756 - reconstruction_loss: 457.5809 - kl_loss: 7.5643\n",
            "Epoch 297/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 465.3119 - reconstruction_loss: 457.2804 - kl_loss: 7.5772\n",
            "Epoch 298/300\n",
            "17/17 [==============================] - 1s 67ms/step - loss: 464.4048 - reconstruction_loss: 457.7224 - kl_loss: 7.4558\n",
            "Epoch 299/300\n",
            "17/17 [==============================] - 1s 69ms/step - loss: 469.1745 - reconstruction_loss: 457.7051 - kl_loss: 7.3877\n",
            "Epoch 300/300\n",
            "17/17 [==============================] - 1s 76ms/step - loss: 464.1122 - reconstruction_loss: 457.5395 - kl_loss: 7.3147\n",
            "Found 66 images belonging to 1 classes.\n",
            "16/16 [==============================] - 0s 7ms/step\n",
            "Training VAE for class: Sofa\n",
            "Found 107 images belonging to 1 classes.\n",
            "Epoch 1/300\n",
            "7/7 [==============================] - 5s 58ms/step - loss: 544.9877 - reconstruction_loss: 539.8769 - kl_loss: 6.9760\n",
            "Epoch 2/300\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 527.8737 - reconstruction_loss: 514.5248 - kl_loss: 6.5846\n",
            "Epoch 3/300\n",
            "7/7 [==============================] - 1s 77ms/step - loss: 506.1947 - reconstruction_loss: 505.2517 - kl_loss: 6.1905\n",
            "Epoch 4/300\n",
            "7/7 [==============================] - 1s 69ms/step - loss: 505.7381 - reconstruction_loss: 500.5533 - kl_loss: 5.9723\n",
            "Epoch 5/300\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 502.7924 - reconstruction_loss: 495.2388 - kl_loss: 5.7854\n",
            "Epoch 6/300\n",
            "7/7 [==============================] - 0s 63ms/step - loss: 500.5998 - reconstruction_loss: 493.7514 - kl_loss: 5.6566\n",
            "Epoch 7/300\n",
            "7/7 [==============================] - 0s 70ms/step - loss: 495.7016 - reconstruction_loss: 492.6629 - kl_loss: 5.7007\n",
            "Epoch 8/300\n",
            "7/7 [==============================] - 1s 68ms/step - loss: 495.9452 - reconstruction_loss: 489.3073 - kl_loss: 5.8317\n",
            "Epoch 9/300\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 492.9033 - reconstruction_loss: 488.6499 - kl_loss: 5.8704\n",
            "Epoch 10/300\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 491.3602 - reconstruction_loss: 487.2510 - kl_loss: 5.9561\n",
            "Epoch 11/300\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 492.8352 - reconstruction_loss: 485.4586 - kl_loss: 6.0551\n",
            "Epoch 12/300\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 490.5230 - reconstruction_loss: 485.3327 - kl_loss: 6.0655\n",
            "Epoch 13/300\n",
            "7/7 [==============================] - 1s 82ms/step - loss: 495.1549 - reconstruction_loss: 484.3400 - kl_loss: 6.1022\n",
            "Epoch 14/300\n",
            "7/7 [==============================] - 1s 101ms/step - loss: 492.2187 - reconstruction_loss: 482.3900 - kl_loss: 6.1810\n",
            "Epoch 15/300\n",
            "7/7 [==============================] - 1s 94ms/step - loss: 486.2053 - reconstruction_loss: 482.0858 - kl_loss: 6.2005\n",
            "Epoch 16/300\n",
            "7/7 [==============================] - 1s 88ms/step - loss: 492.0473 - reconstruction_loss: 482.2824 - kl_loss: 6.1804\n",
            "Epoch 17/300\n",
            "7/7 [==============================] - 1s 75ms/step - loss: 487.7893 - reconstruction_loss: 481.9311 - kl_loss: 6.2118\n",
            "Epoch 18/300\n",
            "7/7 [==============================] - 1s 77ms/step - loss: 489.9358 - reconstruction_loss: 481.0486 - kl_loss: 6.2279\n",
            "Epoch 19/300\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 488.0381 - reconstruction_loss: 480.5746 - kl_loss: 6.2196\n",
            "Epoch 20/300\n",
            "7/7 [==============================] - 1s 77ms/step - loss: 489.1825 - reconstruction_loss: 480.4438 - kl_loss: 6.1914\n",
            "Epoch 21/300\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 489.4330 - reconstruction_loss: 480.5949 - kl_loss: 6.1940\n",
            "Epoch 22/300\n",
            "7/7 [==============================] - 0s 65ms/step - loss: 495.0471 - reconstruction_loss: 478.4446 - kl_loss: 6.2438\n",
            "Epoch 23/300\n",
            "7/7 [==============================] - 1s 68ms/step - loss: 482.1590 - reconstruction_loss: 477.9895 - kl_loss: 6.2802\n",
            "Epoch 24/300\n",
            "7/7 [==============================] - 0s 70ms/step - loss: 482.2766 - reconstruction_loss: 477.8105 - kl_loss: 6.2813\n",
            "Epoch 25/300\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 481.9257 - reconstruction_loss: 477.5978 - kl_loss: 6.3329\n",
            "Epoch 26/300\n",
            "7/7 [==============================] - 1s 68ms/step - loss: 482.8669 - reconstruction_loss: 476.7889 - kl_loss: 6.3850\n",
            "Epoch 27/300\n",
            "7/7 [==============================] - 0s 69ms/step - loss: 481.4679 - reconstruction_loss: 476.9383 - kl_loss: 6.3804\n",
            "Epoch 28/300\n",
            "7/7 [==============================] - 0s 66ms/step - loss: 479.0695 - reconstruction_loss: 476.4844 - kl_loss: 6.3261\n",
            "Epoch 29/300\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 478.0852 - reconstruction_loss: 475.6997 - kl_loss: 6.3621\n",
            "Epoch 30/300\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 482.5168 - reconstruction_loss: 476.9085 - kl_loss: 6.3589\n",
            "Epoch 31/300\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 482.8807 - reconstruction_loss: 477.6913 - kl_loss: 6.3649\n",
            "Epoch 32/300\n",
            "7/7 [==============================] - 0s 68ms/step - loss: 488.8808 - reconstruction_loss: 477.5569 - kl_loss: 6.4171\n",
            "Epoch 33/300\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 484.1895 - reconstruction_loss: 477.2026 - kl_loss: 6.3758\n",
            "Epoch 34/300\n",
            "7/7 [==============================] - 1s 81ms/step - loss: 485.1537 - reconstruction_loss: 476.1324 - kl_loss: 6.4051\n",
            "Epoch 35/300\n",
            "7/7 [==============================] - 1s 99ms/step - loss: 484.9778 - reconstruction_loss: 474.9483 - kl_loss: 6.3400\n",
            "Epoch 36/300\n",
            "7/7 [==============================] - 1s 89ms/step - loss: 484.0306 - reconstruction_loss: 473.8335 - kl_loss: 6.3690\n",
            "Epoch 37/300\n",
            "7/7 [==============================] - 1s 97ms/step - loss: 482.0535 - reconstruction_loss: 475.0150 - kl_loss: 6.3811\n",
            "Epoch 38/300\n",
            "7/7 [==============================] - 1s 101ms/step - loss: 483.1573 - reconstruction_loss: 474.5584 - kl_loss: 6.4133\n",
            "Epoch 39/300\n",
            "7/7 [==============================] - 1s 100ms/step - loss: 485.2952 - reconstruction_loss: 474.7693 - kl_loss: 6.4222\n",
            "Epoch 40/300\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 476.2252 - reconstruction_loss: 473.7955 - kl_loss: 6.4150\n",
            "Epoch 41/300\n",
            "7/7 [==============================] - 1s 77ms/step - loss: 479.2683 - reconstruction_loss: 474.5761 - kl_loss: 6.3629\n",
            "Epoch 42/300\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 476.5674 - reconstruction_loss: 472.8533 - kl_loss: 6.3955\n",
            "Epoch 43/300\n",
            "7/7 [==============================] - 1s 75ms/step - loss: 482.1154 - reconstruction_loss: 473.5349 - kl_loss: 6.3987\n",
            "Epoch 44/300\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 479.7669 - reconstruction_loss: 473.8988 - kl_loss: 6.3985\n",
            "Epoch 45/300\n",
            "7/7 [==============================] - 0s 69ms/step - loss: 476.7798 - reconstruction_loss: 473.5698 - kl_loss: 6.4404\n",
            "Epoch 46/300\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 473.0205 - reconstruction_loss: 471.8411 - kl_loss: 6.4861\n",
            "Epoch 47/300\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 476.9540 - reconstruction_loss: 472.1947 - kl_loss: 6.4188\n",
            "Epoch 48/300\n",
            "7/7 [==============================] - 0s 65ms/step - loss: 482.4020 - reconstruction_loss: 472.1178 - kl_loss: 6.4698\n",
            "Epoch 49/300\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 483.9336 - reconstruction_loss: 473.0360 - kl_loss: 6.5092\n",
            "Epoch 50/300\n",
            "7/7 [==============================] - 0s 65ms/step - loss: 485.5030 - reconstruction_loss: 473.1618 - kl_loss: 6.4850\n",
            "Epoch 51/300\n",
            "7/7 [==============================] - 0s 67ms/step - loss: 473.0596 - reconstruction_loss: 471.8138 - kl_loss: 6.5670\n",
            "Epoch 52/300\n",
            "7/7 [==============================] - 0s 65ms/step - loss: 480.4005 - reconstruction_loss: 471.6617 - kl_loss: 6.5373\n",
            "Epoch 53/300\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 476.7100 - reconstruction_loss: 470.8533 - kl_loss: 6.5265\n",
            "Epoch 54/300\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 478.3183 - reconstruction_loss: 471.0291 - kl_loss: 6.5482\n",
            "Epoch 55/300\n",
            "7/7 [==============================] - 0s 70ms/step - loss: 473.6040 - reconstruction_loss: 471.0731 - kl_loss: 6.4545\n",
            "Epoch 56/300\n",
            "7/7 [==============================] - 1s 84ms/step - loss: 480.9619 - reconstruction_loss: 471.4292 - kl_loss: 6.4400\n",
            "Epoch 57/300\n",
            "7/7 [==============================] - 1s 91ms/step - loss: 476.0062 - reconstruction_loss: 469.1796 - kl_loss: 6.4440\n",
            "Epoch 58/300\n",
            "7/7 [==============================] - 1s 90ms/step - loss: 480.7182 - reconstruction_loss: 471.1223 - kl_loss: 6.4344\n",
            "Epoch 59/300\n",
            "7/7 [==============================] - 1s 91ms/step - loss: 480.2582 - reconstruction_loss: 470.5625 - kl_loss: 6.5472\n",
            "Epoch 60/300\n",
            "7/7 [==============================] - 1s 95ms/step - loss: 472.3203 - reconstruction_loss: 469.8440 - kl_loss: 6.5644\n",
            "Epoch 61/300\n",
            "7/7 [==============================] - 1s 113ms/step - loss: 474.6027 - reconstruction_loss: 470.2254 - kl_loss: 6.5618\n",
            "Epoch 62/300\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 476.8719 - reconstruction_loss: 470.5734 - kl_loss: 6.6127\n",
            "Epoch 63/300\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 472.7620 - reconstruction_loss: 470.0264 - kl_loss: 6.7266\n",
            "Epoch 64/300\n",
            "7/7 [==============================] - 1s 67ms/step - loss: 473.5410 - reconstruction_loss: 469.3848 - kl_loss: 6.7688\n",
            "Epoch 65/300\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 478.9599 - reconstruction_loss: 468.8421 - kl_loss: 6.7351\n",
            "Epoch 66/300\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 479.3732 - reconstruction_loss: 469.9491 - kl_loss: 6.6806\n",
            "Epoch 67/300\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 475.7697 - reconstruction_loss: 469.0473 - kl_loss: 6.6087\n",
            "Epoch 68/300\n",
            "7/7 [==============================] - 1s 78ms/step - loss: 483.0851 - reconstruction_loss: 470.2886 - kl_loss: 6.5200\n",
            "Epoch 69/300\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 472.6693 - reconstruction_loss: 470.2691 - kl_loss: 6.5360\n",
            "Epoch 70/300\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 469.0041 - reconstruction_loss: 468.5812 - kl_loss: 6.5873\n",
            "Epoch 71/300\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 475.0506 - reconstruction_loss: 469.6894 - kl_loss: 6.6003\n",
            "Epoch 72/300\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 472.6498 - reconstruction_loss: 468.1221 - kl_loss: 6.7583\n",
            "Epoch 73/300\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 473.5249 - reconstruction_loss: 467.3238 - kl_loss: 6.6834\n",
            "Epoch 74/300\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 474.3511 - reconstruction_loss: 467.8228 - kl_loss: 6.7000\n",
            "Epoch 75/300\n",
            "7/7 [==============================] - 1s 78ms/step - loss: 479.8967 - reconstruction_loss: 468.9758 - kl_loss: 6.6810\n",
            "Epoch 76/300\n",
            "7/7 [==============================] - 1s 69ms/step - loss: 481.2393 - reconstruction_loss: 468.0076 - kl_loss: 6.6467\n",
            "Epoch 77/300\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 475.4517 - reconstruction_loss: 468.3120 - kl_loss: 6.6077\n",
            "Epoch 78/300\n",
            "7/7 [==============================] - 0s 66ms/step - loss: 479.2086 - reconstruction_loss: 467.4208 - kl_loss: 6.6667\n",
            "Epoch 79/300\n",
            "7/7 [==============================] - 1s 87ms/step - loss: 475.7770 - reconstruction_loss: 468.3869 - kl_loss: 6.6556\n",
            "Epoch 80/300\n",
            "7/7 [==============================] - 1s 96ms/step - loss: 468.9524 - reconstruction_loss: 468.4798 - kl_loss: 6.5808\n",
            "Epoch 81/300\n",
            "7/7 [==============================] - 1s 94ms/step - loss: 473.1426 - reconstruction_loss: 467.9595 - kl_loss: 6.6339\n",
            "Epoch 82/300\n",
            "7/7 [==============================] - 1s 68ms/step - loss: 470.2642 - reconstruction_loss: 465.9077 - kl_loss: 6.6534\n",
            "Epoch 83/300\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 469.5005 - reconstruction_loss: 466.7085 - kl_loss: 6.6469\n",
            "Epoch 84/300\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 473.6245 - reconstruction_loss: 468.7128 - kl_loss: 6.6361\n",
            "Epoch 85/300\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 474.5596 - reconstruction_loss: 466.9174 - kl_loss: 6.6282\n",
            "Epoch 86/300\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 472.8171 - reconstruction_loss: 466.9972 - kl_loss: 6.7256\n",
            "Epoch 87/300\n",
            "7/7 [==============================] - 1s 75ms/step - loss: 473.6732 - reconstruction_loss: 466.9543 - kl_loss: 6.8167\n",
            "Epoch 88/300\n",
            "7/7 [==============================] - 1s 75ms/step - loss: 472.1040 - reconstruction_loss: 466.5886 - kl_loss: 6.8062\n",
            "Epoch 89/300\n",
            "7/7 [==============================] - 1s 69ms/step - loss: 473.7837 - reconstruction_loss: 467.4681 - kl_loss: 6.8004\n",
            "Epoch 90/300\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 472.0969 - reconstruction_loss: 467.1671 - kl_loss: 6.7254\n",
            "Epoch 91/300\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 476.3611 - reconstruction_loss: 467.5587 - kl_loss: 6.6855\n",
            "Epoch 92/300\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 466.1048 - reconstruction_loss: 467.6866 - kl_loss: 6.6954\n",
            "Epoch 93/300\n",
            "7/7 [==============================] - 0s 66ms/step - loss: 470.3368 - reconstruction_loss: 465.7848 - kl_loss: 6.6830\n",
            "Epoch 94/300\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 476.7705 - reconstruction_loss: 466.0903 - kl_loss: 6.6667\n",
            "Epoch 95/300\n",
            "7/7 [==============================] - 0s 66ms/step - loss: 478.0605 - reconstruction_loss: 466.6355 - kl_loss: 6.6482\n",
            "Epoch 96/300\n",
            "7/7 [==============================] - 1s 67ms/step - loss: 474.7465 - reconstruction_loss: 465.1733 - kl_loss: 6.6982\n",
            "Epoch 97/300\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 471.9729 - reconstruction_loss: 465.7401 - kl_loss: 6.7255\n",
            "Epoch 98/300\n",
            "7/7 [==============================] - 1s 69ms/step - loss: 467.0053 - reconstruction_loss: 465.8486 - kl_loss: 6.7099\n",
            "Epoch 99/300\n",
            "7/7 [==============================] - 1s 105ms/step - loss: 471.5964 - reconstruction_loss: 465.7747 - kl_loss: 6.7590\n",
            "Epoch 100/300\n",
            "7/7 [==============================] - 1s 94ms/step - loss: 468.2720 - reconstruction_loss: 464.7800 - kl_loss: 6.8074\n",
            "Epoch 101/300\n",
            "7/7 [==============================] - 1s 98ms/step - loss: 473.3916 - reconstruction_loss: 465.9688 - kl_loss: 6.7073\n",
            "Epoch 102/300\n",
            "7/7 [==============================] - 1s 78ms/step - loss: 471.7290 - reconstruction_loss: 466.7259 - kl_loss: 6.6039\n",
            "Epoch 103/300\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 467.4993 - reconstruction_loss: 465.2643 - kl_loss: 6.6027\n",
            "Epoch 104/300\n",
            "7/7 [==============================] - 1s 69ms/step - loss: 471.5086 - reconstruction_loss: 465.1759 - kl_loss: 6.5875\n",
            "Epoch 105/300\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 475.5337 - reconstruction_loss: 466.1606 - kl_loss: 6.5531\n",
            "Epoch 106/300\n",
            "7/7 [==============================] - 1s 69ms/step - loss: 469.3873 - reconstruction_loss: 465.0584 - kl_loss: 6.6955\n",
            "Epoch 107/300\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 469.8167 - reconstruction_loss: 465.1073 - kl_loss: 6.6910\n",
            "Epoch 108/300\n",
            "7/7 [==============================] - 0s 72ms/step - loss: 484.1641 - reconstruction_loss: 466.5394 - kl_loss: 6.7097\n",
            "Epoch 109/300\n",
            "7/7 [==============================] - 0s 68ms/step - loss: 470.9332 - reconstruction_loss: 464.2954 - kl_loss: 6.7641\n",
            "Epoch 110/300\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 470.5641 - reconstruction_loss: 463.9291 - kl_loss: 6.8052\n",
            "Epoch 111/300\n",
            "7/7 [==============================] - 1s 78ms/step - loss: 478.6246 - reconstruction_loss: 465.8942 - kl_loss: 6.7728\n",
            "Epoch 112/300\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 469.4367 - reconstruction_loss: 464.4939 - kl_loss: 6.7280\n",
            "Epoch 113/300\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 467.6191 - reconstruction_loss: 464.7260 - kl_loss: 6.7632\n",
            "Epoch 114/300\n",
            "7/7 [==============================] - 1s 78ms/step - loss: 469.0510 - reconstruction_loss: 465.5064 - kl_loss: 6.7214\n",
            "Epoch 115/300\n",
            "7/7 [==============================] - 1s 75ms/step - loss: 475.7041 - reconstruction_loss: 464.9779 - kl_loss: 6.7322\n",
            "Epoch 116/300\n",
            "7/7 [==============================] - 1s 75ms/step - loss: 470.3630 - reconstruction_loss: 465.2029 - kl_loss: 6.7397\n",
            "Epoch 117/300\n",
            "7/7 [==============================] - 1s 76ms/step - loss: 471.8089 - reconstruction_loss: 465.3988 - kl_loss: 6.7088\n",
            "Epoch 118/300\n",
            "7/7 [==============================] - 1s 76ms/step - loss: 472.2379 - reconstruction_loss: 464.9805 - kl_loss: 6.8390\n",
            "Epoch 119/300\n",
            "7/7 [==============================] - 1s 88ms/step - loss: 477.8638 - reconstruction_loss: 465.3484 - kl_loss: 6.8873\n",
            "Epoch 120/300\n",
            "7/7 [==============================] - 1s 93ms/step - loss: 475.9155 - reconstruction_loss: 464.1860 - kl_loss: 6.8445\n",
            "Epoch 121/300\n",
            "7/7 [==============================] - 1s 91ms/step - loss: 470.6059 - reconstruction_loss: 464.9952 - kl_loss: 6.7837\n",
            "Epoch 122/300\n",
            "7/7 [==============================] - 1s 105ms/step - loss: 468.5320 - reconstruction_loss: 464.3919 - kl_loss: 6.6896\n",
            "Epoch 123/300\n",
            "7/7 [==============================] - 1s 99ms/step - loss: 468.1990 - reconstruction_loss: 463.0007 - kl_loss: 6.6810\n",
            "Epoch 124/300\n",
            "7/7 [==============================] - 1s 101ms/step - loss: 465.0317 - reconstruction_loss: 462.4016 - kl_loss: 6.7035\n",
            "Epoch 125/300\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 472.5294 - reconstruction_loss: 464.2908 - kl_loss: 6.7013\n",
            "Epoch 126/300\n",
            "7/7 [==============================] - 1s 93ms/step - loss: 469.9186 - reconstruction_loss: 463.7914 - kl_loss: 6.7925\n",
            "Epoch 127/300\n",
            "7/7 [==============================] - 1s 97ms/step - loss: 474.0915 - reconstruction_loss: 464.8306 - kl_loss: 6.8046\n",
            "Epoch 128/300\n",
            "7/7 [==============================] - 1s 85ms/step - loss: 468.4104 - reconstruction_loss: 463.9768 - kl_loss: 6.8791\n",
            "Epoch 129/300\n",
            "7/7 [==============================] - 1s 96ms/step - loss: 467.9757 - reconstruction_loss: 463.3860 - kl_loss: 6.8113\n",
            "Epoch 130/300\n",
            "7/7 [==============================] - 1s 92ms/step - loss: 467.3001 - reconstruction_loss: 464.1027 - kl_loss: 6.7600\n",
            "Epoch 131/300\n",
            "7/7 [==============================] - 1s 99ms/step - loss: 473.4555 - reconstruction_loss: 463.4858 - kl_loss: 6.7215\n",
            "Epoch 132/300\n",
            "7/7 [==============================] - 1s 69ms/step - loss: 469.4724 - reconstruction_loss: 463.8523 - kl_loss: 6.7296\n",
            "Epoch 133/300\n",
            "7/7 [==============================] - 1s 80ms/step - loss: 474.8163 - reconstruction_loss: 462.1489 - kl_loss: 6.7891\n",
            "Epoch 134/300\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 473.2681 - reconstruction_loss: 464.7087 - kl_loss: 6.7652\n",
            "Epoch 135/300\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 459.7383 - reconstruction_loss: 462.8041 - kl_loss: 6.7964\n",
            "Epoch 136/300\n",
            "7/7 [==============================] - 1s 69ms/step - loss: 476.3093 - reconstruction_loss: 463.5585 - kl_loss: 6.7935\n",
            "Epoch 137/300\n",
            "7/7 [==============================] - 1s 67ms/step - loss: 466.3559 - reconstruction_loss: 462.9086 - kl_loss: 6.8133\n",
            "Epoch 138/300\n",
            "7/7 [==============================] - 1s 85ms/step - loss: 471.5995 - reconstruction_loss: 464.4664 - kl_loss: 6.8258\n",
            "Epoch 139/300\n",
            "7/7 [==============================] - 1s 95ms/step - loss: 472.7883 - reconstruction_loss: 463.4351 - kl_loss: 6.9241\n",
            "Epoch 140/300\n",
            "7/7 [==============================] - 1s 100ms/step - loss: 469.3308 - reconstruction_loss: 462.7975 - kl_loss: 6.8811\n",
            "Epoch 141/300\n",
            "7/7 [==============================] - 1s 91ms/step - loss: 475.0629 - reconstruction_loss: 463.5663 - kl_loss: 6.8730\n",
            "Epoch 142/300\n",
            "7/7 [==============================] - 1s 94ms/step - loss: 475.7398 - reconstruction_loss: 462.5976 - kl_loss: 6.8995\n",
            "Epoch 143/300\n",
            "7/7 [==============================] - 1s 90ms/step - loss: 468.6209 - reconstruction_loss: 462.4153 - kl_loss: 6.8461\n",
            "Epoch 144/300\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 467.9163 - reconstruction_loss: 462.3902 - kl_loss: 6.7844\n",
            "Epoch 145/300\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 469.4875 - reconstruction_loss: 463.0126 - kl_loss: 6.8028\n",
            "Epoch 146/300\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 468.9238 - reconstruction_loss: 461.2562 - kl_loss: 6.7574\n",
            "Epoch 147/300\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 467.4788 - reconstruction_loss: 461.9268 - kl_loss: 6.7505\n",
            "Epoch 148/300\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 469.5082 - reconstruction_loss: 462.4048 - kl_loss: 6.7646\n",
            "Epoch 149/300\n",
            "7/7 [==============================] - 1s 75ms/step - loss: 459.8547 - reconstruction_loss: 461.8617 - kl_loss: 6.8244\n",
            "Epoch 150/300\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 463.0822 - reconstruction_loss: 462.9406 - kl_loss: 6.8523\n",
            "Epoch 151/300\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 475.7341 - reconstruction_loss: 460.9521 - kl_loss: 6.9228\n",
            "Epoch 152/300\n",
            "7/7 [==============================] - 1s 69ms/step - loss: 472.2571 - reconstruction_loss: 462.2402 - kl_loss: 6.9272\n",
            "Epoch 153/300\n",
            "7/7 [==============================] - 1s 68ms/step - loss: 468.9482 - reconstruction_loss: 461.2230 - kl_loss: 6.8928\n",
            "Epoch 154/300\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 464.1777 - reconstruction_loss: 462.1008 - kl_loss: 6.9318\n",
            "Epoch 155/300\n",
            "7/7 [==============================] - 1s 68ms/step - loss: 472.5505 - reconstruction_loss: 461.1438 - kl_loss: 6.8459\n",
            "Epoch 156/300\n",
            "7/7 [==============================] - 0s 72ms/step - loss: 468.5066 - reconstruction_loss: 461.8212 - kl_loss: 6.7590\n",
            "Epoch 157/300\n",
            "7/7 [==============================] - 1s 68ms/step - loss: 466.0919 - reconstruction_loss: 462.7949 - kl_loss: 6.7943\n",
            "Epoch 158/300\n",
            "7/7 [==============================] - 0s 68ms/step - loss: 474.0457 - reconstruction_loss: 462.4323 - kl_loss: 6.8593\n",
            "Epoch 159/300\n",
            "7/7 [==============================] - 1s 79ms/step - loss: 470.1231 - reconstruction_loss: 461.2299 - kl_loss: 6.9000\n",
            "Epoch 160/300\n",
            "7/7 [==============================] - 1s 94ms/step - loss: 474.7216 - reconstruction_loss: 461.2473 - kl_loss: 6.8903\n",
            "Epoch 161/300\n",
            "7/7 [==============================] - 1s 102ms/step - loss: 465.0715 - reconstruction_loss: 461.9789 - kl_loss: 6.8299\n",
            "Epoch 162/300\n",
            "7/7 [==============================] - 1s 100ms/step - loss: 470.4371 - reconstruction_loss: 461.7266 - kl_loss: 6.9339\n",
            "Epoch 163/300\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 466.0758 - reconstruction_loss: 461.2767 - kl_loss: 6.8716\n",
            "Epoch 164/300\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 465.5414 - reconstruction_loss: 462.4777 - kl_loss: 6.8645\n",
            "Epoch 165/300\n",
            "7/7 [==============================] - 0s 68ms/step - loss: 466.0887 - reconstruction_loss: 460.5827 - kl_loss: 6.8935\n",
            "Epoch 166/300\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 468.7807 - reconstruction_loss: 461.9075 - kl_loss: 6.8442\n",
            "Epoch 167/300\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 457.4137 - reconstruction_loss: 459.8570 - kl_loss: 6.8036\n",
            "Epoch 168/300\n",
            "7/7 [==============================] - 1s 69ms/step - loss: 470.1941 - reconstruction_loss: 460.8560 - kl_loss: 6.7040\n",
            "Epoch 169/300\n",
            "7/7 [==============================] - 1s 76ms/step - loss: 464.0967 - reconstruction_loss: 461.2838 - kl_loss: 6.6749\n",
            "Epoch 170/300\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 465.9021 - reconstruction_loss: 461.8540 - kl_loss: 6.7086\n",
            "Epoch 171/300\n",
            "7/7 [==============================] - 0s 69ms/step - loss: 471.0915 - reconstruction_loss: 460.0535 - kl_loss: 6.7459\n",
            "Epoch 172/300\n",
            "7/7 [==============================] - 1s 75ms/step - loss: 470.5119 - reconstruction_loss: 461.3869 - kl_loss: 6.7949\n",
            "Epoch 173/300\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 462.2041 - reconstruction_loss: 460.8696 - kl_loss: 6.8608\n",
            "Epoch 174/300\n",
            "7/7 [==============================] - 1s 68ms/step - loss: 464.1605 - reconstruction_loss: 461.4499 - kl_loss: 6.9266\n",
            "Epoch 175/300\n",
            "7/7 [==============================] - 1s 75ms/step - loss: 466.6700 - reconstruction_loss: 460.9467 - kl_loss: 7.0449\n",
            "Epoch 176/300\n",
            "7/7 [==============================] - 1s 69ms/step - loss: 476.8622 - reconstruction_loss: 462.0077 - kl_loss: 7.0223\n",
            "Epoch 177/300\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 468.8949 - reconstruction_loss: 459.0053 - kl_loss: 7.0629\n",
            "Epoch 178/300\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 466.1241 - reconstruction_loss: 460.8185 - kl_loss: 6.9944\n",
            "Epoch 179/300\n",
            "7/7 [==============================] - 1s 78ms/step - loss: 463.0223 - reconstruction_loss: 459.2727 - kl_loss: 6.9912\n",
            "Epoch 180/300\n",
            "7/7 [==============================] - 1s 101ms/step - loss: 460.2820 - reconstruction_loss: 460.6675 - kl_loss: 6.9371\n",
            "Epoch 181/300\n",
            "7/7 [==============================] - 1s 95ms/step - loss: 471.3948 - reconstruction_loss: 459.6989 - kl_loss: 6.9309\n",
            "Epoch 182/300\n",
            "7/7 [==============================] - 1s 89ms/step - loss: 460.3611 - reconstruction_loss: 460.2258 - kl_loss: 7.0045\n",
            "Epoch 183/300\n",
            "7/7 [==============================] - 1s 88ms/step - loss: 464.8636 - reconstruction_loss: 461.0398 - kl_loss: 6.9978\n",
            "Epoch 184/300\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 469.5221 - reconstruction_loss: 461.0804 - kl_loss: 7.0938\n",
            "Epoch 185/300\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 465.4181 - reconstruction_loss: 460.6996 - kl_loss: 7.0089\n",
            "Epoch 186/300\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 466.6168 - reconstruction_loss: 459.8525 - kl_loss: 6.9452\n",
            "Epoch 187/300\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 464.0095 - reconstruction_loss: 458.8683 - kl_loss: 6.9299\n",
            "Epoch 188/300\n",
            "7/7 [==============================] - 1s 75ms/step - loss: 461.6571 - reconstruction_loss: 459.1106 - kl_loss: 6.9168\n",
            "Epoch 189/300\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 466.0261 - reconstruction_loss: 459.8880 - kl_loss: 6.9161\n",
            "Epoch 190/300\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 466.4935 - reconstruction_loss: 458.8184 - kl_loss: 6.8773\n",
            "Epoch 191/300\n",
            "7/7 [==============================] - 1s 76ms/step - loss: 468.9498 - reconstruction_loss: 459.1646 - kl_loss: 6.8495\n",
            "Epoch 192/300\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 458.9841 - reconstruction_loss: 460.6926 - kl_loss: 6.8293\n",
            "Epoch 193/300\n",
            "7/7 [==============================] - 1s 65ms/step - loss: 464.3266 - reconstruction_loss: 460.1813 - kl_loss: 6.8010\n",
            "Epoch 194/300\n",
            "7/7 [==============================] - 1s 67ms/step - loss: 465.6251 - reconstruction_loss: 458.9066 - kl_loss: 6.8382\n",
            "Epoch 195/300\n",
            "7/7 [==============================] - 0s 69ms/step - loss: 465.9365 - reconstruction_loss: 461.1420 - kl_loss: 6.8008\n",
            "Epoch 196/300\n",
            "7/7 [==============================] - 0s 67ms/step - loss: 462.2462 - reconstruction_loss: 460.1928 - kl_loss: 6.8175\n",
            "Epoch 197/300\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 466.8645 - reconstruction_loss: 460.5263 - kl_loss: 6.7535\n",
            "Epoch 198/300\n",
            "7/7 [==============================] - 0s 69ms/step - loss: 463.8470 - reconstruction_loss: 460.6790 - kl_loss: 6.8080\n",
            "Epoch 199/300\n",
            "7/7 [==============================] - 1s 68ms/step - loss: 470.5024 - reconstruction_loss: 461.2331 - kl_loss: 6.9281\n",
            "Epoch 200/300\n",
            "7/7 [==============================] - 1s 81ms/step - loss: 466.9736 - reconstruction_loss: 461.2456 - kl_loss: 6.9836\n",
            "Epoch 201/300\n",
            "7/7 [==============================] - 1s 85ms/step - loss: 471.6999 - reconstruction_loss: 460.4327 - kl_loss: 7.0461\n",
            "Epoch 202/300\n",
            "7/7 [==============================] - 1s 98ms/step - loss: 470.0807 - reconstruction_loss: 458.6958 - kl_loss: 7.0330\n",
            "Epoch 203/300\n",
            "7/7 [==============================] - 1s 93ms/step - loss: 464.9975 - reconstruction_loss: 458.7741 - kl_loss: 6.9343\n",
            "Epoch 204/300\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 462.2509 - reconstruction_loss: 459.3025 - kl_loss: 6.8949\n",
            "Epoch 205/300\n",
            "7/7 [==============================] - 1s 77ms/step - loss: 467.6337 - reconstruction_loss: 460.4256 - kl_loss: 6.8834\n",
            "Epoch 206/300\n",
            "7/7 [==============================] - 0s 68ms/step - loss: 464.6731 - reconstruction_loss: 459.9616 - kl_loss: 6.8798\n",
            "Epoch 207/300\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 468.5522 - reconstruction_loss: 456.3211 - kl_loss: 6.9729\n",
            "Epoch 208/300\n",
            "7/7 [==============================] - 1s 66ms/step - loss: 469.9352 - reconstruction_loss: 459.4052 - kl_loss: 6.9422\n",
            "Epoch 209/300\n",
            "7/7 [==============================] - 0s 68ms/step - loss: 465.8710 - reconstruction_loss: 458.5379 - kl_loss: 6.9005\n",
            "Epoch 210/300\n",
            "7/7 [==============================] - 1s 69ms/step - loss: 471.4362 - reconstruction_loss: 458.7380 - kl_loss: 6.8848\n",
            "Epoch 211/300\n",
            "7/7 [==============================] - 1s 69ms/step - loss: 466.3855 - reconstruction_loss: 458.9442 - kl_loss: 6.9478\n",
            "Epoch 212/300\n",
            "7/7 [==============================] - 1s 77ms/step - loss: 467.5743 - reconstruction_loss: 459.5457 - kl_loss: 6.9232\n",
            "Epoch 213/300\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 467.1309 - reconstruction_loss: 458.3179 - kl_loss: 6.9377\n",
            "Epoch 214/300\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 459.6200 - reconstruction_loss: 458.7752 - kl_loss: 6.9577\n",
            "Epoch 215/300\n",
            "7/7 [==============================] - 0s 68ms/step - loss: 458.1211 - reconstruction_loss: 458.0465 - kl_loss: 6.9735\n",
            "Epoch 216/300\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 461.0386 - reconstruction_loss: 457.5750 - kl_loss: 6.9951\n",
            "Epoch 217/300\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 466.2019 - reconstruction_loss: 458.7956 - kl_loss: 7.0161\n",
            "Epoch 218/300\n",
            "7/7 [==============================] - 0s 67ms/step - loss: 464.8497 - reconstruction_loss: 459.2488 - kl_loss: 6.9823\n",
            "Epoch 219/300\n",
            "7/7 [==============================] - 0s 66ms/step - loss: 459.5780 - reconstruction_loss: 455.7616 - kl_loss: 6.9253\n",
            "Epoch 220/300\n",
            "7/7 [==============================] - 1s 65ms/step - loss: 466.3044 - reconstruction_loss: 459.2127 - kl_loss: 6.8347\n",
            "Epoch 221/300\n",
            "7/7 [==============================] - 1s 82ms/step - loss: 464.6559 - reconstruction_loss: 456.8892 - kl_loss: 6.9241\n",
            "Epoch 222/300\n",
            "7/7 [==============================] - 1s 87ms/step - loss: 467.5308 - reconstruction_loss: 457.7430 - kl_loss: 6.9303\n",
            "Epoch 223/300\n",
            "7/7 [==============================] - 1s 103ms/step - loss: 462.0053 - reconstruction_loss: 457.6015 - kl_loss: 6.9224\n",
            "Epoch 224/300\n",
            "7/7 [==============================] - 1s 95ms/step - loss: 465.2580 - reconstruction_loss: 458.6819 - kl_loss: 6.9130\n",
            "Epoch 225/300\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 464.5482 - reconstruction_loss: 457.5298 - kl_loss: 6.8502\n",
            "Epoch 226/300\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 464.9109 - reconstruction_loss: 458.5265 - kl_loss: 6.8066\n",
            "Epoch 227/300\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 471.2792 - reconstruction_loss: 456.7956 - kl_loss: 6.8308\n",
            "Epoch 228/300\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 464.2846 - reconstruction_loss: 457.9613 - kl_loss: 6.9141\n",
            "Epoch 229/300\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 468.2397 - reconstruction_loss: 458.5495 - kl_loss: 6.9674\n",
            "Epoch 230/300\n",
            "7/7 [==============================] - 1s 75ms/step - loss: 463.0374 - reconstruction_loss: 458.1886 - kl_loss: 6.9637\n",
            "Epoch 231/300\n",
            "7/7 [==============================] - 0s 67ms/step - loss: 463.6124 - reconstruction_loss: 459.0025 - kl_loss: 7.0352\n",
            "Epoch 232/300\n",
            "7/7 [==============================] - 1s 66ms/step - loss: 462.6678 - reconstruction_loss: 458.3784 - kl_loss: 7.0606\n",
            "Epoch 233/300\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 466.2084 - reconstruction_loss: 457.9388 - kl_loss: 7.0566\n",
            "Epoch 234/300\n",
            "7/7 [==============================] - 1s 75ms/step - loss: 469.4859 - reconstruction_loss: 458.2099 - kl_loss: 7.0315\n",
            "Epoch 235/300\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 467.1892 - reconstruction_loss: 458.7052 - kl_loss: 7.0244\n",
            "Epoch 236/300\n",
            "7/7 [==============================] - 1s 68ms/step - loss: 464.2794 - reconstruction_loss: 456.9963 - kl_loss: 6.9842\n",
            "Epoch 237/300\n",
            "7/7 [==============================] - 0s 69ms/step - loss: 466.5768 - reconstruction_loss: 457.8132 - kl_loss: 7.0025\n",
            "Epoch 238/300\n",
            "7/7 [==============================] - 1s 69ms/step - loss: 463.4725 - reconstruction_loss: 458.3419 - kl_loss: 6.9470\n",
            "Epoch 239/300\n",
            "7/7 [==============================] - 0s 66ms/step - loss: 463.9104 - reconstruction_loss: 456.8359 - kl_loss: 6.9381\n",
            "Epoch 240/300\n",
            "7/7 [==============================] - 1s 68ms/step - loss: 462.8268 - reconstruction_loss: 457.3988 - kl_loss: 6.9944\n",
            "Epoch 241/300\n",
            "7/7 [==============================] - 1s 91ms/step - loss: 466.1696 - reconstruction_loss: 457.0958 - kl_loss: 6.8727\n",
            "Epoch 242/300\n",
            "7/7 [==============================] - 1s 100ms/step - loss: 464.7343 - reconstruction_loss: 457.0265 - kl_loss: 6.8796\n",
            "Epoch 243/300\n",
            "7/7 [==============================] - 1s 92ms/step - loss: 463.2637 - reconstruction_loss: 456.3442 - kl_loss: 6.8039\n",
            "Epoch 244/300\n",
            "7/7 [==============================] - 1s 104ms/step - loss: 464.6265 - reconstruction_loss: 457.2087 - kl_loss: 6.7036\n",
            "Epoch 245/300\n",
            "7/7 [==============================] - 0s 68ms/step - loss: 461.6588 - reconstruction_loss: 458.0677 - kl_loss: 6.7720\n",
            "Epoch 246/300\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 464.2743 - reconstruction_loss: 457.3822 - kl_loss: 6.8607\n",
            "Epoch 247/300\n",
            "7/7 [==============================] - 1s 76ms/step - loss: 457.7967 - reconstruction_loss: 456.1238 - kl_loss: 6.9454\n",
            "Epoch 248/300\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 458.5701 - reconstruction_loss: 456.3575 - kl_loss: 6.9771\n",
            "Epoch 249/300\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 466.2758 - reconstruction_loss: 456.2298 - kl_loss: 6.9382\n",
            "Epoch 250/300\n",
            "7/7 [==============================] - 1s 75ms/step - loss: 454.0004 - reconstruction_loss: 455.1164 - kl_loss: 6.9210\n",
            "Epoch 251/300\n",
            "7/7 [==============================] - 1s 76ms/step - loss: 469.3873 - reconstruction_loss: 457.3312 - kl_loss: 6.9180\n",
            "Epoch 252/300\n",
            "7/7 [==============================] - 0s 64ms/step - loss: 467.9365 - reconstruction_loss: 458.3781 - kl_loss: 6.8696\n",
            "Epoch 253/300\n",
            "7/7 [==============================] - 0s 67ms/step - loss: 465.6086 - reconstruction_loss: 456.6843 - kl_loss: 6.9320\n",
            "Epoch 254/300\n",
            "7/7 [==============================] - 1s 75ms/step - loss: 467.0348 - reconstruction_loss: 457.0840 - kl_loss: 6.9288\n",
            "Epoch 255/300\n",
            "7/7 [==============================] - 0s 66ms/step - loss: 459.8794 - reconstruction_loss: 456.5556 - kl_loss: 6.9181\n",
            "Epoch 256/300\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 464.6515 - reconstruction_loss: 456.7111 - kl_loss: 6.9289\n",
            "Epoch 257/300\n",
            "7/7 [==============================] - 0s 65ms/step - loss: 471.5951 - reconstruction_loss: 457.4276 - kl_loss: 6.9474\n",
            "Epoch 258/300\n",
            "7/7 [==============================] - 0s 65ms/step - loss: 463.6415 - reconstruction_loss: 456.9334 - kl_loss: 6.9463\n",
            "Epoch 259/300\n",
            "7/7 [==============================] - 0s 67ms/step - loss: 466.2110 - reconstruction_loss: 456.9706 - kl_loss: 6.9644\n",
            "Epoch 260/300\n",
            "7/7 [==============================] - 0s 63ms/step - loss: 460.9869 - reconstruction_loss: 457.9758 - kl_loss: 6.9656\n",
            "Epoch 261/300\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 457.1812 - reconstruction_loss: 454.6689 - kl_loss: 6.9829\n",
            "Epoch 262/300\n",
            "7/7 [==============================] - 1s 82ms/step - loss: 464.5970 - reconstruction_loss: 456.7520 - kl_loss: 6.9812\n",
            "Epoch 263/300\n",
            "7/7 [==============================] - 1s 90ms/step - loss: 463.5064 - reconstruction_loss: 456.1482 - kl_loss: 6.9415\n",
            "Epoch 264/300\n",
            "7/7 [==============================] - 1s 92ms/step - loss: 461.3855 - reconstruction_loss: 456.0493 - kl_loss: 7.0533\n",
            "Epoch 265/300\n",
            "7/7 [==============================] - 1s 90ms/step - loss: 465.9096 - reconstruction_loss: 455.4117 - kl_loss: 7.0450\n",
            "Epoch 266/300\n",
            "7/7 [==============================] - 1s 91ms/step - loss: 463.7713 - reconstruction_loss: 457.0201 - kl_loss: 7.0301\n",
            "Epoch 267/300\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 459.0330 - reconstruction_loss: 455.9367 - kl_loss: 7.0557\n",
            "Epoch 268/300\n",
            "7/7 [==============================] - 1s 74ms/step - loss: 462.6780 - reconstruction_loss: 456.2189 - kl_loss: 7.0767\n",
            "Epoch 269/300\n",
            "7/7 [==============================] - 1s 76ms/step - loss: 466.0641 - reconstruction_loss: 455.0284 - kl_loss: 6.9981\n",
            "Epoch 270/300\n",
            "7/7 [==============================] - 1s 66ms/step - loss: 457.1778 - reconstruction_loss: 457.3465 - kl_loss: 6.8953\n",
            "Epoch 271/300\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 464.9545 - reconstruction_loss: 457.0891 - kl_loss: 6.8699\n",
            "Epoch 272/300\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 465.6422 - reconstruction_loss: 454.9641 - kl_loss: 6.9258\n",
            "Epoch 273/300\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 467.1210 - reconstruction_loss: 456.9268 - kl_loss: 7.1092\n",
            "Epoch 274/300\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 461.2561 - reconstruction_loss: 456.2939 - kl_loss: 7.0483\n",
            "Epoch 275/300\n",
            "7/7 [==============================] - 0s 70ms/step - loss: 459.1410 - reconstruction_loss: 455.6288 - kl_loss: 7.0871\n",
            "Epoch 276/300\n",
            "7/7 [==============================] - 0s 68ms/step - loss: 469.2092 - reconstruction_loss: 455.1321 - kl_loss: 7.0013\n",
            "Epoch 277/300\n",
            "7/7 [==============================] - 0s 64ms/step - loss: 462.9511 - reconstruction_loss: 456.0905 - kl_loss: 6.9387\n",
            "Epoch 278/300\n",
            "7/7 [==============================] - 0s 68ms/step - loss: 473.8953 - reconstruction_loss: 456.7127 - kl_loss: 7.0120\n",
            "Epoch 279/300\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 462.7231 - reconstruction_loss: 455.2946 - kl_loss: 6.9881\n",
            "Epoch 280/300\n",
            "7/7 [==============================] - 1s 69ms/step - loss: 465.4733 - reconstruction_loss: 456.0833 - kl_loss: 6.9408\n",
            "Epoch 281/300\n",
            "7/7 [==============================] - 1s 68ms/step - loss: 457.4798 - reconstruction_loss: 454.3431 - kl_loss: 6.9877\n",
            "Epoch 282/300\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 464.7363 - reconstruction_loss: 455.4621 - kl_loss: 6.9132\n",
            "Epoch 283/300\n",
            "7/7 [==============================] - 1s 77ms/step - loss: 463.0249 - reconstruction_loss: 456.3201 - kl_loss: 6.9165\n",
            "Epoch 284/300\n",
            "7/7 [==============================] - 1s 97ms/step - loss: 461.6634 - reconstruction_loss: 457.5559 - kl_loss: 6.9188\n",
            "Epoch 285/300\n",
            "7/7 [==============================] - 1s 90ms/step - loss: 453.7898 - reconstruction_loss: 455.8703 - kl_loss: 6.9053\n",
            "Epoch 286/300\n",
            "7/7 [==============================] - 1s 96ms/step - loss: 466.3107 - reconstruction_loss: 455.9417 - kl_loss: 6.9613\n",
            "Epoch 287/300\n",
            "7/7 [==============================] - 1s 93ms/step - loss: 467.5599 - reconstruction_loss: 456.8188 - kl_loss: 7.0145\n",
            "Epoch 288/300\n",
            "7/7 [==============================] - 1s 73ms/step - loss: 461.1374 - reconstruction_loss: 456.6738 - kl_loss: 6.9814\n",
            "Epoch 289/300\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 465.8357 - reconstruction_loss: 456.4010 - kl_loss: 6.9849\n",
            "Epoch 290/300\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 463.3059 - reconstruction_loss: 455.2585 - kl_loss: 7.0318\n",
            "Epoch 291/300\n",
            "7/7 [==============================] - 1s 69ms/step - loss: 468.7163 - reconstruction_loss: 455.2556 - kl_loss: 6.9837\n",
            "Epoch 292/300\n",
            "7/7 [==============================] - 1s 71ms/step - loss: 459.4234 - reconstruction_loss: 454.6534 - kl_loss: 6.9911\n",
            "Epoch 293/300\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 459.7393 - reconstruction_loss: 456.3433 - kl_loss: 6.9933\n",
            "Epoch 294/300\n",
            "7/7 [==============================] - 1s 70ms/step - loss: 464.0702 - reconstruction_loss: 454.9939 - kl_loss: 7.0310\n",
            "Epoch 295/300\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 455.0619 - reconstruction_loss: 453.2596 - kl_loss: 7.0075\n",
            "Epoch 296/300\n",
            "7/7 [==============================] - 1s 66ms/step - loss: 460.3958 - reconstruction_loss: 455.2519 - kl_loss: 7.0054\n",
            "Epoch 297/300\n",
            "7/7 [==============================] - 1s 72ms/step - loss: 464.1177 - reconstruction_loss: 455.5830 - kl_loss: 6.9911\n",
            "Epoch 298/300\n",
            "7/7 [==============================] - 0s 64ms/step - loss: 464.4700 - reconstruction_loss: 455.7131 - kl_loss: 6.9651\n",
            "Epoch 299/300\n",
            "7/7 [==============================] - 0s 63ms/step - loss: 463.7237 - reconstruction_loss: 455.0042 - kl_loss: 6.9478\n",
            "Epoch 300/300\n",
            "7/7 [==============================] - 0s 66ms/step - loss: 456.3868 - reconstruction_loss: 455.1910 - kl_loss: 6.9474\n",
            "Found 27 images belonging to 1 classes.\n",
            "16/16 [==============================] - 0s 7ms/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "output_folder_path= \"/content/generated_data-500samples\"\n",
        "output_folder= \"/content/generated_data-500samples\"\n",
        "# Loop through each class and train the VAE model\n",
        "for class_name in class_names:\n",
        "    print(f\"Training VAE for class: {class_name}\")\n",
        "    # encoder = keras.models.clone_model(encoder)\n",
        "    # decoder = keras.models.clone_model(decoder)\n",
        "    # Create a VAE instance\n",
        "    vae = VAE(encoder, decoder)\n",
        "\n",
        "    # Compile the VAE model\n",
        "    optimizer = optimizers.Adam(learning_rate=0.001)\n",
        "    vae.compile(optimizer=optimizer)\n",
        "\n",
        "    # Create output folder if it doesn't exist\n",
        "    os.makedirs(output_folder_path, exist_ok=True)\n",
        "\n",
        "    # Configure the ImageDataGenerator for loading training data\n",
        "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    # Define the path to the class directory\n",
        "    class_folder_path = os.path.join(train_folder_path, class_name)\n",
        "\n",
        "    # Configure the ImageDataGenerator for loading training data\n",
        "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    # Load training data for the current class\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        directory=class_folder_path,\n",
        "        classes=[class_name],\n",
        "        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "        batch_size=16,\n",
        "        class_mode=None,  # No labels needed, only images\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "\n",
        "    # Train the VAE model\n",
        "    vae.fit(train_generator, epochs=300)\n",
        "    test_folder_path = \"/content/test\"\n",
        "    test_folder_path = os.path.join(test_folder_path, class_name)\n",
        "\n",
        "    # target_size = (224, 224)\n",
        "\n",
        "\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255)  # Normalize pixel values to [0,1]\n",
        "\n",
        "    test_generator = test_datagen.flow_from_directory(\n",
        "    directory=test_folder_path,\n",
        "    classes=[class_name],\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=16,\n",
        "    class_mode=None,  # No labels needed, only images\n",
        "    shuffle=True\n",
        "    )\n",
        "\n",
        "\n",
        "    latent_dim = 2  #latent space dimension is 2\n",
        "    grid_width, grid_height = (50, 10)  #500 samples\n",
        "    z_sample = np.random.normal(size=(grid_width * grid_height, EMBEDDING_DIM))\n",
        "\n",
        "    # Decode the sampled points\n",
        "    reconstructions = vae.decoder.predict(z_sample)\n",
        "\n",
        "\n",
        "    # Create output subfolder for the current class\n",
        "    class_output_folder = os.path.join(output_folder, class_name)\n",
        "    os.makedirs(class_output_folder, exist_ok=True)\n",
        "\n",
        "    # Save the resized images\n",
        "    for i, image in enumerate(reconstructions):\n",
        "        image_path = os.path.join(class_output_folder, f\"image_{i+1}.jpg\")\n",
        "        # Convert image to uint8 format\n",
        "        image_uint8 = (image * 255).astype(np.uint8)\n",
        "        # Create PIL image from numpy array\n",
        "        pil_image = Image.fromarray(image_uint8)\n",
        "        # Save the image\n",
        "        pil_image.save(image_path)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5v-aYr0Mozf"
      },
      "outputs": [],
      "source": [
        "!zip -r /content/images.zip /content/generated_data-500samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "qz0g_IrrNgkQ",
        "outputId": "f2997de2-3550-465e-dfef-d505dc8077b4"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Path to the train directory\n",
        "train_dir = \"/content/train\"\n",
        "\n",
        "# Initialize empty lists to store class names and corresponding file counts\n",
        "class_names = []\n",
        "file_counts = []\n",
        "\n",
        "# Traverse the train directory\n",
        "for class_name in os.listdir(train_dir):\n",
        "    class_dir = os.path.join(train_dir, class_name)\n",
        "    class_dir = os.path.join(class_dir, class_name)\n",
        "    if os.path.isdir(class_dir):\n",
        "        # Count the number of files in the class directory\n",
        "        file_count = len(os.listdir(class_dir))\n",
        "        class_names.append(class_name)\n",
        "        file_counts.append(file_count)\n",
        "\n",
        "# Plot the line graph\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(class_names, file_counts, marker='o', color='skyblue', linestyle='-')\n",
        "plt.title('Number of Images in Each Class')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of Images')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7O3YHiEK3py"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"/content/images.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/generated_data-500samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoeIdLFZP9Ko",
        "outputId": "0a63705f-7cc0-42cf-db7f-40543082dc1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class: Bus, Deficit: 420\n",
            "Class: Tvmonitor, Deficit: 328\n",
            "Class: Bottle, Deficit: 306\n",
            "Class: Dog, Deficit: 190\n",
            "Class: Cow, Deficit: 441\n",
            "Class: Motorbike, Deficit: 337\n",
            "Class: Sheep, Deficit: 449\n",
            "Class: Car, Deficit: 128\n",
            "Class: Diningtable, Deficit: 416\n",
            "Class: Horse, Deficit: 342\n",
            "Class: Pottedplant, Deficit: 356\n",
            "Class: Aeroplane, Deficit: 312\n",
            "Class: Boat, Deficit: 335\n",
            "Class: Chair, Deficit: 220\n",
            "Class: Train, Deficit: 380\n",
            "Class: Bird, Deficit: 256\n",
            "Class: Bicycle, Deficit: 347\n",
            "Class: Cat, Deficit: 238\n",
            "Class: Sofa, Deficit: 393\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Function to count the number of files in a directory\n",
        "def count_files(directory):\n",
        "    return len([name for name in os.listdir(directory) if os.path.isfile(os.path.join(directory, name))])\n",
        "\n",
        "# Function to copy random images from the generated folder to the first subfolder of each class\n",
        "def copy_random_images(source_dir, dest_dir, num_images):\n",
        "    images = os.listdir(source_dir)\n",
        "    random_images = random.sample(images, num_images)\n",
        "    for image in random_images:\n",
        "        shutil.copy(os.path.join(source_dir, image), dest_dir)\n",
        "\n",
        "# Path to the train directory\n",
        "train_dir = \"/content/train\"\n",
        "\n",
        "# Path to the generated folder\n",
        "generated_dir = \"/content/content/generated_data-500samples\"\n",
        "\n",
        "# Traverse each class folder, calculate deficit, and copy random images to fill deficit\n",
        "for class_name in os.listdir(train_dir):\n",
        "    class_subfolder1_dir = os.path.join(train_dir, class_name)\n",
        "    class_subfolder1_dir = os.path.join(class_subfolder1_dir, class_name)\n",
        "    class_generated_dir = os.path.join(generated_dir, class_name)\n",
        "\n",
        "    # Find the maximum number of files among all class generated folders\n",
        "    max_files = max(count_files(class_generated_dir) for class_name in os.listdir(train_dir))\n",
        "\n",
        "    # Count the number of files in class subfolder 1\n",
        "    num_files = count_files(class_subfolder1_dir)\n",
        "\n",
        "    # Calculate deficit\n",
        "    deficit = max_files - num_files\n",
        "    if deficit > 0:\n",
        "        print(f\"Class: {class_name}, Deficit: {deficit}\")\n",
        "        copy_random_images(class_generated_dir, class_subfolder1_dir, deficit)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "zElRR5a3OqDI",
        "outputId": "db40a574-44d6-4de4-b036-04f1e8be2c29"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Path to the train directory\n",
        "train_dir = \"/content/train\"\n",
        "\n",
        "# Initialize empty lists to store class names and corresponding file counts\n",
        "class_names = []\n",
        "file_counts = []\n",
        "\n",
        "# Traverse the train directory\n",
        "for class_name in os.listdir(train_dir):\n",
        "    class_dir = os.path.join(train_dir, class_name)\n",
        "    class_dir = os.path.join(class_dir, class_name)\n",
        "    if os.path.isdir(class_dir):\n",
        "        # Count the number of files in the class directory\n",
        "        file_count = len(os.listdir(class_dir))\n",
        "        class_names.append(class_name)\n",
        "        file_counts.append(file_count)\n",
        "\n",
        "# Plot the line graph\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(class_names, file_counts, marker='o', color='skyblue', linestyle='-')\n",
        "plt.title('Number of Images in Each Class')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of Images')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7AXjQRgU8D0"
      },
      "source": [
        "## Since the class person has 1600 images and we generated only 500, we cannot match the 1600 count, consequently we have removed random files from the person folder to make it even to the rest of the classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwvHzmipQ5Cg",
        "outputId": "a8d03390-45bd-4081-f7ae-8c2591b7f4dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total files before removal: 1601\n",
            "Valid files: ['2008_006078.jpg', '2008_007171.jpg', '2008_000795.jpg', '2008_003051.jpg', '2008_007918.jpg', '2008_005498.jpg', '2008_000090.jpg', '2008_002930.jpg', '2008_007443.jpg', '2008_003043.jpg', '2008_002558.jpg', '2008_003405.jpg', '2008_001182.jpg', '2008_001540.jpg', '2008_004749.jpg', '2008_007833.jpg', '2008_003146.jpg', '2008_008600.jpg', '2008_006117.jpg', '2008_001391.jpg', '2008_008185.jpg', '2008_003933.jpg', '2008_006708.jpg', '2008_005567.jpg', '2008_005501.jpg', '2008_007966.jpg', '2008_000677.jpg', '2008_001060.jpg', '2008_004778.jpg', '2008_000415.jpg', '2008_001068.jpg', '2008_000418.jpg', '2008_003208.jpg', '2008_008403.jpg', '2008_002956.jpg', '2008_004938.jpg', '2008_001349.jpg', '2008_000623.jpg', '2008_000376.jpg', '2008_002932.jpg', '2008_004522.jpg', '2008_002311.jpg', '2008_000854.jpg', '2008_006944.jpg', '2008_001206.jpg', '2008_007435.jpg', '2008_003154.jpg', '2008_003407.jpg', '2008_005790.jpg', '2008_003128.jpg', '2008_001275.jpg', '2008_000540.jpg', '2008_002885.jpg', '2008_002150.jpg', '2008_000970.jpg', '2008_005231.jpg', '2008_004081.jpg', '2008_003672.jpg', '2008_003467.jpg', '2008_006317.jpg', '2008_001245.jpg', '2008_002610.jpg', '2008_001549.jpg', '2008_002113.jpg', '2008_000981.jpg', '2008_004243.jpg', '2008_004017.jpg', '2008_001054.jpg', '2008_006989.jpg', '2008_000489.jpg', '2008_007837.jpg', '2008_007019.jpg', '2008_002001.jpg', '2008_000365.jpg', '2008_004044.jpg', '2008_000972.jpg', '2008_005324.jpg', '2008_008319.jpg', '2008_000275.jpg', '2008_007682.jpg', '2008_000553.jpg', '2008_002960.jpg', '2008_008368.jpg', '2008_001075.jpg', '2008_005444.jpg', '2008_004534.jpg', '2008_001344.jpg', '2008_000311.jpg', '2008_003720.jpg', '2008_002099.jpg', '2008_001751.jpg', '2008_000878.jpg', '2008_001007.jpg', '2008_008272.jpg', '2008_001009.jpg', '2008_003461.jpg', '2008_001183.jpg', '2008_006716.jpg', '2008_001431.jpg', '2008_003929.jpg', '2008_008708.jpg', '2008_002735.jpg', '2008_001905.jpg', '2008_001190.jpg', '2008_000445.jpg', '2008_001475.jpg', '2008_000343.jpg', '2008_008162.jpg', '2008_001797.jpg', '2008_001958.jpg', '2008_006021.jpg', '2008_004056.jpg', '2008_000424.jpg', '2008_006953.jpg', '2008_005934.jpg', '2008_001021.jpg', '2008_007717.jpg', '2008_003205.jpg', '2008_003414.jpg', '2008_001142.jpg', '2008_002156.jpg', '2008_005072.jpg', '2008_008725.jpg', '2008_005863.jpg', '2008_001221.jpg', '2008_001119.jpg', '2008_002549.jpg', '2008_001308.jpg', '2008_004140.jpg', '2008_001318.jpg', '2008_006382.jpg', '2008_000535.jpg', '2008_001802.jpg', '2008_000880.jpg', '2008_006834.jpg', '2008_002598.jpg', '2008_005490.jpg', '2008_002906.jpg', '2008_003330.jpg', '2008_004706.jpg', '2008_003780.jpg', '2008_005848.jpg', '2008_002838.jpg', '2008_002299.jpg', '2008_003773.jpg', '2008_001731.jpg', '2008_003318.jpg', '2008_000144.jpg', '2008_005612.jpg', '2008_005838.jpg', '2008_000803.jpg', '2008_007056.jpg', '2008_004037.jpg', '2008_008659.jpg', '2008_004774.jpg', '2008_001574.jpg', '2008_005646.jpg', '2008_008221.jpg', '2008_006181.jpg', '2008_004459.jpg', '2008_007768.jpg', '2008_006650.jpg', '2008_007648.jpg', '2008_002017.jpg', '2008_001122.jpg', '2008_001501.jpg', '2008_008526.jpg', '2008_003287.jpg', '2008_004872.jpg', '2008_007446.jpg', '2008_003453.jpg', '2008_007348.jpg', '2008_003748.jpg', '2008_006880.jpg', '2008_000745.jpg', '2008_007168.jpg', '2008_004513.jpg', '2008_008034.jpg', '2008_002098.jpg', '2008_002414.jpg', '2008_000207.jpg', '2008_005213.jpg', '2008_003152.jpg', '2008_007185.jpg', '2008_002566.jpg', '2008_004549.jpg', '2008_008095.jpg', '2008_007119.jpg', '2008_001814.jpg', '2008_003507.jpg', '2008_006052.jpg', '2008_007277.jpg', '2008_006570.jpg', '2008_000775.jpg', '2008_000142.jpg', '2008_002576.jpg', '2008_004125.jpg', '2008_002599.jpg', '2008_004841.jpg', '2008_004134.jpg', '2008_002340.jpg', '2008_004866.jpg', '2008_002084.jpg', '2008_001080.jpg', '2008_003295.jpg', '2008_003533.jpg', '2008_002093.jpg', '2008_003433.jpg', '2008_001909.jpg', '2008_000455.jpg', '2008_006424.jpg', '2008_005652.jpg', '2008_008671.jpg', '2008_000003.jpg', '2008_006611.jpg', '2008_002736.jpg', '2008_004930.jpg', '2008_003329.jpg', '2008_002107.jpg', '2008_002733.jpg', '2008_004344.jpg', '2008_002502.jpg', '2008_004504.jpg', '2008_001763.jpg', '2008_006879.jpg', '2008_004203.jpg', '2008_001673.jpg', '2008_007147.jpg', '2008_000222.jpg', '2008_000552.jpg', '2008_005972.jpg', '2008_006250.jpg', '2008_002069.jpg', '2008_001299.jpg', '2008_006807.jpg', '2008_003544.jpg', '2008_004979.jpg', '2008_000432.jpg', '2008_008511.jpg', '2008_000689.jpg', '2008_003313.jpg', '2008_008517.jpg', '2008_004499.jpg', '2008_008058.jpg', '2008_004213.jpg', '2008_003796.jpg', '2008_001358.jpg', '2008_006825.jpg', '2008_003271.jpg', '2008_001504.jpg', '2008_005570.jpg', '2008_005616.jpg', '2008_008466.jpg', '2008_001230.jpg', '2008_003093.jpg', '2008_001874.jpg', '2008_000985.jpg', '2008_004575.jpg', '2008_007112.jpg', '2008_003090.jpg', '2008_006588.jpg', '2008_000758.jpg', '2008_005427.jpg', '2008_002356.jpg', '2008_001482.jpg', '2008_004123.jpg', '2008_003515.jpg', '2008_000700.jpg', '2008_007993.jpg', '2008_000650.jpg', '2008_001382.jpg', '2008_004678.jpg', '2008_002067.jpg', '2008_004090.jpg', '2008_007225.jpg', '2008_007556.jpg', '2008_004391.jpg', '2008_002533.jpg', '2008_008443.jpg', '2008_001272.jpg', '2008_000737.jpg', '2008_005316.jpg', '2008_001533.jpg', '2008_000321.jpg', '2008_000268.jpg', '2008_004976.jpg', '2008_000733.jpg', '2008_005737.jpg', '2008_001914.jpg', '2008_003985.jpg', '2008_000572.jpg', '2008_007146.jpg', '2008_000622.jpg', '2008_003598.jpg', '2008_005395.jpg', '2008_005243.jpg', '2008_006847.jpg', '2008_007207.jpg', '2008_005907.jpg', '2008_001196.jpg', '2008_007653.jpg', '2008_005726.jpg', '2008_000777.jpg', '2008_007928.jpg', '2008_008718.jpg', '2008_006154.jpg', '2008_000656.jpg', '2008_006833.jpg', '2008_007393.jpg', '2008_004903.jpg', '2008_002720.jpg', '2008_008697.jpg', '2008_007675.jpg', '2008_000558.jpg', '2008_006798.jpg', '2008_003265.jpg', '2008_001112.jpg', '2008_001351.jpg', '2008_007770.jpg', '2008_002751.jpg', '2008_000815.jpg', '2008_003611.jpg', '2008_002457.jpg', '2008_004983.jpg', '2008_008757.jpg', '2008_002854.jpg', '2008_004246.jpg', '2008_003962.jpg', '2008_008029.jpg', '2008_008552.jpg', '2008_000194.jpg', '2008_001099.jpg', '2008_002058.jpg', '2008_006059.jpg', '2008_002524.jpg', '2008_007459.jpg', '2008_000252.jpg', '2008_003523.jpg', '2008_006188.jpg', '2008_007913.jpg', '2008_005808.jpg', '2008_000950.jpg', '2008_005978.jpg', '2008_003061.jpg', '2008_002543.jpg', '2008_004510.jpg', '2008_008479.jpg', '2008_001631.jpg', '2008_001284.jpg', '2008_003819.jpg', '2008_000694.jpg', '2008_003883.jpg', '2008_002922.jpg', '2008_007410.jpg', '2008_001837.jpg', '2008_008530.jpg', '2008_008488.jpg', '2008_001842.jpg', '2008_001073.jpg', '2008_004101.jpg', '2008_002931.jpg', '2008_004687.jpg', '2008_006881.jpg', '2008_001205.jpg', '2008_003925.jpg', '2008_006151.jpg', '2008_000661.jpg', '2008_000673.jpg', '2008_004649.jpg', '2008_001466.jpg', '2008_001670.jpg', '2008_003768.jpg', '2008_004546.jpg', '2008_002753.jpg', '2008_002848.jpg', '2008_002540.jpg', '2008_008266.jpg', '2008_006039.jpg', '2008_003522.jpg', '2008_002920.jpg', '2008_007190.jpg', '2008_004301.jpg', '2008_004054.jpg', '2008_007339.jpg', '2008_000499.jpg', '2008_001796.jpg', '2008_005089.jpg', '2008_008210.jpg', '2008_001419.jpg', '2008_000109.jpg', '2008_002439.jpg', '2008_001692.jpg', '2008_004333.jpg', '2008_008069.jpg', '2008_005677.jpg', '2008_000442.jpg', '2008_005408.jpg', '2008_004646.jpg', '2008_001486.jpg', '2008_003081.jpg', '2008_007994.jpg', '2008_000982.jpg', '2008_004471.jpg', '2008_008744.jpg', '2008_006410.jpg', '2008_006646.jpg', '2008_006818.jpg', '2008_003874.jpg', '2008_001930.jpg', '2008_004441.jpg', '2008_007281.jpg', '2008_004330.jpg', '2008_000510.jpg', '2008_001969.jpg', '2008_003650.jpg', '2008_006567.jpg', '2008_003521.jpg', '2008_000436.jpg', '2008_001566.jpg', '2008_002210.jpg', '2008_006779.jpg', '2008_001314.jpg', '2008_003871.jpg', '2008_003840.jpg', '2008_001761.jpg', '2008_000266.jpg', '2008_008388.jpg', '2008_003629.jpg', '2008_002750.jpg', '2008_002652.jpg', '2008_000579.jpg', '2008_007129.jpg', '2008_008229.jpg', '2008_000842.jpg', '2008_002162.jpg', '2008_006390.jpg', '2008_004438.jpg', '2008_004464.jpg', '2008_004288.jpg', '2008_005582.jpg', '2008_008325.jpg', '2008_002988.jpg', '2008_004325.jpg', '2008_004961.jpg', '2008_004092.jpg', '2008_004217.jpg', '2008_005796.jpg', '2008_001035.jpg', '2008_003039.jpg', '2008_006979.jpg', '2008_000041.jpg', '2008_004270.jpg', '2008_001074.jpg', '2008_001706.jpg', '2008_000243.jpg', '2008_005588.jpg', '2008_000143.jpg', '2008_001012.jpg', '2008_003320.jpg', '2008_005779.jpg', '2008_007701.jpg', '2008_005701.jpg', '2008_005884.jpg', '2008_005939.jpg', '2008_004205.jpg', '2008_000036.jpg', '2008_000887.jpg', '2008_003472.jpg', '2008_004881.jpg', '2008_007904.jpg', '2008_001882.jpg', '2008_000971.jpg', '2008_003283.jpg', '2008_003873.jpg', '2008_004088.jpg', '2008_008262.jpg', '2008_002817.jpg', '2008_004231.jpg', '2008_006732.jpg', '2008_008072.jpg', '2008_007392.jpg', '2008_007692.jpg', '2008_005472.jpg', '2008_003479.jpg', '2008_001998.jpg', '2008_002448.jpg', '2008_003228.jpg', '2008_000328.jpg', '2008_002756.jpg', '2008_006331.jpg', '2008_000516.jpg', '2008_002567.jpg', '2008_007729.jpg', '2008_002419.jpg', '2008_000203.jpg', '2008_002035.jpg', '2008_008683.jpg', '2008_001538.jpg', '2008_007038.jpg', '2008_000944.jpg', '2008_006705.jpg', '2008_003143.jpg', '2008_008084.jpg', '2008_001098.jpg', '2008_004321.jpg', '2008_002124.jpg', '2008_002705.jpg', '2008_000636.jpg', '2008_006135.jpg', '2008_006874.jpg', '2008_002523.jpg', '2008_007291.jpg', '2008_000646.jpg', '2008_000128.jpg', '2008_001202.jpg', '2008_001283.jpg', '2008_002362.jpg', '2008_004729.jpg', '2008_007741.jpg', '2008_002296.jpg', '2008_008487.jpg', '2008_006933.jpg', '2008_008619.jpg', '2008_002374.jpg', '2008_002639.jpg', '2008_000226.jpg', '2008_002056.jpg', '2008_005251.jpg', '2008_000008.jpg', '2008_001359.jpg', '2008_003546.jpg', '2008_004478.jpg', '2008_006731.jpg', '2008_007843.jpg', '2008_005094.jpg', '2008_003829.jpg', '2008_008098.jpg', '2008_001589.jpg', '2008_004518.jpg', '2008_003754.jpg', '2008_006631.jpg', '2008_004574.jpg', '2008_000141.jpg', '2008_002716.jpg', '2008_008083.jpg', '2008_005046.jpg', '2008_001081.jpg', '2008_001690.jpg', '2008_003733.jpg', '2008_007902.jpg', '2008_003682.jpg', '2008_003604.jpg', '2008_001248.jpg', '2008_000426.jpg', '2008_003825.jpg', '2008_004599.jpg', '2008_003203.jpg', '2008_004713.jpg', '2008_001955.jpg', '2008_001052.jpg', '2008_002032.jpg', '2008_005297.jpg', '2008_000277.jpg', '2008_000573.jpg', '2008_001444.jpg', '2008_001395.jpg', '2008_000806.jpg', '2008_004142.jpg', '2008_000096.jpg', '2008_000605.jpg', '2008_001765.jpg', '2008_002244.jpg', '2008_001390.jpg', '2008_005682.jpg', '2008_002892.jpg', '2008_008591.jpg', '2008_004457.jpg', '2008_003815.jpg', '2008_003067.jpg', '2008_001373.jpg', '2008_005832.jpg', '2008_008618.jpg', '2008_007184.jpg', '2008_001852.jpg', '2008_000811.jpg', '2008_003094.jpg', '2008_004372.jpg', '2008_002674.jpg', '2008_006714.jpg', '2008_001306.jpg', '2008_003280.jpg', '2008_004616.jpg', '2008_001547.jpg', '2008_003888.jpg', '2008_002247.jpg', '2008_000939.jpg', '2008_003437.jpg', '2008_006064.jpg', '2008_001063.jpg', '2008_003609.jpg', '2008_000690.jpg', '2008_003492.jpg', '2008_002730.jpg', '2008_003755.jpg', '2008_004431.jpg', '2008_002199.jpg', '2008_000792.jpg', '2008_008093.jpg', '2008_001534.jpg', '2008_007242.jpg', '2008_008192.jpg', '2008_003689.jpg', '2008_001434.jpg', '2008_008021.jpg', '2008_002942.jpg', '2008_000764.jpg', '2008_002752.jpg', '2008_001714.jpg', '2008_006032.jpg', '2008_001911.jpg', '2008_008315.jpg', '2008_006609.jpg', '2008_002792.jpg', '2008_005035.jpg', '2008_000916.jpg', '2008_004161.jpg', '2008_000290.jpg', '2008_000783.jpg', '2008_002579.jpg', '2008_003766.jpg', '2008_003983.jpg', '2008_001404.jpg', '2008_000403.jpg', '2008_002096.jpg', '2008_002613.jpg', '2008_006289.jpg', '2008_007872.jpg', '2008_000837.jpg', '2008_006088.jpg', '2008_000740.jpg', '2008_000398.jpg', '2008_000704.jpg', '2008_004198.jpg', '2008_001832.jpg', '2008_006526.jpg', '2008_001188.jpg', '2008_007646.jpg', '2008_004188.jpg', '2008_002820.jpg', '2008_000342.jpg', '2008_001083.jpg', '2008_003596.jpg', '2008_003775.jpg', '2008_008362.jpg', '2008_000613.jpg', '2008_006254.jpg', '2008_001746.jpg', '2008_003813.jpg', '2008_003608.jpg', '2008_000527.jpg', '2008_001789.jpg', '2008_002193.jpg', '2008_002483.jpg', '2008_002795.jpg', '2008_001661.jpg', '2008_004314.jpg', '2008_002366.jpg', '2008_003278.jpg', '2008_000875.jpg', '2008_004016.jpg', '2008_000473.jpg', '2008_002542.jpg', '2008_001867.jpg', '2008_000725.jpg', '2008_003681.jpg', '2008_005549.jpg', '2008_006616.jpg', '2008_003132.jpg', '2008_006497.jpg', '2008_000834.jpg', '2008_002811.jpg', '2008_003578.jpg', '2008_004851.jpg', '2008_004371.jpg', '2008_000330.jpg', '2008_003193.jpg', '2008_000959.jpg', '2008_001910.jpg', '2008_005171.jpg', '2008_001907.jpg', '2008_000480.jpg', '2008_007789.jpg', '2008_003706.jpg', '2008_004327.jpg', '2008_006890.jpg', '2008_001986.jpg', '2008_004512.jpg', '2008_001970.jpg', '2008_003075.jpg', '2008_001937.jpg', '2008_005043.jpg', '2008_003008.jpg', '2008_003882.jpg', '2008_001699.jpg', '2008_006857.jpg', '2008_004711.jpg', '2008_007452.jpg', '2008_001249.jpg', '2008_001158.jpg', '2008_005788.jpg', '2008_001388.jpg', '2008_006275.jpg', '2008_003224.jpg', '2008_000726.jpg', '2008_004937.jpg', '2008_000829.jpg', '2008_002966.jpg', '2008_001967.jpg', '2008_001619.jpg', '2008_003511.jpg', '2008_006441.jpg', '2008_005494.jpg', '2008_001605.jpg', '2008_001881.jpg', '2008_000340.jpg', '2008_003020.jpg', '2008_003662.jpg', '2008_000067.jpg', '2008_003469.jpg', '2008_002857.jpg', '2008_005360.jpg', '2008_000547.jpg', '2008_005957.jpg', '2008_007043.jpg', '2008_000236.jpg', '2008_002590.jpg', '2008_003800.jpg', '2008_001989.jpg', '2008_000928.jpg', '2008_001089.jpg', '2008_007409.jpg', '2008_003707.jpg', '2008_001977.jpg', '2008_002013.jpg', '2008_004770.jpg', '2008_001408.jpg', '2008_007488.jpg', '2008_000629.jpg', '2008_001736.jpg', '2008_003334.jpg', '2008_001659.jpg', '2008_007864.jpg', '2008_000987.jpg', '2008_000615.jpg', '2008_007182.jpg', '2008_004852.jpg', '2008_007293.jpg', '2008_002482.jpg', '2008_002794.jpg', '2008_002037.jpg', '2008_000346.jpg', '2008_000235.jpg', '2008_006120.jpg', '2008_001057.jpg', '2008_008141.jpg', '2008_003847.jpg', '2008_006145.jpg', '2008_004476.jpg', '2008_003996.jpg', '2008_002718.jpg', '2008_004482.jpg', '2008_000705.jpg', '2008_001255.jpg', '2008_002616.jpg', '2008_004948.jpg', '2008_005365.jpg', '2008_007101.jpg', '2008_007950.jpg', '2008_006941.jpg', '2008_004984.jpg', '2008_005650.jpg', '2008_003892.jpg', '2008_001680.jpg', '2008_000195.jpg', '2008_005139.jpg', '2008_004105.jpg', '2008_007223.jpg', '2008_001307.jpg', '2008_002856.jpg', '2008_006844.jpg', '2008_002404.jpg', '2008_003305.jpg', '2008_005359.jpg', '2008_002866.jpg', '2008_001024.jpg', '2008_006750.jpg', '2008_006392.jpg', '2008_008624.jpg', '2008_006152.jpg', '2008_007882.jpg', '2008_007591.jpg', '2008_007336.jpg', '2008_002322.jpg', '2008_003001.jpg', '2008_007565.jpg', '2008_000841.jpg', '2008_002144.jpg', '2008_003062.jpg', '2008_002259.jpg', '2008_000446.jpg', '2008_004874.jpg', '2008_005600.jpg', '2008_003316.jpg', '2008_005032.jpg', '2008_000719.jpg', '2008_000264.jpg', '2008_008629.jpg', '2008_003860.jpg', '2008_004113.jpg', '2008_002634.jpg', '2008_003830.jpg', '2008_003182.jpg', '2008_003127.jpg', '2008_001031.jpg', '2008_006397.jpg', '2008_007525.jpg', '2008_005172.jpg', '2008_007576.jpg', '2008_004130.jpg', '2008_001536.jpg', '2008_003749.jpg', '2008_001369.jpg', '2008_004126.jpg', '2008_002436.jpg', '2008_001367.jpg', '2008_002775.jpg', '2008_003333.jpg', '2008_003921.jpg', '2008_001773.jpg', '2008_007169.jpg', '2008_003552.jpg', '2008_001055.jpg', '2008_007567.jpg', '2008_008232.jpg', '2008_000674.jpg', '2008_000844.jpg', '2008_005610.jpg', '2008_006205.jpg', '2008_001946.jpg', '2008_008758.jpg', '2008_006129.jpg', '2008_002621.jpg', '2008_003076.jpg', '2008_003395.jpg', '2008_000662.jpg', '2008_001177.jpg', '2008_001888.jpg', '2008_004287.jpg', '2008_003351.jpg', '2008_004832.jpg', '2008_002574.jpg', '2008_003344.jpg', '2008_006491.jpg', '2008_000254.jpg', '2008_006663.jpg', '2008_008717.jpg', '2008_006952.jpg', '2008_003120.jpg', '2008_005991.jpg', '2008_001437.jpg', '2008_000278.jpg', '2008_006404.jpg', '2008_002494.jpg', '2008_007895.jpg', '2008_002603.jpg', '2008_003958.jpg', '2008_001106.jpg', '2008_002510.jpg', '2008_004318.jpg', '2008_008579.jpg', '2008_000992.jpg', '2008_005276.jpg', '2008_001854.jpg', '2008_002666.jpg', '2008_001750.jpg', '2008_001493.jpg', '2008_004544.jpg', '2008_002243.jpg', '2008_003697.jpg', '2008_005641.jpg', '2008_002741.jpg', '2008_003613.jpg', '2008_002377.jpg', '2008_007067.jpg', '2008_004950.jpg', '2008_000588.jpg', '2008_004071.jpg', '2008_003542.jpg', '2008_005761.jpg', '2008_001638.jpg', '2008_001402.jpg', '2008_004242.jpg', '2008_007219.jpg', '2008_002378.jpg', '2008_000422.jpg', '2008_001413.jpg', '2008_002809.jpg', '2008_008433.jpg', '2008_000051.jpg', '2008_002946.jpg', '2008_006433.jpg', '2008_007665.jpg', '2008_003249.jpg', '2008_005412.jpg', '2008_007103.jpg', '2008_001432.jpg', '2008_008469.jpg', '2008_002321.jpg', '2008_003965.jpg', '2008_007138.jpg', '2008_003674.jpg', '2008_003565.jpg', '2008_008705.jpg', '2008_008336.jpg', '2008_001346.jpg', '2008_002047.jpg', '2008_008184.jpg', '2008_007286.jpg', '2008_004858.jpg', '2008_002179.jpg', '2008_001225.jpg', '2008_000881.jpg', '2008_007584.jpg', '2008_000699.jpg', '2008_004426.jpg', '2008_004435.jpg', '2008_000776.jpg', '2008_004036.jpg', '2008_003464.jpg', '2008_006816.jpg', '2008_008217.jpg', '2008_004538.jpg', '2008_005110.jpg', '2008_003667.jpg', '2008_000496.jpg', '2008_007745.jpg', '2008_004361.jpg', '2008_000908.jpg', '2008_000281.jpg', '2008_002649.jpg', '2008_005236.jpg', '2008_001048.jpg', '2008_000313.jpg', '2008_003432.jpg', '2008_001551.jpg', '2008_001531.jpg', '2008_000742.jpg', '2008_007421.jpg', '2008_003210.jpg', '2008_001467.jpg', '2008_003978.jpg', '2008_000568.jpg', '2008_005855.jpg', '2008_002007.jpg', '2008_001727.jpg', '2008_007478.jpg', '2008_001353.jpg', '2008_001825.jpg', '2008_003971.jpg', '2008_000283.jpg', '2008_000176.jpg', '2008_002675.jpg', '2008_008676.jpg', '2008_005045.jpg', '2008_000753.jpg', '2008_000979.jpg', '2008_000902.jpg', '2008_007181.jpg', '2008_000406.jpg', '2008_006813.jpg', '2008_003290.jpg', '2008_005937.jpg', '2008_006684.jpg', '2008_004647.jpg', '2008_001271.jpg', '2008_000367.jpg', '2008_001366.jpg', '2008_003442.jpg', '2008_001121.jpg', '2008_002424.jpg', '2008_004046.jpg', '2008_008391.jpg', '2008_000563.jpg', '2008_001322.jpg', '2008_002148.jpg', '2008_001742.jpg', '2008_000364.jpg', '2008_000691.jpg', '2008_002411.jpg', '2008_000648.jpg', '2008_005552.jpg', '2008_001241.jpg', '2008_001951.jpg', '2008_003095.jpg', '2008_000778.jpg', '2008_002459.jpg', '2008_005850.jpg', '2008_002791.jpg', '2008_007285.jpg', '2008_003452.jpg', '2008_005111.jpg', '2008_006892.jpg', '2008_008343.jpg', '2008_008075.jpg', '2008_001401.jpg', '2008_001932.jpg', '2008_001553.jpg', '2008_000213.jpg', '2008_003336.jpg', '2008_003107.jpg', '2008_008450.jpg', '2008_004045.jpg', '2008_006448.jpg', '2008_006487.jpg', '2008_001034.jpg', '2008_007325.jpg', '2008_003658.jpg', '2008_004519.jpg', '2008_000132.jpg', '2008_001312.jpg', '2008_007852.jpg', '2008_008066.jpg', '2008_002458.jpg', '2008_000522.jpg', '2008_001697.jpg', '2008_001227.jpg', '2008_001520.jpg', '2008_008695.jpg', '2008_002823.jpg', '2008_001304.jpg', '2008_007761.jpg', '2008_008637.jpg', '2008_005294.jpg', '2008_000237.jpg', '2008_000607.jpg', '2008_002272.jpg', '2008_001894.jpg', '2008_002514.jpg', '2008_007061.jpg', '2008_003531.jpg', '2008_001523.jpg', '2008_000338.jpg', '2008_002917.jpg', '2008_004018.jpg', '2008_002725.jpg', '2008_004342.jpg', '2008_001022.jpg', '2008_003791.jpg', '2008_004263.jpg', '2008_002870.jpg', '2008_003015.jpg', '2008_000672.jpg', '2008_001919.jpg', '2008_004398.jpg', '2008_006311.jpg', '2008_001036.jpg', '2008_005055.jpg', '2008_003418.jpg', '2008_003592.jpg', '2008_001440.jpg', '2008_002677.jpg', '2008_004862.jpg', '2008_004707.jpg', '2008_004781.jpg', '2008_000828.jpg', '2008_004756.jpg', '2008_000814.jpg', '2008_001593.jpg', '2008_008064.jpg', '2008_002384.jpg', '2008_008212.jpg', '2008_001429.jpg', '2008_002304.jpg', '2008_007334.jpg', '2008_001564.jpg', '2008_001709.jpg', '2008_002880.jpg', '2008_001980.jpg', '2008_004515.jpg', '2008_004470.jpg', '2008_003510.jpg', '2008_003967.jpg', '2008_003202.jpg', '2008_002181.jpg', '2008_001257.jpg', '2008_004230.jpg', '2008_002909.jpg', '2008_002951.jpg', '2008_004258.jpg', '2008_006496.jpg', '2008_002879.jpg', '2008_002512.jpg', '2008_002446.jpg', '2008_003286.jpg', '2008_002774.jpg', '2008_000868.jpg', '2008_005635.jpg', '2008_004389.jpg', '2008_003805.jpg', '2008_002317.jpg', '2008_002103.jpg', '2008_006407.jpg', '2008_000469.jpg', '2008_003685.jpg', '2008_002222.jpg', '2008_004269.jpg', '2008_005338.jpg', '2008_006273.jpg', '2008_003675.jpg', '2008_002365.jpg', '2008_003100.jpg', '2008_002092.jpg', '2008_002852.jpg', '2008_002984.jpg', '2008_000383.jpg', '2008_000599.jpg', '2008_002185.jpg', '2008_000474.jpg', '2008_005921.jpg', '2008_005063.jpg', '2008_008395.jpg', '2008_002622.jpg', '2008_001170.jpg', '2008_004611.jpg', '2008_002999.jpg', '2008_002638.jpg', '2008_003891.jpg', '2008_001488.jpg', '2008_002645.jpg', '2008_002562.jpg', '2008_000393.jpg', '2008_004784.jpg', '2008_000936.jpg', '2008_003769.jpg', '2008_000706.jpg', '2008_005698.jpg', '2008_002831.jpg', '2008_003079.jpg', '2008_004666.jpg', '2008_002804.jpg', '2008_001660.jpg', '2008_007617.jpg', '2008_005625.jpg', '2008_005295.jpg', '2008_003914.jpg', '2008_001527.jpg', '2008_008649.jpg', '2008_003626.jpg', '2008_005484.jpg', '2008_005218.jpg', '2008_002499.jpg', '2008_004636.jpg', '2008_008588.jpg', '2008_000548.jpg', '2008_003277.jpg', '2008_008567.jpg', '2008_002405.jpg', '2008_002023.jpg', '2008_005336.jpg', '2008_000452.jpg', '2008_005877.jpg', '2008_002031.jpg', '2008_005791.jpg', '2008_008564.jpg', '2008_002324.jpg', '2008_004002.jpg', '2008_006776.jpg', '2008_003186.jpg', '2008_006121.jpg', '2008_002357.jpg', '2008_000259.jpg', '2008_004966.jpg', '2008_007195.jpg', '2008_002712.jpg', '2008_005414.jpg', '2008_002808.jpg', '2008_008416.jpg', '2008_003619.jpg', '2008_004740.jpg', '2008_002036.jpg', '2008_008701.jpg', '2008_001607.jpg', '2008_006148.jpg', '2008_003653.jpg', '2008_008474.jpg', '2008_002971.jpg', '2008_004603.jpg', '2008_008155.jpg', '2008_007942.jpg', '2008_001591.jpg', '2008_001613.jpg', '2008_002783.jpg', '2008_004679.jpg', '2008_002568.jpg', '2008_006047.jpg', '2008_005519.jpg', '2008_002248.jpg', '2008_003384.jpg', '2008_003245.jpg', '2008_000683.jpg', '2008_008524.jpg', '2008_003266.jpg', '2008_000413.jpg', '2008_008218.jpg', '2008_003638.jpg', '2008_002042.jpg', '2008_001481.jpg', '2008_001325.jpg', '2008_002485.jpg', '2008_003089.jpg', '2008_000734.jpg', '2008_006796.jpg', '2008_001648.jpg', '2008_002145.jpg', '2008_007696.jpg', '2008_000260.jpg', '2008_006642.jpg', '2008_007828.jpg', '2008_003534.jpg', '2008_002330.jpg', '2008_008307.jpg', '2008_005168.jpg', '2008_001982.jpg', '2008_001667.jpg', '2008_005558.jpg', '2008_001154.jpg', '2008_000191.jpg', '2008_000371.jpg', '2008_008549.jpg', '2008_003311.jpg', '2008_002167.jpg', '2008_003025.jpg', '2008_002869.jpg', '2008_006215.jpg', '2008_008528.jpg', '2008_003242.jpg', '2008_001947.jpg', '2008_002061.jpg', '2008_001791.jpg', '2008_000769.jpg', '2008_001609.jpg', '2008_003842.jpg', '2008_001821.jpg', '2008_002648.jpg', '2008_007218.jpg', '2008_002564.jpg', '2008_000359.jpg', '2008_007280.jpg', '2008_000614.jpg', '2008_007509.jpg', '2008_005431.jpg', '2008_003478.jpg', '2008_000511.jpg', '2008_001596.jpg', '2008_002526.jpg', '2008_002746.jpg', '2008_008522.jpg', '2008_007716.jpg', '2008_003995.jpg', '2008_008231.jpg', '2008_006267.jpg', '2008_001115.jpg', '2008_006519.jpg', '2008_002361.jpg', '2008_003099.jpg', '2008_006998.jpg', '2008_004053.jpg', '2008_008154.jpg', '2008_000924.jpg', '2008_001636.jpg', '2008_007962.jpg', '2008_006108.jpg', '2008_003856.jpg', '2008_000447.jpg', '2008_008519.jpg', '2008_001539.jpg', '2008_005399.jpg', '2008_001838.jpg', '2008_003122.jpg', '2008_007706.jpg', '2008_002700.jpg', '2008_001782.jpg', '2008_004307.jpg', '2008_004003.jpg', '2008_006969.jpg', '2008_001494.jpg', '2008_005599.jpg', '2008_005066.jpg', '2008_006076.jpg', '2008_001655.jpg', '2008_002947.jpg', '2008_001454.jpg', '2008_008440.jpg', '2008_002325.jpg', '2008_001729.jpg', '2008_002678.jpg', '2008_000562.jpg', '2008_000217.jpg', '2008_000435.jpg', '2008_008275.jpg', '2008_000316.jpg', '2008_002344.jpg', '2008_008755.jpg', '2008_003884.jpg', '2008_002787.jpg', '2008_000940.jpg', '2008_003866.jpg', '2008_004926.jpg', '2008_006864.jpg', '2008_001602.jpg', '2008_002738.jpg', '2008_004567.jpg', '2008_002115.jpg', '2008_003056.jpg', '2008_001702.jpg', '2008_007986.jpg', '2008_005151.jpg', '2008_000381.jpg', '2008_005742.jpg', '2008_005738.jpg', '2008_004894.jpg', '2008_004455.jpg', '2008_006370.jpg', '2008_002011.jpg', '2008_003956.jpg', '2008_002813.jpg', '2008_005201.jpg', '2008_000519.jpg', '2008_007625.jpg', '2008_004764.jpg', '2008_000723.jpg', '2008_001104.jpg', '2008_000261.jpg', '2008_007356.jpg', '2008_003030.jpg', '2008_001582.jpg', '2008_000023.jpg', '2008_001139.jpg', '2008_001645.jpg', '2008_004102.jpg', '2008_000867.jpg', '2008_000796.jpg', '2008_006991.jpg', '2008_005976.jpg', '2008_008745.jpg', '2008_003429.jpg', '2008_004308.jpg', '2008_001023.jpg', '2008_003409.jpg', '2008_005101.jpg', '2008_005033.jpg', '2008_007955.jpg', '2008_000748.jpg', '2008_001745.jpg', '2008_001856.jpg', '2008_007133.jpg', '2008_002758.jpg', '2008_002776.jpg', '2008_003134.jpg', '2008_004247.jpg', '2008_000416.jpg', '2008_003945.jpg', '2008_005902.jpg', '2008_001028.jpg', '2008_002955.jpg', '2008_007032.jpg', '2008_000138.jpg', '2008_003289.jpg', '2008_006024.jpg', '2008_005500.jpg', '2008_000993.jpg', '2008_004387.jpg', '2008_001624.jpg', '2008_005447.jpg', '2008_003463.jpg', '2008_004745.jpg', '2008_001140.jpg', '2008_007247.jpg', '2008_006027.jpg', '2008_005923.jpg', '2008_003801.jpg', '2008_001385.jpg', '2008_005271.jpg', '2008_001294.jpg', '2008_002009.jpg', '2008_006256.jpg', '2008_003157.jpg', '2008_004376.jpg', '2008_004541.jpg', '2008_000423.jpg', '2008_007402.jpg', '2008_008572.jpg', '2008_004692.jpg', '2008_002653.jpg', '2008_004365.jpg', '2008_004439.jpg', '2008_007524.jpg', '2008_000655.jpg', '2008_006549.jpg', '2008_002425.jpg', '2008_004968.jpg', '2008_003545.jpg', '2008_005277.jpg', '2008_004849.jpg', '2008_002973.jpg', '2008_008410.jpg', '2008_005016.jpg', '2008_001039.jpg', '2008_000847.jpg', '2008_001376.jpg', '2008_001622.jpg', '2008_001199.jpg', '2008_000628.jpg', '2008_005928.jpg', '2008_006863.jpg', '2008_000583.jpg', '2008_003593.jpg', '2008_003191.jpg', '2008_002789.jpg', '2008_002172.jpg', '2008_004834.jpg', '2008_008337.jpg', '2008_000640.jpg', '2008_006195.jpg', '2008_002191.jpg', '2008_003984.jpg', '2008_001735.jpg', '2008_001171.jpg', '2008_000647.jpg', '2008_005000.jpg', '2008_003514.jpg', '2008_002132.jpg', '2008_001784.jpg', '2008_006341.jpg', '2008_001563.jpg', '2008_001026.jpg', '2008_005098.jpg', '2008_002662.jpg', '2008_002470.jpg', '2008_002882.jpg', '2008_002631.jpg', '2008_001296.jpg', '2008_003493.jpg', '2008_001617.jpg', '2008_005563.jpg', '2008_000564.jpg', '2008_005527.jpg', '2008_005758.jpg', '2008_005253.jpg', '2008_003764.jpg', '2008_000223.jpg', '2008_004654.jpg', '2008_004554.jpg', '2008_003304.jpg', '2008_007990.jpg', '2008_002236.jpg', '2008_006722.jpg', '2008_001263.jpg', '2008_003393.jpg', '2008_001302.jpg', '2008_005178.jpg', '2008_005215.jpg', '2008_002169.jpg', '2008_001235.jpg', '2008_002541.jpg', '2008_001643.jpg', '2008_004221.jpg', '2008_002495.jpg', '2008_000461.jpg', '2008_000984.jpg', '2008_006758.jpg', '2008_000825.jpg', '2008_001192.jpg', '2008_001806.jpg', '2008_000354.jpg', '2008_004278.jpg', '2008_008190.jpg', '2008_001816.jpg', '2008_007058.jpg', '2008_001333.jpg', '2008_006613.jpg', '2008_002262.jpg', '2008_002206.jpg', '2008_001219.jpg', '2008_006272.jpg', '2008_001550.jpg', '2008_002728.jpg', '2008_002843.jpg', '2008_000199.jpg', '2008_002088.jpg', '2008_004331.jpg', '2008_002117.jpg', '2008_007476.jpg', '2008_004358.jpg', '2008_005664.jpg', '2008_002606.jpg', '2008_008357.jpg', '2008_004814.jpg', '2008_004807.jpg', '2008_003966.jpg', '2008_002897.jpg', '2008_007586.jpg', '2008_003560.jpg', '2008_000541.jpg', '2008_007470.jpg', '2008_000835.jpg', '2008_001455.jpg', '2008_003251.jpg', '2008_008097.jpg', '2008_004892.jpg', '2008_002665.jpg', '2008_002868.jpg', '2008_002451.jpg', '2008_003820.jpg', '2008_005197.jpg', '2008_000666.jpg', '2008_002418.jpg', '2008_007861.jpg', '2008_002835.jpg', '2008_000645.jpg', '2008_001929.jpg', '2008_006265.jpg', '2008_002114.jpg', '2008_006041.jpg', '2008_007660.jpg', '2008_008127.jpg', '2008_007237.jpg', '2008_003013.jpg', '2008_003482.jpg', '2008_001576.jpg', '2008_008147.jpg', '2008_000202.jpg', '2008_004084.jpg', '2008_005001.jpg', '2008_000941.jpg', '2008_008091.jpg', '2008_000204.jpg', '2008_008547.jpg', '2008_000965.jpg', '2008_001841.jpg', '2008_002283.jpg', '2008_005156.jpg', '2008_001577.jpg', '2008_007222.jpg', '2008_006872.jpg', '2008_001863.jpg', '2008_002842.jpg', '2008_004066.jpg', '2008_007643.jpg', '2008_005869.jpg', '2008_001834.jpg', '2008_001808.jpg', '2008_008288.jpg', '2008_000910.jpg', '2008_003209.jpg', '2008_000082.jpg', '2008_005133.jpg', '2008_007746.jpg', '2008_001231.jpg', '2008_003617.jpg', '2008_006071.jpg', '2008_003448.jpg', '2008_007841.jpg', '2008_000904.jpg', '2008_002456.jpg', '2008_003451.jpg', '2008_005794.jpg', '2008_008237.jpg', '2008_003141.jpg', '2008_007254.jpg', '2008_001724.jpg', '2008_001076.jpg', '2008_004703.jpg', '2008_001979.jpg', '2008_000660.jpg', '2008_007105.jpg', '2008_001629.jpg', '2008_007933.jpg', '2008_000942.jpg', '2008_001338.jpg', '2008_002241.jpg', '2008_000885.jpg', '2008_003947.jpg', '2008_003402.jpg', '2008_001167.jpg', '2008_003379.jpg', '2008_002086.jpg', '2008_005445.jpg', '2008_004991.jpg', '2008_001092.jpg', '2008_003915.jpg']\n",
            "Excess files to remove: 1101\n",
            "Number of files after removal: 500\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "def count_and_remove_files(directory):\n",
        "    file_count = 0\n",
        "    valid_files = []\n",
        "    files_to_remove = []\n",
        "\n",
        "    # Collecting files and counting valid files\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.startswith('2008_') or filename.startswith('2007_'):\n",
        "            file_count += 1\n",
        "            valid_files.append(filename)\n",
        "        else:\n",
        "            files_to_remove.append(filename)\n",
        "\n",
        "    print(\"Total files before removal:\", file_count)\n",
        "    print(\"Valid files:\", valid_files)\n",
        "\n",
        "    # Calculating excess files to remove\n",
        "    excess_files = file_count - 500\n",
        "\n",
        "    print(\"Excess files to remove:\", excess_files)\n",
        "\n",
        "    # Remove excess files\n",
        "    if excess_files > 0:\n",
        "        random.shuffle(valid_files)\n",
        "        files_to_remove.extend(valid_files[:excess_files])\n",
        "\n",
        "        for filename in files_to_remove:\n",
        "            os.remove(os.path.join(directory, filename))\n",
        "            file_count -= 1\n",
        "\n",
        "    return file_count\n",
        "\n",
        "directory = '/content/train/Person/Person'\n",
        "file_count = count_and_remove_files(directory)\n",
        "print(\"Number of files after removal:\", file_count)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "IuZjY8LGLy7n",
        "outputId": "6e768170-6fc1-4e92-e7a9-0f94c6900a19"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Path to the train directory\n",
        "train_dir = \"/content/train\"\n",
        "\n",
        "# Initialize empty lists to store class names and corresponding file counts\n",
        "class_names = []\n",
        "file_counts = []\n",
        "\n",
        "# Traverse the train directory\n",
        "for class_name in os.listdir(train_dir):\n",
        "    class_dir = os.path.join(train_dir, class_name)\n",
        "    class_dir = os.path.join(class_dir, class_name)\n",
        "    if os.path.isdir(class_dir):\n",
        "        # Count the number of files in the class directory\n",
        "        file_count = len(os.listdir(class_dir))\n",
        "        class_names.append(class_name)\n",
        "        file_counts.append(file_count)\n",
        "\n",
        "# Plot the line graph\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(class_names, file_counts, marker='o', color='skyblue', linestyle='-')\n",
        "plt.title('Number of Images in Each Class')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of Images')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEVdPQ6nUrZs"
      },
      "source": [
        "# Building the VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8bx8zQTWtWb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the path to the train directory\n",
        "train_dir = \"/content/train\"\n",
        "\n",
        "# Iterate over each subfolder in the train directory\n",
        "for class_name in os.listdir(train_dir):\n",
        "    class_dir = os.path.join(train_dir, class_name)\n",
        "\n",
        "    # Check if the item in the directory is a subfolder\n",
        "    if os.path.isdir(class_dir):\n",
        "        # Define the path to the subsubfolder\n",
        "        subsubfolder_dir = os.path.join(class_dir, class_name)\n",
        "\n",
        "        # Check if the subsubfolder exists\n",
        "        if os.path.exists(subsubfolder_dir):\n",
        "            # Iterate over each file in the subsubfolder\n",
        "            for file_name in os.listdir(subsubfolder_dir):\n",
        "                file_path = os.path.join(subsubfolder_dir, file_name)\n",
        "\n",
        "                # Define the destination path\n",
        "                new_file_path = os.path.join(class_dir, file_name)\n",
        "\n",
        "                # Check if the file already exists in the destination directory\n",
        "                if not os.path.exists(new_file_path):\n",
        "                    # Move the file to the parent subfolder\n",
        "                    shutil.move(file_path, new_file_path)\n",
        "\n",
        "            # Remove the empty subsubfolder\n",
        "            os.rmdir(subsubfolder_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfJxTYBVTn2q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Set the paths to the train and test directories\n",
        "train_folder_path = \"/content/train\"\n",
        "\n",
        "# Each class has its own directory within the train directory\n",
        "class_names = [d for d in os.listdir(train_folder_path) if os.path.isdir(os.path.join(train_folder_path, d))]\n",
        "\n",
        "# Create a dictionary to hold our training image paths\n",
        "train_data_lists = {class_name: [os.path.join(train_folder_path, class_name, img)\n",
        "                                 for img in os.listdir(os.path.join(train_folder_path, class_name))]\n",
        "                    for class_name in class_names}\n",
        "\n",
        "def build_binary_classification_model():\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
        "    x = Flatten()(base_model.output)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dense(1, activation='sigmoid')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=x)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Configure the ImageDataGenerator for training data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zQPWYNctkaE"
      },
      "source": [
        "## Since even after balancing each class, when iniating training for binary classifier, we still have imbalance classes as it is 1 class(Positive) vs 19 classes(Negative), so we reduce the of number negative samples to the number of postive samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DN6RNY_VVgw9",
        "outputId": "3bb50bcc-cd33-4931-83ed-87feeeaa8beb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training for class: Bus\n",
            "Number of positive samples for Bus: 500\n",
            "Number of negative samples before balancing: 9500\n",
            "Number of negative samples after balancing: 500\n",
            "Found 800 validated image filenames belonging to 2 classes.\n",
            "Found 200 validated image filenames belonging to 2 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 41s 589ms/step - loss: 0.4048 - accuracy: 0.8000 - val_loss: 0.4266 - val_accuracy: 0.8698\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 15s 607ms/step - loss: 0.3515 - accuracy: 0.8525 - val_loss: 0.3090 - val_accuracy: 0.8594\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 16s 605ms/step - loss: 0.1721 - accuracy: 0.9413 - val_loss: 0.1857 - val_accuracy: 0.9375\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 15s 607ms/step - loss: 0.1498 - accuracy: 0.9400 - val_loss: 0.3710 - val_accuracy: 0.8750\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 16s 609ms/step - loss: 0.1399 - accuracy: 0.9388 - val_loss: 0.2488 - val_accuracy: 0.9271\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 15s 598ms/step - loss: 0.1019 - accuracy: 0.9575 - val_loss: 0.2646 - val_accuracy: 0.9271\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 15s 607ms/step - loss: 0.1854 - accuracy: 0.9325 - val_loss: 0.1908 - val_accuracy: 0.9271\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 15s 599ms/step - loss: 0.1042 - accuracy: 0.9650 - val_loss: 0.2403 - val_accuracy: 0.9323\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 16s 614ms/step - loss: 0.0511 - accuracy: 0.9800 - val_loss: 0.3158 - val_accuracy: 0.9323\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 15s 610ms/step - loss: 0.0515 - accuracy: 0.9787 - val_loss: 0.2643 - val_accuracy: 0.9427\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Bus\n",
            "Training for class: Tvmonitor\n",
            "Number of positive samples for Tvmonitor: 500\n",
            "Number of negative samples before balancing: 9500\n",
            "Number of negative samples after balancing: 500\n",
            "Found 800 validated image filenames belonging to 2 classes.\n",
            "Found 200 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 22s 598ms/step - loss: 0.7221 - accuracy: 0.5750 - val_loss: 0.6732 - val_accuracy: 0.5521\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 16s 623ms/step - loss: 0.5896 - accuracy: 0.6625 - val_loss: 0.5226 - val_accuracy: 0.7396\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 15s 596ms/step - loss: 0.5093 - accuracy: 0.7550 - val_loss: 0.5301 - val_accuracy: 0.7500\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 16s 616ms/step - loss: 0.4562 - accuracy: 0.7788 - val_loss: 0.4513 - val_accuracy: 0.7656\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 15s 605ms/step - loss: 0.4331 - accuracy: 0.7937 - val_loss: 0.5735 - val_accuracy: 0.7292\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 15s 605ms/step - loss: 0.3973 - accuracy: 0.8200 - val_loss: 0.5172 - val_accuracy: 0.6979\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 16s 622ms/step - loss: 0.3533 - accuracy: 0.8475 - val_loss: 0.3820 - val_accuracy: 0.8333\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 15s 611ms/step - loss: 0.3498 - accuracy: 0.8400 - val_loss: 0.5105 - val_accuracy: 0.7760\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 17s 682ms/step - loss: 0.3175 - accuracy: 0.8625 - val_loss: 0.4449 - val_accuracy: 0.8073\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 16s 620ms/step - loss: 0.2674 - accuracy: 0.8900 - val_loss: 0.5057 - val_accuracy: 0.8229\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Tvmonitor\n",
            "Training for class: Bottle\n",
            "Number of positive samples for Bottle: 500\n",
            "Number of negative samples before balancing: 9500\n",
            "Number of negative samples after balancing: 500\n",
            "Found 800 validated image filenames belonging to 2 classes.\n",
            "Found 200 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 21s 609ms/step - loss: 0.6664 - accuracy: 0.5913 - val_loss: 0.6699 - val_accuracy: 0.5521\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 15s 611ms/step - loss: 0.5849 - accuracy: 0.6712 - val_loss: 0.6465 - val_accuracy: 0.5781\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 16s 620ms/step - loss: 0.5314 - accuracy: 0.7113 - val_loss: 0.5972 - val_accuracy: 0.6562\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 16s 606ms/step - loss: 0.4692 - accuracy: 0.7700 - val_loss: 0.4396 - val_accuracy: 0.7760\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 15s 599ms/step - loss: 0.4073 - accuracy: 0.8175 - val_loss: 0.5252 - val_accuracy: 0.7448\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 17s 656ms/step - loss: 0.4062 - accuracy: 0.8025 - val_loss: 0.4247 - val_accuracy: 0.7969\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 16s 606ms/step - loss: 0.3758 - accuracy: 0.8363 - val_loss: 0.4371 - val_accuracy: 0.7917\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 16s 618ms/step - loss: 0.3381 - accuracy: 0.8575 - val_loss: 0.3974 - val_accuracy: 0.8281\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 15s 601ms/step - loss: 0.2983 - accuracy: 0.8788 - val_loss: 0.3875 - val_accuracy: 0.8333\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 16s 620ms/step - loss: 0.2799 - accuracy: 0.8863 - val_loss: 0.3444 - val_accuracy: 0.8594\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Bottle\n",
            "Training for class: Dog\n",
            "Number of positive samples for Dog: 500\n",
            "Number of negative samples before balancing: 9500\n",
            "Number of negative samples after balancing: 500\n",
            "Found 800 validated image filenames belonging to 2 classes.\n",
            "Found 200 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 19s 607ms/step - loss: 0.7233 - accuracy: 0.5325 - val_loss: 0.6822 - val_accuracy: 0.5312\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 16s 619ms/step - loss: 0.6602 - accuracy: 0.6263 - val_loss: 0.6653 - val_accuracy: 0.6042\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 17s 659ms/step - loss: 0.6332 - accuracy: 0.6513 - val_loss: 0.6016 - val_accuracy: 0.6667\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 16s 623ms/step - loss: 0.6006 - accuracy: 0.6925 - val_loss: 0.5760 - val_accuracy: 0.6823\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 15s 608ms/step - loss: 0.5901 - accuracy: 0.6888 - val_loss: 0.6632 - val_accuracy: 0.6146\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 16s 630ms/step - loss: 0.5713 - accuracy: 0.6975 - val_loss: 0.5520 - val_accuracy: 0.6771\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 16s 628ms/step - loss: 0.5547 - accuracy: 0.7100 - val_loss: 0.5900 - val_accuracy: 0.6510\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 15s 609ms/step - loss: 0.5372 - accuracy: 0.7175 - val_loss: 0.5534 - val_accuracy: 0.7188\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 16s 622ms/step - loss: 0.5071 - accuracy: 0.7513 - val_loss: 0.6179 - val_accuracy: 0.6354\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 16s 620ms/step - loss: 0.4525 - accuracy: 0.7887 - val_loss: 0.7532 - val_accuracy: 0.6354\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Dog\n",
            "Training for class: Cow\n",
            "Number of positive samples for Cow: 500\n",
            "Number of negative samples before balancing: 9500\n",
            "Number of negative samples after balancing: 500\n",
            "Found 800 validated image filenames belonging to 2 classes.\n",
            "Found 200 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 20s 653ms/step - loss: 0.6147 - accuracy: 0.6438 - val_loss: 0.5397 - val_accuracy: 0.7708\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 16s 615ms/step - loss: 0.4417 - accuracy: 0.8112 - val_loss: 0.6794 - val_accuracy: 0.6667\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 15s 593ms/step - loss: 0.4064 - accuracy: 0.8275 - val_loss: 0.3866 - val_accuracy: 0.8333\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 15s 613ms/step - loss: 0.4083 - accuracy: 0.8375 - val_loss: 0.3375 - val_accuracy: 0.8646\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 15s 601ms/step - loss: 0.2756 - accuracy: 0.9025 - val_loss: 0.1844 - val_accuracy: 0.9323\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 16s 614ms/step - loss: 0.2939 - accuracy: 0.8988 - val_loss: 0.3219 - val_accuracy: 0.8698\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 15s 609ms/step - loss: 0.2165 - accuracy: 0.9225 - val_loss: 0.2295 - val_accuracy: 0.9219\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 15s 609ms/step - loss: 0.1744 - accuracy: 0.9350 - val_loss: 0.1893 - val_accuracy: 0.9010\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 17s 666ms/step - loss: 0.1885 - accuracy: 0.9262 - val_loss: 0.1956 - val_accuracy: 0.9115\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 15s 606ms/step - loss: 0.1520 - accuracy: 0.9525 - val_loss: 0.1736 - val_accuracy: 0.9375\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Cow\n",
            "Training for class: Motorbike\n",
            "Number of positive samples for Motorbike: 500\n",
            "Number of negative samples before balancing: 9500\n",
            "Number of negative samples after balancing: 500\n",
            "Found 800 validated image filenames belonging to 2 classes.\n",
            "Found 200 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 20s 595ms/step - loss: 0.7098 - accuracy: 0.4988 - val_loss: 0.6916 - val_accuracy: 0.5104\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 16s 620ms/step - loss: 0.6933 - accuracy: 0.5188 - val_loss: 0.6834 - val_accuracy: 0.5365\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 16s 606ms/step - loss: 0.6942 - accuracy: 0.5325 - val_loss: 0.6941 - val_accuracy: 0.5052\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 16s 606ms/step - loss: 0.6983 - accuracy: 0.5138 - val_loss: 0.7349 - val_accuracy: 0.5156\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 15s 608ms/step - loss: 0.6943 - accuracy: 0.5775 - val_loss: 0.6840 - val_accuracy: 0.5938\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 15s 605ms/step - loss: 0.6786 - accuracy: 0.5850 - val_loss: 0.7088 - val_accuracy: 0.5104\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 16s 626ms/step - loss: 0.6988 - accuracy: 0.5188 - val_loss: 0.6914 - val_accuracy: 0.5990\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 16s 619ms/step - loss: 0.6835 - accuracy: 0.5850 - val_loss: 0.6806 - val_accuracy: 0.5521\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 15s 605ms/step - loss: 0.6575 - accuracy: 0.6162 - val_loss: 0.6544 - val_accuracy: 0.6562\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 16s 621ms/step - loss: 0.6594 - accuracy: 0.5975 - val_loss: 0.6681 - val_accuracy: 0.6094\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Motorbike\n",
            "Training for class: Sheep\n",
            "Number of positive samples for Sheep: 500\n",
            "Number of negative samples before balancing: 9500\n",
            "Number of negative samples after balancing: 500\n",
            "Found 800 validated image filenames belonging to 2 classes.\n",
            "Found 200 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 19s 602ms/step - loss: 0.6544 - accuracy: 0.6087 - val_loss: 0.6592 - val_accuracy: 0.6146\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 15s 605ms/step - loss: 0.5975 - accuracy: 0.6925 - val_loss: 0.5213 - val_accuracy: 0.7240\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 15s 596ms/step - loss: 0.4217 - accuracy: 0.8225 - val_loss: 0.2869 - val_accuracy: 0.8750\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 17s 662ms/step - loss: 0.2455 - accuracy: 0.9175 - val_loss: 0.2350 - val_accuracy: 0.9219\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 15s 592ms/step - loss: 0.2099 - accuracy: 0.9225 - val_loss: 0.3091 - val_accuracy: 0.8802\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 15s 593ms/step - loss: 0.2171 - accuracy: 0.9200 - val_loss: 0.2560 - val_accuracy: 0.9375\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 16s 614ms/step - loss: 0.2379 - accuracy: 0.9025 - val_loss: 0.3141 - val_accuracy: 0.8750\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 15s 600ms/step - loss: 0.1895 - accuracy: 0.9400 - val_loss: 0.2039 - val_accuracy: 0.9479\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 16s 614ms/step - loss: 0.1448 - accuracy: 0.9513 - val_loss: 0.1627 - val_accuracy: 0.9427\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 15s 593ms/step - loss: 0.1405 - accuracy: 0.9438 - val_loss: 0.2209 - val_accuracy: 0.9323\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Sheep\n",
            "Training for class: Car\n",
            "Number of positive samples for Car: 500\n",
            "Number of negative samples before balancing: 9500\n",
            "Number of negative samples after balancing: 500\n",
            "Found 800 validated image filenames belonging to 2 classes.\n",
            "Found 200 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 19s 608ms/step - loss: 0.6842 - accuracy: 0.6212 - val_loss: 0.5888 - val_accuracy: 0.7135\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 17s 646ms/step - loss: 0.5629 - accuracy: 0.7075 - val_loss: 0.5437 - val_accuracy: 0.7240\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 16s 614ms/step - loss: 0.5312 - accuracy: 0.7375 - val_loss: 0.5514 - val_accuracy: 0.7240\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 16s 636ms/step - loss: 0.4963 - accuracy: 0.7650 - val_loss: 0.5158 - val_accuracy: 0.7448\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 16s 624ms/step - loss: 0.4739 - accuracy: 0.7738 - val_loss: 0.5110 - val_accuracy: 0.7344\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 16s 634ms/step - loss: 0.4533 - accuracy: 0.7925 - val_loss: 0.4857 - val_accuracy: 0.7865\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 16s 628ms/step - loss: 0.4540 - accuracy: 0.7887 - val_loss: 0.5158 - val_accuracy: 0.7812\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 16s 626ms/step - loss: 0.4073 - accuracy: 0.8087 - val_loss: 0.4684 - val_accuracy: 0.7656\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 16s 653ms/step - loss: 0.4144 - accuracy: 0.8150 - val_loss: 0.4554 - val_accuracy: 0.7708\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 16s 629ms/step - loss: 0.4741 - accuracy: 0.7850 - val_loss: 0.5404 - val_accuracy: 0.7240\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Car\n",
            "Training for class: Diningtable\n",
            "Number of positive samples for Diningtable: 500\n",
            "Number of negative samples before balancing: 9500\n",
            "Number of negative samples after balancing: 500\n",
            "Found 800 validated image filenames belonging to 2 classes.\n",
            "Found 200 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 21s 601ms/step - loss: 0.7100 - accuracy: 0.5125 - val_loss: 0.6614 - val_accuracy: 0.6042\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 15s 614ms/step - loss: 0.6926 - accuracy: 0.5400 - val_loss: 0.7035 - val_accuracy: 0.4948\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 16s 618ms/step - loss: 0.6822 - accuracy: 0.5587 - val_loss: 0.6318 - val_accuracy: 0.7188\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 15s 596ms/step - loss: 0.6041 - accuracy: 0.6888 - val_loss: 0.6110 - val_accuracy: 0.5625\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 16s 611ms/step - loss: 0.6053 - accuracy: 0.6750 - val_loss: 0.5367 - val_accuracy: 0.6615\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 15s 592ms/step - loss: 0.5680 - accuracy: 0.7262 - val_loss: 0.4379 - val_accuracy: 0.8542\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 17s 663ms/step - loss: 0.4953 - accuracy: 0.7613 - val_loss: 0.3697 - val_accuracy: 0.8385\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 15s 611ms/step - loss: 0.4927 - accuracy: 0.7688 - val_loss: 0.3271 - val_accuracy: 0.8802\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 15s 595ms/step - loss: 0.3627 - accuracy: 0.8512 - val_loss: 0.3028 - val_accuracy: 0.8750\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 15s 595ms/step - loss: 0.3885 - accuracy: 0.8438 - val_loss: 0.2701 - val_accuracy: 0.9167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Diningtable\n",
            "Training for class: Horse\n",
            "Number of positive samples for Horse: 500\n",
            "Number of negative samples before balancing: 9500\n",
            "Number of negative samples after balancing: 500\n",
            "Found 800 validated image filenames belonging to 2 classes.\n",
            "Found 200 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 21s 596ms/step - loss: 0.7277 - accuracy: 0.5213 - val_loss: 0.6925 - val_accuracy: 0.5208\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 16s 621ms/step - loss: 0.6935 - accuracy: 0.5225 - val_loss: 0.6906 - val_accuracy: 0.4896\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 15s 595ms/step - loss: 0.6818 - accuracy: 0.5700 - val_loss: 0.6724 - val_accuracy: 0.5625\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 15s 588ms/step - loss: 0.6778 - accuracy: 0.5700 - val_loss: 0.6809 - val_accuracy: 0.6354\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 16s 634ms/step - loss: 0.6693 - accuracy: 0.6125 - val_loss: 0.6560 - val_accuracy: 0.6094\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 15s 611ms/step - loss: 0.6485 - accuracy: 0.6263 - val_loss: 0.6745 - val_accuracy: 0.5781\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 15s 600ms/step - loss: 0.6260 - accuracy: 0.6488 - val_loss: 0.6517 - val_accuracy: 0.6042\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 16s 619ms/step - loss: 0.6213 - accuracy: 0.6400 - val_loss: 0.6326 - val_accuracy: 0.6562\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 16s 624ms/step - loss: 0.5524 - accuracy: 0.7262 - val_loss: 0.5598 - val_accuracy: 0.6979\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 15s 608ms/step - loss: 0.5546 - accuracy: 0.7350 - val_loss: 0.6020 - val_accuracy: 0.6823\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Horse\n",
            "Training for class: Pottedplant\n",
            "Number of positive samples for Pottedplant: 500\n",
            "Number of negative samples before balancing: 9500\n",
            "Number of negative samples after balancing: 500\n",
            "Found 800 validated image filenames belonging to 2 classes.\n",
            "Found 200 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 19s 596ms/step - loss: 0.7141 - accuracy: 0.5163 - val_loss: 0.6916 - val_accuracy: 0.5469\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 16s 630ms/step - loss: 0.6958 - accuracy: 0.5175 - val_loss: 0.7163 - val_accuracy: 0.4635\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 16s 627ms/step - loss: 0.6996 - accuracy: 0.5088 - val_loss: 0.6879 - val_accuracy: 0.5417\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 16s 617ms/step - loss: 0.6947 - accuracy: 0.5400 - val_loss: 0.6944 - val_accuracy: 0.4531\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 16s 620ms/step - loss: 0.6818 - accuracy: 0.5500 - val_loss: 0.6953 - val_accuracy: 0.5521\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 15s 599ms/step - loss: 0.6918 - accuracy: 0.5412 - val_loss: 0.6786 - val_accuracy: 0.5469\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 15s 605ms/step - loss: 0.6985 - accuracy: 0.4850 - val_loss: 0.7012 - val_accuracy: 0.4531\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 16s 611ms/step - loss: 0.6892 - accuracy: 0.5550 - val_loss: 0.6839 - val_accuracy: 0.5729\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 17s 666ms/step - loss: 0.6833 - accuracy: 0.5725 - val_loss: 0.6656 - val_accuracy: 0.5990\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 15s 607ms/step - loss: 0.6717 - accuracy: 0.6125 - val_loss: 0.6781 - val_accuracy: 0.5312\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Pottedplant\n",
            "Training for class: Aeroplane\n",
            "Number of positive samples for Aeroplane: 500\n",
            "Number of negative samples before balancing: 9500\n",
            "Number of negative samples after balancing: 500\n",
            "Found 800 validated image filenames belonging to 2 classes.\n",
            "Found 200 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 21s 618ms/step - loss: 0.5500 - accuracy: 0.7225 - val_loss: 0.6625 - val_accuracy: 0.6719\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 15s 604ms/step - loss: 0.3840 - accuracy: 0.8250 - val_loss: 0.3253 - val_accuracy: 0.8698\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 16s 620ms/step - loss: 0.3112 - accuracy: 0.8700 - val_loss: 0.2995 - val_accuracy: 0.8646\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 16s 616ms/step - loss: 0.2663 - accuracy: 0.9050 - val_loss: 0.2576 - val_accuracy: 0.9062\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 16s 620ms/step - loss: 0.2161 - accuracy: 0.9175 - val_loss: 0.2401 - val_accuracy: 0.9062\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 16s 621ms/step - loss: 0.2243 - accuracy: 0.8988 - val_loss: 0.2047 - val_accuracy: 0.9062\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 15s 601ms/step - loss: 0.1618 - accuracy: 0.9388 - val_loss: 0.1819 - val_accuracy: 0.9479\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 15s 602ms/step - loss: 0.1957 - accuracy: 0.9275 - val_loss: 0.3140 - val_accuracy: 0.9062\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 16s 615ms/step - loss: 0.1508 - accuracy: 0.9425 - val_loss: 0.2712 - val_accuracy: 0.8906\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 15s 596ms/step - loss: 0.1048 - accuracy: 0.9700 - val_loss: 0.0999 - val_accuracy: 0.9583\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Aeroplane\n",
            "Training for class: Person\n",
            "Number of positive samples for Person: 500\n",
            "Number of negative samples before balancing: 9500\n",
            "Number of negative samples after balancing: 500\n",
            "Found 800 validated image filenames belonging to 2 classes.\n",
            "Found 200 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 20s 626ms/step - loss: 0.5719 - accuracy: 0.6850 - val_loss: 0.5833 - val_accuracy: 0.6927\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 16s 645ms/step - loss: 0.4178 - accuracy: 0.8125 - val_loss: 0.3948 - val_accuracy: 0.8073\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 17s 646ms/step - loss: 0.3675 - accuracy: 0.8350 - val_loss: 0.3559 - val_accuracy: 0.8385\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 16s 641ms/step - loss: 0.3435 - accuracy: 0.8450 - val_loss: 0.3755 - val_accuracy: 0.8490\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 16s 627ms/step - loss: 0.3119 - accuracy: 0.8525 - val_loss: 0.3867 - val_accuracy: 0.8125\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 16s 632ms/step - loss: 0.3119 - accuracy: 0.8500 - val_loss: 0.3887 - val_accuracy: 0.8073\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 16s 620ms/step - loss: 0.2876 - accuracy: 0.8750 - val_loss: 0.3809 - val_accuracy: 0.8125\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 16s 639ms/step - loss: 0.2860 - accuracy: 0.8750 - val_loss: 0.4265 - val_accuracy: 0.7969\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 16s 641ms/step - loss: 0.3002 - accuracy: 0.8587 - val_loss: 0.3768 - val_accuracy: 0.8438\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 17s 666ms/step - loss: 0.2883 - accuracy: 0.8587 - val_loss: 0.3920 - val_accuracy: 0.8125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Person\n",
            "Training for class: Boat\n",
            "Number of positive samples for Boat: 500\n",
            "Number of negative samples before balancing: 9500\n",
            "Number of negative samples after balancing: 500\n",
            "Found 800 validated image filenames belonging to 2 classes.\n",
            "Found 200 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 19s 598ms/step - loss: 0.6925 - accuracy: 0.5888 - val_loss: 0.5659 - val_accuracy: 0.7240\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 15s 599ms/step - loss: 0.5714 - accuracy: 0.7250 - val_loss: 0.4963 - val_accuracy: 0.7708\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 15s 611ms/step - loss: 0.5930 - accuracy: 0.7163 - val_loss: 0.5158 - val_accuracy: 0.8333\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 15s 601ms/step - loss: 0.4025 - accuracy: 0.8388 - val_loss: 0.3677 - val_accuracy: 0.8594\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 15s 600ms/step - loss: 0.3105 - accuracy: 0.8725 - val_loss: 0.3284 - val_accuracy: 0.8646\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 15s 600ms/step - loss: 0.2415 - accuracy: 0.9112 - val_loss: 0.3432 - val_accuracy: 0.8802\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 16s 641ms/step - loss: 0.2725 - accuracy: 0.9013 - val_loss: 0.3036 - val_accuracy: 0.8802\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 16s 620ms/step - loss: 0.1962 - accuracy: 0.9300 - val_loss: 0.2331 - val_accuracy: 0.9167\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 16s 613ms/step - loss: 0.2151 - accuracy: 0.9112 - val_loss: 0.2476 - val_accuracy: 0.8958\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 16s 606ms/step - loss: 0.1895 - accuracy: 0.9312 - val_loss: 0.2448 - val_accuracy: 0.9167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Boat\n",
            "Training for class: Chair\n",
            "Number of positive samples for Chair: 500\n",
            "Number of negative samples before balancing: 9500\n",
            "Number of negative samples after balancing: 500\n",
            "Found 800 validated image filenames belonging to 2 classes.\n",
            "Found 200 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 20s 620ms/step - loss: 0.7218 - accuracy: 0.5350 - val_loss: 0.6532 - val_accuracy: 0.6094\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 16s 615ms/step - loss: 0.6706 - accuracy: 0.5838 - val_loss: 0.6829 - val_accuracy: 0.5365\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 16s 616ms/step - loss: 0.6303 - accuracy: 0.6513 - val_loss: 0.6239 - val_accuracy: 0.6562\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 18s 685ms/step - loss: 0.6037 - accuracy: 0.6662 - val_loss: 0.5468 - val_accuracy: 0.7240\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 15s 607ms/step - loss: 0.5692 - accuracy: 0.6950 - val_loss: 0.5301 - val_accuracy: 0.7604\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 16s 622ms/step - loss: 0.5012 - accuracy: 0.7700 - val_loss: 0.4609 - val_accuracy: 0.7812\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 16s 621ms/step - loss: 0.4545 - accuracy: 0.7950 - val_loss: 0.5025 - val_accuracy: 0.7604\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 16s 629ms/step - loss: 0.4093 - accuracy: 0.7950 - val_loss: 0.4869 - val_accuracy: 0.7865\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 16s 627ms/step - loss: 0.4805 - accuracy: 0.7675 - val_loss: 0.4273 - val_accuracy: 0.8229\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 16s 605ms/step - loss: 0.4525 - accuracy: 0.7887 - val_loss: 0.4354 - val_accuracy: 0.8177\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Chair\n",
            "Training for class: Train\n",
            "Number of positive samples for Train: 500\n",
            "Number of negative samples before balancing: 9500\n",
            "Number of negative samples after balancing: 500\n",
            "Found 800 validated image filenames belonging to 2 classes.\n",
            "Found 200 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 19s 597ms/step - loss: 0.6958 - accuracy: 0.5725 - val_loss: 0.7206 - val_accuracy: 0.4792\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 17s 672ms/step - loss: 0.6357 - accuracy: 0.6438 - val_loss: 0.5794 - val_accuracy: 0.7292\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 15s 603ms/step - loss: 0.5906 - accuracy: 0.6550 - val_loss: 0.4530 - val_accuracy: 0.7760\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 15s 599ms/step - loss: 0.5554 - accuracy: 0.7088 - val_loss: 0.4297 - val_accuracy: 0.8281\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 16s 619ms/step - loss: 0.4737 - accuracy: 0.7875 - val_loss: 0.4039 - val_accuracy: 0.8698\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 15s 597ms/step - loss: 0.4185 - accuracy: 0.8150 - val_loss: 0.3425 - val_accuracy: 0.8750\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 15s 603ms/step - loss: 0.3186 - accuracy: 0.8675 - val_loss: 0.2930 - val_accuracy: 0.9010\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 15s 596ms/step - loss: 0.2948 - accuracy: 0.8737 - val_loss: 0.3570 - val_accuracy: 0.8542\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 17s 655ms/step - loss: 0.2335 - accuracy: 0.9000 - val_loss: 0.2946 - val_accuracy: 0.8698\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 16s 614ms/step - loss: 0.2098 - accuracy: 0.9150 - val_loss: 0.3387 - val_accuracy: 0.8542\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Train\n",
            "Training for class: Bird\n",
            "Number of positive samples for Bird: 500\n",
            "Number of negative samples before balancing: 9500\n",
            "Number of negative samples after balancing: 500\n",
            "Found 800 validated image filenames belonging to 2 classes.\n",
            "Found 200 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 20s 601ms/step - loss: 0.7097 - accuracy: 0.5525 - val_loss: 0.6724 - val_accuracy: 0.5885\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 16s 621ms/step - loss: 0.6423 - accuracy: 0.6413 - val_loss: 0.6474 - val_accuracy: 0.5885\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 16s 619ms/step - loss: 0.6106 - accuracy: 0.6712 - val_loss: 0.6557 - val_accuracy: 0.5938\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 16s 620ms/step - loss: 0.5602 - accuracy: 0.7262 - val_loss: 0.6057 - val_accuracy: 0.6250\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 15s 611ms/step - loss: 0.5638 - accuracy: 0.6950 - val_loss: 0.5576 - val_accuracy: 0.7240\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 15s 606ms/step - loss: 0.5337 - accuracy: 0.7212 - val_loss: 0.5989 - val_accuracy: 0.6510\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 15s 596ms/step - loss: 0.6053 - accuracy: 0.6388 - val_loss: 0.5992 - val_accuracy: 0.6562\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 15s 606ms/step - loss: 0.5905 - accuracy: 0.6888 - val_loss: 0.5376 - val_accuracy: 0.7344\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 16s 622ms/step - loss: 0.4845 - accuracy: 0.7563 - val_loss: 0.4866 - val_accuracy: 0.7396\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 16s 621ms/step - loss: 0.4639 - accuracy: 0.7875 - val_loss: 0.4956 - val_accuracy: 0.7292\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Bird\n",
            "Training for class: Bicycle\n",
            "Number of positive samples for Bicycle: 500\n",
            "Number of negative samples before balancing: 9500\n",
            "Number of negative samples after balancing: 500\n",
            "Found 800 validated image filenames belonging to 2 classes.\n",
            "Found 200 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 20s 625ms/step - loss: 0.7151 - accuracy: 0.5400 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 15s 601ms/step - loss: 0.6957 - accuracy: 0.5175 - val_loss: 0.6906 - val_accuracy: 0.5052\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 16s 611ms/step - loss: 0.6668 - accuracy: 0.5987 - val_loss: 0.6523 - val_accuracy: 0.6146\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 15s 598ms/step - loss: 0.6373 - accuracy: 0.6525 - val_loss: 0.6296 - val_accuracy: 0.6042\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 15s 599ms/step - loss: 0.6258 - accuracy: 0.6650 - val_loss: 0.6269 - val_accuracy: 0.5885\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 15s 614ms/step - loss: 0.5878 - accuracy: 0.6950 - val_loss: 0.6071 - val_accuracy: 0.7188\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 15s 612ms/step - loss: 0.5711 - accuracy: 0.7175 - val_loss: 0.6452 - val_accuracy: 0.6406\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 16s 617ms/step - loss: 0.5687 - accuracy: 0.6950 - val_loss: 0.6546 - val_accuracy: 0.6719\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 15s 607ms/step - loss: 0.5319 - accuracy: 0.7450 - val_loss: 0.5379 - val_accuracy: 0.7656\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 17s 657ms/step - loss: 0.4704 - accuracy: 0.7825 - val_loss: 0.5250 - val_accuracy: 0.7708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Bicycle\n",
            "Training for class: Cat\n",
            "Number of positive samples for Cat: 500\n",
            "Number of negative samples before balancing: 9500\n",
            "Number of negative samples after balancing: 500\n",
            "Found 800 validated image filenames belonging to 2 classes.\n",
            "Found 200 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 20s 607ms/step - loss: 0.6702 - accuracy: 0.6187 - val_loss: 0.6661 - val_accuracy: 0.6250\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 16s 625ms/step - loss: 0.5588 - accuracy: 0.6988 - val_loss: 0.5445 - val_accuracy: 0.6719\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 16s 625ms/step - loss: 0.5512 - accuracy: 0.7212 - val_loss: 0.5759 - val_accuracy: 0.6823\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 16s 628ms/step - loss: 0.4712 - accuracy: 0.7850 - val_loss: 0.4543 - val_accuracy: 0.7500\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 15s 612ms/step - loss: 0.3690 - accuracy: 0.8263 - val_loss: 0.5564 - val_accuracy: 0.7969\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 16s 621ms/step - loss: 0.3486 - accuracy: 0.8487 - val_loss: 0.4935 - val_accuracy: 0.7656\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 17s 658ms/step - loss: 0.2985 - accuracy: 0.8587 - val_loss: 0.4993 - val_accuracy: 0.7865\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 16s 617ms/step - loss: 0.2266 - accuracy: 0.9087 - val_loss: 0.4852 - val_accuracy: 0.8021\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 16s 628ms/step - loss: 0.1726 - accuracy: 0.9287 - val_loss: 0.5846 - val_accuracy: 0.8229\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 16s 622ms/step - loss: 0.2263 - accuracy: 0.9175 - val_loss: 0.3897 - val_accuracy: 0.8333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Cat\n",
            "Training for class: Sofa\n",
            "Number of positive samples for Sofa: 500\n",
            "Number of negative samples before balancing: 9500\n",
            "Number of negative samples after balancing: 500\n",
            "Found 800 validated image filenames belonging to 2 classes.\n",
            "Found 200 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 19s 608ms/step - loss: 0.7545 - accuracy: 0.5575 - val_loss: 0.6791 - val_accuracy: 0.5781\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 16s 618ms/step - loss: 0.6646 - accuracy: 0.5962 - val_loss: 0.6793 - val_accuracy: 0.5000\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 15s 605ms/step - loss: 0.6402 - accuracy: 0.6288 - val_loss: 0.6278 - val_accuracy: 0.6823\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 16s 633ms/step - loss: 0.6431 - accuracy: 0.6500 - val_loss: 0.6650 - val_accuracy: 0.5417\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 16s 617ms/step - loss: 0.5928 - accuracy: 0.6712 - val_loss: 0.4796 - val_accuracy: 0.8021\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 15s 605ms/step - loss: 0.4951 - accuracy: 0.7763 - val_loss: 0.4864 - val_accuracy: 0.7760\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 15s 589ms/step - loss: 0.4856 - accuracy: 0.7563 - val_loss: 0.4048 - val_accuracy: 0.8385\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 15s 608ms/step - loss: 0.3709 - accuracy: 0.8350 - val_loss: 0.3023 - val_accuracy: 0.8958\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 16s 613ms/step - loss: 0.3449 - accuracy: 0.8512 - val_loss: 0.4297 - val_accuracy: 0.7969\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 16s 602ms/step - loss: 0.4182 - accuracy: 0.8138 - val_loss: 0.4759 - val_accuracy: 0.7812\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Sofa\n"
          ]
        }
      ],
      "source": [
        "# Loop through each class and train a binary classification model\n",
        "for class_name in class_names:\n",
        "    print(f\"Training for class: {class_name}\")\n",
        "\n",
        "    # Retrieve the list of image paths for the positive class\n",
        "    positive_images = train_data_lists[class_name]\n",
        "    if not positive_images:\n",
        "        print(f\"No images found for class {class_name}. Skipping this class.\")\n",
        "        continue\n",
        "    positive_labels = [1] * len(positive_images)\n",
        "\n",
        "    # Build a list of image paths for the negative class (all other classes)\n",
        "    negative_images = []\n",
        "    for other_class_name, image_paths in train_data_lists.items():\n",
        "        if other_class_name != class_name:\n",
        "            negative_images.extend(image_paths)\n",
        "\n",
        "    print(f\"Number of positive samples for {class_name}: {len(positive_images)}\")\n",
        "    print(f\"Number of negative samples before balancing: {len(negative_images)}\")\n",
        "\n",
        "\n",
        "    random.shuffle(negative_images)  # Shuffle the negative images\n",
        "    negative_images = negative_images[:len(positive_images)]  # Balance the positive and negative datasets\n",
        "    negative_labels = [0] * len(negative_images)\n",
        "    print(f\"Number of negative samples after balancing: {len(negative_images)}\")\n",
        "\n",
        "    # Combine and shuffle the positive and negative samples\n",
        "    combined_images = positive_images + negative_images\n",
        "    combined_labels = positive_labels + negative_labels\n",
        "    combined_list = list(zip(combined_images, combined_labels))\n",
        "    random.shuffle(combined_list)\n",
        "    combined_images, combined_labels = zip(*combined_list)\n",
        "\n",
        "    # Split the data into training and validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(combined_images, combined_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Create DataFrames for the training and validation sets\n",
        "    train_df = pd.DataFrame({\n",
        "    'filename': X_train,\n",
        "    'label': [str(label) for label in y_train]  # Convert labels to strings\n",
        "})\n",
        "    val_df = pd.DataFrame({\n",
        "    'filename': X_val,\n",
        "    'label': [str(label) for label in y_val]  # Convert labels to strings\n",
        "})\n",
        "\n",
        "    # Create data generators for training and validation\n",
        "    train_generator = train_datagen.flow_from_dataframe(\n",
        "        train_df,\n",
        "        x_col='filename',\n",
        "        y_col='label',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='binary'\n",
        "    )\n",
        "\n",
        "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    val_generator = val_datagen.flow_from_dataframe(\n",
        "        val_df,\n",
        "        x_col='filename',\n",
        "        y_col='label',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='binary'\n",
        "    )\n",
        "\n",
        "    #Build the binary classification model\n",
        "    model = build_binary_classification_model()\n",
        "\n",
        "    # Train the model on the data\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=len(X_train) // 32,\n",
        "        validation_data=val_generator,\n",
        "        validation_steps=len(X_val) // 32,\n",
        "        epochs=10\n",
        "    )\n",
        "\n",
        "    # Save the trained model\n",
        "    model_save_path = os.path.join('models', f\"{class_name}_binary_model.h5\")\n",
        "    os.makedirs('models', exist_ok=True)\n",
        "    model.save(model_save_path)\n",
        "\n",
        "    print(f\"Finished training for class: {class_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPtPyqDkaFy6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the path to the train directory\n",
        "train_dir = \"/content/test\"\n",
        "\n",
        "# Iterate over each subfolder in the train directory\n",
        "for class_name in os.listdir(train_dir):\n",
        "    class_dir = os.path.join(train_dir, class_name)\n",
        "\n",
        "    # Check if the item in the directory is a subfolder\n",
        "    if os.path.isdir(class_dir):\n",
        "        # Define the path to the subsubfolder\n",
        "        subsubfolder_dir = os.path.join(class_dir, class_name)\n",
        "\n",
        "        # Check if the subsubfolder exists\n",
        "        if os.path.exists(subsubfolder_dir):\n",
        "            # Iterate over each file in the subsubfolder\n",
        "            for file_name in os.listdir(subsubfolder_dir):\n",
        "                file_path = os.path.join(subsubfolder_dir, file_name)\n",
        "\n",
        "                # Move the file to the parent subfolder\n",
        "                if os.path.isfile(file_path):\n",
        "                    shutil.move(file_path, class_dir)\n",
        "\n",
        "            # Remove the empty subsubfolder\n",
        "            os.rmdir(subsubfolder_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcSQK1hyMEj3",
        "outputId": "32924f33-9876-48bf-f1c8-43163633fb99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loading model Aeroplane_binary_model.h5...\n",
            "Model for class 'Aeroplane' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 12s 319ms/step\n",
            "\n",
            "Loading model Bicycle_binary_model.h5...\n",
            "Model for class 'Bicycle' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 6s 142ms/step\n",
            "\n",
            "Loading model Bird_binary_model.h5...\n",
            "Model for class 'Bird' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 7s 173ms/step\n",
            "\n",
            "Loading model Boat_binary_model.h5...\n",
            "Model for class 'Boat' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 6s 143ms/step\n",
            "\n",
            "Loading model Bottle_binary_model.h5...\n",
            "Model for class 'Bottle' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 7s 167ms/step\n",
            "\n",
            "Loading model Bus_binary_model.h5...\n",
            "Model for class 'Bus' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 7s 167ms/step\n",
            "\n",
            "Loading model Car_binary_model.h5...\n",
            "Model for class 'Car' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 6s 142ms/step\n",
            "\n",
            "Loading model Cat_binary_model.h5...\n",
            "Model for class 'Cat' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 8s 202ms/step\n",
            "\n",
            "Loading model Chair_binary_model.h5...\n",
            "Model for class 'Chair' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 6s 146ms/step\n",
            "\n",
            "Loading model Cow_binary_model.h5...\n",
            "Model for class 'Cow' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 6s 140ms/step\n",
            "\n",
            "Loading model Diningtable_binary_model.h5...\n",
            "Model for class 'Diningtable' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 6s 153ms/step\n",
            "\n",
            "Loading model Dog_binary_model.h5...\n",
            "Model for class 'Dog' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 6s 147ms/step\n",
            "\n",
            "Loading model Horse_binary_model.h5...\n",
            "Model for class 'Horse' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 6s 154ms/step\n",
            "\n",
            "Loading model Motorbike_binary_model.h5...\n",
            "Model for class 'Motorbike' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 6s 142ms/step\n",
            "\n",
            "Loading model Person_binary_model.h5...\n",
            "Model for class 'Person' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 6s 143ms/step\n",
            "\n",
            "Loading model Pottedplant_binary_model.h5...\n",
            "Model for class 'Pottedplant' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 7s 169ms/step\n",
            "\n",
            "Loading model Sheep_binary_model.h5...\n",
            "Model for class 'Sheep' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 6s 150ms/step\n",
            "\n",
            "Loading model Sofa_binary_model.h5...\n",
            "Model for class 'Sofa' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 6s 156ms/step\n",
            "\n",
            "Loading model Train_binary_model.h5...\n",
            "Model for class 'Train' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 6s 158ms/step\n",
            "\n",
            "Loading model Tvmonitor_binary_model.h5...\n",
            "Model for class 'Tvmonitor' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 6s 153ms/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import classification_report, confusion_matrix, average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "model_dir = '/content/models'\n",
        "test_data_dir = '/content/test'\n",
        "\n",
        "# Initialize ImageDataGenerator for preprocessing\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Store average precision scores for mAP calculation\n",
        "ap_scores = []\n",
        "\n",
        "# Loop through each model file in the models directory\n",
        "for model_file in sorted(os.listdir(model_dir)):\n",
        "    if model_file.endswith(\".h5\"):\n",
        "        print(f\"\\nLoading model {model_file}...\")\n",
        "        model_path = os.path.join(model_dir, model_file)\n",
        "        model = load_model(model_path)\n",
        "        class_name = model_file.replace(\"_binary_model.h5\", \"\")\n",
        "        print(f\"Model for class '{class_name}' loaded successfully.\")\n",
        "\n",
        "        # Create DataFrame for test data with labels as strings\n",
        "        images = []\n",
        "        labels = []\n",
        "        for folder in os.listdir(test_data_dir):\n",
        "            folder_path = os.path.join(test_data_dir, folder)\n",
        "            for image_file in os.listdir(folder_path):\n",
        "                images.append(os.path.join(folder, image_file))\n",
        "                labels.append(str(int(folder == class_name)))  # Convert boolean to int to string\n",
        "\n",
        "        test_df = pd.DataFrame({\n",
        "            'filename': images,\n",
        "            'label': labels  # Labels are now strings\n",
        "        })\n",
        "\n",
        "        # Prepare test generator\n",
        "        test_generator = test_datagen.flow_from_dataframe(\n",
        "            dataframe=test_df,\n",
        "            directory=test_data_dir,\n",
        "            x_col='filename',\n",
        "            y_col='label',\n",
        "            target_size=(224, 224),\n",
        "            batch_size=32,\n",
        "            class_mode='binary',\n",
        "            shuffle=False)\n",
        "\n",
        "        # Predict and evaluate\n",
        "        predictions = model.predict(test_generator, steps=int(np.ceil(len(test_df)/32)))\n",
        "\n",
        "        predicted_labels = (predictions > 0.5).astype(int)\n",
        "        ap_score = average_precision_score(test_generator.classes, predictions)\n",
        "        ap_scores.append(ap_score)\n",
        "        #print(f\"AP score for class '{class_name}': {ap_score:.3f}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_x7jFNuEVlMA",
        "outputId": "be9ee713-307f-47e4-cc5e-5bcc7ba82956"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Mean Average Precision (mAP) across all classes: 0.185\n"
          ]
        }
      ],
      "source": [
        "# Calculate mean Average Precision (mAP)\n",
        "mAP = np.mean(ap_scores)\n",
        "print(f\"\\nMean Average Precision (mAP) across all classes: {mAP:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Edrjx7l9brSI"
      },
      "source": [
        "# Without Class Balancing, Orginal Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j84-DdBXa5g-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Set the paths to the train and test directories\n",
        "train_folder_path = \"/content/train\"\n",
        "\n",
        "# Each class has its own directory within the train directory\n",
        "class_names = [d for d in os.listdir(train_folder_path) if os.path.isdir(os.path.join(train_folder_path, d))]\n",
        "\n",
        "# Create a dictionary to hold our training image paths\n",
        "train_data_lists = {class_name: [os.path.join(train_folder_path, class_name, img)\n",
        "                                 for img in os.listdir(os.path.join(train_folder_path, class_name))]\n",
        "                    for class_name in class_names}\n",
        "\n",
        "def build_binary_classification_model():\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
        "    x = Flatten()(base_model.output)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dense(1, activation='sigmoid')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=x)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Configure the ImageDataGenerator for training data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCdet5oKbvWN",
        "outputId": "5b2b2c19-29c1-4f70-f64e-23efedcf133e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training for class: Bus\n",
            "Number of positive samples for Bus: 80\n",
            "Number of negative samples before balancing: 4827\n",
            "Number of negative samples after balancing: 80\n",
            "Found 128 validated image filenames belonging to 2 classes.\n",
            "Found 32 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 8s 590ms/step - loss: 0.8476 - accuracy: 0.5000 - val_loss: 0.6888 - val_accuracy: 0.5312\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 3s 635ms/step - loss: 0.6795 - accuracy: 0.5703 - val_loss: 0.6940 - val_accuracy: 0.5625\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 3s 835ms/step - loss: 0.7080 - accuracy: 0.5156 - val_loss: 0.7083 - val_accuracy: 0.4375\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 3s 610ms/step - loss: 0.6866 - accuracy: 0.5156 - val_loss: 0.6818 - val_accuracy: 0.4688\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 3s 618ms/step - loss: 0.6545 - accuracy: 0.6406 - val_loss: 0.6253 - val_accuracy: 0.6875\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 3s 624ms/step - loss: 0.6183 - accuracy: 0.7266 - val_loss: 0.5623 - val_accuracy: 0.6875\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 3s 599ms/step - loss: 0.6478 - accuracy: 0.6797 - val_loss: 0.6526 - val_accuracy: 0.5625\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 3s 620ms/step - loss: 0.5828 - accuracy: 0.6719 - val_loss: 0.5054 - val_accuracy: 0.7812\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 4s 808ms/step - loss: 0.5101 - accuracy: 0.7656 - val_loss: 0.4209 - val_accuracy: 0.8438\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 3s 611ms/step - loss: 0.5016 - accuracy: 0.7500 - val_loss: 0.7528 - val_accuracy: 0.5938\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Bus\n",
            "Training for class: Tvmonitor\n",
            "Number of positive samples for Tvmonitor: 172\n",
            "Number of negative samples before balancing: 4735\n",
            "Number of negative samples after balancing: 172\n",
            "Found 275 validated image filenames belonging to 2 classes.\n",
            "Found 69 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "8/8 [==============================] - 10s 550ms/step - loss: 0.7262 - accuracy: 0.5679 - val_loss: 0.6540 - val_accuracy: 0.6250\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 5s 568ms/step - loss: 0.6143 - accuracy: 0.7160 - val_loss: 1.4279 - val_accuracy: 0.5000\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 6s 722ms/step - loss: 0.7541 - accuracy: 0.6091 - val_loss: 0.5925 - val_accuracy: 0.7344\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 5s 573ms/step - loss: 0.5601 - accuracy: 0.6831 - val_loss: 0.4965 - val_accuracy: 0.7812\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 5s 667ms/step - loss: 0.4146 - accuracy: 0.8148 - val_loss: 0.8727 - val_accuracy: 0.7031\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 5s 571ms/step - loss: 0.3940 - accuracy: 0.8272 - val_loss: 0.4873 - val_accuracy: 0.8281\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 8s 962ms/step - loss: 0.2924 - accuracy: 0.8930 - val_loss: 0.6166 - val_accuracy: 0.8281\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 5s 562ms/step - loss: 0.3168 - accuracy: 0.8848 - val_loss: 0.6198 - val_accuracy: 0.7500\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 5s 660ms/step - loss: 0.2319 - accuracy: 0.9259 - val_loss: 0.7148 - val_accuracy: 0.7656\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 5s 570ms/step - loss: 0.1462 - accuracy: 0.9342 - val_loss: 0.8354 - val_accuracy: 0.8125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Tvmonitor\n",
            "Training for class: Bottle\n",
            "Number of positive samples for Bottle: 194\n",
            "Number of negative samples before balancing: 4713\n",
            "Number of negative samples after balancing: 194\n",
            "Found 310 validated image filenames belonging to 2 classes.\n",
            "Found 78 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "9/9 [==============================] - 10s 556ms/step - loss: 0.7667 - accuracy: 0.5216 - val_loss: 0.7412 - val_accuracy: 0.4688\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 6s 668ms/step - loss: 0.6951 - accuracy: 0.5576 - val_loss: 0.6679 - val_accuracy: 0.6562\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 5s 587ms/step - loss: 0.6760 - accuracy: 0.5755 - val_loss: 0.6443 - val_accuracy: 0.6406\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 7s 722ms/step - loss: 0.6153 - accuracy: 0.6736 - val_loss: 0.7848 - val_accuracy: 0.4844\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 5s 608ms/step - loss: 0.6547 - accuracy: 0.5971 - val_loss: 0.7363 - val_accuracy: 0.4531\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 7s 722ms/step - loss: 0.6652 - accuracy: 0.6076 - val_loss: 0.6396 - val_accuracy: 0.6406\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 5s 581ms/step - loss: 0.5748 - accuracy: 0.7266 - val_loss: 0.5798 - val_accuracy: 0.7188\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 6s 583ms/step - loss: 0.5985 - accuracy: 0.6871 - val_loss: 0.6685 - val_accuracy: 0.6094\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 7s 776ms/step - loss: 0.6038 - accuracy: 0.6619 - val_loss: 0.6697 - val_accuracy: 0.5938\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 7s 710ms/step - loss: 0.5774 - accuracy: 0.7158 - val_loss: 0.7393 - val_accuracy: 0.5781\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Bottle\n",
            "Training for class: Dog\n",
            "Number of positive samples for Dog: 310\n",
            "Number of negative samples before balancing: 4597\n",
            "Number of negative samples after balancing: 310\n",
            "Found 496 validated image filenames belonging to 2 classes.\n",
            "Found 124 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "15/15 [==============================] - 13s 616ms/step - loss: 0.7362 - accuracy: 0.5022 - val_loss: 0.7257 - val_accuracy: 0.4583\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 10s 675ms/step - loss: 0.6987 - accuracy: 0.5259 - val_loss: 0.6888 - val_accuracy: 0.4479\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 10s 602ms/step - loss: 0.6859 - accuracy: 0.5022 - val_loss: 0.6730 - val_accuracy: 0.6458\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 10s 646ms/step - loss: 0.6311 - accuracy: 0.6625 - val_loss: 0.5583 - val_accuracy: 0.6979\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 10s 648ms/step - loss: 0.6085 - accuracy: 0.6746 - val_loss: 0.6455 - val_accuracy: 0.5521\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 9s 578ms/step - loss: 0.5957 - accuracy: 0.6961 - val_loss: 0.6332 - val_accuracy: 0.6875\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 9s 568ms/step - loss: 0.6044 - accuracy: 0.6853 - val_loss: 0.5335 - val_accuracy: 0.7604\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 10s 642ms/step - loss: 0.5859 - accuracy: 0.6918 - val_loss: 0.5212 - val_accuracy: 0.7708\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 10s 670ms/step - loss: 0.5729 - accuracy: 0.6875 - val_loss: 0.6856 - val_accuracy: 0.6042\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 9s 616ms/step - loss: 0.5525 - accuracy: 0.7220 - val_loss: 0.5166 - val_accuracy: 0.7500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Dog\n",
            "Training for class: Cow\n",
            "Number of positive samples for Cow: 59\n",
            "Number of negative samples before balancing: 4848\n",
            "Number of negative samples after balancing: 59\n",
            "Found 94 validated image filenames belonging to 2 classes.\n",
            "Found 24 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "2/2 [==============================] - 11s 6s/step - loss: 0.6747 - accuracy: 0.6613 - val_loss: 1.6547 - val_accuracy: 0.5833\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 2s 814ms/step - loss: 1.4670 - accuracy: 0.5000 - val_loss: 0.7102 - val_accuracy: 0.5000\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 2s 809ms/step - loss: 0.7168 - accuracy: 0.4839 - val_loss: 0.7455 - val_accuracy: 0.4167\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 2s 828ms/step - loss: 0.5768 - accuracy: 0.6875 - val_loss: 0.6091 - val_accuracy: 0.6250\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 2s 857ms/step - loss: 0.5128 - accuracy: 0.8750 - val_loss: 0.7058 - val_accuracy: 0.5000\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3921 - accuracy: 0.8281 - val_loss: 0.6111 - val_accuracy: 0.6250\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 2s 868ms/step - loss: 0.3097 - accuracy: 0.8871 - val_loss: 0.9817 - val_accuracy: 0.6667\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 2s 821ms/step - loss: 0.4018 - accuracy: 0.8226 - val_loss: 0.8191 - val_accuracy: 0.6250\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 2s 767ms/step - loss: 0.3449 - accuracy: 0.8548 - val_loss: 0.6466 - val_accuracy: 0.6667\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 2s 830ms/step - loss: 0.1906 - accuracy: 0.9355 - val_loss: 0.4726 - val_accuracy: 0.7917\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Cow\n",
            "Training for class: Motorbike\n",
            "Number of positive samples for Motorbike: 163\n",
            "Number of negative samples before balancing: 4744\n",
            "Number of negative samples after balancing: 163\n",
            "Found 260 validated image filenames belonging to 2 classes.\n",
            "Found 66 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "8/8 [==============================] - 15s 1s/step - loss: 0.7347 - accuracy: 0.4956 - val_loss: 0.7012 - val_accuracy: 0.5312\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 5s 547ms/step - loss: 0.7010 - accuracy: 0.5175 - val_loss: 0.6921 - val_accuracy: 0.5781\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 5s 631ms/step - loss: 0.6851 - accuracy: 0.5859 - val_loss: 0.6785 - val_accuracy: 0.5938\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 5s 592ms/step - loss: 0.6624 - accuracy: 0.6172 - val_loss: 0.6604 - val_accuracy: 0.6406\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 6s 706ms/step - loss: 0.6592 - accuracy: 0.6009 - val_loss: 0.7262 - val_accuracy: 0.5156\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 5s 537ms/step - loss: 0.6596 - accuracy: 0.6096 - val_loss: 0.7200 - val_accuracy: 0.4688\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 6s 653ms/step - loss: 0.5982 - accuracy: 0.7061 - val_loss: 0.6328 - val_accuracy: 0.6562\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 5s 544ms/step - loss: 0.5584 - accuracy: 0.7237 - val_loss: 0.6858 - val_accuracy: 0.7031\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 6s 767ms/step - loss: 0.5732 - accuracy: 0.7018 - val_loss: 0.5858 - val_accuracy: 0.6719\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 5s 546ms/step - loss: 0.5595 - accuracy: 0.7018 - val_loss: 0.7880 - val_accuracy: 0.5625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Motorbike\n",
            "Training for class: Sheep\n",
            "Number of positive samples for Sheep: 51\n",
            "Number of negative samples before balancing: 4856\n",
            "Number of negative samples after balancing: 51\n",
            "Found 81 validated image filenames belonging to 2 classes.\n",
            "Found 21 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "2/2 [==============================] - 23s 17s/step - loss: 0.8245 - accuracy: 0.5306 - val_loss: 0.8284 - val_accuracy: 0.4762\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 1s 598ms/step - loss: 0.7438 - accuracy: 0.4898 - val_loss: 0.6308 - val_accuracy: 0.5714\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 1s 974ms/step - loss: 0.5797 - accuracy: 0.7347 - val_loss: 0.6025 - val_accuracy: 0.6667\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 1s 878ms/step - loss: 0.5659 - accuracy: 0.6939 - val_loss: 0.5240 - val_accuracy: 0.7143\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 2s 689ms/step - loss: 0.5137 - accuracy: 0.7143 - val_loss: 0.4856 - val_accuracy: 0.7143\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 2s 740ms/step - loss: 0.4191 - accuracy: 0.8281 - val_loss: 0.4279 - val_accuracy: 0.7619\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 1s 596ms/step - loss: 0.2796 - accuracy: 0.8980 - val_loss: 0.4807 - val_accuracy: 0.7619\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 1s 599ms/step - loss: 0.2055 - accuracy: 0.9388 - val_loss: 0.3839 - val_accuracy: 0.8571\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 1s 600ms/step - loss: 0.2504 - accuracy: 0.8776 - val_loss: 0.5132 - val_accuracy: 0.7143\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 1s 879ms/step - loss: 0.1684 - accuracy: 0.9184 - val_loss: 0.6693 - val_accuracy: 0.7619\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Sheep\n",
            "Training for class: Car\n",
            "Number of positive samples for Car: 372\n",
            "Number of negative samples before balancing: 4535\n",
            "Number of negative samples after balancing: 372\n",
            "Found 595 validated image filenames belonging to 2 classes.\n",
            "Found 149 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "18/18 [==============================] - 17s 705ms/step - loss: 0.7342 - accuracy: 0.5044 - val_loss: 0.7555 - val_accuracy: 0.4062\n",
            "Epoch 2/10\n",
            "18/18 [==============================] - 11s 616ms/step - loss: 0.6913 - accuracy: 0.5027 - val_loss: 0.6732 - val_accuracy: 0.5703\n",
            "Epoch 3/10\n",
            "18/18 [==============================] - 11s 576ms/step - loss: 0.6760 - accuracy: 0.5879 - val_loss: 0.6583 - val_accuracy: 0.6484\n",
            "Epoch 4/10\n",
            "18/18 [==============================] - 12s 624ms/step - loss: 0.6658 - accuracy: 0.6057 - val_loss: 0.6161 - val_accuracy: 0.7188\n",
            "Epoch 5/10\n",
            "18/18 [==============================] - 12s 641ms/step - loss: 0.6601 - accuracy: 0.6288 - val_loss: 0.5934 - val_accuracy: 0.7031\n",
            "Epoch 6/10\n",
            "18/18 [==============================] - 12s 636ms/step - loss: 0.6166 - accuracy: 0.6590 - val_loss: 0.5479 - val_accuracy: 0.7656\n",
            "Epoch 7/10\n",
            "18/18 [==============================] - 11s 593ms/step - loss: 0.6070 - accuracy: 0.6874 - val_loss: 0.5990 - val_accuracy: 0.6719\n",
            "Epoch 8/10\n",
            "18/18 [==============================] - 12s 629ms/step - loss: 0.5637 - accuracy: 0.7087 - val_loss: 0.5548 - val_accuracy: 0.7266\n",
            "Epoch 9/10\n",
            "18/18 [==============================] - 12s 640ms/step - loss: 0.5756 - accuracy: 0.7052 - val_loss: 0.5509 - val_accuracy: 0.7266\n",
            "Epoch 10/10\n",
            "18/18 [==============================] - 11s 607ms/step - loss: 0.5609 - accuracy: 0.7318 - val_loss: 0.5811 - val_accuracy: 0.6875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Car\n",
            "Training for class: Diningtable\n",
            "Number of positive samples for Diningtable: 84\n",
            "Number of negative samples before balancing: 4823\n",
            "Number of negative samples after balancing: 84\n",
            "Found 134 validated image filenames belonging to 2 classes.\n",
            "Found 34 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 12s 3s/step - loss: 0.8521 - accuracy: 0.5588 - val_loss: 0.6402 - val_accuracy: 0.6875\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 3s 826ms/step - loss: 0.6350 - accuracy: 0.6471 - val_loss: 0.7676 - val_accuracy: 0.5312\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 3s 639ms/step - loss: 0.6879 - accuracy: 0.5547 - val_loss: 0.6679 - val_accuracy: 0.5625\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 2s 491ms/step - loss: 0.6329 - accuracy: 0.6176 - val_loss: 0.6446 - val_accuracy: 0.5625\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 2s 506ms/step - loss: 0.6660 - accuracy: 0.6275 - val_loss: 0.7093 - val_accuracy: 0.5312\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 3s 812ms/step - loss: 0.5995 - accuracy: 0.6471 - val_loss: 0.6455 - val_accuracy: 0.7500\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 2s 493ms/step - loss: 0.5272 - accuracy: 0.7451 - val_loss: 0.5788 - val_accuracy: 0.5938\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 3s 621ms/step - loss: 0.4807 - accuracy: 0.7812 - val_loss: 0.5037 - val_accuracy: 0.8750\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 2s 702ms/step - loss: 0.3664 - accuracy: 0.8333 - val_loss: 0.5537 - val_accuracy: 0.7188\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 3s 745ms/step - loss: 0.3459 - accuracy: 0.8333 - val_loss: 0.6011 - val_accuracy: 0.7812\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Diningtable\n",
            "Training for class: Horse\n",
            "Number of positive samples for Horse: 158\n",
            "Number of negative samples before balancing: 4749\n",
            "Number of negative samples after balancing: 158\n",
            "Found 252 validated image filenames belonging to 2 classes.\n",
            "Found 64 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 27s 4s/step - loss: 0.7280 - accuracy: 0.5591 - val_loss: 0.7175 - val_accuracy: 0.4375\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 4s 620ms/step - loss: 0.6999 - accuracy: 0.5312 - val_loss: 0.7579 - val_accuracy: 0.4375\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 4s 608ms/step - loss: 0.7184 - accuracy: 0.5000 - val_loss: 0.6863 - val_accuracy: 0.5625\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 5s 733ms/step - loss: 0.6901 - accuracy: 0.5536 - val_loss: 0.7071 - val_accuracy: 0.4375\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 4s 609ms/step - loss: 0.7008 - accuracy: 0.4773 - val_loss: 0.6877 - val_accuracy: 0.5938\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 5s 782ms/step - loss: 0.6892 - accuracy: 0.5536 - val_loss: 0.6885 - val_accuracy: 0.5000\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 4s 597ms/step - loss: 0.6930 - accuracy: 0.5045 - val_loss: 0.7030 - val_accuracy: 0.4531\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 5s 769ms/step - loss: 0.6823 - accuracy: 0.5682 - val_loss: 0.6605 - val_accuracy: 0.6406\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 5s 625ms/step - loss: 0.6600 - accuracy: 0.6273 - val_loss: 0.6356 - val_accuracy: 0.6094\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 6s 729ms/step - loss: 0.6170 - accuracy: 0.6364 - val_loss: 0.6386 - val_accuracy: 0.7031\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Horse\n",
            "Training for class: Pottedplant\n",
            "Number of positive samples for Pottedplant: 144\n",
            "Number of negative samples before balancing: 4763\n",
            "Number of negative samples after balancing: 144\n",
            "Found 230 validated image filenames belonging to 2 classes.\n",
            "Found 58 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 9s 606ms/step - loss: 0.8406 - accuracy: 0.4899 - val_loss: 0.6832 - val_accuracy: 0.5625\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 4s 524ms/step - loss: 0.6955 - accuracy: 0.5152 - val_loss: 0.6869 - val_accuracy: 0.4688\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 5s 670ms/step - loss: 0.6933 - accuracy: 0.4949 - val_loss: 0.6642 - val_accuracy: 0.7812\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 4s 521ms/step - loss: 0.6780 - accuracy: 0.6010 - val_loss: 0.7320 - val_accuracy: 0.3438\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 4s 525ms/step - loss: 0.6954 - accuracy: 0.5707 - val_loss: 0.7058 - val_accuracy: 0.5312\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 5s 732ms/step - loss: 0.6948 - accuracy: 0.5556 - val_loss: 0.6533 - val_accuracy: 0.5938\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 4s 526ms/step - loss: 0.6779 - accuracy: 0.5202 - val_loss: 0.6340 - val_accuracy: 0.5938\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 5s 674ms/step - loss: 0.6658 - accuracy: 0.6061 - val_loss: 0.6251 - val_accuracy: 0.6562\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 4s 525ms/step - loss: 0.6488 - accuracy: 0.6566 - val_loss: 0.7817 - val_accuracy: 0.5000\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 4s 534ms/step - loss: 0.6736 - accuracy: 0.6162 - val_loss: 0.7111 - val_accuracy: 0.4688\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Pottedplant\n",
            "Training for class: Aeroplane\n",
            "Number of positive samples for Aeroplane: 188\n",
            "Number of negative samples before balancing: 4719\n",
            "Number of negative samples after balancing: 188\n",
            "Found 300 validated image filenames belonging to 2 classes.\n",
            "Found 76 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "9/9 [==============================] - 11s 606ms/step - loss: 0.7213 - accuracy: 0.6493 - val_loss: 0.3931 - val_accuracy: 0.8594\n",
            "Epoch 2/10\n",
            "9/9 [==============================] - 15s 2s/step - loss: 0.4202 - accuracy: 0.8060 - val_loss: 0.4452 - val_accuracy: 0.7500\n",
            "Epoch 3/10\n",
            "9/9 [==============================] - 5s 542ms/step - loss: 0.3529 - accuracy: 0.8433 - val_loss: 0.2589 - val_accuracy: 0.9375\n",
            "Epoch 4/10\n",
            "9/9 [==============================] - 7s 760ms/step - loss: 0.2670 - accuracy: 0.9097 - val_loss: 0.2629 - val_accuracy: 0.8750\n",
            "Epoch 5/10\n",
            "9/9 [==============================] - 5s 549ms/step - loss: 0.2325 - accuracy: 0.8881 - val_loss: 0.1536 - val_accuracy: 0.9062\n",
            "Epoch 6/10\n",
            "9/9 [==============================] - 6s 682ms/step - loss: 0.1281 - accuracy: 0.9552 - val_loss: 0.4489 - val_accuracy: 0.7812\n",
            "Epoch 7/10\n",
            "9/9 [==============================] - 5s 548ms/step - loss: 0.1573 - accuracy: 0.9403 - val_loss: 0.2061 - val_accuracy: 0.9219\n",
            "Epoch 8/10\n",
            "9/9 [==============================] - 6s 660ms/step - loss: 0.0968 - accuracy: 0.9627 - val_loss: 0.1808 - val_accuracy: 0.9219\n",
            "Epoch 9/10\n",
            "9/9 [==============================] - 7s 737ms/step - loss: 0.0901 - accuracy: 0.9664 - val_loss: 0.1738 - val_accuracy: 0.9375\n",
            "Epoch 10/10\n",
            "9/9 [==============================] - 5s 553ms/step - loss: 0.0625 - accuracy: 0.9701 - val_loss: 0.1778 - val_accuracy: 0.9219\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Aeroplane\n",
            "Training for class: Person\n",
            "Number of positive samples for Person: 1601\n",
            "Number of negative samples before balancing: 3306\n",
            "Number of negative samples after balancing: 1601\n",
            "Found 2561 validated image filenames belonging to 2 classes.\n",
            "Found 641 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "80/80 [==============================] - 57s 662ms/step - loss: 0.7048 - accuracy: 0.4994 - val_loss: 0.6932 - val_accuracy: 0.4797\n",
            "Epoch 2/10\n",
            "80/80 [==============================] - 49s 606ms/step - loss: 0.6930 - accuracy: 0.4990 - val_loss: 0.6947 - val_accuracy: 0.4766\n",
            "Epoch 3/10\n",
            "80/80 [==============================] - 50s 622ms/step - loss: 0.6931 - accuracy: 0.4962 - val_loss: 0.6933 - val_accuracy: 0.4797\n",
            "Epoch 4/10\n",
            "80/80 [==============================] - 49s 613ms/step - loss: 0.6929 - accuracy: 0.5014 - val_loss: 0.6933 - val_accuracy: 0.4766\n",
            "Epoch 5/10\n",
            "80/80 [==============================] - 50s 621ms/step - loss: 0.6931 - accuracy: 0.5073 - val_loss: 0.6933 - val_accuracy: 0.4766\n",
            "Epoch 6/10\n",
            "80/80 [==============================] - 51s 636ms/step - loss: 0.6931 - accuracy: 0.5049 - val_loss: 0.6934 - val_accuracy: 0.4766\n",
            "Epoch 7/10\n",
            "80/80 [==============================] - 49s 612ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4766\n",
            "Epoch 8/10\n",
            "80/80 [==============================] - 51s 634ms/step - loss: 0.6931 - accuracy: 0.5061 - val_loss: 0.6935 - val_accuracy: 0.4766\n",
            "Epoch 9/10\n",
            "80/80 [==============================] - 51s 636ms/step - loss: 0.6931 - accuracy: 0.5065 - val_loss: 0.6935 - val_accuracy: 0.4750\n",
            "Epoch 10/10\n",
            "80/80 [==============================] - 50s 621ms/step - loss: 0.6931 - accuracy: 0.5065 - val_loss: 0.6934 - val_accuracy: 0.4766\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Person\n",
            "Training for class: Boat\n",
            "Number of positive samples for Boat: 165\n",
            "Number of negative samples before balancing: 4742\n",
            "Number of negative samples after balancing: 165\n",
            "Found 264 validated image filenames belonging to 2 classes.\n",
            "Found 66 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "8/8 [==============================] - 17s 2s/step - loss: 0.7495 - accuracy: 0.5302 - val_loss: 0.6666 - val_accuracy: 0.6406\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 5s 607ms/step - loss: 0.6671 - accuracy: 0.6016 - val_loss: 0.7369 - val_accuracy: 0.4844\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 6s 678ms/step - loss: 0.6065 - accuracy: 0.7026 - val_loss: 0.3972 - val_accuracy: 0.8750\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 5s 583ms/step - loss: 0.5657 - accuracy: 0.7543 - val_loss: 0.4647 - val_accuracy: 0.8438\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 6s 710ms/step - loss: 0.5172 - accuracy: 0.7845 - val_loss: 0.6304 - val_accuracy: 0.6875\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 5s 585ms/step - loss: 0.6070 - accuracy: 0.6897 - val_loss: 0.4958 - val_accuracy: 0.7656\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 6s 640ms/step - loss: 0.5027 - accuracy: 0.7586 - val_loss: 0.3649 - val_accuracy: 0.8906\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 5s 566ms/step - loss: 0.4340 - accuracy: 0.8017 - val_loss: 0.3986 - val_accuracy: 0.8281\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 6s 779ms/step - loss: 0.4294 - accuracy: 0.8276 - val_loss: 0.3916 - val_accuracy: 0.8594\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 5s 556ms/step - loss: 0.4159 - accuracy: 0.8190 - val_loss: 0.4008 - val_accuracy: 0.8438\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Boat\n",
            "Training for class: Chair\n",
            "Number of positive samples for Chair: 280\n",
            "Number of negative samples before balancing: 4627\n",
            "Number of negative samples after balancing: 280\n",
            "Found 448 validated image filenames belonging to 2 classes.\n",
            "Found 112 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "14/14 [==============================] - 13s 582ms/step - loss: 0.7254 - accuracy: 0.5134 - val_loss: 0.6989 - val_accuracy: 0.4896\n",
            "Epoch 2/10\n",
            "14/14 [==============================] - 10s 672ms/step - loss: 0.6683 - accuracy: 0.5826 - val_loss: 0.6812 - val_accuracy: 0.5417\n",
            "Epoch 3/10\n",
            "14/14 [==============================] - 10s 731ms/step - loss: 0.6860 - accuracy: 0.5580 - val_loss: 0.6768 - val_accuracy: 0.5625\n",
            "Epoch 4/10\n",
            "14/14 [==============================] - 8s 592ms/step - loss: 0.6391 - accuracy: 0.6183 - val_loss: 0.5992 - val_accuracy: 0.6875\n",
            "Epoch 5/10\n",
            "14/14 [==============================] - 9s 663ms/step - loss: 0.5758 - accuracy: 0.7009 - val_loss: 0.6631 - val_accuracy: 0.6354\n",
            "Epoch 6/10\n",
            "14/14 [==============================] - 9s 659ms/step - loss: 0.5616 - accuracy: 0.7098 - val_loss: 0.6896 - val_accuracy: 0.5729\n",
            "Epoch 7/10\n",
            "14/14 [==============================] - 8s 591ms/step - loss: 0.5811 - accuracy: 0.6875 - val_loss: 0.5981 - val_accuracy: 0.6562\n",
            "Epoch 8/10\n",
            "14/14 [==============================] - 9s 589ms/step - loss: 0.5569 - accuracy: 0.6920 - val_loss: 0.6659 - val_accuracy: 0.6667\n",
            "Epoch 9/10\n",
            "14/14 [==============================] - 9s 596ms/step - loss: 0.5219 - accuracy: 0.7232 - val_loss: 0.6393 - val_accuracy: 0.6771\n",
            "Epoch 10/10\n",
            "14/14 [==============================] - 9s 667ms/step - loss: 0.5515 - accuracy: 0.7009 - val_loss: 0.7756 - val_accuracy: 0.6667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Chair\n",
            "Training for class: Train\n",
            "Number of positive samples for Train: 120\n",
            "Number of negative samples before balancing: 4787\n",
            "Number of negative samples after balancing: 120\n",
            "Found 192 validated image filenames belonging to 2 classes.\n",
            "Found 48 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "6/6 [==============================] - 9s 737ms/step - loss: 0.8996 - accuracy: 0.5625 - val_loss: 0.6505 - val_accuracy: 0.6875\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 4s 603ms/step - loss: 0.6381 - accuracy: 0.7240 - val_loss: 0.5835 - val_accuracy: 0.6562\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 4s 602ms/step - loss: 0.5096 - accuracy: 0.7448 - val_loss: 0.4033 - val_accuracy: 0.7812\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 4s 697ms/step - loss: 0.4016 - accuracy: 0.8281 - val_loss: 0.4845 - val_accuracy: 0.8438\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 4s 595ms/step - loss: 0.3942 - accuracy: 0.8281 - val_loss: 0.3758 - val_accuracy: 0.8750\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 4s 600ms/step - loss: 0.2867 - accuracy: 0.8646 - val_loss: 0.4214 - val_accuracy: 0.8438\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 5s 726ms/step - loss: 0.2225 - accuracy: 0.8958 - val_loss: 0.2935 - val_accuracy: 0.8750\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 4s 595ms/step - loss: 0.1604 - accuracy: 0.9375 - val_loss: 0.2258 - val_accuracy: 0.9375\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 4s 600ms/step - loss: 0.1626 - accuracy: 0.9271 - val_loss: 0.1706 - val_accuracy: 0.9375\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 5s 714ms/step - loss: 0.2141 - accuracy: 0.9115 - val_loss: 0.5318 - val_accuracy: 0.8125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Train\n",
            "Training for class: Bird\n",
            "Number of positive samples for Bird: 244\n",
            "Number of negative samples before balancing: 4663\n",
            "Number of negative samples after balancing: 244\n",
            "Found 390 validated image filenames belonging to 2 classes.\n",
            "Found 98 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "12/12 [==============================] - 12s 672ms/step - loss: 0.6749 - accuracy: 0.5894 - val_loss: 0.5884 - val_accuracy: 0.7083\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 8s 617ms/step - loss: 0.6196 - accuracy: 0.6844 - val_loss: 0.6302 - val_accuracy: 0.5833\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 7s 558ms/step - loss: 0.5846 - accuracy: 0.6816 - val_loss: 0.4786 - val_accuracy: 0.8229\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 8s 660ms/step - loss: 0.4411 - accuracy: 0.8017 - val_loss: 0.4993 - val_accuracy: 0.7917\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 7s 580ms/step - loss: 0.4724 - accuracy: 0.7849 - val_loss: 0.4741 - val_accuracy: 0.8021\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 8s 617ms/step - loss: 0.3925 - accuracy: 0.8212 - val_loss: 0.4940 - val_accuracy: 0.7500\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 8s 640ms/step - loss: 0.3221 - accuracy: 0.8771 - val_loss: 0.5214 - val_accuracy: 0.7917\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 7s 560ms/step - loss: 0.3418 - accuracy: 0.8324 - val_loss: 0.4954 - val_accuracy: 0.7812\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 8s 709ms/step - loss: 0.2871 - accuracy: 0.8743 - val_loss: 0.5217 - val_accuracy: 0.7708\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 8s 623ms/step - loss: 0.2116 - accuracy: 0.9078 - val_loss: 0.5631 - val_accuracy: 0.8438\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Bird\n",
            "Training for class: Bicycle\n",
            "Number of positive samples for Bicycle: 153\n",
            "Number of negative samples before balancing: 4754\n",
            "Number of negative samples after balancing: 153\n",
            "Found 244 validated image filenames belonging to 2 classes.\n",
            "Found 62 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 22s 3s/step - loss: 0.7375 - accuracy: 0.5425 - val_loss: 0.7491 - val_accuracy: 0.4375\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 5s 622ms/step - loss: 0.6855 - accuracy: 0.5283 - val_loss: 0.8117 - val_accuracy: 0.3438\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 4s 586ms/step - loss: 0.6712 - accuracy: 0.5849 - val_loss: 0.6867 - val_accuracy: 0.5000\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 6s 895ms/step - loss: 0.6498 - accuracy: 0.6698 - val_loss: 0.6829 - val_accuracy: 0.5625\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 4s 568ms/step - loss: 0.5812 - accuracy: 0.6840 - val_loss: 0.7063 - val_accuracy: 0.5938\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 5s 733ms/step - loss: 0.5352 - accuracy: 0.7358 - val_loss: 0.7112 - val_accuracy: 0.6875\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 4s 577ms/step - loss: 0.4906 - accuracy: 0.7689 - val_loss: 0.6080 - val_accuracy: 0.6875\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 4s 614ms/step - loss: 0.4058 - accuracy: 0.8066 - val_loss: 0.6089 - val_accuracy: 0.7812\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 5s 610ms/step - loss: 0.3598 - accuracy: 0.8302 - val_loss: 1.4082 - val_accuracy: 0.5938\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 4s 605ms/step - loss: 0.3775 - accuracy: 0.8438 - val_loss: 0.7573 - val_accuracy: 0.7500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Bicycle\n",
            "Training for class: Cat\n",
            "Number of positive samples for Cat: 262\n",
            "Number of negative samples before balancing: 4645\n",
            "Number of negative samples after balancing: 262\n",
            "Found 419 validated image filenames belonging to 2 classes.\n",
            "Found 105 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "13/13 [==============================] - 17s 896ms/step - loss: 0.7230 - accuracy: 0.5245 - val_loss: 0.6800 - val_accuracy: 0.5521\n",
            "Epoch 2/10\n",
            "13/13 [==============================] - 8s 591ms/step - loss: 0.6212 - accuracy: 0.6298 - val_loss: 0.6276 - val_accuracy: 0.7188\n",
            "Epoch 3/10\n",
            "13/13 [==============================] - 9s 648ms/step - loss: 0.5838 - accuracy: 0.6718 - val_loss: 0.6648 - val_accuracy: 0.6250\n",
            "Epoch 4/10\n",
            "13/13 [==============================] - 8s 615ms/step - loss: 0.4603 - accuracy: 0.7829 - val_loss: 0.4887 - val_accuracy: 0.7812\n",
            "Epoch 5/10\n",
            "13/13 [==============================] - 8s 558ms/step - loss: 0.4590 - accuracy: 0.8010 - val_loss: 0.4386 - val_accuracy: 0.7604\n",
            "Epoch 6/10\n",
            "13/13 [==============================] - 8s 554ms/step - loss: 0.3772 - accuracy: 0.8475 - val_loss: 0.4462 - val_accuracy: 0.8021\n",
            "Epoch 7/10\n",
            "13/13 [==============================] - 9s 645ms/step - loss: 0.3709 - accuracy: 0.8450 - val_loss: 0.5486 - val_accuracy: 0.7500\n",
            "Epoch 8/10\n",
            "13/13 [==============================] - 9s 651ms/step - loss: 0.4021 - accuracy: 0.8062 - val_loss: 0.6309 - val_accuracy: 0.7500\n",
            "Epoch 9/10\n",
            "13/13 [==============================] - 8s 561ms/step - loss: 0.4251 - accuracy: 0.8165 - val_loss: 0.5039 - val_accuracy: 0.8021\n",
            "Epoch 10/10\n",
            "13/13 [==============================] - 10s 742ms/step - loss: 0.4626 - accuracy: 0.7700 - val_loss: 0.4507 - val_accuracy: 0.8125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Cat\n",
            "Training for class: Sofa\n",
            "Number of positive samples for Sofa: 107\n",
            "Number of negative samples before balancing: 4800\n",
            "Number of negative samples after balancing: 107\n",
            "Found 171 validated image filenames belonging to 2 classes.\n",
            "Found 43 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "5/5 [==============================] - 15s 615ms/step - loss: 1.0511 - accuracy: 0.5396 - val_loss: 0.6313 - val_accuracy: 0.7812\n",
            "Epoch 2/10\n",
            "5/5 [==============================] - 3s 627ms/step - loss: 0.6109 - accuracy: 0.6835 - val_loss: 0.5671 - val_accuracy: 0.7188\n",
            "Epoch 3/10\n",
            "5/5 [==============================] - 3s 538ms/step - loss: 0.5428 - accuracy: 0.6978 - val_loss: 0.8403 - val_accuracy: 0.5000\n",
            "Epoch 4/10\n",
            "5/5 [==============================] - 3s 543ms/step - loss: 0.4886 - accuracy: 0.7410 - val_loss: 0.5617 - val_accuracy: 0.7188\n",
            "Epoch 5/10\n",
            "5/5 [==============================] - 4s 701ms/step - loss: 0.3867 - accuracy: 0.8417 - val_loss: 0.7608 - val_accuracy: 0.5625\n",
            "Epoch 6/10\n",
            "5/5 [==============================] - 3s 566ms/step - loss: 0.3601 - accuracy: 0.8201 - val_loss: 0.4419 - val_accuracy: 0.7500\n",
            "Epoch 7/10\n",
            "5/5 [==============================] - 3s 534ms/step - loss: 0.2524 - accuracy: 0.9137 - val_loss: 0.4483 - val_accuracy: 0.7812\n",
            "Epoch 8/10\n",
            "5/5 [==============================] - 4s 746ms/step - loss: 0.2133 - accuracy: 0.9137 - val_loss: 0.3437 - val_accuracy: 0.8750\n",
            "Epoch 9/10\n",
            "5/5 [==============================] - 3s 628ms/step - loss: 0.1254 - accuracy: 0.9568 - val_loss: 0.3512 - val_accuracy: 0.8125\n",
            "Epoch 10/10\n",
            "5/5 [==============================] - 3s 533ms/step - loss: 0.2117 - accuracy: 0.9209 - val_loss: 0.5205 - val_accuracy: 0.7500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished training for class: Sofa\n"
          ]
        }
      ],
      "source": [
        "# Loop through each class and train a binary classification model\n",
        "for class_name in class_names:\n",
        "    print(f\"Training for class: {class_name}\")\n",
        "\n",
        "    # Retrieve the list of image paths for the positive class\n",
        "    positive_images = train_data_lists[class_name]\n",
        "    if not positive_images:\n",
        "        print(f\"No images found for class {class_name}. Skipping this class.\")\n",
        "        continue\n",
        "    positive_labels = [1] * len(positive_images)\n",
        "\n",
        "    # Build a list of image paths for the negative class (all other classes)\n",
        "    negative_images = []\n",
        "    for other_class_name, image_paths in train_data_lists.items():\n",
        "        if other_class_name != class_name:\n",
        "            negative_images.extend(image_paths)\n",
        "\n",
        "    print(f\"Number of positive samples for {class_name}: {len(positive_images)}\")\n",
        "    print(f\"Number of negative samples before balancing: {len(negative_images)}\")\n",
        "\n",
        "\n",
        "    random.shuffle(negative_images)  # Shuffle the negative images\n",
        "    negative_images = negative_images[:len(positive_images)]  # Balance the positive and negative datasets\n",
        "    negative_labels = [0] * len(negative_images)\n",
        "    print(f\"Number of negative samples after balancing: {len(negative_images)}\")\n",
        "\n",
        "    # Combine and shuffle the positive and negative samples\n",
        "    combined_images = positive_images + negative_images\n",
        "    combined_labels = positive_labels + negative_labels\n",
        "    combined_list = list(zip(combined_images, combined_labels))\n",
        "    random.shuffle(combined_list)\n",
        "    combined_images, combined_labels = zip(*combined_list)\n",
        "\n",
        "    # Split the data into training and validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(combined_images, combined_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Create DataFrames for the training and validation sets\n",
        "    train_df = pd.DataFrame({\n",
        "    'filename': X_train,\n",
        "    'label': [str(label) for label in y_train]  # Convert labels to strings\n",
        "})\n",
        "    val_df = pd.DataFrame({\n",
        "    'filename': X_val,\n",
        "    'label': [str(label) for label in y_val]  # Convert labels to strings\n",
        "})\n",
        "\n",
        "    # Create data generators for training and validation\n",
        "    train_generator = train_datagen.flow_from_dataframe(\n",
        "        train_df,\n",
        "        x_col='filename',\n",
        "        y_col='label',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='binary'\n",
        "    )\n",
        "\n",
        "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    val_generator = val_datagen.flow_from_dataframe(\n",
        "        val_df,\n",
        "        x_col='filename',\n",
        "        y_col='label',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='binary'\n",
        "    )\n",
        "\n",
        "    #Build the binary classification model\n",
        "    model = build_binary_classification_model()\n",
        "    steps_per_epoch = max(1, len(X_train) // 32)\n",
        "    validation_steps = max(1, len(X_val) // 32)\n",
        "    # Train the model on the data\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        validation_data=val_generator,\n",
        "        validation_steps=validation_steps,\n",
        "        epochs=10\n",
        "    )\n",
        "\n",
        "    # Save the trained model\n",
        "    model_save_path = os.path.join('models', f\"{class_name}_binary_model.h5\")\n",
        "    os.makedirs('models', exist_ok=True)\n",
        "    model.save(model_save_path)\n",
        "\n",
        "    print(f\"Finished training for class: {class_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvJNp3-ybzMi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the path to the train directory\n",
        "train_dir = \"/content/test\"\n",
        "\n",
        "# Iterate over each subfolder in the train directory\n",
        "for class_name in os.listdir(train_dir):\n",
        "    class_dir = os.path.join(train_dir, class_name)\n",
        "\n",
        "    # Check if the item in the directory is a subfolder\n",
        "    if os.path.isdir(class_dir):\n",
        "        # Define the path to the subsubfolder\n",
        "        subsubfolder_dir = os.path.join(class_dir, class_name)\n",
        "\n",
        "        # Check if the subsubfolder exists\n",
        "        if os.path.exists(subsubfolder_dir):\n",
        "            # Iterate over each file in the subsubfolder\n",
        "            for file_name in os.listdir(subsubfolder_dir):\n",
        "                file_path = os.path.join(subsubfolder_dir, file_name)\n",
        "\n",
        "                # Move the file to the parent subfolder\n",
        "                if os.path.isfile(file_path):\n",
        "                    shutil.move(file_path, class_dir)\n",
        "\n",
        "            # Remove the empty subsubfolder\n",
        "            os.rmdir(subsubfolder_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eyaPL2qcK26",
        "outputId": "547512b7-5ddc-445a-ac9c-07ea6e7c2838"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loading model Aeroplane_binary_model.h5...\n",
            "Model for class 'Aeroplane' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 10s 260ms/step\n",
            "\n",
            "Loading model Bicycle_binary_model.h5...\n",
            "Model for class 'Bicycle' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 5s 136ms/step\n",
            "\n",
            "Loading model Bird_binary_model.h5...\n",
            "Model for class 'Bird' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 6s 159ms/step\n",
            "\n",
            "Loading model Boat_binary_model.h5...\n",
            "Model for class 'Boat' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 5s 136ms/step\n",
            "\n",
            "Loading model Bottle_binary_model.h5...\n",
            "Model for class 'Bottle' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 6s 139ms/step\n",
            "\n",
            "Loading model Bus_binary_model.h5...\n",
            "Model for class 'Bus' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 6s 143ms/step\n",
            "\n",
            "Loading model Car_binary_model.h5...\n",
            "Model for class 'Car' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 6s 142ms/step\n",
            "\n",
            "Loading model Cat_binary_model.h5...\n",
            "Model for class 'Cat' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 6s 156ms/step\n",
            "\n",
            "Loading model Chair_binary_model.h5...\n",
            "Model for class 'Chair' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 6s 161ms/step\n",
            "\n",
            "Loading model Cow_binary_model.h5...\n",
            "Model for class 'Cow' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 6s 139ms/step\n",
            "\n",
            "Loading model Diningtable_binary_model.h5...\n",
            "Model for class 'Diningtable' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 6s 156ms/step\n",
            "\n",
            "Loading model Dog_binary_model.h5...\n",
            "Model for class 'Dog' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 6s 152ms/step\n",
            "\n",
            "Loading model Horse_binary_model.h5...\n",
            "Model for class 'Horse' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 6s 145ms/step\n",
            "\n",
            "Loading model Motorbike_binary_model.h5...\n",
            "Model for class 'Motorbike' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 6s 143ms/step\n",
            "\n",
            "Loading model Person_binary_model.h5...\n",
            "Model for class 'Person' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 6s 144ms/step\n",
            "\n",
            "Loading model Pottedplant_binary_model.h5...\n",
            "Model for class 'Pottedplant' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 6s 139ms/step\n",
            "\n",
            "Loading model Sheep_binary_model.h5...\n",
            "Model for class 'Sheep' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 6s 161ms/step\n",
            "\n",
            "Loading model Sofa_binary_model.h5...\n",
            "Model for class 'Sofa' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 5s 134ms/step\n",
            "\n",
            "Loading model Train_binary_model.h5...\n",
            "Model for class 'Train' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 6s 152ms/step\n",
            "\n",
            "Loading model Tvmonitor_binary_model.h5...\n",
            "Model for class 'Tvmonitor' loaded successfully.\n",
            "Found 1236 validated image filenames belonging to 2 classes.\n",
            "39/39 [==============================] - 7s 168ms/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import classification_report, confusion_matrix, average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "model_dir = '/content/models'\n",
        "test_data_dir = '/content/test'\n",
        "\n",
        "# Initialize ImageDataGenerator for preprocessing\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Store average precision scores for mAP calculation\n",
        "ap_scores = []\n",
        "\n",
        "# Loop through each model file in the models directory\n",
        "for model_file in sorted(os.listdir(model_dir)):\n",
        "    if model_file.endswith(\".h5\"):\n",
        "        print(f\"\\nLoading model {model_file}...\")\n",
        "        model_path = os.path.join(model_dir, model_file)\n",
        "        model = load_model(model_path)\n",
        "        class_name = model_file.replace(\"_binary_model.h5\", \"\")\n",
        "        print(f\"Model for class '{class_name}' loaded successfully.\")\n",
        "\n",
        "        # Create DataFrame for test data with labels as strings\n",
        "        images = []\n",
        "        labels = []\n",
        "        for folder in os.listdir(test_data_dir):\n",
        "            folder_path = os.path.join(test_data_dir, folder)\n",
        "            for image_file in os.listdir(folder_path):\n",
        "                images.append(os.path.join(folder, image_file))\n",
        "                labels.append(str(int(folder == class_name)))  # Convert boolean to int to string\n",
        "\n",
        "        test_df = pd.DataFrame({\n",
        "            'filename': images,\n",
        "            'label': labels  # Labels are now strings\n",
        "        })\n",
        "\n",
        "        # Prepare test generator\n",
        "        test_generator = test_datagen.flow_from_dataframe(\n",
        "            dataframe=test_df,\n",
        "            directory=test_data_dir,\n",
        "            x_col='filename',\n",
        "            y_col='label',\n",
        "            target_size=(224, 224),\n",
        "            batch_size=32,\n",
        "            class_mode='binary',\n",
        "            shuffle=False)\n",
        "\n",
        "        # Predict and evaluate\n",
        "        predictions = model.predict(test_generator, steps=int(np.ceil(len(test_df)/32)))\n",
        "\n",
        "        predicted_labels = (predictions > 0.5).astype(int)\n",
        "        ap_score = average_precision_score(test_generator.classes, predictions)\n",
        "        ap_scores.append(ap_score)\n",
        "        #print(f\"AP score for class '{class_name}': {ap_score:.3f}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISYh4Yq0cQHX",
        "outputId": "a1ca3c72-85a6-4f16-e938-fa0ea576ab7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Mean Average Precision (mAP) across all classes: 0.175\n"
          ]
        }
      ],
      "source": [
        "# Calculate mean Average Precision (mAP)\n",
        "mAP = np.mean(ap_scores)\n",
        "print(f\"\\nMean Average Precision (mAP) across all classes: {mAP:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "5oIvBdplnJMG",
        "outputId": "6c2c1130-db9b-41f4-ca8e-4a31fb5e200d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "sample_sizes = [\"Orginal Data\", \"Balanced Classes\"]   #Samples\n",
        "mAP_values = [0.175, 0.185]  #  mAP values\n",
        "\n",
        "# Plot the graph\n",
        "plt.plot(sample_sizes, mAP_values, marker='o', linestyle='-')\n",
        "plt.title('mAP vs Sample Size')\n",
        "plt.xlabel('Sample Size')\n",
        "plt.ylabel('mAP')\n",
        "plt.grid(True)\n",
        "plt.xticks(sample_sizes)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yarHdA6t5y2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
