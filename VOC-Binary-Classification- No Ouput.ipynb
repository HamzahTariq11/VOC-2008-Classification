{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lrlq6gks9nmR"
      },
      "source": [
        "The Models have been trained using our own GPU; now we will calculate the mAP and show top 10 images with some more metrics.                                Models are stored in google drive due to size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "folder_path = \"/content/VOCdevkit/VOC2008/JPEGImages\"\n",
        "def extract_positive_images(directory, file_name):\n",
        "    positive_images = []\n",
        "    variations = [\n",
        "        file_name,\n",
        "        file_name.replace(\"_train\", \"_trainval\"),\n",
        "        file_name.replace(\"_train\", \"_val\")\n",
        "    ]\n",
        "\n",
        "    for variation in variations:\n",
        "        file_path = os.path.join(directory, variation)\n",
        "        with open(file_path, \"r\") as file:\n",
        "            lines = file.readlines()\n",
        "\n",
        "        for line in lines:\n",
        "            if line.strip().endswith(\" 1\"):\n",
        "                image_name = line.split()[0] + \".jpg\"\n",
        "                if image_name not in positive_images:\n",
        "                    positive_images.append(image_name)\n",
        "\n",
        "    return positive_images\n",
        "\n",
        "\n",
        "data_directory = \"VOCdevkit/VOC2008/ImageSets/Main/\"\n",
        "folder_path = \"/VOCdevkit/VOC2008/JPEGImages\"\n",
        "\n",
        "aeroplane_images = extract_positive_images(data_directory, \"aeroplane_train.txt\")\n",
        "bicycle_images = extract_positive_images(data_directory, \"bicycle_train.txt\")\n",
        "bird_images = extract_positive_images(data_directory, \"bird_train.txt\")\n",
        "boat_images = extract_positive_images(data_directory, \"boat_train.txt\")\n",
        "bottle_images = extract_positive_images(data_directory, \"bottle_train.txt\")\n",
        "bus_images = extract_positive_images(data_directory, \"bus_train.txt\")\n",
        "car_images = extract_positive_images(data_directory, \"car_train.txt\")\n",
        "cat_images = extract_positive_images(data_directory, \"cat_train.txt\")\n",
        "chair_images = extract_positive_images(data_directory, \"chair_train.txt\")\n",
        "cow_images = extract_positive_images(data_directory, \"cow_train.txt\")\n",
        "diningtable_images = extract_positive_images(data_directory, \"diningtable_train.txt\")\n",
        "dog_images = extract_positive_images(data_directory, \"dog_train.txt\")\n",
        "horse_images = extract_positive_images(data_directory, \"horse_train.txt\")\n",
        "motorbike_images = extract_positive_images(data_directory, \"motorbike_train.txt\")\n",
        "person_images = extract_positive_images(data_directory, \"person_train.txt\")\n",
        "pottedplant_images = extract_positive_images(data_directory, \"pottedplant_train.txt\")\n",
        "sheep_images = extract_positive_images(data_directory, \"sheep_train.txt\")\n",
        "sofa_images = extract_positive_images(data_directory, \"sofa_train.txt\")\n",
        "train_images = extract_positive_images(data_directory, \"train_train.txt\")\n",
        "tvmonitor_images = extract_positive_images(data_directory, \"tvmonitor_train.txt\")\n",
        "\n",
        "jpg_files = []\n",
        "\n",
        "for file in os.listdir(folder_path):\n",
        "    if file.endswith(\".jpg\"):\n",
        "        jpg_files.append(file)\n",
        "\n",
        "\n",
        "class_data_lists = {\n",
        "    \"Aeroplane\": aeroplane_images,\n",
        "    \"Bicycle\": bicycle_images,\n",
        "    \"Bird\": bird_images,\n",
        "    \"Boat\": boat_images,\n",
        "    \"Bottle\": bottle_images,\n",
        "    \"Bus\": bus_images,\n",
        "    \"Car\": car_images,\n",
        "    \"Cat\": cat_images,\n",
        "    \"Chair\": chair_images,\n",
        "    \"Cow\": cow_images,\n",
        "    \"Diningtable\": diningtable_images,\n",
        "    \"Dog\": dog_images,\n",
        "    \"Horse\": horse_images,\n",
        "    \"Motorbike\": motorbike_images,\n",
        "    \"Person\": person_images,\n",
        "    \"Pottedplant\": pottedplant_images,\n",
        "    \"Sheep\": sheep_images,\n",
        "    \"Sofa\": sofa_images,\n",
        "    \"Train\": train_images,\n",
        "    \"Tvmonitor\": tvmonitor_images\n",
        "}\n",
        "\n",
        "\n",
        "train_data_lists = {class_name: [] for class_name in class_data_lists}\n",
        "test_data_lists = {class_name: [] for class_name in class_data_lists}\n",
        "\n",
        "\n",
        "for class_name, data_list in class_data_lists.items():\n",
        "    train_images, test_images = train_test_split(data_list, test_size=0.2, random_state=42)\n",
        "    train_data_lists[class_name] = train_images\n",
        "    test_data_lists[class_name] = test_images\n",
        "\n",
        "\n",
        "for class_name, train_images in train_data_lists.items():\n",
        "    for file in train_images:\n",
        "        try:\n",
        "            src_path = os.path.join(folder_path, file)\n",
        "            dest_dir = os.path.join(\"train\", class_name)\n",
        "            dest_path = os.path.join(dest_dir, file)\n",
        "            os.makedirs(dest_dir, exist_ok=True)\n",
        "            shutil.copyfile(src_path, dest_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Error copying {file} to {dest_dir}: {e}\")\n",
        "\n",
        "\n",
        "for class_name, test_images in test_data_lists.items():\n",
        "    for file in test_images:\n",
        "        try:\n",
        "            src_path = os.path.join(folder_path, file)\n",
        "            dest_dir = os.path.join(\"test\", class_name)\n",
        "            dest_path = os.path.join(dest_dir, file)\n",
        "            os.makedirs(dest_dir, exist_ok=True)\n",
        "            shutil.copyfile(src_path, dest_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Error copying {file} to {dest_dir}: {e}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_WHrNKMt04U"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Set the paths to the train and test directories\n",
        "train_folder_path = \"train\"\n",
        "\n",
        "# Each class has its own directory within the train directory\n",
        "class_names = [d for d in os.listdir(train_folder_path) if os.path.isdir(os.path.join(train_folder_path, d))]\n",
        "\n",
        "# Create a dictionary to hold our training image paths\n",
        "train_data_lists = {class_name: [os.path.join(train_folder_path, class_name, img)\n",
        "                                 for img in os.listdir(os.path.join(train_folder_path, class_name))]\n",
        "                    for class_name in class_names}\n",
        "\n",
        "def build_binary_classification_model():\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
        "    x = Flatten()(base_model.output)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dense(1, activation='sigmoid')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=x)\n",
        "    model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Configure the ImageDataGenerator for training data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Loop through each class and train a binary classification model\n",
        "for class_name in class_names:\n",
        "    print(f\"Training for class: {class_name}\")\n",
        "\n",
        "    # Retrieve the list of image paths for the positive class\n",
        "    positive_images = train_data_lists[class_name]\n",
        "    if not positive_images:\n",
        "        print(f\"No images found for class {class_name}. Skipping this class.\")\n",
        "        continue\n",
        "    positive_labels = [1] * len(positive_images)\n",
        "\n",
        "    # Build a list of image paths for the negative class (all other classes)\n",
        "    negative_images = []\n",
        "    for other_class_name, image_paths in train_data_lists.items():\n",
        "        if other_class_name != class_name:\n",
        "            negative_images.extend(image_paths)\n",
        "\n",
        "    print(f\"Number of positive samples for {class_name}: {len(positive_images)}\")\n",
        "    print(f\"Number of negative samples before balancing: {len(negative_images)}\")\n",
        "\n",
        "\n",
        "    random.shuffle(negative_images)  # Shuffle the negative images\n",
        "    negative_images = negative_images[:len(positive_images)]  # Balance the positive and negative datasets\n",
        "    negative_labels = [0] * len(negative_images)\n",
        "    print(f\"Number of negative samples after balancing: {len(negative_images)}\")\n",
        "\n",
        "    # Combine and shuffle the positive and negative samples\n",
        "    combined_images = positive_images + negative_images\n",
        "    combined_labels = positive_labels + negative_labels\n",
        "    combined_list = list(zip(combined_images, combined_labels))\n",
        "    random.shuffle(combined_list)\n",
        "    combined_images, combined_labels = zip(*combined_list)\n",
        "\n",
        "    # Split the data into training and validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(combined_images, combined_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Create DataFrames for the training and validation sets\n",
        "    train_df = pd.DataFrame({\n",
        "    'filename': X_train,\n",
        "    'label': [str(label) for label in y_train]  # Convert labels to strings\n",
        "})\n",
        "    val_df = pd.DataFrame({\n",
        "    'filename': X_val,\n",
        "    'label': [str(label) for label in y_val]  # Convert labels to strings\n",
        "})\n",
        "\n",
        "    # Create data generators for training and validation\n",
        "    train_generator = train_datagen.flow_from_dataframe(\n",
        "        train_df,\n",
        "        x_col='filename',\n",
        "        y_col='label',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='binary'\n",
        "    )\n",
        "\n",
        "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    val_generator = val_datagen.flow_from_dataframe(\n",
        "        val_df,\n",
        "        x_col='filename',\n",
        "        y_col='label',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='binary'\n",
        "    )\n",
        "\n",
        "    # Build the binary classification model\n",
        "    model = build_binary_classification_model()\n",
        "\n",
        "    # Train the model on the data\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=len(X_train) // 32,\n",
        "        validation_data=val_generator,\n",
        "        validation_steps=len(X_val) // 32,\n",
        "        epochs=50\n",
        "    )\n",
        "\n",
        "    # Save the trained model\n",
        "    model_save_path = os.path.join('models', f\"{class_name}_binary_model.h5\")\n",
        "    os.makedirs('models', exist_ok=True)\n",
        "    model.save(model_save_path)\n",
        "\n",
        "    print(f\"Finished training for class: {class_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elAIW7eqzQRH",
        "outputId": "a14f9234-f2e7-473a-9aea-3ac61aca9a2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huLqmSY8bndD",
        "outputId": "c7f06238-866a-44ea-ae3a-b6d121118b20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extraction Completed\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to the zip file\n",
        "zip_path = '/content/test.zip'\n",
        "\n",
        "# Extract to a folder named 'test_data'\n",
        "extract_folder = '/content/test_data'\n",
        "\n",
        "# Create directory if it doesn't exist\n",
        "os.makedirs(extract_folder, exist_ok=True)\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_folder)\n",
        "\n",
        "print(\"Extraction Completed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zL6GuFCjeVxA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import classification_report, confusion_matrix, average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw, ImageFont\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hpk3Xf4me421"
      },
      "outputs": [],
      "source": [
        "# Paths to models and test data\n",
        "model_dir = '/content/drive/My Drive/models'\n",
        "test_data_dir = '/content/test_data/test'\n",
        "\n",
        "# Initialize ImageDataGenerator\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "def display_image_with_prediction(image_path, prediction, confidence):\n",
        "    image = Image.open(image_path)\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    try:\n",
        "        font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf\", size=20)\n",
        "    except IOError:\n",
        "        font = ImageFont.load_default()\n",
        "    text = f\"{prediction}, {confidence:.2f}\"\n",
        "    draw.text((10, 10), text, fill=\"red\", font=font)\n",
        "    display(image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_dir = '/content/drive/My Drive/models'\n",
        "test_data_dir = '/content/test_data/test'\n",
        "\n",
        "# Initialize ImageDataGenerator for preprocessing\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Store average precision scores for mAP calculation\n",
        "ap_scores = []\n",
        "\n",
        "# Loop through each model file in the models directory\n",
        "for model_file in sorted(os.listdir(model_dir)):\n",
        "    if model_file.endswith(\".h5\"):\n",
        "        print(f\"\\nLoading model {model_file}...\")\n",
        "        model_path = os.path.join(model_dir, model_file)\n",
        "        model = load_model(model_path)\n",
        "        class_name = model_file.replace(\"_binary_model.h5\", \"\")\n",
        "        print(f\"Model for class '{class_name}' loaded successfully.\")\n",
        "\n",
        "        # Create DataFrame for test data with labels as strings\n",
        "        images = []\n",
        "        labels = []\n",
        "        for folder in os.listdir(test_data_dir):\n",
        "            folder_path = os.path.join(test_data_dir, folder)\n",
        "            for image_file in os.listdir(folder_path):\n",
        "                images.append(os.path.join(folder, image_file))\n",
        "                labels.append(str(int(folder == class_name)))  # Convert boolean to int to string\n",
        "\n",
        "        test_df = pd.DataFrame({\n",
        "            'filename': images,\n",
        "            'label': labels  # Labels are now strings\n",
        "        })\n",
        "\n",
        "        # Prepare test generator\n",
        "        test_generator = test_datagen.flow_from_dataframe(\n",
        "            dataframe=test_df,\n",
        "            directory=test_data_dir,\n",
        "            x_col='filename',\n",
        "            y_col='label',\n",
        "            target_size=(224, 224),\n",
        "            batch_size=32,\n",
        "            class_mode='binary',\n",
        "            shuffle=False)\n",
        "\n",
        "        # Predict and evaluate\n",
        "        predictions = model.predict(test_generator, steps=np.ceil(len(test_df)/32))\n",
        "        predicted_labels = (predictions > 0.5).astype(int)\n",
        "        ap_score = average_precision_score(test_generator.classes, predictions)\n",
        "        ap_scores.append(ap_score)\n",
        "        print(f\"AP score for class '{class_name}': {ap_score:.3f}\")\n",
        "\n",
        "\n",
        "        # Display top 10 images based on prediction scores\n",
        "        top_indices = np.argsort(predictions[:, 0])[::-1][:10]  # Indices of top 10 predictions\n",
        "        for idx in top_indices:\n",
        "            image_path = test_df.iloc[idx]['filename']\n",
        "            actual_label = \"Positive\" if test_df.iloc[idx]['label'] == '1' else \"Negative\"\n",
        "            predicted_confidence = predictions[idx, 0]\n",
        "            display_image_with_prediction(os.path.join(test_data_dir, image_path), actual_label, predicted_confidence)\n",
        "\n",
        "\n",
        "        # Display metrics and confusion matrix\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(classification_report(test_generator.classes, predicted_labels))\n",
        "        print(\"Confusion Matrix:\")\n",
        "        print(confusion_matrix(test_generator.classes, predicted_labels))\n",
        "\n",
        "# Calculate mean Average Precision (mAP)\n",
        "mAP = np.mean(ap_scores)\n",
        "print(f\"\\nMean Average Precision (mAP) across all classes: {mAP:.3f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
